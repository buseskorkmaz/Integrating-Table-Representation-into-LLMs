<R> <C> system <C> Alchemy 3utts <C> Alchemy 5utts <C> Tangrams 3utts <C> Tangrams 5utts <C> Scene 3utts <C> Scene 5utts <R> <C> Long+16 <C> 56.8 <C> 52.3 <C> 64.9 <C> 27.6 <C> 23.2 <C> 14.7 <R> <C> REINFORCE <C> 58.3 <C> 44.6 <C> [BOLD] 68.5 <C> [BOLD] 37.3 <C> 47.8 <C> 33.9 <R> <C> BS-MML <C> 58.7 <C> 47.3 <C> 62.6 <C> 32.2 <C> 53.5 <C> 32.5 <R> <C> RandoMer <C> [BOLD] 66.9 <C> [BOLD] 52.9 <C> 65.8 <C> 37.1 <C> [BOLD] 64.8 <C> [BOLD] 46.2 <CAP> Table 2: Comparison to prior work. Long+16 results are directly from Long et al. (2016). Hyperparameters are chosen by best performance on validation set (see Appendix A).
<R> <C> random <C> beam <C> Alchemy 3utts <C> Alchemy 5utts <C> Tangrams 3utts <C> Tangrams 5utts <C> Scene 3utts <C> Scene 5utts <R> <C> [BOLD] classic beam search <C> [BOLD] classic beam search <C> [BOLD] classic beam search <C> [BOLD] classic beam search <C> [BOLD] classic beam search <C> [BOLD] classic beam search <C> [BOLD] classic beam search <C> [BOLD] classic beam search <R> <C> None <C> 32 <C> 30.3 <C> 23.2 <C> 0.0 <C> 0.0 <C> 33.4 <C> 20.1 <R> <C> None <C> 128 <C> 59.0 <C> 46.4 <C> 60.9 <C> 28.6 <C> 24.5 <C> 13.9 <R> <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <C> [BOLD] randomized beam search <R> <C> [ITALIC] ϵ=0.05 <C> 32 <C> 58.7 <C> 45.5 <C> 61.1 <C> 32.5 <C> 33.4 <C> 23.0 <R> <C> [ITALIC] ϵ=0.15 <C> 32 <C> [BOLD] 61.3 <C> 48.3 <C> [BOLD] 65.2 <C> [BOLD] 34.3 <C> 50.8 <C> 33.5 <R> <C> [ITALIC] ϵ=0.25 <C> 32 <C> 60.5 <C> [BOLD] 48.6 <C> 60.0 <C> 27.3 <C> [BOLD] 54.1 <C> [BOLD] 35.7 <CAP> Table 3: Randomized beam search. All listed models use gradient weight qMML and Tokens to represent execution history.
<R> <C> [ITALIC] q( [BOLD] z) <C> Alchemy 3utts <C> Alchemy 5utts <C> Tangrams 3utts <C> Tangrams 5utts <C> Scene 3utts <C> Scene 5utts <R> <C> [ITALIC] qRL <C> 0.2 <C> 0.0 <C> 0.9 <C> 0.6 <C> 0.0 <C> 0.0 <R> <C> [ITALIC] qMML( [ITALIC] qβ=1) <C> 61.3 <C> 48.3 <C> [BOLD] 65.2 <C> [BOLD] 34.3 <C> 50.8 <C> 33.5 <R> <C> [ITALIC] qβ=0.25 <C> [BOLD] 64.4 <C> [BOLD] 48.9 <C> 60.6 <C> 29.0 <C> 42.4 <C> 29.7 <R> <C> [ITALIC] qβ=0 <C> 63.6 <C> 46.3 <C> 54.0 <C> 23.5 <C> [BOLD] 61.0 <C> [BOLD] 42.4 <CAP> Table 4: β-meritocratic updates. All listed models use randomized beam search, ϵ=0.15 and Tokens to represent execution history.
<R> <C> Hyperparameter <C> Environments (a) <C> Environments (b) <R> <C> [ITALIC] λQ1 factor <C> 1.0 <C> 1.0 <R> <C> [ITALIC] λBC factor <C> 1.0 <C> 1.0 <R> <C> [ITALIC] λA factor <C> 1.0 <C> 1.0 <R> <C> [ITALIC] λL2 factor <C> 1.0 [ITALIC] e−5 <C> 1.0 [ITALIC] e−5 <R> <C> Batch size <C> 512 <C> 512 <R> <C> Actor learning rate <C> 1.0 [ITALIC] e−3 <C> 1.0 [ITALIC] e−3 <R> <C> Critic learning rate <C> 1.0 [ITALIC] e−4 <C> 1.0 [ITALIC] e−4 <R> <C> Memory size <C> 5.0 [ITALIC] e5 <C> 5.0 [ITALIC] e5 <R> <C> Expert trajectories <C> 20 <C> 10 <R> <C> Pre-training steps <C> 2.0 [ITALIC] e4 <C> 2.0 [ITALIC] e4 <R> <C> Training steps <C> 5.0 [ITALIC] e6 <C> 5.0 [ITALIC] e5 <R> <C> Discount factor  [ITALIC] γ <C> 0.99 <C> 0.99 <R> <C> Hidden layers <C> 3 <C> 3 <R> <C> Neurons per layer <C> 128 <C> 128 <R> <C> Activation function <C> ELU <C> ELU <CAP> Table 2: Cycle-of-Learning hyperparemeters for each environment: (a) LunarLanderContinuous-v2 and (b) Microsoft AirSim.
<R> <C> Model <C> 250 labeled 73257 unlabeled <C> 500 labeled 73257 unlabeled <C> 1000 labeled 73257 unlabeled <R> <C> Supervised <C> 40.62±0.95 <C> 22.93±0.67 <C> 15.54±0.61 <R> <C> Supervised (Mixup) <C> 33.73±1.79 <C> 21.08±0.61 <C> 13.70±0.47 <R> <C> Supervised ( Manifold Mixup) <C> 31.75±1.39 <C> 20.57±0.63 <C> 13.07±0.53 <R> <C> Π model (Laine & Aila,  2016 ) <C> 9.93±1.15 <C> 6.65±0.53 <C> 4.82±0.17 <R> <C> TempEns (Laine & Aila,  2016 ) <C> 12.62±2.91 <C> 5.12±0.13 <C> 4.42±0.16 <R> <C> MT (Tarvainen & Valpola,  2017 ) <C> 4.35±0.50 <C> 4.18±0.27 <C> 3.95±0.19 <R> <C> VAT (Miyato et al.,  2018 ) <C> – <C> – <C> 5.42±NA <R> <C> VAT+Ent (Miyato et al.,  2018 ) <C> – <C> – <C> 3.86±NA <R> <C> VAdD (Park et al.,  2018 ) <C> – <C> – <C> 4.16±0.08 <R> <C> SNTG (Luo et al.,  2018 ) <C> [BOLD] 4.29± [BOLD] 0.23 <C> [BOLD] 3.99± [BOLD] 0.24 <C> [BOLD] 3.86± [BOLD] 0.27 <R> <C> ICT <C> 4.78±0.68 <C> 4.23±0.15 <C> 3.89±0.04 <CAP> Table 2: Error rates (%) on SVHN using CNN-13 architecture. We ran three trials for ICT.
<R> <C> Models <C> Natural <C> 0.1 <C> FGSM 0.2 <C> 0.3 <C> 0.1 <C> BIM 0.2 <C> 0.3 <C> 0.1 <C> C&W 0.2 <C> 0.3 <R> <C> Natural Model <C> 99.1 <C> 67.3 <C> 12.9 <C> 4.7 <C> 22.5 <C> 0.0 <C> 0.0 <C> 21.6 <C> 0.0 <C> 0.0 <R> <C> AdvTrain <C> 99.1 <C> 73.0 <C> 52.7 <C> 10.9 <C> 62.0 <C> 6.5 <C> 0.0 <C> 71.09 <C> 17.0 <C> 2.1 <R> <C> CrossEntropy <C> 99.2 <C> 91.6 <C> 60.4 <C> 18.3 <C> 87.9 <C> 19.9 <C> 0.0 <C> 88.09 <C> 20.0 <C> 0.0 <R> <C> Ours <C> 98.4 <C> 91.6 <C> 70.3 <C> 41.6 <C> 88.1 <C> 64.9 <C> 26.7 <C> 89.2 <C> 72.6 <C> 37.6 <CAP> Table 1: Test Accuracy of adversarial examples on MNIST dataset (%)
<R> <C> Models <C> Natural <C> 3 <C> FGSM 6 <C> 9 <C> 3 <C> BIM 6 <C> 9 <C> 3 <C> C&W 6 <C> 9 <R> <C> Natural Model <C> 87.2 <C> 5.8 <C> 2.4 <C> 1.6 <C> 0.7 <C> 0.0 <C> 0.0 <C> 0.6 <C> 0.0 <C> 0.0 <R> <C> AdvTrain* <C> 84.5 <C> 10.2 <C> 5.8 <C> 2.6 <C> 1.4 <C> 0.0 <C> 0.0 <C> 0.0 <C> 0.0 <C> 0.0 <R> <C> CrossEntropy* <C> 86.2 <C> 19.1 <C> 9.5 <C> 6.1 <C> 2.6 <C> 0.7 <C> 0.4 <C> 2.1 <C> 1.5 <C> 1.4 <R> <C> Ours <C> 84.2 <C> 59.8 <C> 41.9 <C> 31.0 <C> 54.6 <C> 29.5 <C> 20.3 <C> 53.7 <C> 29.8 <C> 20.1 <R> <C> Ours+AdvTrain <C> 83.1 <C> 68.5 <C> 48.5 <C> 38.2 <C> 62.7 <C> 39.3 <C> 30.3 <C> 60.5 <C> 39.0 <C> 30.3 <R> <C> MinMax* <C> 79.4 <C> 65.8 <C> 55.6 <C> 47.4 <C> 64.2 <C> 49.3 <C> 41.1 <C> 62.9 <C> 48.5 <C> 40.7 <CAP> Table 2: Test Accuracy of adversarial examples on CIFAR10 dataset (%)
<R> <C> [BOLD] Sample number <C> 1 <C> 2 <C> 3 <R> <C> Δ [ITALIC] J <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> IP <C> 0.91 <C> 0.88 <C> 0.72 <R> <C> Bethe <C> 0.57 <C> 0.58 <C> 0.60 <R> <C> SM <C> 1.23 <C> 1.17 <C> 1.19 <R> <C> TRW <C> 0.40 <C> 0.39 <C> 0.49 <CAP> TABLE I: Distances of inferred interaction matrices from gradient ascent results
<R> <C> Data sets <C> Nodes <C> Training <C> Testing <C> Bits <C> Accuracy <C> Time <R> <C> [ITALIC] USPS <C> 2 <C> 7291 <C> 2007 <C> 5 <C> 0.916 <C> 45.82  [ITALIC] secs <R> <C> [ITALIC] USPS <C> 2 <C> 7291 <C> 2007 <C> 25 <C> 0.936 <C> 227.17  [ITALIC] secs / 3.78  [ITALIC] mins <R> <C> [ITALIC] USPS <C> 2 <C> 7291 <C> 2007 <C> 45 <C> 0.941 <C> 408.66  [ITALIC] secs / 6.90  [ITALIC] mins <R> <C> [ITALIC] Mnist <C> 2 <C> 60 [ITALIC] K <C> 10 [ITALIC] K <C> 5 <C> 0.826 <C> 1690.46  [ITALIC] secs / 28.17  [ITALIC] mins <R> <C> [ITALIC] Mnist <C> 2 <C> 60 [ITALIC] K <C> 10 [ITALIC] K <C> 25 <C> 0.960 <C> 8406.04  [ITALIC] secs / 140.08  [ITALIC] mins / 2.33  [ITALIC] hours <R> <C> [ITALIC] Mnist <C> 2 <C> 60 [ITALIC] K <C> 10 [ITALIC] K <C> 45 <C> 0.969 <C> 4253.28  [ITALIC] secs / 251.85  [ITALIC] mins / 4.20  [ITALIC] hours <R> <C> [ITALIC] Mnist <C> 10 <C> 60 [ITALIC] K <C> 10 [ITALIC] K <C> 5 <C> 0.839 <C> 487.88  [ITALIC] secs / 8.13  [ITALIC] mins <R> <C> [ITALIC] Mnist <C> 10 <C> 60 [ITALIC] K <C> 10 [ITALIC] K <C> 25 <C> 0.962 <C> 2361.07  [ITALIC] secs / 39.35  [ITALIC] mins <R> <C> [ITALIC] Mnist <C> 10 <C> 60 [ITALIC] K <C> 10 [ITALIC] K <C> 45 <C> 0.964 <C> 4253.28  [ITALIC] secs / 70.89  [ITALIC] mins / 1.18  [ITALIC] hours <R> <C> [ITALIC] Mnist1M <C> 10 <C> 1 [ITALIC] M <C> 100 [ITALIC] K <C> 5 <C> 0.824 <C> 7918.38  [ITALIC] secs / 131.97  [ITALIC] mins / 2.20  [ITALIC] hours <R> <C> [ITALIC] Mnist1M <C> 10 <C> 1 [ITALIC] M <C> 100 [ITALIC] K <C> 25 <C> 0.927 <C> 28066.37  [ITALIC] secs / 467.77  [ITALIC] mins / 7.80  [ITALIC] hours <R> <C> [ITALIC] Mnist1M <C> 10 <C> 1 [ITALIC] M <C> 100 [ITALIC] K <C> 45 <C> 0.934665 <C> 48574.96  [ITALIC] secs / 809.58  [ITALIC] mins / 13.49  [ITALIC] hours <CAP> TABLE I: Top-10 retrieval results and running time for *SHL for various data sets. Here, running time secs means seconds, mins means minutes and hours means hours.
<R> <C> Model <C> SVQA <C> TGIF-QA (*) Action <C> TGIF-QA (*) Trans. <C> TGIF-QA (*) Frame <C> TGIF-QA (*) Count <R> <C> Linguistic only <C> 42.6 <C> 51.5 <C> 52.8 <C> 46.0 <C> 4.77 <R> <C> Ling.+S.Frame <C> 44.6 <C> 51.3 <C> 53.4 <C> 50.4 <C> 4.63 <R> <C> S.Frame+MAC <C> 58.1 <C> 67.8 <C> 76.1 <C> 57.1 <C> 4.41 <R> <C> Avg.Pool+MAC <C> 67.4 <C> 70.1 <C> 77.7 <C> 58.0 <C> 4.31 <R> <C> TRN+MAC <C> 70.8 <C> 69.0 <C> 78.4 <C> 58.7 <C> 4.33 <R> <C> CRN+MLP <C> 49.3 <C> 51.5 <C> 53.0 <C> 53.5 <C> 4.53 <R> <C> [BOLD] CRN+MAC <C> [BOLD] 75.8 <C> [BOLD] 71.3 <C> [BOLD] 78.7 <C> [BOLD] 59.2 <C> [BOLD] 4.23 <CAP> Table 1: Ablation studies. (*) For count, the lower the better.
<R> <C> [EMPTY] <C> Exist <C> Count <C> Integer Comparison More <C> Integer Comparison Equal <C> Integer Comparison Less <C> Attribute Comparison Color <C> Attribute Comparison Size <C> Attribute Comparison Type <C> Attribute Comparison Dir <C> Attribute Comparison Shape <C> Query Color <C> Query Size <C> Query Type <C> Query Dir <C> Query Shape <C> All <R> <C> SA(S)  <C> 51.7 <C> 36.3 <C> 72.7 <C> 54.8 <C> 58.6 <C> 52.2 <C> 53.6 <C> 52.7 <C> 53.0 <C> 52.3 <C> 29.0 <C> 54.0 <C> 55.7 <C> 38.1 <C> 46.3 <C> 43.1 <R> <C> TA-GRU(T)  <C> 54.6 <C> 36.6 <C> 73.0 <C> 57.3 <C> 57.7 <C> 53.8 <C> 53.4 <C> 54.8 <C> 55.1 <C> 52.4 <C> 22.0 <C> 54.8 <C> 55.5 <C> 41.7 <C> 42.9 <C> 44.2 <R> <C> SA+TA-GRU  <C> 52.0 <C> 38.2 <C> 74.3 <C> 57.7 <C> 61.6 <C> 56.0 <C> 55.9 <C> 53.4 <C> 57.5 <C> 53.0 <C> 23.4 <C> 63.3 <C> 62.9 <C> 43.2 <C> 41.7 <C> 44.9 <R> <C> [BOLD] CRN+MAC <C> [BOLD] 72.8 <C> [BOLD] 56.7 <C> [BOLD] 84.5 <C> [BOLD] 71.7 <C> [BOLD] 75.9 <C> [BOLD] 70.5 <C> [BOLD] 76.2 <C> [BOLD] 90.7 <C> [BOLD] 75.9 <C> [BOLD] 57.2 <C> [BOLD] 76.1 <C> [BOLD] 92.8 <C> [BOLD] 91.0 <C> [BOLD] 87.4 <C> [BOLD] 85.4 <C> [BOLD] 75.8 <CAP> Table 3: Comparison with the state-of-the-art method on SVQA.
<R> <C> Model <C> Action <C> Trans. <C> Frame <C> Count <R> <C> VIS+LSTM (aggr) <C> 46.8 <C> 56.9 <C> 34.6 <C> 5.09 <R> <C> VIS+LSTM (avg) <C> 48.8 <C> 34.8 <C> 35.0 <C> 4.80 <R> <C> VQA-MCB (aggr) <C> 58.9 <C> 24.3 <C> 25.7 <C> 5.17 <R> <C> VQA-MCB (avg) <C> 29.1 <C> 33.0 <C> 15.5 <C> 5.54 <R> <C> Yu et al. <C> 56.1 <C> 64.0 <C> 39.6 <C> 5.13 <R> <C> ST(R+C) <C> 60.1 <C> 65.7 <C> 48.2 <C> 4.38 <R> <C> ST-SP(R+C) <C> 57.3 <C> 63.7 <C> 45.5 <C> 4.28 <R> <C> ST-SP-TP(R+C) <C> 57.0 <C> 59.6 <C> 47.8 <C> 4.56 <R> <C> ST-TP(R+C) <C> 60.8 <C> 67.1 <C> 49.3 <C> 4.40 <R> <C> ST-TP(R+F) <C> 62.9 <C> 69.4 <C> 49.5 <C> 4.32 <R> <C> Co-memory(R+F) <C> 68.2 <C> 74.3 <C> 51.5 <C> [BOLD] 4.10 <R> <C> PSAC(R) <C> 70.4 <C> 76.9 <C> 55.7 <C> 4.27 <R> <C> [BOLD] CRN+MAC(R) <C> [BOLD] 71.3 <C> [BOLD] 78.7 <C> [BOLD] 59.2 <C> 4.23 <CAP> Table 4: Comparison with the state-of-the-art method on TGIF-QA dataset. For count, the lower the better. R: ResNet, C: C3D features, F: flow features.
<R> <C> Methods <C> MAML <C> MR-MAML (A) (ours) <C> MR-MAML (W) (ours) <C> CNP <C> MR-CNP (A) (ours) <C> MR-CNP (W) (ours) <R> <C> 5 shot <C> 0.46 (0.04) <C> [BOLD] 0.17 (0.03) <C> [BOLD] 0.16 (0.04)  <C> 0.91 (0.10) <C> [BOLD] 0.10 (0.01) <C> [BOLD] 0.11 (0.02) <R> <C> 10 shot <C> 0.13 (0.01) <C> [BOLD] 0.07 (0.02) <C> [BOLD] 0.06 (0.01) <C> 0.92 (0.05) <C> [BOLD] 0.09 (0.01) <C> [BOLD] 0.09 (0.01) <CAP> Table 1: Test MSE for the non-mutually-exclusive sinusoid regression problem. We compare MAML and CNP against meta-regularized MAML (MR-MAML) and meta-regularized CNP (MR-CNP) where regularization is either on the activations (A) or the weights (W). We report the mean over 5 trials and the standard deviation in parentheses.
<R> <C> Method <C> MAML <C> MR-MAML (W) (ours) <C> CNP <C> MR-CNP (W) (ours) <C> FT <C> FT + Weight Decay <R> <C> MSE <C> 5.39 (1.31) <C> [BOLD] 2.26 (0.09) <C> 8.48 (0.12) <C> 2.89 (0.18) <C> 7.33 (0.35) <C> 6.16 (0.12) <CAP> Table 2: Meta-test MSE for the pose prediction problem. We compare MR-MAML (ours) with conventional MAML and fine-tuning (FT). We report the average over 5 trials and standard deviation in parentheses.
<R> <C> [ITALIC] NME Omniglot <C> 20-way 1-shot <C> 20-way 5-shot <R> <C> MAML <C> 7.8 (0.2)% <C> 50.7 (22.9)% <R> <C> TAML (Jamal & Qi,  2019 ) <C> 9.6 (2.3)% <C> 67.9 (2.3)% <R> <C> MR-MAML (W) (ours) <C> [BOLD] 83.3 (0.8)% <C> [BOLD] 94.1 (0.1)% <CAP> Table 4: Meta-test accuracy on non-mutually-exclusive (NME) classification. The fine-tuning and nearest-neighbor baseline results for MiniImagenet are from (Ravi & Larochelle, 2016).
<R> <C> [ITALIC] NME MiniImagenet <C> 5-way 1-shot <C> 5-way 5-shot <R> <C> Fine-tuning <C> 28.9 (0.5))% <C> 49.8 (0.8))% <R> <C> Nearest-neighbor <C> 41.1 (0.7)% <C> 51.0 (0.7) % <R> <C> MAML <C> 26.3 (0.7)% <C> 41.6 (2.6)% <R> <C> TAML (Jamal & Qi,  2019 ) <C> 26.1 (0.6)% <C> 44.2 (1.7)% <R> <C> MR-MAML (W) (ours) <C> [BOLD] 43.6 (0.6)% <C> [BOLD] 53.8 (0.9)% <CAP> Table 4.2: Meta-test accuracy on non-mutually-exclusive (NME) classification. The fine-tuning and nearest-neighbor baseline results for MiniImagenet are from (Ravi & Larochelle, 2016).
<R> <C> Method <C> Average error rate Food-101N <C> Average error rate Clothing-1M <R> <C> Supervised <C> Supervised <C> Supervised <R> <C> MLP <C> 10.42 <C> 16.09 <R> <C> Label Prop  <C> 13.24 <C> 17.81 <R> <C> Label Spread  <C> 12.03 <C> 17.71 <R> <C> CleanNet  <C> 6.99 <C> 15.77 <R> <C> Weakly-Supervised <C> Weakly-Supervised <C> Weakly-Supervised <R> <C> Cls. Filt. <C> 16.60 <C> 23.55 <R> <C> Avg. Base.  <C> 16.20 <C> 30.56 <R> <C> Unsupervised <C> Unsupervised <C> Unsupervised <R> <C> DRAE  <C> 18.70 <C> 38.95 <R> <C> unsup-kNN <C> 26.63 <C> 43.31 <R> <C> NoiseRank <C> 24.02 <C> 23.54 <R> <C> [BOLD] NoiseRank (I) <C> [BOLD] 18.43 <C> [BOLD] 22.81 <CAP> Table 2: Label noise detection accuracy. Left: average error rate over all the classes (%) Right: Label noise recall, F1 and macro-F1 (%). NoiseRank(I) is iterative NoiseRank
<R> <C> Method <C> Type <C> Recall <C> F1 <C> MacroF1 <R> <C> Food-101N (19.66% estimated noise) <C> Food-101N (19.66% estimated noise) <C> Food-101N (19.66% estimated noise) <C> Food-101N (19.66% estimated noise) <C> Food-101N (19.66% estimated noise) <R> <C> CleanNet <C> sup. <C> 71.06 <C> [BOLD] 74.01 <C> [BOLD] 84.04 <R> <C> Avg. Base. <C> weakly <C> 47.70 <C> 59.57 <C> 76.08 <R> <C> unsup-kNN <C> unsup. <C> 22.02 <C> 24.23 <C> 54.03 <R> <C> NoiseRank (I) <C> unsup. <C> [BOLD] 85.61 <C> 64.42 <C> 76.06 <R> <C> Clothing-1M (38.46% estimated noise) <C> Clothing-1M (38.46% estimated noise) <C> Clothing-1M (38.46% estimated noise) <C> Clothing-1M (38.46% estimated noise) <C> Clothing-1M (38.46% estimated noise) <R> <C> CleanNet <C> sup. <C> 69.40 <C> [BOLD] 73.99 <C> [BOLD] 79.65 <R> <C> Avg. Base. <C> weakly <C> 43.92 <C> 55.14 <C> 67.65 <R> <C> unsup-kNN <C> unsup. <C> 10.85 <C> 16.60 <C> 44.26 <R> <C> NoiseRank (I) <C> unsup. <C> [BOLD] 74.18 <C> 71.74 <C> 76.52 <CAP> Table 2: Label noise detection accuracy. Left: average error rate over all the classes (%) Right: Label noise recall, F1 and macro-F1 (%). NoiseRank(I) is iterative NoiseRank
<R> <C> [BOLD] # <C> Method <C> Training <C> Pre-training <C> Top-1 <R> <C> 1 <C> None  <C> noisy train <C> ImageNet <C> 81.44 <R> <C> 2 <C> CleanNet  <C> noisy(+verified) <C> ImageNet <C> 83.95 <R> <C> 3 <C> DeepSelf  <C> noisy train <C> ImageNet <C> 85.11 <R> <C> 4 <C> NoiseRank <C> cleaned train <C> ImageNet <C> 85.20 <R> <C> 5 <C> [EMPTY] <C> cleaned train <C> noisy train #1 <C> [BOLD] 85.78 <CAP> Table 3: Image classification on Food-101N results in terms of top-1 accuracy (%). Train data (310k) and test data (25k). CleanNet is trained with an additional 55k/5k (tr/va) verification labels to provide the required supervision on noise detection
<R> <C> # <C> Method <C> Training <C> Pre-training <C> Top-1 <R> <C> 1 <C> None  <C> clean50k <C> ImageNet <C> 75.19 <R> <C> 2 <C> None  <C> noisy train <C> ImageNet <C> 68.94 <R> <C> 3 <C> [EMPTY] <C> clean50k <C> noisy train # 2 <C> 79.43 <R> <C> 4 <C> loss cor. <C> noisy(+verified) <C> ImageNet <C> 69.84 <R> <C> 5 <C> [EMPTY] <C> clean50k <C> # 4 <C> 80.38 <R> <C> 6 <C> Joint opt.  <C> noisy train <C> ImageNet <C> 72.16 <R> <C> 7 <C> PENCIL  <C> noisy train <C> ImageNet <C> 73.49 <R> <C> 8 <C> CleanNet  <C> noisy(+verified) <C> ImageNet <C> 74.69 <R> <C> 9 <C> [EMPTY] <C> clean50k <C> # 8 <C> 79.90 <R> <C> 10 <C> DeepSelf  <C> noisy train <C> ImageNet <C> 74.45 <R> <C> 11 <C> [EMPTY] <C> clean50k <C> # 10 <C> [BOLD] 81.16 <R> <C> 12 <C> [EMPTY] <C> cleaned train <C> ImageNet <C> 73.77 <R> <C> 13 <C> NoiseRank <C> cleaned train <C> noisy train #2 <C> 73.82 <R> <C> 14 <C> [EMPTY] <C> clean50k <C> # 13 <C> 79.57 <CAP> Table 4: Image classification on Clothing-1M results in terms of top-1 accuracy (%). Train data (1M) and test data (10k). CleanNet and Loss Correction are trained with an additional 25k/7k (train/validation) verification labels to provide required supervision on noise detection/correction
<R> <C> Layer Name <C> conv1_1 <C> conv1_2 <C> pool1 <C> conv2_1 <C> conv2_2 <C> pool2 <C> conv3_1 <C> conv3_2 <C> conv3_3 <C> pool3 <R> <C> #Neuron <C> 64 <C> 64 <C> 64 <C> 128 <C> 128 <C> 128 <C> 256 <C> 256 <C> 256 <C> 256 <R> <C> #Left Eye <C> 1 <C> - <C> - <C> - <C> 2 <C> 3 <C> 4 <C> 2 <C> 3 <C> 2 <R> <C> #Right Eye <C> 1 <C> - <C> - <C> - <C> 3 <C> 3 <C> 4 <C> 3 <C> 2 <C> 3 <R> <C> #Nose <C> 1 <C> - <C> - <C> - <C> 1 <C> 3 <C> 2 <C> - <C> 1 <C> 3 <R> <C> #Mouth <C> 1 <C> - <C> - <C> - <C> 3 <C> 2 <C> 4 <C> 3 <C> 15 <C> 7 <R> <C> #Left Eye & Right Eye <C> 1 <C> - <C> - <C> - <C> 2 <C> 3 <C> 3 <C> 1 <C> - <C> - <R> <C> #Left Eye & Nose <C> 1 <C> - <C> - <C> - <C> 1 <C> 3 <C> 2 <C> - <C> - <C> - <R> <C> #Left Eye & Mouth <C> 1 <C> - <C> - <C> - <C> 2 <C> 1 <C> 2 <C> 1 <C> 1 <C> - <R> <C> #Right Eye & Nose <C> 1 <C> - <C> - <C> - <C> 1 <C> 3 <C> 1 <C> - <C> - <C> - <R> <C> #Right Eye & Mouth <C> 1 <C> - <C> - <C> - <C> 3 <C> 1 <C> 2 <C> 2 <C> 1 <C> 1 <R> <C> #Nose & Mouth <C> 1 <C> - <C> - <C> - <C> 1 <C> 1 <C> 1 <C> - <C> - <C> - <R> <C> #Shared <C> 1 <C> - <C> - <C> - <C> 1 <C> 1 <C> 1 <C> - <C> - <C> - <R> <C> Layer Name <C> conv4_1 <C> conv4_2 <C> conv4_3 <C> pool4 <C> conv5_1 <C> conv5_2 <C> conv5_3 <C> pool5 <C> fc6 <C> fc7 <R> <C> #Neuron <C> 512 <C> 512 <C> 512 <C> 512 <C> 512 <C> 512 <C> 512 <C> 512 <C> 4096 <C> 4096 <R> <C> #Left Eye <C> 9 <C> 5 <C> 15 <C> 7 <C> 12 <C> 4 <C> 1 <C> 1 <C> - <C> 1 <R> <C> #Right Eye <C> 7 <C> 3 <C> 10 <C> 9 <C> 9 <C> 1 <C> - <C> - <C> - <C> - <R> <C> #Nose <C> 10 <C> 8 <C> 17 <C> 13 <C> 7 <C> 2 <C> 2 <C> 1 <C> - <C> 1 <R> <C> #Mouth <C> 19 <C> 12 <C> 12 <C> 11 <C> 8 <C> 2 <C> 1 <C> 2 <C> 1 <C> 1 <R> <C> #Left Eye & Right Eye <C> 5 <C> 1 <C> 3 <C> 4 <C> 2 <C> - <C> - <C> - <C> - <C> - <R> <C> #Left Eye & Nose <C> 3 <C> - <C> 4 <C> - <C> 1 <C> - <C> - <C> - <C> - <C> - <R> <C> #Left Eye & Mouth <C> 1 <C> 1 <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> - <R> <C> #Right Eye & Nose <C> 3 <C> - <C> 1 <C> 1 <C> 1 <C> - <C> - <C> - <C> - <C> - <R> <C> #Right Eye & Mouth <C> 2 <C> - <C> 2 <C> - <C> - <C> - <C> - <C> - <C> - <C> - <R> <C> #Nose & Mouth <C> 5 <C> 1 <C> 2 <C> 2 <C> - <C> - <C> - <C> - <C> - <C> - <R> <C> #Shared <C> 1 <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> - <CAP> Table 1: Number of extracted attribute witnesses in VGG-Face. The first row lists the layers used in VGG-Face. The second row shows the number of neurons at each layer. The following four rows present the number of extracted witnesses for individual attributes. The following six rows denote the pairwise overlap of witnesses between different attributes. The bottom row shows the number of neurons shared by the witness sets of different attributes.
<R> <C> Metric <C> [BOLD] Detectron <C> [BOLD] Ours <R> <C> AP <C> 0.4759 <C> [BOLD] 0.477 <R> <C> AP50 <C> 0.7687 <C> [BOLD] 0.7696 <R> <C> AP75 <C> 0.539 <C> [BOLD] 0.541 <R> <C> APm <C> 0.4173 <C> [BOLD] 0.42 <R> <C> APl <C> 0.4973 <C> [BOLD] 0.4989 <CAP> Table 2. Results on the MPII validation dataset
<R> <C> Metric <C> [BOLD] Detectron <C> [BOLD] PAF test-dev <C> [BOLD] PAF test-challenge <C> [BOLD] Ours <R> <C> AP <C> 0.6423 <C> 0.618 <C> 0.605 <C> [BOLD] 0.6465 <R> <C> AP50 <C> 0.8643 <C> 0.849 <C> 0.834 <C> [BOLD] 0.8677 <R> <C> AP75 <C> 0.6992 <C> 0.675 <C> 0.664 <C> [BOLD] 0.7044 <R> <C> APm <C> 0.5854 <C> 0.571 <C> 0.551 <C> [BOLD] 0.5904 <R> <C> APl <C> 0.7339 <C> 0.682 <C> 0.681 <C> [BOLD] 0.7361 <CAP> Table 1: Results on the COCO keypoints 2017 validation and test datasets
<R> <C> [EMPTY] <C> Action Set 6 <C> Action Set 8 <C> Action Set 20 <C> Action Set 27 <C> Action Set 54 <R> <C> Limit Jump Actions <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> [EMPTY] <R> <C> Limit Backward Actions <C> ✓ <C> ✓ <C> ✓ <C> [EMPTY] <C> [EMPTY] <R> <C> Limit Forward Actions <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> [BOLD] Ave Floor <C> 3 <C> [BOLD] 5 <C> [BOLD] 5 <C> [BOLD] 5 <C> 3 <CAP> Table 5: Comparison of action sets and their impact on the maximum floor reached after 10m steps.
<R> <C> Dataset Attribute <C> VF Parkhi et al. ( 2015 ) Left Eye <C> VF Parkhi et al. ( 2015 ) Right Eye <C> VF Parkhi et al. ( 2015 ) Nose <C> VF Parkhi et al. ( 2015 ) Mouth <C> LFW Huang et al. ( 2007 ) Left Eye <C> LFW Huang et al. ( 2007 ) Right Eye <C> LFW Huang et al. ( 2007 ) Nose <C> LFW Huang et al. ( 2007 ) Mouth <R> <C> Face Descriptor <C> 0.830 <C> 0.830 <C> 0.955 <C> 0.855 <C> 0.825 <C> 0.835 <C> 0.915 <C> 0.935 <R> <C> Attribute Witness <C> 0.940 <C> 0.935 <C> 0.985 <C> 0.990 <C> 0.870 <C> 0.845 <C> 0.975 <C> 0.965 <CAP> Table 2: Accuracy of attribute detection. Attribute detection using extracted witnesses versus using an existing layer in VGG-Face called face descriptor (i.e., the fc7 layer), whose neurons are considered representing abstract features of human faces Parkhi et al. (2015).
<R> <C> [EMPTY] <C> Numenta_Standard <C> F1_T_Front_Flat <C> F1_T_Back_Flat <R> <C> Front-Predicted <C> 0.67 <C> 0.42 <C> 0.11 <R> <C> Back-Predicted <C> 0.63 <C> 0.11 <C> 0.42 <CAP> Table 2: Sensitivity to positional bias
<R> <C> Algorithm <C> Kosarak <C> MSNBC <C> BMS2 <C> BMS1 <C> Kosarak(small) <R> <C> MPP1 <C> 47 <C> 45 <C> 2 <C> - <C> - <R> <C> MPP2 <C> 106 <C> 103 <C> 4 <C> - <C> - <R> <C> MPP3 <C> 151 <C> 158 <C> 5 <C> - <C> - <R> <C> MPP <C> - <C> - <C> 2 <C> 0.5 <C> 4 <CAP> Table 4: Time (in seconds) required for MDD construction and information generation.
<R> <C> RiverSwim <C> E3 3.0 <C> R-Max 3.0 <C> MBIE 3.3 <C> ESSR 3.1 <C> ESSR (0.06) <R> <C> [0.5pt/2pt] SixArms <C> 1.8 <C> 2.8 <C> 9.3 <C> 7.3 <C> (1.2) <CAP> Table 2: Comparison between ESSR, R-Max, E3, and MBIE. The numbers reported for R-Max, E3, and MBIE were extracted from the histograms presented by Strehl08 (Strehl08). ESSR’s performance is the average over 100 runs. A 95% confidence interval is reported between parentheses. All numbers are reported in millions (i.e., ×106).
<R> <C> Freeway <C> DQN 32.4 <C> DQN (0.3) <C> DQNMMC [ITALIC] e 29.5 <C> DQNMMC [ITALIC] e (0.1) <C> DQNMMC\scriptsize{CTS} 29.2 <C> DQNMMC\scriptsize{PixelCNN} 29.4 <C> RND - <C> RND - <C> DQNMMC [ITALIC] e+SR 29.4 <C> DQNMMC [ITALIC] e+SR (0.1) <R> <C> [0.5pt/2pt] Gravitar <C> 118.5 <C> (22.0) <C> 1078.3 <C> (254.1) <C> 199.8 <C> 275.4 <C> 790.0 <C> (122.9) <C> 457.4 <C> (120.3) <R> <C> [0.5pt/2pt] Mont. Rev. <C> 0.0 <C> (0.0) <C> 0.0 <C> (0.0) <C> 2941.9 <C> 1671.7 <C> 524.8 <C> (314.0) <C> 1395.4 <C> (1121.8) <R> <C> [0.5pt/2pt] Private Eye <C> 1447.4 <C> (2,567.9) <C> 113.4 <C> (42.3) <C> 32.8 <C> 14386.0 <C> 61.3 <C> (53.7) <C> 104.4 <C> (50.4) <R> <C> [0.5pt/2pt] Solaris <C> 783.4 <C> (55.3) <C> 2244.6 <C> (378.8) <C> 1147.1 <C> 2279.4 <C> 1270.3 <C> (291.0) <C> 1890.1 <C> (163.1) <R> <C> [0.5pt/2pt] Venture <C> 4.4 <C> (5.4) <C> 1220.1 <C> (51.0) <C> 0.0 <C> 856.2 <C> 953.7 <C> (167.3) <C> 1348.5 <C> (56.5) <CAP> Table 3: Performance of the proposed algorithm, DQNMMCe+SR, compared to various agents on the “hard exploration” subset of Atari 2600 games. The DQN results reported are from Machado18a (Machado18a) while the DQNMMC\scriptsize{CTS}, DQNMMC\scriptsize{PixelCNN} and RND results were obtained through personal communication with the authors of the corresponding papers. Burda19 did not evaluate RND in Freeway. When available, standard deviation is reported between parentheses. See text for details.
<R> <C> RiverSwim <C> Sarsa 24,770 <C> Sarsa (196) <C> Sarsa + SR 1,213,544 <C> Sarsa + SR (540,454) <R> <C> [0.5pt/2pt] SixArms <C> 247,977 <C> (4,970) <C> 1,052,934 <C> (2,311,617) <CAP> Table 1: Comparison between Sarsa and Sarsa+SR. A 95% confidence interval is reported between parentheses.
<R> <C> RiverSwim <C> ℓ1-norm 1,213,544 <C> ℓ1-norm (540,454) <C> ℓ2-norm 1,192,052 <C> ℓ2-norm (507,179) <R> <C> [0.5pt/2pt] SixArms <C> 1,052,934 <C> (2,311,617) <C> 819,927 <C> (2,132,003) <CAP> Table 5: Performance of Sarsa+SR when using the ℓ1-norm and ℓ2-norm of the SR to generate the exploration bonus. A 95% confidence interval is reported between parentheses.
<R> <C> Detector <C> FP <C> Targeted Patch <C> Targeted Patch <C> Targeted Glasses <C> Targeted Glasses <C> Targeted C&W0 <C> Targeted C&W0 <C> Targeted C&W2 <C> Targeted C&W2 <C> Targeted C&W∞ <C> Targeted C&W∞ <C> Untargeted FGSM <C> Untargeted BIM <R> <C> Detector <C> FP <C> First <C> Next <C> First <C> Next <C> First <C> Next <C> First <C> Next <C> First <C> Next <C> FGSM <C> BIM <R> <C> FS Xu et al. ( 2018 ) <C> 23.32% <C> 0.77 <C> 0.71 <C> 0.73 <C> 0.58 <C> 0.68 <C> 0.65 <C> 0.60 <C> 0.50 <C> 0.42 <C> 0.37 <C> 0.36 <C> 0.20 <R> <C> AS <C> 20.41% <C> 0.96 <C> 0.98 <C> 0.97 <C> 0.97 <C> 0.93 <C> 0.99 <C> 0.99 <C> 1.00 <C> 0.96 <C> 1.00 <C> 0.85 <C> 0.76 <R> <C> AP <C> 30.61% <C> 0.89 <C> 0.96 <C> 0.69 <C> 0.75 <C> 0.96 <C> 0.94 <C> 0.99 <C> 0.97 <C> 0.95 <C> 0.99 <C> 0.87 <C> 0.89 <R> <C> WKN <C> 7.87% <C> 0.94 <C> 0.97 <C> 0.71 <C> 0.76 <C> 0.83 <C> 0.89 <C> 0.99 <C> 0.97 <C> 0.97 <C> 0.96 <C> 0.86 <C> 0.87 <R> <C> STN <C> 2.33% <C> 0.08 <C> 0.19 <C> 0.16 <C> 0.19 <C> 0.90 <C> 0.94 <C> 0.97 <C> 1.00 <C> 0.76 <C> 0.87 <C> 0.46 <C> 0.41 <R> <C> AmI <C> 9.91% <C> 0.97 <C> 0.98 <C> 0.85 <C> 0.85 <C> 0.91 <C> 0.95 <C> 0.99 <C> 0.99 <C> 0.97 <C> 1.00 <C> 0.91 <C> 0.90 <R> <C> w/o Left Eye <C> 18.37% <C> 0.97 <C> 0.99 <C> 0.75 <C> 0.79 <C> 0.88 <C> 0.92 <C> 0.99 <C> 0.95 <C> 0.97 <C> 0.98 <C> 0.89 <C> 0.90 <R> <C> w/o Right Eeye <C> 18.08% <C> 0.93 <C> 0.96 <C> 0.73 <C> 0.80 <C> 0.86 <C> 0.91 <C> 0.99 <C> 0.96 <C> 0.98 <C> 0.98 <C> 0.86 <C> 0.87 <R> <C> w/o Nose <C> 27.41% <C> 0.97 <C> 0.99 <C> 0.78 <C> 0.84 <C> 0.91 <C> 0.94 <C> 0.98 <C> 0.97 <C> 0.99 <C> 0.98 <C> 0.94 <C> 0.90 <R> <C> w/o Mouth <C> 20.99% <C> 0.91 <C> 0.97 <C> 0.74 <C> 0.79 <C> 0.86 <C> 0.95 <C> 1.00 <C> 0.95 <C> 0.99 <C> 0.98 <C> 0.86 <C> 0.87 <CAP> Table 3: Detecting adversarial samples. We have two settings for targeted attacks. ‘First’ denotes that the first label is the target whereas ‘Next’ denotes the next label of the correct label is the target. FS stands feature squeezing; AS attribute substitution only; AP attribute preservation only; WKN non-witness weakening only; STN witness strengthening only; and AmI our final result. The bottom four rows denote detection accuracy of AmI using witnesses excluding some certain attribute (e.g., w/o Nose).
<R> <C> Dataset <C> Local ELM testing error <C> Local ELM running time <C> MTFL testing error <C> MTFL running time <C> GO-MTL testing error <C> GO-MTL running time <C> MTL-ELM testing error <C> MTL-ELM running time <C> DGSP testing error <C> DGSP running time <C> DNSP testing error <C> DNSP running time <C> DMTL-ELM testing error <C> DMTL-ELM running time <C> FO-DMTL-ELM testing error <C> FO-DMTL-ELM running time <R> <C> USPS <C> 4.26 <C> 0.009 <C> 4.67 <C> 0.10 <C> 6.30 <C> 7.52 <C> [BOLD] 3.49 <C> 226.1 <C> 5.05 <C> 0.03 <C> 4.47 <C> 0.04 <C> [BOLD] 3.54 <C> 184.2 <C> 3.89 <C> 22.5 <R> <C> MNIST <C> 6.58 <C> 0.004 <C> 6.84 <C> 0.20 <C> 9.76 <C> 8.10 <C> [BOLD] 5.90 <C> 244.2 <C> 7.9 <C> 0.04 <C> 7.35 <C> 0.07 <C> [BOLD] 5.96 <C> 192.6 <C> 6.20 <C> 19.7 <CAP> TABLE I: Comparison of testing error(%) and running time (s) for different learning approaches and training data sets.
<R> <C> [EMPTY] <C> Larsson et al. <C> Iizuka et al. <C> Zhang et al. <C> Ours <R> <C> Top1 <C> 0.152 <C> 0.13 <C> 0.14 <C> 0.51 <R> <C> Top2 <C> 0.34 <C> 0.159 <C> 0.18 <C> 0.19 <R> <C> Top3 <C> 0.156 <C> 0.36 <C> 0.156 <C> 0.12 <R> <C> Top4 <C> 0.17 <C> 0.153 <C> 0.42 <C> 0.18 <R> <C> Avg. rank <C> 2.39±1.03 <C> 2.68±0.93 <C> 2.95±1.16 <C> 1.98±1.36 <CAP> Table 6: User study result on comparison with the automatic video colorization
<R> <C> [EMPTY] <C> STN <C> VPN <C> Ours <R> <C> Top1 <C> 0.13 <C> 0.07 <C> 0.8 <R> <C> Top2 <C> 0.66 <C> 0.17 <C> 0.17 <R> <C> Top3 <C> 0.151 <C> 0.76 <C> 0.05 <R> <C> Avg. rank <C> 2.07±0.33 <C> 2.69±0.36 <C> 1.24±0.156 <CAP> Table 7: User study result on comparison with the video color propagation
<R> <C> Approach <C> LC-QuAD <C> QALD-6 <C> QALD-7 <R> <C> SENNA <C> 0.10 <C> 0.02 <C> 0.06 <R> <C> LSTM <C> 0.28 <C> 0.20 <C> 0.15 <R> <C> Bi-LSTM <C> 0.25 <C> 0.06 <C> 0.03 <R> <C> SIBKB* <C> 0.14 <C> [EMPTY] <C> [EMPTY] <R> <C> ReMatch* <C> 0.16 <C> [EMPTY] <C> [EMPTY] <R> <C> EARL <C> 0.26 <C> 0.18 <C> 0.15 <R> <C> Falcon <C> 0.38 <C> 0.30 <C> 0.13 <R> <C> MDP-Parser <C> [BOLD] 0.45 <C> [BOLD] 0.34 <C> [BOLD] 0.25 <R> <C> EARL+MDP-Parser <C> 0.34 <C> 0.22 <C> 0.24 <CAP> Table 2: Accuracies for relation linking task.
<R> <C> Approach <C> Entity linking <C> Relation linking <R> <C> EARL <C> 0.006 <C> 0.164 <R> <C> Falcon <C> 0.453 <C> 0.152 <R> <C> MDP-Parser <C> [BOLD] 0.612 <C> [BOLD] 0.443 <CAP> Table 3: Accuracies on LC-QuAD in lowercase
<R> <C> [BOLD] hyper-parameter <C> [BOLD] value <R> <C> iteration <C> 1000 <R> <C> fitness threshold <C> 0.999 <R> <C> evolution size <C> 6 <R> <C> activation <C> relu <R> <C> episode steps <C> 500 <R> <C> episode generation <C> 20 <CAP> TABLE II: Hyper-parameters in the Cartpole v0.
<R> <C> task <C> method <C> fall rate <C> Avg.gen <C> StDev.gen <R> <C> IMPLY <C> NEAT <C> 0.1% <C> 7.03 <C> 1.96 <R> <C> IMPLY <C> FS-NEAT <C> 0.0% <C> 6.35 <C> 2.21 <R> <C> IMPLY <C> Bi-NEAT <C> 0.0% <C> 5.00 <C> 2.50 <R> <C> IMPLY <C> GS-NEAT <C> 0.0% <C> 5.82 <C> 2.88 <R> <C> NAND <C> NEAT <C> 0.1% <C> 13.02 <C> 3.87 <R> <C> NAND <C> FS-NEAT <C> 0.0% <C> 12.50 <C> 4.34 <R> <C> NAND <C> Bi-NEAT <C> 0.0% <C> 10.26 <C> 5.26 <R> <C> NAND <C> GS-NEAT <C> 0.0% <C> 11.74 <C> 5.82 <R> <C> NOR <C> NEAT <C> 0.1% <C> 13.13 <C> 4.18 <R> <C> NOR <C> FS-NEAT <C> 0.0% <C> 12.83 <C> 4.58 <R> <C> NOR <C> Bi-NEAT <C> 0.0% <C> 10.60 <C> 5.64 <R> <C> NOR <C> GS-NEAT <C> 0.0% <C> 11.86 <C> 6.29 <R> <C> XOR <C> NEAT <C> 0.1% <C> 103.42 <C> 56.02 <R> <C> XOR <C> FS-NEAT <C> 0.1% <C> 101.19 <C> 50.72 <R> <C> XOR <C> Bi-NEAT <C> 0.0% <C> 84.15 <C> 30.58 <R> <C> XOR <C> GS-NEAT <C> 0.0% <C> 88.11 <C> 36.13 <CAP> TABLE V: Result statistics in the experiments of logic gates.
<R> <C> task <C> method <C> fall rate <C> Avg.gen <C> StDev.gen <R> <C> CartPole v0 <C> NEAT <C> 26.5% <C> 147.33 <C> 99.16 <R> <C> CartPole v0 <C> FS-NEAT <C> 4.8% <C> 72.86 <C> 85.08 <R> <C> CartPole v0 <C> Bi-NEAT <C> 0.0% <C> 29.35 <C> 18.86 <R> <C> CartPole v0 <C> GS-NEAT <C> 0.0% <C> 31.95 <C> 22.56 <R> <C> LunarLander v2 <C> NEAT <C> 4.9% <C> 144.21 <C> 111.87 <R> <C> LunarLander v2 <C> FS-NEAT <C> 3.3% <C> 152.91 <C> 108.61 <R> <C> LunarLander v2 <C> Bi-NEAT <C> 0.0% <C> 48.66 <C> 44.57 <R> <C> LunarLander v2 <C> GS-NEAT <C> 0.0% <C> 44.57 <C> 50.29 <CAP> TABLE VI: Result statistics in the complex experiments.
<R> <C> [BOLD] Feature Selection <C> Filters <C> [BOLD] Method CC <C> [BOLD] # features 290 <C> [BOLD] Accuracy 50.90% <R> <C> [BOLD] Feature Selection <C> Filters <C> MI <C> 400 <C> 68.44% <R> <C> [BOLD] Feature Selection <C> Filters <C> [ITALIC] χ2 Statistics <C> 400 <C> 67.46% <R> <C> [BOLD] Feature Selection <C> Filters <C> FCBF <C> 15 <C> 31.10% <R> <C> [BOLD] Feature Selection <C> Wrappers <C> SFS <C> 400 <C> 86.67% <R> <C> [BOLD] Feature Selection <C> Wrappers <C> PSO <C> 403 <C> 59.42% <R> <C> [BOLD] Feature Selection <C> Wrappers <C> GA <C> 396 <C> 61.80% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> PCA <C> 5 <C> 60.80% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> Kernel PCA <C> 5 <C> 9.2% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> MDS <C> 5 <C> 61.66% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> Isomap <C> 5 <C> 75.30% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> LLE <C> 5 <C> 65.56% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> LE <C> 5 <C> 77.04% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> AE <C> 5 <C> 83.20% <R> <C> [BOLD] Feature Extraction <C> Unsupervised <C> [ITALIC] t-SNE <C> 3 <C> 89.62% <R> <C> [BOLD] Feature Extraction <C> Supervised <C> FLDA <C> 5 <C> 76.04% <R> <C> [BOLD] Feature Extraction <C> Supervised <C> Kernel FLDA <C> 5 <C> 21.34% <R> <C> [BOLD] Feature Extraction <C> Supervised <C> SPCA <C> 5 <C> 55.68% <R> <C> [BOLD] Feature Extraction <C> Supervised <C> ML <C> 5 <C> 56.98% <R> <C> – <C> – <C> Original data <C> 784 <C> 53.50% <CAP> TABLE II: Performance of feature selection and extraction methods on MNIST dataset.
<R> <C> Sequence -10 <C> Sequence -112 <C> Sequence 68 <C> Sequence -39 <C> Sequence -123 <C> Sequence 35 <C> Sequence -45 <C> Sequence 66 <C> Sequence -28 <C> Sequence 62 <C> Average NIST Value <C> Average NIST Value 0.24 <R> <C> 22 <C> -113 <C> 34 <C> -111 <C> 44 <C> 42 <C> 63 <C> 114 <C> -63 <C> -41 <C> [EMPTY] <C> 0.57 <R> <C> -48 <C> -111 <C> 20 <C> -102 <C> 10 <C> -18 <C> 55 <C> 11 <C> 80 <C> 62 <C> [EMPTY] <C> 0.16 <CAP> Table 1: Sequences in decimal representation of one trained PRNG with seed=0 and B=80, alongside their average NIST value.
<R> <C> [EMPTY] <C> MountainCar <C> DoublePendulum <C> Hopper <C> Walker2d <C> HalfCheetah <C> Ant <R> <C> S / A <C> R4 / {0,1} <C> R11 / R1 <C> R11 / R3 <C> R17 / R6 <C> R17 / R6 <C> R111 / R8 <R> <C> Setting / Demo <C> [BOLD] S1 / 81.25 <C> [BOLD] S3 / 1488.28 <C> [BOLD] S2 / 969.71 <C> [BOLD] S2 / 1843.75 <C> [BOLD] S2 / 2109.80 <C> [BOLD] S2 / 1942.05 <R> <C> PPO <C> -0.74±9.61 <C> 302.77±37.09 <C> 17.09±13.54 <C> 1.54±5.75 <C> 978.84±665.61 <C> -2332.95±2193.85 <R> <C> MMD-IL <C> 82.99±4.57 <C> 218.43±13.72 <C> 118.66±0.38 <C> 8.88±6.07 <C> 161.74±219.85 <C> 967.83±0.87 <R> <C> Pre-train <C> 83.35±6.32 <C> 8928.79±388.61 <C> 1356.47±470.43 <C> 2607.38±301.94 <C> 3831.96±150.30 <C> -5377.25±1682.56 <R> <C> POfD <C> 45.01±28.16 <C> 628.47±69.36 <C> 32.13±24.23 <C> -1.48±0.03 <C> 2801.59±66.03 <C> -68.59±19.17 <R> <C> Penalty <C> -120.29±48.30 <C> 1902.95±210.41 <C> 1225.03±296.52 <C> 286.23±12.46 <C> 1517.68±35.85 <C> -3711.12±794.97 <R> <C> Penalty + Ann. <C> 79.00±1.04 <C> 1671.78±108.80 <C> 1220.10±112.74 <C> 282.00±6.70 <C> 2592.94±870.04 <C> -116.89±88.01 <R> <C> Ours <C> [BOLD] 83.46±1.42 <C> [BOLD] 9331.40±5.95 <C> [BOLD] 2329.89±125.85 <C> [BOLD] 3483.78±269.59 <C> [BOLD] 4106.69±95.47 <C> [BOLD] 2645.58±118.55 <CAP> Table 1: Comparative results (with only 1 imperfect demonstration). All results are measured in the original exact reward.
<R> <C> [BOLD] type_points <C> [BOLD] kernel <C> [BOLD] method <C> [BOLD] 1 <C> [BOLD] 2 <C> [BOLD] 3 <C> [BOLD] 4 <C> [BOLD] 5 <C> [BOLD] 6 <R> <C> inliers <C> linear <C> split <C> 17 <C> 56 <C> 1064 <C> 49 <C> 1075 <C> 9 <R> <C> inliers <C> rbf <C> split <C> 14 <C> 53 <C> 1064 <C> 111 <C> 1092 <C> 276 <R> <C> outliers <C> rbf <C> split <C> 23 <C> 63 <C> 1080 <C> 61 <C> 178 <C> 279 <R> <C> inliers <C> linear <C> keep <C> 46 <C> 60 <C> 82 <C> 7 <C> 177 <C> 49 <R> <C> inliers <C> rbf <C> keep <C> 100 <C> 166 <C> 349 <C> 26 <C> 199 <C> 56 <R> <C> outliers <C> rbf <C> keep <C> 48 <C> 93 <C> 90 <C> 1 <C> 150 <C> 59 <R> <C> inliers <C> linear <C> keep_reset <C> 13 <C> 52 <C> 344 <C> 39 <C> 704 <C> 12 <R> <C> inliers <C> rbf <C> keep_reset <C> 21 <C> 56 <C> 354 <C> 7 <C> 552 <C> 47 <R> <C> outliers <C> rbf <C> keep_reset <C> 15 <C> 60 <C> 937 <C> 49 <C> 119 <C> 157 <CAP> Table 2: Number of rules for clustering methods and K-means clustering.
<R> <C> [BOLD] Algorithm <C> Beijing (15/ 30/ 45 min) MAE <C> Beijing (15/ 30/ 45 min) RMSE <C> Shenzhen (15/ 30/ 45 min) MAE <C> Shenzhen (15/ 30/ 45 min) RMSE <R> <C> LR <C> 29.90 / 30.27 / 30.58 <C> 69.74 / 70.95 / 72.00 <C> 24.59 / 24.80 / 25.09 <C> 51.31 / 52.36 / 52.80 <R> <C> GBRT <C> 17.29 / 17.81 / 18.40 <C> 44.60 / 48.50 / 51.59 <C> 13.90 / 14.67 / 14.71 <C> 35.05 / 37.98 / 38.09 <R> <C> GRU <C> 18.51 / 18.78 / 19.73 <C> 55.43 / 55.92 / 58.64 <C> 16.73 / 16.88 / 17.14 <C> 46.92 / 47.26 / 47.56 <R> <C> Google-Parking <C> 21.49 / 21.68 / 22.85 <C> 57.26 / 59.25 / 60.48 <C> 17.10 / 18.33 / 18.69 <C> 47.30 / 48.45 / 49.34 <R> <C> Du-Parking <C> 17.67 / 17.70 / 18.03 <C> 50.17 / 50.63 / 51.75 <C> 13.91 / 14.17 / 14.39 <C> 42.66 / 43.24 / 43.56 <R> <C> STGCN <C> 16.57 / 16.44 / 17.10 <C> 50.79 / 51.04 / 52.61 <C> 13.46 / 13.59 / 13.88 <C> 39.26 / 39.96 / 40.29 <R> <C> DCRNN <C> 15.66 / 15.97 / 16.30 <C> 46.28 / 47.80 / 48.87 <C> 13.11 / 13.19 / 13.89 <C> 42.74 / 43.37 / 44.27 <R> <C> CxtGNN (ours) <C> 15.29 / 15.69 / 16.15 <C> 45.55 / 46.69 / 47.78 <C> 12.39 / 12.73 / 13.09 <C> 36.31 / 36.92 / 37.46 <R> <C> CAGNN (ours) <C> 12.45 / 12.77 / 13.20 <C> 39.99 / 40.81 / 41.31 <C> 10.50 / 10.62 / 10.98 <C> 31.86 / 32.12 / 32.83 <R> <C> [BOLD] SHARE (ours) <C> [BOLD] 10.68 / 10.97 / 11.43 <C> [BOLD] 32.00 / 32.78 / 33.78 <C> [BOLD] 9.23 / 9.41 / 9.66 <C> [BOLD] 30.44 / 30.90 / 31.70 <CAP> Table 2: Parking availability prediction error given by MAE and RMSE on Beijing and Shenzhen.
<R> <C> [EMPTY] <C> TDD accuracy Fixed <C> TDD accuracy Random <C> Used as training data in 10 GD steps Rand. real <C> Used as training data in 10 GD steps Optim. real <C> Used as training data in 10 GD steps  [ITALIC] k-means <C> Used as training data in 10 GD steps Avg. real <C> Used in K-NN Rand. real <C> Used in K-NN k-means <R> <C> IMDB <C> [BOLD] 75.0 <C> [BOLD] 73.4 ± 3.3 <C> 49.7 ± 0.9 <C> 49.9 ± 0.8 <C> 49.9 ± 0.6 <C> 50.0 ± 0.1 <C> 50.0 ± 0.1 <C> 50.0 ± 0.0 <R> <C> SST5 <C> [BOLD] 37.5 <C> [BOLD] 36.3 ± 1.5 <C> 21.2 ± 4.9 <C> 24.6 ± 2.6 <C> 19.6 ± 4.5 <C> 21.3 ± 4.1 <C> 23.1 ± 0.0 <C> 20.9 ± 2.1 <R> <C> TREC6 <C> [BOLD] 79.2 <C> [BOLD] 77.3 ± 2.9 <C> 37.5 ± 10.1 <C> 44.6 ± 7.5 <C> 34.4 ± 13.0 <C> 28.0 ± 9.5 <C> 31.5 ± 9.9 <C> 50.5 ± 6.8 <R> <C> TREC50 <C> [BOLD] 57.6 <C> 11.0 ± 0.0 <C> 8.2 ± 6.0 <C> 9.9 ± 6.6 <C> 14.7 ± 5.5 <C> 12.5 ± 6.4 <C> 15.4 ± 5.1 <C> [BOLD] 45.1 ± 6.6 <R> <C> TREC502 <C> 67.4 <C> 42.1 ± 2.1 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <CAP> Table 3: Means and standard deviations of TDD and baseline accuracies on text data using TextConvNet. All values are percentages. The first four baselines are used to train the same neural network as in the distillation experiments. The last two baselines are used to train a K-Nearest Neighbors classifier. Each result uses 10 GD steps aside from IMDB with k-means and TREC50 which had to be done with 2 GD steps due to GPU memory constraints and also insufficient training samples for some classes in TREC50. The second TREC50 row uses TDD with 5 GD steps with 4 images per class. Experiments with random initializations have their results listed in the form [mean ± standard deviation] and are based on the resulting performance of 200 randomly initialized networks.
<R> <C> Layer <C> Filter <C> Stride <C> Activation <R> <C> no. <C> size <C> [EMPTY] <C> function <R> <C> 1 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> 2 <C> 32×3×3 <C> 1 <C> ReLU <R> <C> 3 <C> 16×3×3 <C> 2 <C> ReLU <R> <C> 4 <C> 32×3×3 <C> 0.5 <C> ReLU <R> <C> 5 <C> 3×3×3 <C> 1 <C> tanh <R> <C> 6 <C> 3×⌈8 [ITALIC] σc⌉×⌈8 [ITALIC] σc⌉ <C> 1 <C> identity <CAP> Table 1: The architecture of the CNN for learning. From the first to the fifth layers constituted a CAE. The sixth layer had the weights obtained from the Laplacian filter bank in which three filters were used.
<R> <C> Model <C> [ITALIC] L>=1 SR(%) <C> [ITALIC] L>=1 SPL(%) <C> [ITALIC] L>=5 SR(%) <C> [ITALIC] L>=5 SPL(%) <R> <C> Random <C> 11.2 <C> 5.1 <C> 1.1 <C> 0.50 <R> <C> Baseline [zhu2017target] <C> 35.0 <C> 10.3 <C> 25.0 <C> 10.5 <R> <C> Scene-prior [yang2018visual] <C> 35.4 <C> 10.9 <C> 23.8 <C> 10.7 <R> <C> SAVN [Wortsman_2019_CVPR] <C> 35.7 <C> 9.3 <C> 23.9 <C> 9.4 <R> <C> [BOLD] MJOLNIR-r (our) <C> 54.8 <C> 19.2 <C> 41.7 <C> 18.9 <R> <C> [BOLD] MJOLNIR-o (our) <C> [BOLD] 65.3 <C> [BOLD] 21.1 <C> [BOLD] 50.0 <C> [BOLD] 20.9 <CAP> TABLE I: Comparison with state-of-the-art visual navigation algorithms
<R> <C> DONE action <C> Model <C> [ITALIC] L>=1 SR(%) <C> [ITALIC] L>=1 SPL(%) <C> [ITALIC] L>=5 SR(%) <C> [ITALIC] L>=5 SPL(%) <R> <C> only sampled <C> MJOLNIR-r <C> 54.8 <C> 19.2 <C> 41.7 <C> 18.9 <R> <C> only sampled <C> MJOLNIR-o <C> 65.3 <C> 21.1 <C> 50.0 <C> 20.9 <R> <C> only sampled <C> MJOLNIR-o (no_g) <C> 59.0 <C> 16.6 <C> 41.0 <C> 16.9 <R> <C> only sampled <C> MJOLNIR-o (w) <C> 64.7 <C> 21.6 <C> 46.4 <C> 20.6 <R> <C> sampled + env <C> SAVN <C> 54.4 <C> 35.55 <C> 37.87 <C> 23.47 <R> <C> sampled + env <C> [BOLD] MJOLNIR-o <C> [BOLD] 83.1 <C> [BOLD] 53.9 <C> [BOLD] 71.6 <C> [BOLD] 36.9 <CAP> TABLE III: Ablation study for MJOLNIR
<R> <C> Algorithm <C> F1-Score <R> <C> Naïve persistence <C> 0.629 <R> <C> Naïve majority <C> [ITALIC] 0.640 <R> <C> Vanilla TrueSkill <C> 0.400 <R> <C> Multi skill KT <C> 0.259 <R> <C> TrueLearn <C> [BOLD] 0.677 <CAP> Table 1: Mean F1-Score with the full VLN dataset
<R> <C> [BOLD] Augment Size <C> [BOLD] Top-1 Error (%) <C> [BOLD] Top-3 Error (%) <R> <C> 0 <C> 10.94 <C> 4.01 <R> <C> 430 <C> 9.75 <C> 3.75 <R> <C> 860 <C> 9.35 <C> 3.68 <R> <C> 1290 <C> 9.09 <C> 3.69 <R> <C> 1720 <C> 9.05 <C> 3.66 <CAP> TABLE I: Effect of Data Augmentation on the UTD-MHAD dataset.
<R> <C> [BOLD] Model <C> [BOLD] 16 <C> [BOLD] 32 <C> [BOLD] 64 <C> [BOLD] 128 <C> [BOLD] Average <R> <C> No  [ITALIC] Lcyc <C> 65.58 <C> 24.03 <C> 28.37 <C> 35.19 <C> 38.29 <R> <C> No  [ITALIC] Lsem <C> 40.15 <C> 11.60 <C> [BOLD] 9.75 <C> 12.01 <C> 18.38 <R> <C> No UNet <C> 82.89 <C> 24.78 <C> 17.54 <C> 16.54 <C> 35.44 <R> <C> With Style Embedding <C> [BOLD] 26.85 <C> 10.87 <C> 9.89 <C> 13.06 <C> 15.16 <R> <C> No Style Embedding <C> 29.23 <C> [BOLD] 9.21 <C> 10.51 <C> [BOLD] 10.41 <C> [BOLD] 14.84 <CAP> Table 2: Sliced Wasserstein Score
<R> <C> [BOLD] Source Image  [BOLD] TwinGAN <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <CAP> Table 3: Human to Cat Translation
<R> <C> [BOLD] Dataset (Mortality task) <C> [BOLD] 1h-24h PR-AUC <C> [BOLD] 1h-24h ROC <C> [BOLD] 24h-720h PR-AUC <C> [BOLD] 24h-720h ROC <R> <C> PSV (Code+Signal) <C> 62.46 (± 0.20) <C> [BOLD] 90.06 (± 0.12) <C> 48.88 (± 0.13) <C> [BOLD] 85.90 (± 0.09) <R> <C> PSV (Code) <C> 45.35 (± 0.22) <C> 81.69 (± 0.29) <C> 30.50 (± 0.22) <C> 77.98 (± 0.14) <R> <C> PSV (Signal) <C> 49.42 (± 0.18) <C> 82.27 (± 0.04) <C> 31.32 (±0.10) <C> 82.27 (± 0.04) <R> <C> PSV (Semi-supervised) <C> [BOLD] 65.40 (± 0.35) <C> 89.10 (± 0.59) <C> [BOLD] 53.76 (± 0.26) <C> 85.15 (± 0.66) <R> <C> Seq2Seq (lyu2018improving) <C> 7.73 (± 0.60) <C> 51.32 (± 0.31) <C> 8.17 (± 0.05) <C> 61.90 (± 0.19) <R> <C> Seq2Seq (Semi-supervised) <C> 8.58(±0.32) <C> 51.23(± 0.22) <C> 19.22 (± 0.06) <C> 61.63 (± 61.63) <R> <C> Transformer (darabi2019taper)2 <C> 11.18 (± 0.35) <C> 53.01 (± 0.64) <C> 10.67 (± 0.30) <C> 50.45 (± 0.88) <CAP> Table 2: Mortality downstream task ablation, and comparison with baselines. Results reported are average of 5 runs on a test split of 15% and the std are reported in parenthesis.
<R> <C> [BOLD] Dataset (Readmission task) <C> [BOLD] 1h-24h PR-AUC <C> [BOLD] 1h-24h ROC <C> [BOLD] 24h-720h PR-AUC <C> [BOLD] 24h-720h ROC <R> <C> PSV (Code+Signal) <C> 61.25 (± 0.26) <C> 80.99 (± 0.11) <C> 57.86 (± 0.19) <C> 80.94 (± 0.09) <R> <C> PSV (Code) <C> 57.24 (± 0.56) <C> 79.58 (± 0.12) <C> 49.63 (± 0.38) <C> 76.15 (± 0.24) <R> <C> PSV (Signal) <C> 30.47 (± 0.13) <C> 59.35 (± 0.15) <C> 30.34 (± 0.10) <C> 59.22 (± 0.14) <R> <C> PSV (Semi-supervised) <C> [BOLD] 69.02 (± 0.42) <C> [BOLD] 83.40 (± 0.23) <C> [BOLD] 68.04 (± 0.51) <C> [BOLD] 82.25 (± 0.24) <R> <C> Seq2Seq (lyu2018improving)2 <C> 26.43 (± 0.56) <C> 51.45 (± 1.13) <C> 20.30 (± 0.18) <C> 52.35 (± 0.34) <R> <C> Seq2Seq (Semi-supervised) <C> 26.68(± 0.19) <C> 51.80 (±0.54) <C> 22.31 (± 0.11) <C> 52.18 (± 0.42) <R> <C> Transformer (darabi2019taper)2 <C> 28.22 (± 0.60) <C> 58.82 (± 0.43) <C> 27.70 (± 0.79) <C> 59.45 (± 0.91) <CAP> Table 3: Readmission downstream task ablation, and comparison with baselines. Results reported are average of 5 runs on a test split of 15% and the std are reported in parenthesis.
<R> <C> Place <C> Bot <C> Frags <C> F/D ratio <C> Kills <C> Suicides <C> Deaths <R> <C> 1 <C> F1 <C> [BOLD] 559 <C> 1.35 <C> [BOLD] 597 <C> [BOLD] 38 <C> 413 <R> <C> 2 <C> Arnold <C> 413 <C> [BOLD] 1.90 <C> 532 <C> 119 <C> [BOLD] 217 <R> <C> 3 <C> Clyde <C> 393 <C> 0.77 <C> 476 <C> 83 <C> 509 <R> <C> 4 <C> TUHO <C> 312 <C> 0.67 <C> 424 <C> 112 <C> 465 <R> <C> 5 <C> 5vision <C> 142 <C> 0.28 <C> 206 <C> 64 <C> 497 <R> <C> 6 <C> ColbyMules <C> 131 <C> 0.25 <C> 222 <C> 91 <C> 516 <R> <C> 7 <C> AbyssII <C> 118 <C> 0.21 <C> 217 <C> 99 <C> 542 <R> <C> 8 <C> WallDestroyerXxx <C> -130 <C> -0.41 <C> [ITALIC] 13 <C> 143 <C> 315 <R> <C> 9 <C> Ivomi <C> [ITALIC] -578 <C> [ITALIC] -0.68 <C> 149 <C> [ITALIC] 727 <C> [ITALIC] 838 <CAP> Table II: Results of the 2016 Competition: Track 1. ‘Frags’ is the number of opponent kills decreased by the number of suicides of the agent. ‘F/D’ denotes Frags/Death. ‘Deaths’ include suicides.
<R> <C> Place <C> Bot <C> Total Frags <C> F/D ratio <C> Kills M1 <C> Kills M2 <C> Kills M3 <C> Kills T <C> Suicides M1 <C> Suicides M2 <C> Suicides M3 <C> Suicides T <C> Deaths M1 <C> Deaths M2 <C> Deaths M3 <C> Deaths T <R> <C> 1 <C> IntelAct <C> [BOLD] 256 <C> 3.08 <C> [BOLD] 113 <C> [BOLD] 49 <C> [BOLD] 135 <C> [BOLD] 297 <C> [ITALIC] 19 <C> [ITALIC] 17 <C> 5 <C> [ITALIC] 41 <C> 47 <C> 24 <C> 12 <C> 83 <R> <C> 2 <C> Arnold <C> 164 <C> [BOLD] 32.8 <C> 76 <C> 37 <C> 53 <C> 167 <C> 2 <C> [BOLD] 1 <C> [BOLD] 0 <C> [BOLD] 3 <C> [BOLD] 3 <C> [BOLD] 1 <C> [BOLD] 1 <C> [BOLD] 5 <R> <C> 3 <C> TUHO <C> 51 <C> 0.66 <C> 51 <C> 9 <C> 13 <C> 73 <C> 7 <C> 15 <C> [BOLD] 0 <C> 22 <C> 31 <C> 29 <C> 17 <C> 77 <R> <C> 4 <C> ColbyMules <C> 18 <C> 0.13 <C> 8 <C> 5 <C> 13 <C> 26 <C> 1 <C> 7 <C> [BOLD] 0 <C> 8 <C> 60 <C> 27 <C> 44 <C> 129 <R> <C> 5 <C> 5vision <C> 12 <C> 0.09 <C> 12 <C> 10 <C> 4 <C> 26 <C> 3 <C> 8 <C> 3 <C> 14 <C> 45 <C> [ITALIC] 37 <C> 47 <C> 131 <R> <C> 6 <C> Ivomi <C> -2 <C> -0.01 <C> 6 <C> 5 <C> 2 <C> 13 <C> 2 <C> 13 <C> [BOLD] 0 <C> 15 <C> [ITALIC] 69 <C> 33 <C> 35 <C> 137 <R> <C> 7 <C> WallDestroyerXxx <C> [ITALIC] -9 <C> [ITALIC] -0.06 <C> [ITALIC] 2 <C> [ITALIC] 0 <C> [ITALIC] 0 <C> [ITALIC] 2 <C> [BOLD] 0 <C> 5 <C> [ITALIC] 6 <C> 11 <C> 48 <C> 30 <C> [ITALIC] 78 <C> [ITALIC] 156 <CAP> Table III: Results of the 2016 Competition: Track 2. ‘M’ denotes map and ‘T’ denotes a total statistic.
<R> <C> Place <C> Bot <C> Frags <C> F/D ratio <C> Kills <C> Suicides <C> Deaths <R> <C> 1 <C> Marvin <C> [BOLD] 248 <C> [BOLD] 1.16 <C> [BOLD] 315 <C> 67 <C> [BOLD] 213 <R> <C> 2 <C> Arnold2 <C> 245 <C> 0.84 <C> 314 <C> 69 <C> 291 <R> <C> 3 <C> Axon <C> 215 <C> 0.77 <C> 252 <C> 37 <C> 278 <R> <C> 4 <C> TBoy <C> 198 <C> 0.60 <C> 229 <C> 31 <C> [ITALIC] 330 <R> <C> 5 <C> F1 <C> 164 <C> 0.57 <C> 179 <C> [BOLD] 15 <C> 290 <R> <C> 6 <C> YanShi <C> 158 <C> 0.58 <C> 246 <C> [ITALIC] 88 <C> 273 <R> <C> 7 <C> DoomNet <C> 139 <C> 0.50 <C> 179 <C> 40 <C> 280 <R> <C> 8 <C> Turmio <C> 132 <C> 0.47 <C> 209 <C> 77 <C> 280 <R> <C> 9 <C> AlphaDoom <C> [ITALIC] 109 <C> [ITALIC] 0.39 <C> [ITALIC] 139 <C> 30 <C> 281 <CAP> Table V: Results of the 2017 Competition: Track 1. ‘F/D’ denotes Frags/Death. Deaths include suicides.
<R> <C> Objective <C> [BOLD] G <C> L <C> Random <C> LDP <C> FV <C> ERes <C> Greedy <C> RNet–DQN  [ITALIC] avg <C> RNet–DQN  [ITALIC] best <R> <C> F [ITALIC] random <C> BA <C> 2 <C> 0.018±0.001 <C> 0.036 <C> 0.051 <C> 0.053 <C> 0.033 <C> 0.051±0.001 <C> [BOLD] 0.057 <R> <C> [EMPTY] <C> [EMPTY] <C> 5 <C> 0.049±0.002 <C> 0.089 <C> 0.098 <C> 0.106 <C> 0.079 <C> 0.124±0.001 <C> [BOLD] 0.130 <R> <C> [EMPTY] <C> [EMPTY] <C> 10 <C> 0.100±0.003 <C> 0.158 <C> 0.176 <C> 0.180 <C> 0.141 <C> 0.211±0.001 <C> [BOLD] 0.222 <R> <C> [EMPTY] <C> ER <C> 2 <C> 0.029±0.001 <C> 0.100 <C> 0.103 <C> 0.103 <C> 0.082 <C> 0.098±0.001 <C> [BOLD] 0.104 <R> <C> [EMPTY] <C> [EMPTY] <C> 5 <C> 0.071±0.002 <C> 0.168 <C> 0.172 <C> [BOLD] 0.175 <C> 0.138 <C> 0.164±0.001 <C> 0.173 <R> <C> [EMPTY] <C> [EMPTY] <C> 10 <C> 0.138±0.002 <C> 0.238 <C> 0.252 <C> [BOLD] 0.253 <C> 0.217 <C> 0.240±0.001 <C> 0.249 <R> <C> F [ITALIC] targeted <C> BA <C> 2 <C> 0.010±0.001 <C> 0.022 <C> 0.018 <C> 0.018 <C> 0.045 <C> 0.042±0.001 <C> [BOLD] 0.047 <R> <C> [EMPTY] <C> [EMPTY] <C> 5 <C> 0.025±0.001 <C> 0.091 <C> 0.037 <C> 0.077 <C> 0.077 <C> 0.108±0.001 <C> [BOLD] 0.117 <R> <C> [EMPTY] <C> [EMPTY] <C> 10 <C> 0.054±0.003 <C> 0.246 <C> 0.148 <C> 0.232 <C> 0.116 <C> 0.272±0.002 <C> [BOLD] 0.289 <R> <C> [EMPTY] <C> ER <C> 2 <C> 0.020±0.002 <C> 0.103 <C> 0.090 <C> 0.098 <C> [BOLD] 0.149 <C> 0.122±0.001 <C> 0.128 <R> <C> [EMPTY] <C> [EMPTY] <C> 5 <C> 0.050±0.002 <C> 0.205 <C> 0.166 <C> 0.215 <C> [BOLD] 0.293 <C> 0.268±0.001 <C> 0.279 <R> <C> [EMPTY] <C> [EMPTY] <C> 10 <C> 0.098±0.003 <C> 0.306 <C> 0.274 <C> 0.299 <C> 0.477 <C> 0.461±0.003 <C> [BOLD] 0.482 <CAP> Table 1: Mean cumulative reward per episode obtained by the agents on graphs with |V|=20, grouped by objective function, graph family, and number of edge additions L.
<R> <C> [BOLD] Object <C> [BOLD] Training Set Size <C> [BOLD] ex/cm <C> [BOLD] ey/cm <C> [BOLD] e [ITALIC] ψ [BOLD] /° <R> <C> Purple detergent bottle <C> 1200 <C> 1.029 <C> 0.975 <C> 3.43 <R> <C> Blue watering pot <C> 600 <C> 1.140 <C> 0.987 <C> 1.75 <R> <C> Black and white mug <C> 600 <C> 1.190 <C> 1.182 <C> 5.98 <R> <C> Green water ladle <C> 600 <C> 1.092 <C> 1.123 <C> 3.35 <CAP> TABLE I: Testing Set Performance
<R> <C> Accuracy: <C> [BOLD] 99.84% <C> [BOLD] 99.83% <C> 99.82% <R> <C> Not Learnable <C> 0 <C> 4 <C> 1,183 <R> <C> Random Init. <C> 0 <C> 21 <C> 2,069 <R> <C> Ones Init. <C> 1 <C> 19 <C> 1,292 <CAP> Table 3: Ensembles
<R> <C> Datasets <C> accuracy(%) <C> ranking(%) <R> <C> whole dataset <C> 93.95 ± 0.11 <C> 0.02 <R> <C> sub dataset <C> [BOLD] 94.02 ± 0.14 <C> [BOLD] 0.01 <CAP> Table 7: Predictors trained and evaluated with the whole NASBench dataset and sub dataset. The experiments are repeated 20 times to alleviate the randomness of the results.
<R> <C> Network <C> Data Source <C> Algorithm <C> # iterations <C> [ITALIC] Finit×10−3 <C> [ITALIC] Fopt×10−3 <C> Ratio to CG <C> Deep/Shallow <R> <C> [ITALIC] B1 <C> [ITALIC] B1 <C> Adadelta <C> 2000 <C> 332.2 <C> 6.748 <C> 578.43 <C> – <R> <C> - <C> [ITALIC] B1 <C> RMSprop <C> 2000 <C> 332.2 <C> 0.098 <C> 8.40 <C> – <R> <C> [EMPTY] <C> [ITALIC] B1 <C> SGD <C> 2000 <C> 332.2 <C> 90.402 <C> 7748.77 <C> – <R> <C> [EMPTY] <C> [ITALIC] B1 <C> CG <C> 821 <C> 332.2 <C> 0.012 <C> – <C> – <R> <C> [ITALIC] B3 <C> [ITALIC] B3 <C> Adadelta <C> 2000 <C> 143.3 <C> 6.446 <C> 173.67 <C> – <R> <C> [ITALIC] B3 <C> [ITALIC] B3 <C> RMSprop <C> 2000 <C> 143.3 <C> 0.243 <C> 6.54 <C> – <R> <C> [ITALIC] B3 <C> [ITALIC] B3 <C> SGD <C> 2000 <C> 143.3 <C> 50.485 <C> 1360.22 <C> – <R> <C> [ITALIC] B3 <C> [ITALIC] B3 <C> CG <C> 2200 <C> 143.3 <C> 0.037 <C> – <C> – <R> <C> [ITALIC] B5 <C> [ITALIC] B5 <C> Adadelta <C> 2000 <C> 83.8 <C> 4.915 <C> 41.04 <C> – <R> <C> [ITALIC] B5 <C> [ITALIC] B5 <C> RMSprop <C> 2000 <C> 83.8 <C> 0.277 <C> 2.31 <C> – <R> <C> [ITALIC] B5 <C> [ITALIC] B5 <C> SGD <C> 2000 <C> 83.8 <C> 33.233 <C> 277.51 <C> – <R> <C> [ITALIC] B5 <C> [ITALIC] B5 <C> CG <C> 1490 <C> 83.8 <C> 0.120 <C> – <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B3 <C> Adadelta <C> 2000 <C> 235.8 <C> 2.577 <C> 70.41 <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B3 <C> RMSprop <C> 2000 <C> 235.8 <C> 0.075 <C> 2.04 <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B3 <C> SGD <C> 2000 <C> 235.8 <C> 45.396 <C> 1240.02 <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B3 <C> CG <C> 420 <C> 235.8 <C> 0.037 <C> – <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B5 <C> Adadelta <C> 2000 <C> 206.7 <C> 1.594 <C> 52.44 <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B5 <C> RMSprop <C> 2000 <C> 206.7 <C> 0.070 <C> 2.29 <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B5 <C> SGD <C> 2000 <C> 206.7 <C> 32.404 <C> 1065.83 <C> – <R> <C> [ITALIC] B1 <C> [ITALIC] B5 <C> CG <C> 333 <C> 206.7 <C> 0.030 <C> – <C> – <R> <C> [ITALIC] B3 <C> [ITALIC] B1 <C> Adadelta <C> 2000 <C> 237.8 <C> 28.331 <C> 6.75 <C> 11.0 <R> <C> [ITALIC] B3 <C> [ITALIC] B1 <C> RMSprop <C> 2000 <C> 237.8 <C> 4.415 <C> 1.05 <C> 59.2 <R> <C> [ITALIC] B3 <C> [ITALIC] B1 <C> SGD <C> 2000 <C> 237.8 <C> 118.896 <C> 28.34 <C> 2.6 <R> <C> [ITALIC] B3 <C> [ITALIC] B1 <C> CG <C> 1072 <C> 237.8 <C> 4.195 <C> – <C> 114.6 <R> <C> [ITALIC] B5 <C> [ITALIC] B1 <C> Adadelta <C> 2000 <C> 208.6 <C> 44.980 <C> 5.32 <C> 28.2 <R> <C> [ITALIC] B5 <C> [ITALIC] B1 <C> RMSprop <C> 2000 <C> 208.6 <C> 9.629 <C> 1.14 <C> 138.1 <R> <C> [ITALIC] B5 <C> [ITALIC] B1 <C> SGD <C> 2000 <C> 208.6 <C> 136.118 <C> 16.11 <C> 4.2 <R> <C> [ITALIC] B5 <C> [ITALIC] B1 <C> CG <C> 2125 <C> 208.6 <C> 8.451 <C> – <C> 278.0 <CAP> Table 2: Detailed results for problems of size B.
<R> <C> Shallow <C> Deep <C> Data deep – NN shallow ×10−3 <C> Data shallow – NN deep ×10−3 <C> Ratio Deep/Shallow <R> <C> [ITALIC] A1 <C> [ITALIC] A3 <C> 0.038 <C> 5.368 <C> 140.5 <R> <C> [ITALIC] A1 <C> [ITALIC] A5 <C> 0.035 <C> 11.353 <C> 320.5 <R> <C> [ITALIC] B1 <C> [ITALIC] B3 <C> 0.075 <C> 4.415 <C> 59.2 <R> <C> [ITALIC] B1 <C> [ITALIC] B5 <C> 0.070 <C> 9.629 <C> 138.1 <R> <C> [ITALIC] C1 <C> [ITALIC] C3 <C> 0.182 <C> 4.663 <C> 25.7 <R> <C> [ITALIC] C1 <C> [ITALIC] C5 <C> 0.148 <C> 9.777 <C> 66.1 <CAP> Table 3: Results for all given problems and their ratio between shallow and deep networks.
<R> <C> Teacher: baseline <C> Student: baseline <C> Normal KD (T→S) <C> Re-KD (S→T) <R> <C> ResNet18: 75.87 <C> MobileNetV2: 68.38 <C> 71.05±0.16 ( [BOLD] +2.67) <C> 77.28±0.28 ( [BOLD] +1.41) <R> <C> ResNet18: 75.87 <C> ShuffleNetV2: 70.34 <C> 72.05±0.13 ( [BOLD] +1.71) <C> 77.35±0.32 ( [BOLD] +1.48) <R> <C> ResNet50: 78.16 <C> MobileNetV2: 68.38 <C> 71.04±0.20 ( [BOLD] +2.66) <C> 79.30±0.11 ( [BOLD] +1.14) <R> <C> ResNet50: 78.16 <C> ShuffleNetV2: 70.34 <C> 72.15±0.18 ( [BOLD] +1.81) <C> 79.43±0.39 ( [BOLD] +1.27) <R> <C> DenseNet121: 79.04 <C> MobileNetV2: 68.38 <C> 71.29±0.23 ( [BOLD] +2.91) <C> 79.55±0.11 ( [BOLD] +0.51) <R> <C> DenseNet121: 79.04 <C> ShuffleNetV2: 70.34 <C> 72.32±0.25 ( [BOLD] +1.98) <C> 79.83±0.05 ( [BOLD] +0.79) <R> <C> ResNeXt29: 81.03 <C> MobileNetV2: 68.38 <C> 71.65±0.41 ( [BOLD] +3.27) <C> 81.53±0.14 ( [BOLD] +0.50) <R> <C> ResNeXt29: 81.03 <C> ResNet18: 75.87 <C> 77.84±0.15 ( [BOLD] +1.97) <C> 81.62±0.22 ( [BOLD] +0.59) <CAP> Table 1: Normal KD and Re-KD experiment results on CIFAR100. We report mean±std (in %) over 3 runs. The number in parenthesis means increased accuracy over baseline (T: teacher, S: student).
<R> <C> Teacher: baseline <C> Student: baseline <C> Normal KD (T→S) <C> Re-KD (S→T) <R> <C> ResNet18: 95.12 <C> Plain CNN: 87.14 <C> 87.67±0.17 ( [BOLD] +0.53) <C> 95.33±0.12  [BOLD] (+0.21) <R> <C> ResNet18: 95.12 <C> MobileNetV2: 90.98 <C> 91.69±0.14  [BOLD] (+0.71) <C> 95.71±0.11  [BOLD] (+0.59) <R> <C> MobileNetV2: 90.98 <C> Plain CNN: 87.14 <C> 87.45±0.18 ( [BOLD] +0.31) <C> 91.81±0.23 ( [BOLD] +0.92) <R> <C> ResNeXt29: 95.76 <C> ResNet18: 95.12 <C> 95.80±0.13 ( [BOLD] +0.68) <C> 96.49±0.15 ( [BOLD] +0.73) <CAP> Table 2: Re-KD experiment results (accuracy, mean±std over 3 runs in %) on CIFAR10.
<R> <C> Dataset <C> Pt-Teacher: baseline <C> Student: baseline <C> De-KD <R> <C> CIFAR100 <C> ResNet18: 15.48 <C> MobileNetV2: 68.38 <C> 70.65±0.35 ( [BOLD] +2.27) <R> <C> CIFAR100 <C> ResNet18: 15.48 <C> ShuffleNetV2: 70.34 <C> 71.82±0.11 ( [BOLD] +1.48) <R> <C> CIFAR100 <C> ResNet50: 45.82 <C> MobileNetV2: 68.38 <C> 71.45±0.23 ( [BOLD] +3.09) <R> <C> CIFAR100 <C> ResNet50: 45.82 <C> ShuffleNetV2: 70.34 <C> 72.11±0.09 ( [BOLD] +1.77) <R> <C> CIFAR100 <C> ResNet50: 45.82 <C> ResNet18: 75.87 <C> 77.23±0.11 ( [BOLD] +1.23) <R> <C> CIFAR100 <C> ResNeXt29: 51.94 <C> MobileNetV2: 68.38 <C> 71.52±0.27 ( [BOLD] +3.14) <R> <C> CIFAR100 <C> ResNeXt29: 51.94 <C> ShuffleNetV2:70.34 <C> 72.26±0.36 ( [BOLD] +1.92) <R> <C> CIFAR100 <C> ResNeXt29: 51.94 <C> ResNet18: 75.87 <C> 77.28±0.17 ( [BOLD] +1.41) <R> <C> Tiny-ImageNet <C> ResNet18: 9.41 <C> MobileNetV2: 55.06 <C> 56.22 ( [BOLD] +1.16) <R> <C> Tiny-ImageNet <C> ResNet18: 9.41 <C> ShuffleNetV2: 60.51 <C> 60.66 ( [BOLD] +0.15) <R> <C> Tiny-ImageNet <C> ResNet50: 31.01 <C> MobileNetV2:55.06 <C> 56.02 ( [BOLD] +0.96) <R> <C> Tiny-ImageNet <C> ResNet50: 31.01 <C> ShuffleNetV2: 60.51 <C> 61.09 ( [BOLD] +0.58) <CAP> Table 4: De-KD accuracy (in %) on two datasets. Pt-Teacher is “Poorly-trained Teacher”. Refer to the “Normal KD” in Tabs. 1 to 3 for the accuracy of students taught by “fully-trained teacher”.
<R> <C> Model <C> Baseline <C> Tf-KD [ITALIC] self <C> Normal KD [Teacher] <R> <C> MobileNetV2 <C> 55.06 <C> 56.77 ( [BOLD] +1.71) <C> 56.70 ( [BOLD] +1.64) [ResNet18] <R> <C> ShuffleNetV2 <C> 60.51 <C> 61.36 ( [BOLD] +0.85) <C> 61.19 ( [BOLD] +0.68) [ResNet18] <R> <C> ResNet50 <C> 67.47 <C> 68.18 ( [BOLD] +0.71) <C> 68.23 ( [BOLD] +0.76) [DenseNet121] <R> <C> DenseNet121 <C> 68.15 <C> 68.29 ( [BOLD] +0.14) <C> 68.31 ( [BOLD] +0.16) [ResNeXt29] <CAP> Table 5: Tf-KDself experiment results on Tiny-ImageNet (in %).
<R> <C> Model <C> Baseline <C> Tf-KD [ITALIC] self <R> <C> ResNet18 <C> 69.84 <C> 70.42 ( [BOLD] +0.58) <R> <C> ResNet50 <C> 75.77 <C> 76.41 ( [BOLD] +0.64) <R> <C> DenseNet121 <C> 75.28 <C> 75.72 ( [BOLD] +0.44) <R> <C> ResNeXt101 <C> 79.28 <C> 79.56 ( [BOLD] +0.28) <CAP> Table 6: Tf-KDself experiment results on ImageNet (Top1 accuracy, in %).
<R> <C> Architecture <C> Backbone model <C> Pre-trained on <C> # Parameters (millions) <C> Best  [ITALIC] T <C> AUC <R> <C> FbF CNN <C> - <C> - <C> 1.6 <C> 1 <C> 0.815 <R> <C> FbF FT <C> VGG19  <C> ImageNET <C> 144.1 <C> 1 <C> 0.809 <R> <C> FbF FT <C> MobileNet  <C> ImageNET <C> 3.7 <C> 1 <C> 0.779 <R> <C> FbF FT <C> Inceptionresnet  <C> ImageNET <C> 56 <C> 1 <C> 0.617 <R> <C> FbF FT <C> NASNet  <C> ImageNET <C> 89.5 <C> 1 <C> 0.738 <R> <C> FbF FT <C> Xception  <C> ImageNET <C> 23.1 <C> 1 <C> 0.683 <R> <C> FbF FT <C> ResNet50  <C> ImageNET <C> 25.8 <C> 1 <C> 0.861 <R> <C> FbF SMT+CNN <C> YOLOv3  <C> COCO <C> 63.6 <C> 1 <C> 0.854 <R> <C> FbF SMT+CNN <C> Mask RCNN  <C> COCO <C> 65.8 <C> 1 <C> 0.853 <R> <C> CNN+LSTM <C> - <C> - <C> 0.6 <C> 50 <C> 0.888 <R> <C> FT+LSTM <C> VGG19  <C> ImageNET <C> 143.9 <C> 50 <C> 0.886 <R> <C> FT+LSTM <C> MobileNet  <C> ImageNET <C> 3.6 <C> 10 <C> 0.844 <R> <C> FT+LSTM <C> Inceptionresnet  <C> ImageNET <C> 56 <C> 20 <C> 0.5 <R> <C> FT+LSTM <C> NASNet  <C> ImageNET <C> 89.3 <C> 5 <C> 0.761 <R> <C> FT+LSTM <C> Xception  <C> ImageNET <C> 23 <C> 50 <C> 0.768 <R> <C> [BOLD] Best 3 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> FT+LSTM <C> ResNet50  <C> ImageNET <C> 25.8 <C> 20 <C> 0.910 <R> <C> SMT+CNN+LSTM <C> YOLOv3  <C> COCO <C> 62.5 <C> 50 <C> 0.927 <R> <C> [BOLD] SMT+CNN+LSTM <C> [BOLD] Mask R-CNN <C> COCO <C> 64.8 <C> 50 <C> [BOLD] 0.937 <CAP> TABLE I: Classification performances on the lane change dataset. Our method, smt+cnn+lstm, achieved the best AUC score.
<R> <C> Schemes CNN Image Classifier  [BOLD] (naive baseline) <C> # of Lane Acc. 71.8% <C> Gain - <C> Road Type Acc. 89.1% <C> Gain - <C> ALE 0.374 <C> Reduction - <R> <C> - with smoothing post-processing <C> [BOLD] 74.1% <C> [BOLD] 2.3% <C> 90.6% <C> 1.5% <C> [BOLD] 0.337 <C> [BOLD] 9.8% <R> <C> - with MRF post-processing <C> 73.7% <C> 1.9% <C> 92.2% <C> 3.1% <C> 0.355 <C> 5.1% <R> <C> CNN Image Classifier (1.5x receptive field) <C> 71.8% <C> 0.0% <C> 90.1% <C> 1.0% <C> 0.367 <C> 1.9% <R> <C> - with smoothing post-processing <C> 74.0% <C> 2.2% <C> 91.1% <C> 2.0% <C> 0.340 <C> 9.1% <R> <C> - with MRF post-processing <C> [BOLD] 74.1% <C> [BOLD] 2.3% <C> [BOLD] 92.9% <C> [BOLD] 3.8% <C> 0.340 <C> 9.1% <R> <C> CNN Image Classifier (2.0x receptive field) <C> 68.8% <C> -2.0% <C> 89.1% <C> 0.0% <C> 0.393 <C> -5.1% <R> <C> - with smoothing post-processing <C> 70.6% <C> -1.2% <C> 89.9% <C> 0.8% <C> 0.371 <C> 0.8% <R> <C> - with MRF post-processing <C> 70.2% <C> -1.6% <C> 91.6% <C> 2.5% <C> 0.386 <C> -3.2% <R> <C> [BOLD] RoadTagger (ours) <C> [BOLD] 77.2% <C> [BOLD] 5.4% <C> [BOLD] 93.1% <C> [BOLD] 4.0% <C> [BOLD] 0.291 <C> [BOLD] 22.2% <CAP> Table 1: Performance of RoadTagger and different CNN image classifier baselines. In the table, we highlight both the best and the second best results.
<R> <C> Scheme <C> # of Lane <C> Road Type <C> ALE <R> <C> RoadTagger with <C> - <C> - <C> - <R> <C> - Raw <C> 74.0% <C> 91.2% <C> 0.332 <R> <C> - Road <C> 75.5% <C> 92.3% <C> 0.327 <R> <C> - Road(D) <C> 75.6% <C> 92.0% <C> 0.324 <R> <C> - Raw+Road(D)+Aux <C> 77.2% <C> 93.1% <C> 0.291 <CAP> Table 2: Impact of different graph structures used in RoadTagger. Here, we use abbreviations to denote different graphs. We use Raw for the original road network graph, Road for the road extraction graph, Road(D) for the road extraction graph with directional decomposition and Aux for the auxiliary graph for parallel roads.
<R> <C> Scheme <C> # of Lane <C> Road Type <C> ALE <R> <C> RoadTagger <C> 77.2% <C> 93.1% <C> 0.291 <R> <C> No Vertex Dropout <C> 74.7% <C> 92.7% <C> 0.325 <R> <C> No Regularization. <C> 76.5% <C> 90.8% <C> 0.300 <CAP> Table 3: Impact of random vertex dropout and graph Laplace regularization.
<R> <C> [BOLD] Dataset <C> [BOLD] FID score  [BOLD] VAE <C> [BOLD] FID score  [ITALIC] β [BOLD] -VAE ( [ITALIC] β=3) <C> [BOLD] FID score  [BOLD] RKM <C> [BOLD] FID score  [BOLD] Ro. Gen-RKM <R> <C> [BOLD] MNIST <C> 142.54±0.73 <C> 187.21±0.11 <C> 134.95±1.61 <C> [BOLD] 87.32±1.92 <R> <C> [BOLD] F-MNIST <C> 245.84±0.43 <C> 291.11±1.6 <C> 163.51±1.24 <C> [BOLD] 153.32±0.05 <R> <C> [BOLD] SVHN <C> 168.21±0.23 <C> 234.87±1.45 <C> 112.45±1.4 <C> [BOLD] 98.14 ±1.2 <R> <C> [BOLD] CIFAR-10 <C> 201.21±0.71 <C> 241.23±0.34 <C> 187.08±0.58 <C> [BOLD] 132.6±0.21 <R> <C> [BOLD] Dsprites <C> 234.51±1.10 <C> 298.21±1.5 <C> 182.65±0.57 <C> [BOLD] 160.56±0.96 <R> <C> [BOLD] 3Dshapes <C> 233.18±0.94 <C> 252.41±0.38 <C> 177.29±1.60 <C> [BOLD] 131.18±1.45 <CAP> Table 1: FID Scores [13] over 10 iterations for 4000 randomly generated samples when the training data is contaminated with 20% outliers. (smaller is better).
<R> <C> [BOLD] Dataset <C> [ITALIC] hdim <C> [BOLD] Algorithm <C> [BOLD] Lasso  [BOLD] Disent. <C> [BOLD] Lasso  [BOLD] Comple. <C> [BOLD] Lasso  [BOLD] Inform. <C> [BOLD] Random Forest  [BOLD] Disent. <C> [BOLD] Random Forest  [BOLD] Comple. <C> [BOLD] Random Forest  [BOLD] Inform. <R> <C> [BOLD] DSprites <C> 2 <C> [ITALIC] β-VAE ( [ITALIC] β=3) <C> 0.19 <C> 0.16 <C> 6.42 <C> 0.13 <C> 0.32 <C> [BOLD] 1.39 <R> <C> [BOLD] DSprites <C> 2 <C> Gen-RKM <C> 0.07 <C> 0.07 <C> [BOLD] 5.82 <C> 0.25 <C> 0.27 <C> 5.91 <R> <C> [EMPTY] <C> [EMPTY] <C> Ro. Gen-RKM <C> [BOLD] 0.21 <C> [BOLD] 0.21 <C> 9.13 <C> [BOLD] 0.36 <C> [BOLD] 0.38 <C> 5.95 <R> <C> [BOLD] 3DShapes <C> 3 <C> [ITALIC] β-VAE ( [ITALIC] β=3) <C> 0.24 <C> 0.28 <C> [BOLD] 2.72 <C> 0.12 <C> 0.13 <C> 2.15 <R> <C> [BOLD] 3DShapes <C> 3 <C> Gen-RKM <C> 0.14 <C> 0.14 <C> 3.03 <C> 0.15 <C> 0.15 <C> 1.09 <R> <C> [EMPTY] <C> [EMPTY] <C> Ro. Gen-RKM <C> [BOLD] 0.47 <C> [BOLD] 0.49 <C> 3.13 <C> [BOLD] 0.44 <C> [BOLD] 0.45 <C> [BOLD] 1.02 <CAP> Table 2: Disentanglement Metric on DSprites and 3D Shapes dataset. The training subset is contaminated with extra generating factors (20% of the data is considered as outliers). The framework of [9] with Lasso and Random Forest regressor [9] is used to evaluate the learned representation. For disentanglement and completeness higher score is better, for informativeness, lower is better.
<R> <C> [EMPTY] <C> mean IoU (w/o kNN) <C> mean IoU (+kNN) <C> Number of Parameters <R> <C> SalsaNet  <C> 44.2 <C> 45.4 <C> 6.58M <R> <C> + extra layers <C> 45.2 <C> 46.6 <C> 26.38M <R> <C> + context module <C> 46.4 <C> 48.2 <C> 26.40M <R> <C> + new dropoout <C> 49.6 <C> 52.0 <C> 26.40M <R> <C> + average pooling <C> 50.4 <C> 52.9 <C> 23.26M <R> <C> +  [ITALIC] Lovász-Softmax loss <C> 51.5 <C> 54.5 <C> 23.26M <CAP> TABLE II: Ablative analysis.
<R> <C> [EMPTY] <C> Mean (msec) <C> Std (msec) <C> Speed (fps) <R> <C> RangeNet++  <C> 14.27 <C> 2.86 <C> 70 Hz <R> <C> SalsaNet  <C> 10.38 <C> 1.72 <C> 96 Hz <R> <C> SalsaNext [Ours] <C> 12.00 <C> 1.99 <C> 83 Hz <CAP> TABLE III: Runtime performance on the Semantic-KITTI dataset [2]
<R> <C> [EMPTY] <C> Mean perturb, with edge detection <C> Random perturb, with edge detection <C> Mean perturb, excluding edge detection <C> Random perturb, excluding edge detection <R> <C> Faithfulness, F <C> 0.18 (0.17—0.20) <C> 0.10 (0.09—0.12) <C> 0.04 (0.03—0.05) <C> 0.09 (0.08—0.10) <R> <C> AOPCMoRF,  [ITALIC] L=20 <C> 0.29 (0.27—0.31) <C> 0.15 (0.14—0.17) <C> 0.19 (0.17—0.20) <C> 0.07 (0.06—0.08) <R> <C> AOPCMoRF,  [ITALIC] L=40 <C> 0.38 (0.36—0.39) <C> 0.18 (0.17—0.20) <C> 0.27 (0.25—0.28) <C> 0.09 (0.08—0.11) <R> <C> AOPCMoRF,  [ITALIC] L=60 <C> 0.42 (0.40—0.44) <C> 0.20 (0.18—0.21) <C> 0.31 (0.29—0.33) <C> 0.11 (0.10—0.12) <R> <C> AOPCMoRF,  [ITALIC] L=80 <C> 0.46 (0.44—0.48) <C> 0.21 (0.20—0.23) <C> 0.34 (0.32—0.36) <C> 0.12 (0.11—0.14) <R> <C> AOPCMoRF,  [ITALIC] L=100 <C> 0.48 (0.46—0.50) <C> 0.22 (0.21—0.24) <C> 0.37 (0.35—0.39) <C> 0.13 (0.12—0.15) <R> <C> AOPCLeRF,  [ITALIC] L=20 <C> 0.05 (0.04—0.06) <C> 0.13 (0.11—0.15) <C> 0.06 (0.05—0.07) <C> 0.15 (0.13—0.17) <R> <C> AOPCLeRF,  [ITALIC] L=40 <C> 0.11 (0.09—0.12) <C> 0.18 (0.16—0.20) <C> 0.11 (0.09—0.12) <C> 0.20 (0.18—0.22) <R> <C> AOPCLeRF,  [ITALIC] L=60 <C> 0.16 (0.14—0.17) <C> 0.22 (0.20—0.24) <C> 0.15 (0.14—0.17) <C> 0.23 (0.21—0.25) <R> <C> AOPCLeRF,  [ITALIC] L=80 <C> 0.20 (0.18—0.22) <C> 0.25 (0.23—0.27) <C> 0.19 (0.17—0.21) <C> 0.26 (0.23—0.28) <R> <C> AOPCLeRF,  [ITALIC] L=100 <C> 0.24 (0.22—0.25) <C> 0.28 (0.26—0.30) <C> 0.23 (0.21—0.25) <C> 0.28 (0.26—0.30) <CAP> Table 1: Krippendorf’s α under different perturbation functions for the saliency metrics, measured using saliency method ranking across images. Numbers in brackets are 99.9% confidence intervals estimated with 10,000 bootstrap samples.
<R> <C> [EMPTY] <C> Sensitivity <C> gradient⊙input <C> SHAP <C> Deep Taylor <C> Edge detection <R> <C> Faithfulness, F vs AOPCMoRF, <C> 0.34 <C> 0.11 <C> 0.00 <C> 0.24 <C> 0.17 <R> <C> Faithfulness vs AOPCLeRF, <C> -0.11 <C> -0.14 <C> -0.09 <C> -0.22 <C> -0.09 <R> <C> AOPCMoRF vs AOPCLeRF <C> 0.28 <C> 0.53 <C> 0.77 <C> 0.16 <C> 0.11 <R> <C> AOPCMoRF, random RGB perturb vs AOPCMoRF, mean perturb <C> 0.62 <C> 0.71 <C> 0.77 <C> 0.58 <C> 0.57 <CAP> Table 2: Spearman correlations between pairs of metrics, measured over all images, for each saliency method. AOPC was taken at L=100 perturbation steps. Unless otherwise stated, mean perturbation was used.
<R> <C> [BOLD] Naïve Cholesky decomposition 1 seed point <C> [BOLD] Naïve Cholesky decomposition 1 seed point <C> [BOLD] Naïve Cholesky decomposition 100 seed points <C> [BOLD] Naïve Cholesky decomposition 100 seed points <R> <C> Iteration <C> Accuracy <C> [EMPTY] <C> [EMPTY] <R> <C> 82 <C> -5.23 <C> 168 <C> -0.52 <R> <C> 126 <C> -4.5 <C> 169 <C> -0.41 <R> <C> 386 <C> -4.3 <C> 170 <C> -0.30 <R> <C> 479 <C> -4.1 <C> [BOLD] 232 <C> [BOLD] -0.04 <R> <C> [BOLD] Optimized Cholesky decomposition <C> [BOLD] Optimized Cholesky decomposition <C> [BOLD] Optimized Cholesky decomposition <C> [BOLD] Optimized Cholesky decomposition <R> <C> 1 seed point <C> 1 seed point <C> 100 seed points <C> 100 seed points <R> <C> Iteration <C> Accuracy <C> [EMPTY] <C> [EMPTY] <R> <C> 103 <C> -1.3 <C> 648 <C> -0.95 <R> <C> 139 <C> -0.77 <C> 673 <C> -0.61 <R> <C> 156 <C> -0.33 <C> 731 <C> -0.23 <R> <C> 297 <C> -0.18 <C> 838 <C> -0.19 <R> <C> 318 <C> -0.14 <C> 972 <C> -0.18 <R> <C> [BOLD] 611 <C> [BOLD] -0.01 <C> 975 <C> -0.09 <CAP> Table 1: Accuracy improvements of our approach and the naïve Cholesky decomposition for the 5D Levy function.
<R> <C> [BOLD] Naïve Cholesky decomposition Iteration <C> [BOLD] Naïve Cholesky decomposition Accuracy <R> <C> 13 <C> 0.25 <R> <C> 15 <C> 0.67 <R> <C> 24 <C> 0.83 <R> <C> 26 <C> 0.88 <R> <C> 63 <C> 0.90 <R> <C> 198 <C> 0.93 <R> <C> 239 <C> 0.96 <R> <C> 732 <C> [BOLD] 0.97 <R> <C> [BOLD] Optimized Cholesky decomposition <C> [BOLD] Optimized Cholesky decomposition <R> <C> Iteration <C> Accuracy <R> <C> 1 <C> 0.11 <R> <C> 4 <C> 0.12 <R> <C> 11 <C> 0.96 <R> <C> [BOLD] 168 <C> [BOLD] 0.97 <CAP> Table 2: Accuracy improvements of our approach and the naïve Cholesky decomposition for LeNet5 and MNIST.
<R> <C> [BOLD] Naïve Cholesky decomposition Iteration <C> [BOLD] Naïve Cholesky decomposition Accuracy <R> <C> 16 <C> 0.74 <R> <C> 26 <C> 0.75 <R> <C> 43 <C> 0.77 <R> <C> 50 <C> 0.78 <R> <C> 176 <C> 0.79 <R> <C> [BOLD] Optimized Cholesky decomposition <C> [BOLD] Optimized Cholesky decomposition <R> <C> Iteration <C> Accuracy <R> <C> 24 <C> 0.77 <R> <C> 53 <C> 0.78 <R> <C> 62 <C> 0.79 <R> <C> 117 <C> 0.80 <R> <C> 237 <C> [BOLD] 0.81 <CAP> Table 3: Accuracy improvements of our approach and the naïve Cholesky decomposition for ResNet32 and CIFAR10.
<R> <C> [BOLD] Optimized Cholesky decomposition Iteration <C> [BOLD] Optimized Cholesky decomposition Accuracy <R> <C> 1 <C> 0.11 <R> <C> 16 <C> 0.51 <R> <C> 21 <C> 0.77 <R> <C> 35 <C> 0.79 <R> <C> 61 <C> [BOLD] 0.80 <CAP> Table 4: Accuracy improvements of our approach decomposition for ResNet32 and CIFAR10 in a parallel setting.
<R> <C> Network <C> Dataset <C> Steps Baseline <C> Steps Ours <C> Accuracy Baseline <C> Accuracy Ours <R> <C> ResNet-44 <C> CIFAR10 <C> 156K <C> [BOLD] 44K <C> 93.24% <C> 93% <R> <C> WRN-28-10 <C> CIFAR100 <C> 156K <C> [BOLD] 80K <C> 82.26% <C> 82.2% <CAP> Table 1: Test accuracy (Top-1) results for CIFAR10/100. We compare model accuracy using our training scheme and early learning-rate drop as described in section 4.3. We emphasize the reduces number of steps required reaching this accuracy using our MMS method.
<R> <C> Task <C> Category <C> MLP <C> LR <C> XGB <C> RF <C> Ensemble <R> <C> Det <C> S <C> 0.91 <C> 0.86 <C> 0.96 <C> 0.96 <C> [BOLD] 0.97 <R> <C> Det <C> SS <C> 0.92 <C> 0.85 <C> 0.96 <C> 0.96 <C> [BOLD] 0.96 <R> <C> Det <C> SK <C> 0.86 <C> 0.75 <C> 0.90 <C> 0.90 <C> [BOLD] 0.91 <R> <C> Pred <C> S <C> 0.84 <C> 0.76 <C> 0.88 <C> 0.88 <C> [BOLD] 0.90 <R> <C> Pred <C> SS <C> 0.86 <C> 0.76 <C> 0.90 <C> 0.90 <C> [BOLD] 0.91 <R> <C> Pred <C> SK <C> 0.85 <C> 0.73 <C> 0.89 <C> 0.89 <C> [BOLD] 0.90 <CAP> Table 1: AUC using different classifiers for three sepsis gold standards. Here, Det = Detection, Pred = Prediction, S = Sepsis, SS = Severe Sepsis, SK = Septic Shock, MLP = Multilayer Perceptron, LR = Logistic Regression, XGB = XGBoost, RF = Random Forest.
<R> <C> Task <C> Category <C> SOFA <C> qSOFA <C> MEWS <C> Ensemble <R> <C> Det <C> S <C> 0.62 <C> 0.66 <C> 0.72 <C> [BOLD] 0.97 <R> <C> Det <C> SS <C> 0.66 <C> 0.72 <C> 0.76 <C> [BOLD] 0.96 <R> <C> Det <C> SK <C> 0.63 <C> 0.61 <C> 0.66 <C> [BOLD] 0.91 <R> <C> Pred <C> S <C> 0.54 <C> 0.44 <C> 0.49 <C> [BOLD] 0.90 <R> <C> Pred <C> SS <C> 0.60 <C> 0.56 <C> 0.59 <C> [BOLD] 0.91 <R> <C> Pred <C> SK <C> 0.64 <C> 0.57 <C> 0.63 <C> [BOLD] 0.90 <CAP> Table 2: Comparison with rule-based scoring systems in term of AUC. Here, Det = Detection, Pred = Prediction, S = Sepsis, SS = Severe Sepsis, SK = Septic Shock.
<R> <C> Number of nodes <C> Mini-batch size <C> Regular loader (%) <C> Locality-aware loader(%) <R> <C> 16 <C> 8,192 <C> 76.67 <C> 76.81 <R> <C> 32 <C> 16,384 <C> 75.33 <C> 75.12 <R> <C> 64 <C> 32,768 <C> 68.69 <C> 69.54 <CAP> TABLE I: Imagenet-1K ResNet50 validation accuracy comparison between the regular data loader and the locality-aware data loader.
<R> <C> Feature No. <C> Sepsis Detection <C> Septic Shock Prediction <R> <C> 1 <C> 0.85 <C> 0.75 <R> <C> 2 <C> 0.82 <C> 0.70 <R> <C> 3 <C> 0.87 <C> 0.74 <R> <C> 4 <C> 0.80 <C> [BOLD] 0.79 <R> <C> 5 <C> 0.81 <C> 0.69 <R> <C> 6 <C> [BOLD] 0.90 <C> 0.71 <CAP> Table 3: Features ranking in term of AUC. Systolic blood pressure and temperature are the most important vital signs for sepsis prediction and detection respectively.
<R> <C> # of Features <C> Sepsis Detection <C> Septic Shock Prediction <R> <C> 1 <C> 0.91 <C> 0.79 <R> <C> 2 <C> 0.90 <C> 0.80 <R> <C> 3 <C> 0.91 <C> 0.80 <R> <C> 4 <C> 0.92 <C> 0.83 <R> <C> 5 <C> 0.92 <C> 0.83 <R> <C> 6 <C> [BOLD] 0.97 <C> [BOLD] 0.90 <CAP> Table 4: Features ablation in term of AUC. Sepsis is highly correlated with six vital signs. All models perform significantly better when six vital signs are used.
<R> <C> Method <C> Supervision <C> Dataset <C> Cap <C> Abs Rel <C> Sq Rel <C> RMSE <C> RMSE log <C> [ITALIC] δ<1.25 <C> [ITALIC] δ<1.252 <C> [ITALIC] δ<1.253 <R> <C> Train set mean <C> - <C> K <C> 80m <C> 0.361 <C> 4.826 <C> 8.102 <C> 0.377 <C> 0.638 <C> 0.804 <C> 0.894 <R> <C> Eigen  Coarse <C> Depth <C> K <C> 80m <C> 0.214 <C> 1.605 <C> 6.563 <C> 0.292 <C> 0.673 <C> 0.884 <C> 0.957 <R> <C> Eigen  Fine <C> Depth <C> K <C> 80m <C> 0.203 <C> 1.548 <C> 6.307 <C> 0.282 <C> 0.702 <C> 0.890 <C> 0.958 <R> <C> Liu  <C> Depth <C> K <C> 80m <C> 0.201 <C> 1.584 <C> 6.471 <C> 0.273 <C> 0.680 <C> 0.898 <C> 0.967 <R> <C> SfMLearner  <C> - <C> K <C> 80m <C> 0.208 <C> 1.768 <C> 6.856 <C> 0.283 <C> 0.678 <C> 0.885 <C> 0.957 <R> <C> Vid2Depth  <C> - <C> K <C> 80m <C> 0.163 <C> 1.240 <C> 6.220 <C> 0.250 <C> 0.762 <C> 0.916 <C> 0.968 <R> <C> GeoNet  <C> - <C> K <C> 80m <C> 0.155 <C> 1.296 <C> 5.857 <C> 0.233 <C> 0.793 <C> 0.931 <C> 0.973 <R> <C> Zhan  <C> Stereo <C> K <C> 80m <C> [BOLD] 0.135 <C> 1.132 <C> 5.585 <C> 0.229 <C> 0.820 <C> 0.933 <C> 0.971 <R> <C> Ours <C> - <C> K <C> 80m <C> 0.150 <C> [BOLD] 1.127 <C> [BOLD] 5.564 <C> [BOLD] 0.229 <C> [BOLD] 0.823 <C> [BOLD] 0.936 <C> [BOLD] 0.974 <R> <C> Garg  <C> Stereo <C> K <C> 50m <C> 0.169 <C> 1.080 <C> 5.104 <C> 0.273 <C> 0.740 <C> 0.904 <C> 0.962 <R> <C> SfMLearner  <C> - <C> K <C> 50m <C> 0.201 <C> 1.391 <C> 5.181 <C> 0.264 <C> 0.696 <C> 0.900 <C> 0.966 <R> <C> Vid2Depth  <C> - <C> K <C> 50m <C> 0.155 <C> 0.927 <C> 4.549 <C> 0.231 <C> 0.781 <C> 0.931 <C> 0.975 <R> <C> GeoNet  <C> - <C> K <C> 50m <C> 0.147 <C> 0.936 <C> 4.348 <C> 0.218 <C> 0.810 <C> 0.941 <C> 0.977 <R> <C> Zhan  <C> Stereo <C> K <C> 50m <C> [BOLD] 0.128 <C> [BOLD] 0.815 <C> 4.204 <C> 0.216 <C> [BOLD] 0.835 <C> 0.941 <C> 0.975 <R> <C> Ours <C> - <C> K <C> 50m <C> 0.146 <C> 0.927 <C> [BOLD] 4.107 <C> [BOLD] 0.216 <C> 0.819 <C> [BOLD] 0.943 <C> [BOLD] 0.981 <R> <C> SfMLearner  <C> - <C> CS+K <C> 80m <C> 0.198 <C> 1.836 <C> 6.565 <C> 0.275 <C> 0.718 <C> 0.901 <C> 0.960 <R> <C> Vid2Depth  <C> - <C> CS+K <C> 80m <C> 0.159 <C> 1.231 <C> 5.912 <C> 0.243 <C> 0.784 <C> 0.923 <C> 0.970 <R> <C> GeoNet  <C> - <C> CS+K <C> 80m <C> 0.153 <C> 1.328 <C> 5.737 <C> 0.232 <C> 0.802 <C> 0.934 <C> 0.972 <R> <C> Ours <C> - <C> CS+K <C> 80m <C> [BOLD] 0.136 <C> [BOLD] 1.064 <C> [BOLD] 5.176 <C> [BOLD] 0.289 <C> [BOLD] 0.830 <C> [BOLD] 0.942 <C> [BOLD] 0.976 <CAP> Table 1: Monodular depth estimation results on KITTI dataset by the split of Eigen [10]. K and CS refer to KITTI and Cityscapes datasets, respectively. As for supervision, ‘Depth’ means the ground truth depth is used during training, ‘Stereo’ means stereo image sequences with known baselines between two cameras are used during training, and ‘-’ means no supervision is provided. The results are capped at 80m and 50m, respectively. As for error metrics Abs Rel, Seq Rel, RMSE and RMSE log, lower value is better; as for accuracy metrics δ<1.25, δ<1.252 and δ<1.253, higher value is better.
<R> <C> Method <C> Seq.09 <C> Seq.10 <R> <C> ORB-SLAM  (short) <C> 0.064±0.141 <C> 0.064±0.130 <R> <C> ORB-SLAM  (full) <C> 0.014±0.008 <C> 0.012±0.011 <R> <C> SfMLearner  <C> 0.021±0.017 <C> 0.020±0.015 <R> <C> SfMLearner  modified <C> 0.016±0.009 <C> 0.013±0.009 <R> <C> Zhan  <C> 0.013±0.009 <C> 0.013±0.008 <R> <C> Vid2Depth  <C> 0.013±0.010 <C> 0.012±0.011 <R> <C> GeoNet  <C> 0.012±0.007 <C> 0.012±0.009 <R> <C> Ours <C> [BOLD] 0.0030±0.0014 <C> [BOLD] 0.0029±0.0012 <CAP> Table 2: Absolute Trajectory Error (ATE) on sequence 09 and 10 in KITTI odometry dataset. Our method outperforms all the other baselines by a large margin.
<R> <C> Method <C> Dataset <C> Cap <C> Abs Rel <C> Sq Rel <C> RMSE <C> RMSE log <C> [ITALIC] δ<1.25 <C> [ITALIC] δ<1.252 <C> [ITALIC] δ<1.253 <R> <C> Baseline <C> K <C> 50m <C> 0.218 <C> 1.462 <C> 5.837 <C> 0.275 <C> 0.723 <C> 0.908 <C> 0.967 <R> <C> Baseline+code <C> K <C> 50m <C> 0.162 <C> 1.178 <C> 4.533 <C> 0.236 <C> 0.811 <C> 0.933 <C> 0.973 <R> <C> Baseline+code+GAN <C> K <C> 50m <C> 0.152 <C> 0.937 <C> 4.120 <C> 0.217 <C> 0.816 <C> 0.939 <C> 0.979 <R> <C> Baseline+code+LSTM <C> K <C> 50m <C> 0.148 <C> 0.939 <C> 4.271 <C> 0.217 <C> 0.816 <C> 0.941 <C> 0.977 <R> <C> Baseline+code+GAN+LSTM <C> K <C> 50m <C> 0.150 <C> 0.931 <C> 4.116 <C> 0.216 <C> 0.819 <C> 0.943 <C> 0.979 <R> <C> Baseline+code+GAN+LSTM+TC <C> K <C> 50m <C> [BOLD] 0.146 <C> [BOLD] 0.927 <C> [BOLD] 4.107 <C> [BOLD] 0.216 <C> [BOLD] 0.819 <C> [BOLD] 0.943 <C> [BOLD] 0.981 <CAP> Table 3: Ablation study on depth estimation for various versions of our method. Baseline denotes our framework without code, LSTM, discriminator (GAN) and trajectory consistency (TC) loss.
<R> <C> Method <C> Seq.09 <C> Seq.10 <R> <C> Baseline <C> 0.0072±0.0025 <C> 0.0070±0.0023 <R> <C> B+code <C> 0.0069±0.0021 <C> 0.0065±0.0020 <R> <C> B+code+GAN <C> 0.0064±0.0019 <C> 0.0062±0.0019 <R> <C> B+code+LSTM <C> 0.0045±0.0015 <C> 0.0043±0.0015 <R> <C> B+code+GAN+LSTM <C> 0.0036±0.0013 <C> 0.0036±0.0012 <R> <C> B+code+GAN+LSTM+TC <C> [BOLD] 0.0030±0.0014 <C> [BOLD] 0.0029±0.0012 <CAP> Table 4: Ablation study on pose estimation for various versions of our method on KITTI sequence 09 and 10. B denotes baseline.
<R> <C> Data of each sequence <C> 1 hour data <R> <C> Time-step length <C> 15 mins <R> <C> Sequence length <C> 4 <R> <C> Number of regions <C> 64 <R> <C> Number of features <C> 68 <R> <C> Number of hidden layers <C> 2 <R> <C> Number of neurons in each hidden layer <C> 1500-2000 <R> <C> Activation function of hidden recurrent layers <C> tanh <R> <C> Loss function <C> Mean squared error <CAP> Table 3: Experimental Parameters
<R> <C> [BOLD] Method <C> [BOLD] RMSE <C> [BOLD] MAPE (%) <C> [BOLD] Training time <R> <C> DEMA <C> 4.37 <C> 48.54 <C> - <R> <C> LASSO <C> 3.87 <C> 41.42 <C> 4 mins/37 secs <R> <C> XGBoost <C> 3.78 <C> 40.80 <C> 120 mins/53 secs <R> <C> LSTM <C> 3.46 <C> 39.04 <C> 146 mins/43 secs <R> <C> Simple RNN <C> 3.22 <C> 37.42 <C> 16 mins/40 secs <R> <C> GRU <C> 3.21 <C> 37.50 <C> 119 mins/19 secs <CAP> Table 4: Errors over the entire city
<R> <C> [BOLD] Statement  [BOLD] Level <C> [BOLD] Opinion  [BOLD] Agree <C> [BOLD] Opinion  [BOLD] Partially Agree <C> [BOLD] Opinion  [BOLD] Disagree <R> <C> Legibility <C> 37 <C> 0 <C> 3 <R> <C> Fluency <C> 28 <C> 8 <C> 4 <R> <C> Effectiveness <C> 30 <C> 6 <C> 4 <R> <C> UI <C> 35 <C> 4 <C> 1 <R> <C> Experience <C> 31 <C> 7 <C> 2 <CAP> TABLE II: Related Attributes of Bullet Data
<R> <C> [ITALIC] method <C> BlogCatalog mic. <C> BlogCatalog mac. <C> PubMed mic. <C> PubMed mac. <C> Cora mic. <C> Cora mac. <C> Reddit mic. <C> Reddit mac. <C> Flickr mic. <C> Flickr mac. <C> Youtube mic. <C> Youtube mac. <C> CoCit mic. <C> CoCit mac. <R> <C> DeepWalk <C> 42.15 <C> 28.48 <C> 73.96 <C> 71.34 <C> 64.98 <C> 51.53 <C> 94.40 <C> 92.01 <C> [BOLD] 42.20 <C> [BOLD] 31.00 <C> 47.09 <C> 39.89 <C> 41.92 <C> 30.07 <R> <C> Node2vec <C> 42.46 <C> [BOLD] 29.16 <C> 72.36 <C> 68.54 <C> 65.74 <C> 49.12 <C> 94.11 <C> 91.73 <C> 42.11 <C> 30.57 <C> [BOLD] 48.41 <C> [BOLD] 42.04 <C> 41.64 <C> 28.18 <R> <C> Verse <C> 35.51 <C> 21.77 <C> 71.24 <C> 68.68 <C> 60.87 <C> 45.52 <C> 92.87 <C> 89.69 <C> 35.70 <C> 23.00 <C> 45.12 <C> 37.28 <C> 40.17 <C> 27.56 <R> <C> APP <C> 20.60 <C> 5.39 <C> 69.00 <C> 65.20 <C> 64.58 <C> 47.03 <C> 77.11 <C> 56.28 <C> 24.26 <C> 4.21 <C> 45.04 <C> 36.61 <C> 40.34 <C> 28.06 <R> <C> HOPE <C> n.a <C> n.a <C> 63.00 <C> 54.6 <C> 26.23 <C> 1.22 <C> n.a <C> n.a <C> n.a <C> n.a <C> n.a <C> n.a <C> 16.66 <C> 1.91 <R> <C> NetMF <C> [BOLD] 43.29 <C> 29.04 <C> 73.66 <C> 71.11 <C> 63.38 <C> 46.16 <C> 91.99 <C> 86.92 <C> 37.44 <C> 21.55 <C> ✗ <C> ✗ <C> 40.42 <C> 28.7 <R> <C> LINE-1+2 <C> 41.01 <C> 25.02 <C> 62.29 <C> 59.79 <C> 54.04 <C> 41.83 <C> [BOLD] 94.50 <C> [BOLD] 92.08 <C> 41.46 <C> 27.65 <C> 48.22 <C> 41.51 <C> 37.71 <C> 26.75 <R> <C> LINE-1 <C> 41.54 <C> 24.28 <C> 55.65 <C> 53.83 <C> 62.36 <C> 47.19 <C> 94.31 <C> 91.96 <C> 40.92 <C> 26.19 <C> 47.49 <C> 41.17 <C> 36.10 <C> 25.70 <R> <C> LINE-2 <C> 36.70 <C> 18.80 <C> 56.81 <C> 51.71 <C> 51.05 <C> 35.37 <C> 94.30 <C> 91.81 <C> 40.49 <C> 24.24 <C> 47.46 <C> 39.97 <C> 31.4 <C> 20.59 <R> <C> GraphSAGE <C> 19.28 <C> 5.07 <C> 77.90 <C> 76.39 <C> 67.07 <C> 44.78 <C> 89.94 <C> 82.28 <C> 25.52 <C> 5.84 <C> 40.45 <C> 29.97 <C> 43.71 <C> 30.52 <R> <C> GraphSAGE-GCN <C> 26.76 <C> 10.82 <C> [BOLD] 79.19 <C> [BOLD] 77.85 <C> 69.64 <C> 51.64 <C> 91.65 <C> 86.88 <C> 29.66 <C> 9.69 <C> 42.54 <C> 32.54 <C> 44.08 <C> 30.73 <R> <C> SDNE <C> 26.40 <C> 12.29 <C> 46.41 <C> 32.32 <C> 32.43 <C> 8.27 <C> ✗ <C> ✗ <C> 29.10 <C> 10.53 <C> ✗ <C> ✗ <C> 21.67 <C> 9.53 <R> <C> Max-Vote <C> 32.71 <C> 19.60 <C> 76.81 <C> 75.25 <C> [BOLD] 71.96 <C> [BOLD] 57.21 <C> 93.26 <C> 90.11 <C> 34.60 <C> 22.48 <C> 28.96 <C> 25.65 <C> [BOLD] 44.66 <C> [BOLD] 33.39 <CAP> TABLE VI: Multilabel Node Classification results in terms of Micro-F1 and Macro-F1. All results are mean of 5-fold cross validations. ✗ indicates the corresponding method failed to finish for the given dataset. ’n.a’ indicates the given method is ’not applicable’ to the corresponding graph.
<R> <C> Software Engineer <C> Experience with IoT Development (None/Low/ Medium/ High) <C> Solution Performance (Fitness Average) <C> Does the solution work? <R> <C> 1 <C> High <C> 55.48 <C> Y <R> <C> 2 <C> None <C> 26.99 <C> N <R> <C> 3 <C> High <C> 62.88 <C> Y <R> <C> 4 <C> Low <C> 62.49 <C> Y <R> <C> 5 <C> None <C> 30.50 <C> N <R> <C> 6 <C> Low <C> 51.09 <C> Y <R> <C> 7 <C> Medium <C> 54.37 <C> Y <R> <C> 8 <C> None <C> 16.59 <C> N <R> <C> 9 <C> High <C> 28.62 <C> N <R> <C> 10 <C> None <C> 61.60 <C> Y <R> <C> 11 <C> None <C> 29.67 <C> N <R> <C> 12 <C> Medium <C> 47.81 <C> Y <R> <C> 13 <C> None <C> 30.32 <C> N <R> <C> 14 <C> Low <C> 56.91 <C> Y <R> <C> [BOLD] Learning <C> [EMPTY] <C> [BOLD] 59.53 <C> [BOLD] Y <R> <C> zeroed <C> [EMPTY] <C> 28.33 <C> N <CAP> TABLE III: Correlation between participants expertises in the Internet of Things with their solution results.
<R> <C> Variable <C> n samples <C> Highest value <C> Mean ¯¯¯ [ITALIC] x <C> Median <C> Standard deviation  [ITALIC] σ <C> Degrees of freedom (n-1) <C> t critical value (.99%) <R> <C> Software Engineers <C> 14 <C> 62.88 <C> 43.95 <C> 49.45 <C> 16.00 <C> 13 <C> 2.65 <R> <C> Software Engineers with IoT knowledge <C> 8 <C> 62.88 <C> 52.46 <C> 54.92 <C> 10.91 <C> 7 <C> 3.00 <R> <C> Software Engineers without IoT knowledge <C> 6 <C> 61.60 <C> 32.61 <C> 30.00 <C> 15.15 <C> 5 <C> 3.37 <R> <C> Machine- learning based approach <C> 1 <C> 59.53 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <CAP> TABLE IV: Data to perform test statistic.
<R> <C> [EMPTY] <C> Energy% <C> People% <C> Trip% <C> [BOLD] Fitness <R> <C> Average Participant 12 <C> 50.52 <C> 100 <C> 38.14 <C> [BOLD] 56.90 <R> <C> Average Learning <C> 8.46 <C> 100 <C> 46.29 <C> [BOLD] 68.83 <CAP> TABLE VI: Using the same solution in a different environment - day average.
<R> <C> # [ITALIC] Batch <C> [ITALIC] Training <C> [ITALIC] Validation <C> [ITALIC] Test <C> [ITALIC] Thr(2) <C> [ITALIC] Thr(1) <R> <C> 100 <C> 0.8954 <C> 6.1547 <C> 9.1574 <C> 71.52% <C> 65.14% <R> <C> 300 <C> 0.8521 <C> 5.9856 <C> 7.1259 <C> 74.32% <C> 70.78% <R> <C> 500 <C> 0.7485 <C> 5.0198 <C> 5.1245 <C> 78.91% <C> 73.15% <R> <C> 700 <C> 0.6574 <C> 3.1497 <C> 4.1547 <C> 85.47% <C> 80.19% <R> <C> 1000 <C> 0.5782 <C> 1.8643 <C> 3.0214 <C> 91.71% <C> 89.18% <CAP> TABLE III: Batch number sensitivity analyze Batch.
<R> <C> [ITALIC] k <C> [ITALIC] Thr(2) <C> [ITALIC] Thr(1) <C> [ITALIC] Thr(0.5) <R> <C> 2.125∗10−2 <C> 87.56% <C> 82.39% <C> 79.45% <R> <C> 2.125∗10−5 <C> 87.84% <C> 83.05% <C> 80.25% <R> <C> 2.125∗10−7 <C> 88.69% <C> 84.58% <C> 82.12% <R> <C> 2.125∗10−10 <C> 80.32% <C> 78.73% <C> 77.45% <R> <C> 2.125∗10−13 <C> 64.78% <C> 63.58% <C> 61.03% <CAP> TABLE IV: Accuracy analyze of deep learning solution based on changing coefficie.
<R> <C> [ITALIC] De <C> [ITALIC] Thr(2) <C> [ITALIC] Thr(1) <C> [ITALIC] Thr(0.5) <R> <C> 2.6∗10−5 <C> 73.38% <C> 66.39% <C> 61.45% <R> <C> 2.6∗10−7 <C> 84.29% <C> 82.48% <C> 76.21% <R> <C> 2.6∗10−10 <C> 89.29% <C> 87.78% <C> 82.27% <R> <C> 2.6∗10−12 <C> 88.57% <C> 86.54% <C> 82.12% <R> <C> 2.6∗10−15 <C> 81.33% <C> 75.91% <C> 70.67% <CAP> TABLE IV: Accuracy analyze of deep learning solution based on changing coefficie.
<R> <C> [BOLD] Dataset <C> [BOLD] HAR Model <C> [BOLD] Interpolant <C> [BOLD] Input <C> [BOLD] Window Size <C> [BOLD] Precision [ITALIC] m <C> [BOLD] Recall [ITALIC] m <C> [BOLD] F-score [ITALIC] m <R> <C> (clinical room) <C> [EMPTY] <C> (acceleration) <C> [EMPTY] <C> ( [ITALIC] δt) <C> (mean±std) <C> (mean±std) <C> (mean±std) <R> <C> [ITALIC] Roomset1 <C> SVM [ITALIC] lin∗ <C> Cubic <C> Hand-crafted features <C> 4 seconds <C> 87.87±2.55 <C> 83.44±1.72 <C> 84.96±1.23 <R> <C> [ITALIC] Roomset1 <C> SVM [ITALIC] rbf∗ <C> None <C> Hand-crafted features <C> 8 seconds <C> 90.39±2.70 <C> 87.42±1.42 <C> 88.45±1.68 <R> <C> [ITALIC] Roomset1 <C> CRF∗ <C> Linear <C> Hand-crafted features <C> 2 seconds <C> 85.97±2.43 <C> 82.35±3.08 <C> 83.73±2.40 <R> <C> [ITALIC] Roomset1 <C> Bi-LSTM <C> Linear <C> Raw sensor readings <C> 2 seconds <C> 89.97±0.78 <C> 85.11±0.99 <C> 86.96±1.06 <R> <C> [ITALIC] Roomset1 <C> DeepCNN <C> Quadratic <C> Raw sensor readings <C> 4 seconds <C> 92.43±1.21 <C> 87.93±1.74 <C> 89.73±1.55 <R> <C> [ITALIC] Roomset1 <C> DeepConvLSTM <C> Linear <C> Raw sensor readings <C> 4 seconds <C> 91.87±1.43 <C> 88.88±1.79 <C> 90.42±1.54 <R> <C> [ITALIC] Roomset1 <C> [BOLD] (Ours) SparseSense <C> None <C> Raw sensor readings <C> 2 seconds <C> [BOLD] 95.0±0.75 <C> [BOLD] 94.08±0.78 <C> [BOLD] 94.51±0.62 <R> <C> [ITALIC] Roomset2 <C> SVM [ITALIC] lin∗ <C> Cubic <C> Hand-crafted features <C> 2 seconds <C> 87.06±4.10 <C> 84.00±2.90 <C> 84.97±3.74 <R> <C> [ITALIC] Roomset2 <C> SVM [ITALIC] rbf∗ <C> None <C> Hand-crafted features <C> 8 seconds <C> 90.97±4.11 <C> 83.88±2.04 <C> 85.53±2.86 <R> <C> [ITALIC] Roomset2 <C> CRF∗ <C> None <C> Hand-crafted features <C> 16 seconds <C> 83.68±6.50 <C> 78.29±3.58 <C> 79.99±4.76 <R> <C> [ITALIC] Roomset2 <C> Bi-LSTM <C> Previous <C> Raw sensor readings <C> 2 seconds <C> 92.38±0.91 <C> 91.4±0.62 <C> 91.78±0.58 <R> <C> [ITALIC] Roomset2 <C> DeepCNN <C> Linear <C> Raw sensor readings <C> 4 seconds <C> 93.11±0.94 <C> 91.7±1.18 <C> 92.36±0.99 <R> <C> [ITALIC] Roomset2 <C> DeepConvLSTM <C> Previous <C> Raw sensor readings <C> 4 seconds <C> 94.16±0.52 <C> 93.05±0.78 <C> 93.77±0.63 <R> <C> [ITALIC] Roomset2 <C> [BOLD] (Ours) SparseSense <C> None <C> Raw sensor readings <C> 2 seconds <C> [BOLD] 97.07±0.52 <C> [BOLD] 96.88±0.34 <C> [BOLD] 96.97±0.37 <CAP> Table 1: A comparison of the best performing activity recognition models for the naturally sparse clinical room datasets. Numbers and design choices for the baselines with asterisks are quoted from [Wickramasinghe and Ranasinghe2015]. The remaining baselines are replicated following their original paper descriptions. For a fair comparison, the reported results are for the best performing configuration of interpolants and window durations for each baseline.
<R> <C> Decoder <C> R <C> B <C> T <C> C (‰) 0-3s <C> Centroid @ 3s L2 <C> Centroid @ 3s NLL <C> Centroid @ 3s H <C> Heading @ 3s L2 <C> Heading @ 3s NLL <C> Heading @ 3s H <R> <C> MLP <C> ✗ <C> ✗ <C> ✗ <C> 9.79 <C> 127 <C> 2.56 <C> 0.47 <C> 5.68 <C> -3.32 <C> 0.15 <R> <C> MLP <C> ✓ <C> ✗ <C> ✗ <C> 2.23 <C> 118 <C> 1.50 <C> 0.47 <C> 4.97 <C> -7.01 <C> 1.49 <R> <C> GNN <C> ✓ <C> ✗ <C> ✗ <C> 2.91 <C> 122 <C> 1.73 <C> 0.72 <C> 5.09 <C> -6.65 <C> 2.37 <R> <C> GNN <C> ✓ <C> G <C> ✗ <C> 2.14 <C> 116 <C> 1.42 <C> 0.50 <C> 5.14 <C> [BOLD] -7.31 <C> 1.17 <R> <C> GNN <C> ✓ <C> R <C> ✗ <C> 1.32 <C> 109 <C> 1.14 <C> 0.39 <C> 4.77 <C> -7.12 <C> -1.97 <R> <C> GNN <C> ✓ <C> R <C> R <C> [BOLD] 0.78 <C> [BOLD] 105 <C> [BOLD] 1.08 <C> 0.24 <C> [BOLD] 4.75 <C> -6.99 <C> -1.87 <CAP> TABLE III: [ATG4D] Ablation study of the different contributions at 95% recall
<R> <C> Model <C> Col. (‰) 0-1s <C> Col. (‰) 0-3s <C> L2 x,y (cm) 0s <C> L2 x,y (cm) 1s <C> L2 x,y (cm) 3s <C> Heading err (deg) 0s <C> Heading err (deg) 1s <C> Heading err (deg) 3s <R> <C> D+T+S-LSTM  <C> 1.43 <C> 16.31 <C> 22 <C> 147 <C> 607 <C> 4.06 <C> 5.14 <C> 8.07 <R> <C> D+T+CSP  <C> 1.64 <C> 20.78 <C> 22 <C> 95 <C> 282 <C> 4.06 <C> 4.70 <C> 6.20 <R> <C> D+T+CAR-Net  <C> 0.28 <C> 12.30 <C> 22 <C> 46 <C> 149 <C> 4.06 <C> 4.87 <C> 6.14 <R> <C> FaF  <C> 1.12 <C> 17.41 <C> 30 <C> 54 <C> 183 <C> 4.71 <C> 4.98 <C> 6.43 <R> <C> IntentNet  <C> 0.28 <C> 7.03 <C> 26 <C> 45 <C> 146 <C> 4.21 <C> 4.40 <C> 5.64 <R> <C> NMP  <C> 0.05 <C> 3.06 <C> 23 <C> 36 <C> 114 <C> 4.10 <C> 4.24 <C> 5.09 <R> <C> E2E S-LSTM  <C> 0.06 <C> 1.14 <C> 22 <C> 36 <C> 106 <C> 4.97 <C> 4.85 <C> 5.61 <R> <C> E2E CSP  <C> 0.06 <C> 4.47 <C> 23 <C> 38 <C> 114 <C> 4.82 <C> 5.04 <C> 5.84 <R> <C> E2E CAR-Net  <C> 0.07 <C> 1.15 <C> 22 <C> 35 <C> 105 <C> 4.44 <C> 4.41 <C> 5.12 <R> <C> SpAGNN (Ours) <C> [BOLD] 0.03 <C> [BOLD] 0.42 <C> [BOLD] 22 <C> [BOLD] 33 <C> [BOLD] 96 <C> [BOLD] 3.92 <C> [BOLD] 3.89 <C> [BOLD] 4.55 <CAP> TABLE I: [ATG4D] Social interaction and motion forecasting metrics at 80% detection recall
<R> <C> Model <C> Col. (‰) 0-1s <C> Col. (‰) 0-3s <C> L2 x,y (cm) 0s <C> L2 x,y (cm) 1s <C> L2 x,y (cm) 3s <C> Heading err (deg) 0s <C> Heading err (deg) 1s <C> Heading err (deg) 3s <R> <C> E2E S-LSTM  <C> 0.84 <C> 9.64 <C> 24 <C> 71 <C> 185 <C> 3.08 <C> 3.59 <C> 4.63 <R> <C> E2E CSP  <C> 0.41 <C> 5.77 <C> 24 <C> 70 <C> 174 <C> 3.14 <C> 3.51 <C> 4.64 <R> <C> E2E CAR-Net  <C> 0.36 <C> 4.90 <C> 23 <C> 61 <C> 158 <C> [BOLD] 2.84 <C> [BOLD] 3.07 <C> 4.06 <R> <C> SpAGNN (Ours) <C> [BOLD] 0.25 <C> [BOLD] 2.22 <C> [BOLD] 22 <C> [BOLD] 58 <C> [BOLD] 145 <C> 2.99 <C> 3.12 <C> [BOLD] 3.96 <CAP> TABLE II: [nuScenes] Social interaction and motion forecasting metrics at 60% recall
<R> <C> Reso- <C> Method <C> Inception <C> FID <C> Accu- <R> <C> lution <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> racy <R> <C> 64x64 <C> Real Images <C> 16.3±0.4 <C> 0 <C> 54.5 <R> <C> 64x64 <C>  GT Layout <C> 7.3±0.1 <C> 86.5 <C> 33.9 <R> <C> 64x64 <C>  GT Layout <C> 9.1±0.1 <C> [EMPTY] <C> [EMPTY] <R> <C> 64x64 <C> Ours GT Layout <C> 10.3±0.1 <C> 48.7 <C> 46.1 <R> <C> 64x64 <C>  <C> 6.7±0.1 <C> 103.4 <C> 28.8 <R> <C> [EMPTY] <C> Ours <C> 7.9±0.2 <C> 65.3 <C> 43.3 <R> <C> 128x128 <C> Real Images <C> 24.2± 0.9 <C> 0 <C> 59.3 <R> <C> 128x128 <C> Ours GT Layout <C> 12.5±0.3 <C> 59.5 <C> 44.6 <R> <C> 128x128 <C> Ours <C> 10.4±0.4 <C> 75.4 <C> 42.8 <R> <C> 256x256 <C> Real Images <C> 30.7±1.2 <C> 0 <C> 62.4 <R> <C> 256x256 <C> Ours GT Layout <C> 16.4±0.7 <C> 65.2 <C> 45.3 <R> <C> 256x256 <C> Ours <C> 14.5±0.7 <C> 81.0 <C> 42.2 <CAP> Table 1: A quantitative comparison using various image generation scores. In order to support a fair comparison, our model does not use location attributes and employs random appearance attributes.
<R> <C> Res <C> Method <C> Diversity <R> <C> 64x64 <C> Johnson  <C> 0.15±0.08 <R> <C> [EMPTY] <C> Zhao  GT layout <C> 0.15±0.06 <R> <C> [EMPTY] <C> Ours fixed appearance attributes <C> 0.23±0.01 <R> <C> [EMPTY] <C> and zeroed location attributes <C> [EMPTY] <R> <C> [EMPTY] <C> Ours zeroed location attributes <C> 0.35±0.01 <R> <C> [EMPTY] <C> Ours fixed appearance attributes <C> 0.37±0.01 <R> <C> [EMPTY] <C> Our full method <C> 0.43±0.07 <R> <C> 256x256 <C> Ours fixed appearance attributes <C> 0.48±0.09 <R> <C> [EMPTY] <C> and zeroed location attributes <C> [EMPTY] <R> <C> [EMPTY] <C> Ours zeroed location attributes <C> 0.61±0.07 <R> <C> [EMPTY] <C> Ours fixed appearance attributes <C> 0.62±0.05 <R> <C> [EMPTY] <C> Our full method <C> 0.67±0.05 <CAP> Table 2: The diversity score of [27]. The results of [9] are computed by us and are considerably higher than those reported for the same method by [28]. The results of [28] are from their paper.
<R> <C> [EMPTY] <C> IoU <C> R@0.5 <C> R@0.3 <R> <C> Johnson  <C> 0.37 <C> 0.32 <C> 0.52 <R> <C> Ours (w/o location attributes) <C> 0.41 <C> 0.37 <C> 0.62 <R> <C> Ours (w/ location attributes) <C> 0.61 <C> 0.66 <C> 0.86 <CAP> Table 3. Comparison of predicted bounding boxes
<R> <C> User Study <C>  <C> Ours <R> <C> More realistic output <C> 16.7% <C> 83.3% <R> <C> Better adherence to scene graph <C> 19.3% <C> 80.7% <R> <C> Ratio of observed objects <C> 27.31% <C> 45.38% <R> <C> among all COCO objects <C> [EMPTY] <C> [EMPTY] <R> <C> Ratio of observed objects <C> 46.49% <C> 65.23% <R> <C> among all COCO stuff <C> [EMPTY] <C> [EMPTY] <CAP> Table 4. User study results
<R> <C> Model <C> Inception <C> FID <R> <C> Full method <C> 10.4±0.4 <C> 75.4 <R> <C> No Lperceptual <C> 6.2±0.1 <C> 125.1 <R> <C> No LD-mask <C> 5.2±0.1 <C> 183.6 <R> <C> No LD-image <C> 7.4±0.2 <C> 122.5 <R> <C> No LD-object <C> 8.7±0.1 <C> 94.5 <R> <C> Using  [ITALIC] Dimage of  <C> 8.1±0.3 <C> 114.2 <CAP> Table 5: Ablation Study
<R> <C> Hyperparameter <C> Lower bound <C> Upper bound <C> Step size <R> <C> #Layers <C> 1 <C> 6 <C> 1 <R> <C> #Neurons per layer <C> 50 <C> 600 <C> 25 <R> <C> DR method <C> 1 <C> 11 <C> 1 <R> <C> DR ratio <C> 1 <C> 20 <C> 0.1 <R> <C> Quantization <C> bin 1 <C> bin 4 <C> 1 <CAP> TABLE II: General search space for FFNNs
<R> <C> Dataset <C> SenDrive <C> HAR <C> Musk <C> Pendigits <C> SatIm <C> Letter <C> Seizure <C> SHAR <C> DNA <R> <C> Baseline <C> 93.53% <C> 95.01% <C> 98.68% <C> 97.22% <C> 91.30% <C> 95.24% <C> 87.53% <C> 90.66% <C> 94.86% <R> <C> SCANN [hassantabar2019scann] <C> 97.10% <C> 95.52% <C> 99.09% <C> 97.22% <C> 90.10% <C> 92.60% <C> 96.96% <C> 93.78% <C> 95.86% <R> <C> DR + SCANN [hassantabar2019scann] <C> 99.34% <C> 95.28% <C> 98.08% <C> 97.93% <C> 89.40% <C> 92.70% <C> 97.62% <C> 94.84% <C> 93.76% <R> <C> STEERAGE (GS) <C> 99.07% <C> 95.90% <C> 98.90% <C> 97.30% <C> 90.35% <C> [BOLD] 97.20% <C> 95.50% <C> 94.86% <C> 95.56% <R> <C> STEERAGE (GS+LS) <C> [BOLD] 99.36% <C> [BOLD] 96.43% <C> [BOLD] 99.19% <C> [BOLD] 98.05% <C> [BOLD] 92.00% <C> 95.10% <C> [BOLD] 97.72% <C> [BOLD] 95.50% <C> [BOLD] 95.95% <CAP> TABLE III: Highest test accuracy comparison on small- to medium-size datasets (the highest number is highlighted)
<R> <C> Method <C> Error rate (%) <C> Weights <R> <C> Baseline <C> 0.80 <C> 62.0k <R> <C> Network pruning [han2015learning] <C> 0.77 <C> 34.5k <R> <C> NeST [dai2017nest] <C> 0.77% <C> 5.8k <R> <C> SCANN Scheme A[hassantabar2019scann] <C> 0.68% <C> 186.4k <R> <C> SCANN Scheme C[hassantabar2019scann] <C> 0.72% <C> 9.3k <R> <C> STEERAGE (GS) (14×14) <C> 4.96% <C> 38.9k <R> <C> STEERAGE (GS+LS) (14×14) <C> 1.2% <C> 5.0k <R> <C> STEERAGE (GS) (21×21) <C> 1.9% <C> 207.2k <R> <C> [BOLD] STEERAGE (GS+LS) (21×21) <C> [BOLD] 0.72% <C> [BOLD] 5.2k <R> <C> [BOLD] STEERAGE (GS+LS) (21×21) <C> [BOLD] 0.66% <C> [BOLD] 7.2k <R> <C> STEERAGE (GS) (28×28) <C> 0.86% <C> 131.1k <R> <C> STEERAGE (GS+LS) (28×28) <C> 0.68% <C> 9.9k <CAP> TABLE VII: Comparison of results for LeNet-5 (the size of the image is shown in parentheses for STEERAGE)
<R> <C> [EMPTY] <C> Mean <C> Median <R> <C> SVR-DQN <C> [BOLD] 139.75% <C> [BOLD] 118.02% <R> <C> Double DQN <C> 92.48% <C> 63.13% <CAP> Table 1: Mean and median normalized scores.
<R> <C> G <C> Training Loss <C> Evaluation Metric  [ITALIC] L1 <C> Evaluation Metric  [ITALIC] L2 <C> Evaluation Metric Percept. <C> Evaluation Metric SSIM <C> Evaluation Metric MS- <R> <C> G <C> Training Loss <C> [ITALIC] L1 <C> [ITALIC] L2 <C> Percept. <C> SSIM <C> SSIM <R> <C> none <C> [ITALIC] L1 <C> .0452 <C> .0067 <C> .2564 <C> .1707 <C> .1144 <R> <C> none <C> [ITALIC] L2 <C> .0516 <C> .0082 <C> .2663 <C> .1911 <C> .1369 <R> <C> none <C> Percept. <C> .0424 <C> .0062 <C> [BOLD] .1868 <C> .1440 <C> .0992 <R> <C> none <C> SSIM <C> [BOLD] .0406 <C> [BOLD] .0055 <C> .2138 <C> [BOLD] .1378 <C> .0930 <R> <C> none <C> MS-SSIM <C> .0422 <C> .0058 <C> .2358 <C> .1547 <C> [BOLD] .0913 <R> <C> partial <C> [ITALIC] L1 <C> .0366 <C> .0050 <C> .2312 <C> .1409 <C> .0861 <R> <C> partial <C> [ITALIC] L2 <C> .0410 <C> .0056 <C> .2641 <C> .1628 <C> .0968 <R> <C> partial <C> Percept. <C> .0363 <C> .0047 <C> [BOLD] .1658 <C> .1282 <C> .0785 <R> <C> partial <C> SSIM <C> [BOLD] .0336 <C> [BOLD] .0040 <C> .1962 <C> [BOLD] .1159 <C> [BOLD] .0689 <R> <C> partial <C> MS-SSIM <C> .0366 <C> .0044 <C> .2257 <C> .1399 <C> .0758 <R> <C> full <C> [ITALIC] L1 <C> .0406 <C> .0055 <C> .2237 <C> .1484 <C> .0913 <R> <C> full <C> [ITALIC] L2 <C> .0415 <C> .0056 <C> .2302 <C> .1547 <C> .0953 <R> <C> full <C> Percept. <C> .0365 <C> .0048 <C> [BOLD] .1701 <C> .1308 <C> .0803 <R> <C> full <C> SSIM <C> [BOLD] .0362 <C> [BOLD] .0045 <C> .2008 <C> [BOLD] .1270 <C> [BOLD] .0793 <R> <C> full <C> MS-SSIM <C> .0410 <C> .0055 <C> .2165 <C> .1470 <C> .0910 <CAP> Table 1: Loss Selection. We explore the influence of different training losses and evaluation metrics on 3 models with different degrees of structured guidance. For each class, we show validation scores for all pairwise combinations of 5 training losses (rows) and the same 5 evaluation metrics (columns). The best model for each evaluation metric is shown in bold. SSIM/MS-SSIM are expressed as dissimilarities (Eq. 7).
<R> <C> L <C> Model/ Guidance <C> Evaluation Metric  [ITALIC] L1 <C> Evaluation Metric  [ITALIC] L2 <C> Evaluation Metric Percept. <C> Evaluation Metric SSIM <C> Evaluation Metric MS- <R> <C> L <C> Model/ Guidance <C> [ITALIC] L1 <C> [ITALIC] L2 <C> Percept. <C> SSIM <C> SSIM <R> <C> [EMPTY] <C> PMS <C> .0391 <C> .0047 <C> .1630 <C> .1125 <C> .0561 <R> <C> with <C> SfSNet (R) <C> .0636 <C> .0121 <C> .2508 <C> .1840 <C> .1277 <R> <C> with <C> no guidance (P2P) <C> .0668 <C> .0144 <C> .2430 <C> .1832 <C> .1328 <R> <C> with <C> partial guidance <C> [BOLD] .0590 <C> [BOLD] .0118 <C> .2195 <C> [BOLD] .1609 <C> [BOLD] .1111 <R> <C> with <C> full guidance <C> .0609 <C> .0123 <C> [BOLD] .2144 <C> .1618 <C> .1138 <R> <C> w/o <C> SfSNet (P) <C> .1359 <C> .0424 <C> .4703 <C> .3221 <C> .3121 <R> <C> w/o <C> no guidance (P2P) <C> .0815 <C> .0189 <C> .2783 <C> .2076 <C> .1623 <R> <C> w/o <C> partial guidance <C> .0695 <C> .0144 <C> [BOLD] .2325 <C> .1801 <C> .1353 <R> <C> w/o <C> full guidance <C> [BOLD] .0684 <C> [BOLD] .0142 <C> .2273 <C> [BOLD] .1763 <C> [BOLD] .1316 <CAP> Table 2: Baseline Comparison. We show a quantitative comparison of our approach to baseline methods. Performance is reported under the assumption of both known (‘with’) and unknown (‘w/o’) source illumination. All models have been trained with the SSIM loss.
<R> <C> [BOLD] KSC update (KSC initialisation) Strategies <C> [BOLD] KSC update (KSC initialisation)  [ITALIC] K=2 <C> [BOLD] KSC update (KSC initialisation)  [ITALIC] K=3 <C> [BOLD] KSC update (KSC initialisation)  [ITALIC] K=5 <C> [BOLD] KSC update (KSC initialisation)  [ITALIC] K=8 <C> [BOLD] KSC update (KSC initialisation)  [ITALIC] K=10 <R> <C> [ITALIC] SCAL <C> [BOLD] 21.09% <C> [BOLD] 19.79% <C> [BOLD] 24.06% <C> [BOLD] 63.48% <C> [BOLD] 53.91% <R> <C> [ITALIC] SCAL <C> [BOLD] 96.10% <C> [BOLD] 98.28% <C> [BOLD] 93.80% <C> 80.02% <C> 86.45% <R> <C> [ITALIC] MinMargin <C> 64.84% <C> 36.46% <C> 83.13% <C> 98.44% <C> 99.84% <R> <C> [ITALIC] MinMargin <C> 90.30% <C> 97.31% <C> 91.83% <C> [BOLD] 81.92% <C> [BOLD] 88.95% <R> <C> [ITALIC] MaxResid <C> 96.88% <C> 95.31% <C> 99.69% <C> 99.81% <C> 99.84% <R> <C> [ITALIC] MaxResid <C> 77.19% <C> 85.85% <C> 77.43% <C> 79.01% <C> 82.22% <R> <C> [ITALIC] Random <C> 97.66% <C> 96.35% <C> 99.69% <C> 97.85% <C> 97.97% <R> <C> [ITALIC] Random <C> 77.59% <C> 88.08% <C> 76.27% <C> 77.77% <C> 83.46% <CAP> TABLE III: Performance on Yale Faces data sets.
<R> <C> training set test set <C> CUB <C> mini-ImageNet <C> mini-ImageNet CUB <C> CUB mini-ImageNet <R> <C> MatchingNet <C> 83.75 ± 0.60 <C> 69.14 ± 0.69 <C> 52.59 ± 0.71 <C> 48.95 ± 0.67 <R> <C> ProtoNet <C> 85.70 ± 0.52 <C> 73.77 ± 0.64 <C> 59.22 ± 0.74 <C> 53.58 ± 0.73 <R> <C> RelationNet <C> 82.67 ± 0.61 <C> 69.97 ± 0.68 <C> 54.36 ± 0.71 <C> 45.27 ± 0.66 <R> <C> [BOLD] SubspaceNet (ours) <C> [BOLD] 87.45 ± 0.48 <C> [BOLD] 74.03 ± 0.68 <C> [BOLD] 62.71 ± 0.71 <C> [BOLD] 56.66 ± 0.68 <CAP> Table 1: Identical domain and domain shift accuracies for 5-way 5-shot classification using a ResNet-10 backbone and mini-ImageNet and CUB datasets. The best-performing method is highlighted.
<R> <C> Metric <C> Model <C> Dish washer <C> Fridge <C> Microwave <C> Washing machine <C> Average <C> Average improvement <R> <C> MAE <C> FHMM  <C> 101.30 <C> 98.67 <C> 87.00 <C> 66.76 <C> 88.43 <C> - <R> <C> MAE <C> DAE  <C> 29.38 <C> 76.62 <C> 21.31 <C> 31.35 <C> 39.66 <C> - <R> <C> MAE <C> Seq2Seq  <C> 27.07 <C> 26.03 <C> 16.57 <C> 22.72 <C> 23.10 <C> 0.00 % <R> <C> MAE <C> SGN <C> [BOLD] 14.97 <C> 23.89 <C> 17.52 <C> 20.07 <C> 19.09 <C> 17.34 % <R> <C> MAE <C> SGN-sp <C> 15.96 <C> 22.89 <C> [BOLD] 15.98 <C> 20.61 <C> [BOLD] 18.86 <C> 18.36 % <R> <C> MAE <C> Hard SGN <C> 21.27 <C> 24.45 <C> 17.38 <C> [BOLD] 18.24 <C> 20.33 <C> 11.97 % <R> <C> MAE <C> Hard SGN-sp <C> 24.29 <C> [BOLD] 22.86 <C> 17.16 <C> 21.94 <C> 21.56 <C> 6.67 % <R> <C> [ITALIC] SAEδ <C> FHMM <C> 93.64 <C> 46.73 <C> 65.03 <C> 58.77 <C> 66.04 <C> - <R> <C> [ITALIC] SAEδ <C> DAE <C> 29.21 <C> 20.48 <C> 17.86 <C> 27.64 <C> 23.80 <C> - <R> <C> [ITALIC] SAEδ <C> Seq2Seq <C> 26.93 <C> 11.67 <C> 11.43 <C> 16.82 <C> 16.71 <C> 0.00 % <R> <C> [ITALIC] SAEδ <C> SGN <C> [BOLD] 11.74 <C> [BOLD] 10.62 <C> 14.84 <C> 10.70 <C> [BOLD] 11.97 <C> 28.34 % <R> <C> [ITALIC] SAEδ <C> SGN-sp <C> 12.07 <C> 12.26 <C> [BOLD] 11.31 <C> 13.28 <C> 12.23 <C> 26.81 % <R> <C> [ITALIC] SAEδ <C> Hard SGN <C> 20.72 <C> 14.51 <C> 16.53 <C> [BOLD] 8.47 <C> 12.40 <C> 25.77 % <R> <C> [ITALIC] SAEδ <C> Hard SGN-sp <C> 27.63 <C> 10.99 <C> 15.52 <C> 15.66 <C> 13.31 <C> 20.37 % <CAP> Table 2: Experiment results for REDD data.
<R> <C> Grid Size <C> F-score (%) <R> <C> 1×1 <C> 67.3 <R> <C> 8×8 <C> 70.9 <R> <C> 15×15 <C> 71.7 <R> <C> 20×20 <C> 70.4 <CAP> Table 1: Results achieved by our SummaryNet model for different optical flow grid sizes. We choose to use a grid size of 15×15 for the remaining experiments in this paper. The values in this table correspond to the TvSum50 dataset.
<R> <C> [BOLD] Method <C> [BOLD] Features <C> [BOLD] RGB <C> [BOLD] Opt. Flow <C> [BOLD] RGB+Opt. Flow <R> <C> Baseline <C> ResNet <C> - <C> - <C> 50.48 <R> <C> Baseline <C> I3D <C> 67.30 <C> 67.28 <C> 68.64 <R> <C> ConvNet <C> I3D <C> 70.00 <C> 67.40 <C> 68.40 <R> <C> ConvLSTM <C> I3D <C> 70.18 <C> 70.44 <C> 69.10 <R> <C> SummaryNet <C> I3D <C> 70.06 <C> 71.70 <C> [BOLD] 72.02 <CAP> Table 2: Comparison of video summarisation methods using F-score (%) on TvSum50 dataset. These results clearly show the advantage of using spatio-temporal features.
<R> <C> [BOLD] Method <C> [BOLD] Features <C> [BOLD] RGB <C> [BOLD] Opt. Flow <C> [BOLD] RGB+Opt. Flow <R> <C> Baseline <C> ResNet <C> - <C> - <C> 38.06 <R> <C> Baseline <C> I3D <C> 33.86 <C> 41.45 <C> 40.64 <R> <C> ConvNet <C> I3D <C> 33.90 <C> 41.77 <C> 42.85 <R> <C> ConvLSTM <C> I3D <C> 33.88 <C> 42.58 <C> 43.75 <R> <C> SummaryNet <C> I3D <C> 35.83 <C> 43.07 <C> [BOLD] 44.60 <CAP> Table 3: Comparison of video summarisation methods using F-score (%) on SumMe dataset. These results clearly show the advantage of using spatio-temporal features.
<R> <C> [BOLD] Method <C> [BOLD] SumMe <C> [BOLD] TvSum50 <R> <C>  <C> 39.7 <C> - <R> <C>  <C> - <C> 51.3 <R> <C>  <C> 38.6 <C> 54.7 <R> <C>  <C> 41.7 <C> 56.3 <R> <C>  <C> 42.1 <C> 58.1 <R> <C>  <C> [BOLD] 47.5 <C> 56.8 <R> <C>  <C> - <C> 57 <R> <C>  <C> 44.4 <C> [BOLD] 61 <R> <C>  <C> 40.1 <C> 56.3 <R> <C>  <C> 41.9 <C> 57.6 <R> <C>  <C> [BOLD] 51.3 <C> 58.8 <R> <C> SummaryNet (ours) <C> [BOLD] 44.6 <C> [BOLD] 72.02 <CAP> Table 4: Comparison of video summarisation methods using F-score (%). The best results are shown in dark blue and second best is shown in light blue.
<R> <C> Model <C> Y RMSE @ 10 s (m) <C> Velocity RMSE @ 10 s (m/s) <R> <C> Fully-connected (FC) <C> 2.89 <C> 0.526 <R> <C> GCN base <C> 3.52 <C> 0.622 <R> <C> GAT <C> 4.13 <C> 0.688 <R> <C> EGCN <C> [BOLD] 1.40 <C> [BOLD] 0.258 <R> <C> DGCN <C> 1.91 <C> 0.360 <R> <C> LSTM <C> [BOLD] 1.61 <C> 0.331 <R> <C> GCN with LSTM <C> 3.40 <C> 0.653 <R> <C> GAT with LSTM <C> 4.09 <C> 0.728 <R> <C> EGCN with LSTM <C> 1.86 <C> 0.321 <R> <C> DGCN with LSTM <C> 1.63 <C> [BOLD] 0.256 <CAP> TABLE II: RMSE Analysis
<R> <C> Model <C> Jerk Sign Inversions <C> Negative Headway Occurrence Rate <R> <C> Fully-connected (FC) <C> 7.5 <C> 0.08 <R> <C> GCN base <C> 7.5 <C> 0.17 <R> <C> GAT <C> [BOLD] 5.9 <C> 0.27 <R> <C> EGCN <C> 7.5 <C> [BOLD] 0 <R> <C> DGCN <C> 7.3 <C> 0.03 <R> <C> LSTM <C> 13.7 <C> 0.02 <R> <C> GCN with LSTM <C> [BOLD] 6.7 <C> 0.17 <R> <C> GAT with LSTM <C> 0.0 <C> 0.27 <R> <C> EGCN with LSTM <C> 9.5 <C> 0.01 <R> <C> DGCN with LSTM <C> 7.3 <C> [BOLD] 0 <R> <C> True trajectory <C> 6.3 <C> / <CAP> TABLE III: Jerk Sign Inversions Per Trajectory
<R> <C> Category CD↓ <C> Category 3D-R2N2  <C> table 1.116 <C> car 0.845 <C> chair 1.432 <C> plane 0.895 <C> couch 1.135 <C> firearm 0.993 <C> lamp 4.009 <C> watercraft 1.215 <C> bench 1.891 <C> speaker 1.507 <C> cabinet 0.735 <C> monitor 1.707 <C> cellphone 1.137 <C> mean 1.445 <R> <C> CD↓ <C> PSG  <C> 0.517 <C> 0.333 <C> 0.645 <C> 0.430 <C> 0.549 <C> 0.423 <C> 1.193 <C> 0.633 <C> 0.629 <C> 0.756 <C> 0.439 <C> 0.722 <C> 0.438 <C> 0.593 <R> <C> CD↓ <C> Pixel2mesh  <C> 0.498 <C> 0.268 <C> 0.610 <C> 0.477 <C> 0.490 <C> 0.453 <C> 1.295 <C> 0.670 <C> 0.624 <C> 0.739 <C> 0.381 <C> 0.755 <C> 0.421 <C> 0.591 <R> <C> CD↓ <C> Ours (FC) <C> 0.314 <C> 0.220 <C> 0.333 <C> 0.127 <C> 0.289 <C> 0.128 <C> 0.560 <C> 0.30 <C> 0.211 <C> 0.471 <C> 0.310 <C> 0.275 <C> 0.181 <C> 0.286 <R> <C> CD↓ <C> Ours (ResFC) <C> 0.305 <C> 0.216 <C> 0.321 <C> 0.123 <C> 0.284 <C> 0.123 <C> 0.543 <C> 0.228 <C> 0.204 <C> 0.474 <C> 0.309 <C> 0.272 <C> 0.181 <C> 0.276 <R> <C> CD↓ <C> Ours (GraphX) <C> 0.299 <C> 0.192 <C> 0.317 <C> 0.123 <C> 0.265 <C> 0.127 <C> 0.549 <C> 0.214 <C> 0.202 <C> 0.433 <C> 0.272 <C> 0.258 <C> 0.159 <C> 0.262 <R> <C> CD↓ <C> Ours (ResGraphX) <C> 0.291 <C> 0.188 <C> 0.313 <C> 0.120 <C> 0.259 <C> 0.124 <C> 0.529 <C> 0.214 <C> 0.199 <C> 0.430 <C> 0.275 <C> 0.257 <C> 0.159 <C> 0.259 <R> <C> CD↓ <C> Ours (UpResGraphX) <C> [BOLD] 0.284 <C> [BOLD] 0.184 <C> [BOLD] 0.306 <C> [BOLD] 0.116 <C> [BOLD] 0.254 <C> [BOLD] 0.119 <C> [BOLD] 0.523 <C> [BOLD] 0.210 <C> [BOLD] 0.189 <C> [BOLD] 0.419 <C> [BOLD] 0.265 <C> [BOLD] 0.248 <C> [BOLD] 0.155 <C> [BOLD] 0.252 <R> <C> IoU↑ <C> 3D-R2N2  <C> 0.580 <C> [BOLD] 0.836 <C> 0.550 <C> 0.561 <C> 0.706 <C> 0.600 <C> 0.421 <C> 0.610 <C> 0.527 <C> 0.717 <C> 0.772 <C> 0.565 <C> 0.754 <C> 0.631 <R> <C> IoU↑ <C> PSG  <C> 0.606 <C> 0.831 <C> 0.544 <C> 0.601 <C> 0.708 <C> 0.604 <C> 0.462 <C> 0.611 <C> 0.550 <C> [BOLD] 0.737 <C> 0.771 <C> 0.552 <C> 0.749 <C> 0.640 <R> <C> IoU↑ <C> GAL  <C> [BOLD] 0.714 <C> 0.737 <C> 0.700 <C> 0.685 <C> 0.739 <C> 0.715 <C> [BOLD] 0.670 <C> 0.675 <C> 0.709 <C> 0.698 <C> 0.772 <C> [BOLD] 0.804 <C> 0.773 <C> 0.712 <R> <C> IoU↑ <C> Ours (FC) <C> 0.676 <C> 0.820 <C> 0.693 <C> 0.779 <C> 0.784 <C> 0.757 <C> 0.552 <C> 0.769 <C> 0.739 <C> 0.713 <C> 0.769 <C> 0.764 <C> 0.846 <C> 0.743 <R> <C> IoU↑ <C> Ours (ResFC) <C> 0.688 <C> 0.821 <C> [BOLD] 0.704 <C> [BOLD] 0.791 <C> 0.786 <C> [BOLD] 0.765 <C> 0.573 <C> [BOLD] 0.772 <C> [BOLD] 0.746 <C> 0.715 <C> 0.770 <C> 0.765 <C> 0.848 <C> [BOLD] 0.750 <R> <C> IoU↑ <C> Ours (GraphX) <C> 0.487 <C> 0.720 <C> 0.550 <C> 0.734 <C> 0.645 <C> 0.715 <C> 0.487 <C> 0.705 <C> 0.592 <C> 0.617 <C> 0.677 <C> 0.680 <C> 0.821 <C> 0.648 <R> <C> IoU↑ <C> Ours (ResGraphX) <C> 0.532 <C> 0.833 <C> 0.689 <C> 0.766 <C> [BOLD] 0.790 <C> 0.751 <C> 0.532 <C> 0.763 <C> 0.738 <C> 0.724 <C> [BOLD] 0.781 <C> 0.757 <C> [BOLD] 0.858 <C> 0.732 <R> <C> IoU↑ <C> Ours (UpResGraphX) <C> 0.605 <C> 0.819 <C> 0.663 <C> 0.758 <C> 0.770 <C> 0.747 <C> 0.516 <C> 0.754 <C> 0.725 <C> 0.708 <C> 0.770 <C> 0.735 <C> 0.857 <C> 0.725 <CAP> Table 1: Quantitative performance of different single image point cloud generation methods on 13 major categories of ShapeNet. “↑” indicates higher is better. “↓” specifies the opposition. Best performance is highlighted in bold.
<R> <C> Category CD↓ <C> Category Ours (projection) <C> table 0.637 <C> car 0.284 <C> chair 0.490 <C> plane 0.177 <C> lamp 0.670 <C> mean 0.452 <R> <C> CD↓ <C> Ours (AdaIN) <C> 0.372 <C> 0.222 <C> 0.703 <C> 0.243 <C> 0.564 <C> 0.421 <R> <C> CD↓ <C> Ours (full) <C> 0.301 <C> 0.195 <C> 0.319 <C> 0.124 <C> 0.550 <C> 0.298 <R> <C> IoU↑ <C> Ours (projection) <C> 0.540 <C> 0.818 <C> 0.657 <C> 0.704 <C> 0.501 <C> 0.644 <R> <C> IoU↑ <C> Ours (AdaIN) <C> 0.651 <C> 0.840 <C> 0.575 <C> 0.667 <C> 0.523 <C> 0.651 <R> <C> IoU↑ <C> Ours (full) <C> 0.694 <C> 0.844 <C> 0.725 <C> 0.750 <C> 0.566 <C> 0.716 <CAP> Table 2: Quantitative performance of PCDNet when different features are ablated.
<R> <C> N <C> I <C> EO  [ITALIC] E0 <C> EO time <C> SA  [ITALIC] E0 <C> SA time (s) <C> GSO ( [ITALIC] Nbs=1)  [ITALIC] E0 <C> GSO ( [ITALIC] Nbs=1) time (s) <R> <C> 256 <C> 5000 <C> [BOLD] -0.74585(2) <C> ∼268s <C> -0.7278(2) <C> 1.28 <C> -0.7270(2) <C> [BOLD] 0.75 <R> <C> 512 <C> 2500 <C> [BOLD] -0.75235(3) <C> ∼1.2h <C> -0.7327(2) <C> 3.20 <C> -0.7403(2) <C> [BOLD] 1.62 <R> <C> 1024 <C> 1250 <C> [BOLD] –0.7563(2) <C> ∼20h <C> -0.7352(2) <C> 15.27 <C> -0.7480(2) <C> [BOLD] 3.54 <R> <C> 2048 <C> 400 <C> - <C> - <C> -0.7367(2) <C> 63.27 <C> [BOLD] -0.7524(1) <C> [BOLD] 5.63 <R> <C> 4096 <C> 200 <C> - <C> - <C> -0.73713(6) <C> 1591.93 <C> [BOLD] -0.7548(2) <C> [BOLD] 8.38 <R> <C> 8192 <C> 100 <C> - <C> - <C> - <C> - <C> [BOLD] -0.7566(4) <C> [BOLD] 26.54 <CAP> Table 1: Results on optimization of ground state energy of SK model for different system size N and instances I. [27] only reported results of system size up to N=1024. In the implementation of simulated annealing, the program failed to finish within 96 hours for N=8192. We also present the comparison of time consumption.
<R> <C> N <C> I <C> GD (Adam)  [ITALIC] E0 <C> GD (Adam) time (s) <C> GD (L-BFGS)  [ITALIC] E0 <C> GD (L-BFGS) time (s) <C> GSO ( [ITALIC] Nbs=1)  [ITALIC] E0 <C> GSO ( [ITALIC] Nbs=1) time (s) <C> GSO ( [ITALIC] Nbs=128)  [ITALIC] E0 <C> GSO ( [ITALIC] Nbs=128) time (s) <R> <C> 256 <C> 5000 <C> -0.6433(3) <C> 2.84 <C> -0.535(2) <C> 2.29 <C> -0.7270(2) <C> 0.75 <C> [BOLD] -0.7369(1) <C> [BOLD] 0.69 <R> <C> 512 <C> 2500 <C> -0.6456(3) <C> 2.87 <C> -0.520(3) <C> 2.56 <C> -0.7403(2) <C> 1.62 <C> [BOLD] -0.7461(2) <C> [BOLD] 1.61 <R> <C> 1024 <C> 1250 <C> -0.6466(4) <C> 3.22 <C> -0.501(5) <C> [BOLD] 2.73 <C> -0.7480(2) <C> 3.54 <C> [BOLD] -0.7522(1) <C> 4.09 <R> <C> 2048 <C> 400 <C> -0.6493(2) <C> 3.53 <C> -0.495(8) <C> [BOLD] 3.06 <C> -0.7524(1) <C> 5.63 <C> [BOLD] -0.75563(5) <C> 12.19 <R> <C> 4096 <C> 200 <C> -0.6496(5) <C> 4.62 <C> -0.49(1) <C> [BOLD] 3.55 <C> -0.7548(2) <C> 8.38 <C> [BOLD] -0.75692(2) <C> 39.64 <R> <C> 8192 <C> 100 <C> -0.6508(4) <C> 16.26 <C> -0.46(2) <C> [BOLD] 4.82 <C> -0.7566(4) <C> 26.54 <C> [BOLD] -0.75769(2) <C> 204.26 <CAP> Table 2: Results on optimization of ground state energy of SK model for different system size N and instances I. We use different optimizer in gradient descent (GD). We also present the results of parallel version of our proposed method where we choose Nbs=128.
<R> <C> Graph <C> size <C> S2V-DQN <C> GCNs <C> GD (L-BFGS) <C> Greedy <C> GSO <R> <C> Cora <C> 2708 <C> 1381 <C> [BOLD] 1451 <C> 1446 <C> [BOLD] 1451 <C> [BOLD] 1451 <R> <C> Citeseer <C> 3327 <C> 1705 <C> [BOLD] 1867 <C> 1529 <C> 1818 <C> 1802 <R> <C> PubMed <C> 19717 <C> 15709 <C> [BOLD] 15912 <C> 15902 <C> [BOLD] 15912 <C> 15861 <CAP> Table 3: Results on MIS problems.
<R> <C> Graph <C> size <C>   [ITALIC] Q <C>  No. comms <C> EO  [ITALIC] Q <C> EO No. comms <C> GSO  [ITALIC] Q <C> GSO No. comms <R> <C> Zachary <C> 34 <C> 0.3810 <C> 2 <C> 0.4188 <C> 4 <C> [BOLD] 0.4198 <C> 4 <R> <C> Jazz <C> 198 <C> 0.4379 <C> 4 <C> [BOLD] 0.4452 <C> 5 <C> 0.4451 <C> 4 <R> <C> C. elegans <C> 453 <C> 0.4001 <C> 10 <C> [BOLD] 0.4342 <C> 12 <C> 0.4304 <C> 8 <R> <C> E-mail <C> 1133 <C> 0.4796 <C> 13 <C> [BOLD] 0.5738 <C> 15 <C> 0.5275 <C> 8 <CAP> Table 4: Results on modularity optimization. We report the maximum modularity and the corresponding number of communities.
<R> <C> N <C> [ITALIC] s,  [ITALIC] λ <C> Accuracy (%) <R> <C> 10 <C> 0.2, 3.5 <C> 96.80 <R> <C> 10 <C> 0.2, 3.8 <C> 100 <R> <C> 30 <C> 0.2, 3.5 <C> 93.11 <R> <C> 30 <C> 0.2, 3.8 <C> 100 <CAP> Table 5: Results on structural optimization.
<R> <C> Test Case <C> [ITALIC] Tin <C> [ITALIC] pout <C> ˙ [ITALIC] q <C> [ITALIC] G <C> [ITALIC] A <C> [ITALIC] AR <C> [ITALIC] d <C> [ITALIC] r <R> <C> [–] <C> [K] <C> [bar] <C> [MWm2] <C> [kgm2s] <C> [mm2] <C> [–] <C> [mm] <C> [µm] <R> <C> 1 <C> 140 <C> 80 <C> 49 <C> 11700 <C> 1.9 <C> 2.0 <C> 0.83 <C> 2.1 <R> <C> 2 <C> 131 <C> 217 <C> 81 <C> 11700 <C> 4.1 <C> 4.1 <C> 0.90 <C> 3.0 <R> <C> 3 <C> 173 <C> 129 <C> 57 <C> 23900 <C> 7.4 <C> 3.7 <C> 1.14 <C> 3.0 <R> <C> 4 <C> 127 <C> 57 <C> 55 <C> 26000 <C> 6.0 <C> 7.5 <C> 0.96 <C> 14.2 <R> <C> 5 <C> 290 <C> 51 <C> 14 <C> 10100 <C> 7.4 <C> 3.7 <C> 1.14 <C> 1.7 <R> <C> 6 <C> 148 <C> 174 <C> 37 <C> 13200 <C> 3.2 <C> 2.3 <C> 1.07 <C> 6.4 <CAP> Table 2: Exemplary boundary conditions for the test dataset
<R> <C> [EMPTY] <C> [ITALIC] Tb <C> [ITALIC] hb <C> [ITALIC] pb <C> [ITALIC] vb <C> [ITALIC] G <C> ˙ [ITALIC] q <C> [ITALIC] r <C> [ITALIC] A <C> [ITALIC] AR <C> [ITALIC] d <C> [ITALIC] Tw <R> <C> [EMPTY] <C> [K] <C> [kJkg] <C> [bar] <C> [ms] <C> [kgsm2] <C> [MWm2] <C> [µm] <C> [mm2] <C> [–] <C> [mm] <C> [K] <R> <C> Mean <C> 251 <C> 566 <C> 125 <C> 126 <C> 18483 <C> 36 <C> 6.9 <C> 6.7 <C> 4.4 <C> 1.0 <C> 669 <R> <C> Std <C> 84 <C> 317 <C> 42 <C> 78 <C> 8078 <C> 24 <C> 6.1 <C> 3.2 <C> 3.1 <C> 0.1 <C> 302 <R> <C> 1 \char 37 <C> 123 <C> 56 <C> 53 <C> 18 <C> 3027 <C> 9 <C> 0.2 <C> 1.0 <C> 1.0 <C> 0.8 <C> 230 <R> <C> 25 \char 37 <C> 183 <C> 279 <C> 90 <C> 64 <C> 12500 <C> 10 <C> 1.0 <C> 5.0 <C> 1.7 <C> 1.0 <C> 426 <R> <C> 50 \char 37 <C> 240 <C> 572 <C> 119 <C> 109 <C> 17500 <C> 30 <C> 5.0 <C> 5.0 <C> 3.5 <C> 1.0 <C> 620 <R> <C> 75 \char 37 <C> 302 <C> 790 <C> 158 <C> 174 <C> 25000 <C> 50 <C> 15.0 <C> 10.0 <C> 9.2 <C> 1.0 <C> 854 <R> <C> 99 \char 37 <C> 433 <C> 1175 <C> 215 <C> 357 <C> 35000 <C> 80 <C> 20.0 <C> 10.0 <C> 9.2 <C> 1.2 <C> 1482 <CAP> Table 3: Mean value, standard deviation and percentiles of the training data
<R> <C> Index <C> DB-12 <C> WDB-12 <C> DB-24 <C> WDB-24 <C> DB-48 <C> WDB-48 <R> <C> PSNR <C> 31.27 <C> 31.28 <C> 31.65 <C> 31.71 <C> 31.82 <C> 31.89 <R> <C> SSIM <C> 0.8911 <C> 0.8916 <C> 0.8956 <C> 0.8957 <C> 0.8970 <C> 0.8975 <CAP> Table 1: Investigations of WDB with different growth rates on Set5 with scaling factor 4.
<R> <C> Index <C> noSA-16 <C> SA-16 <C> noSA-20 <C> SA-20 <C> noSA-32 <C> SA-32 <R> <C> PSNR <C> 28.25 <C> 28.39 <C> 28.28 <C> 28.43 <C> 28.43 <C> 28.55 <R> <C> SSIM <C> 0.7784 <C> 0.7820 <C> 0.7788 <C> 0.7830 <C> 0.7827 <C> 0.7848 <R> <C> RCIR <C> 0.172 <C> 0.175 <C> 0.173 <C> 0.183 <C> 0.181 <C> 0.190 <CAP> Table 2: Evaluation of SA with different growth rates on Set14 with 4× up-scaling factor.
<R> <C> Dataset <C> Index <C> Bicubic <C> A+ <C> SRCNN <C> VDSR <C> LapSRN <C> SRDense <C> SR-DDNet <C> RDN <C> D-DBPN <C> ADRD <R> <C> Set5 <C> PSNR <C> 28.42 <C> 30.28 <C> 30.48 <C> 31.35 <C> 31.54 <C> 32.02 <C> 32.21 <C> 32.47 <C> [BOLD] 32.47 <C> 32.45 <R> <C> [EMPTY] <C> SSIM <C> 0.8104 <C> 0.8603 <C> 0.8820 <C> 0.8855 <C> 0.8934 <C> 0.8982 <C> 0.8988 <C> 0.8990 <C> 0.8980 <C> [BOLD] 0.8999 <R> <C> Set14 <C> PSNR <C> 26.00 <C> 27.32 <C> 27.50 <C> 28.03 <C> 28.19 <C> 28.50 <C> 28.71 <C> 28.81 <C> 28.82 <C> [BOLD] 28.84 <R> <C> [EMPTY] <C> SSIM <C> 0.7027 <C> 0.7491 <C> 0.7513 <C> 0.7701 <C> 0.7720 <C> 0.7782 <C> 0.7805 <C> 0.7871 <C> 0.7861 <C> [BOLD] 0.7923 <R> <C> BSD100 <C> PSNR <C> 25.96 <C> 26.82 <C> 26.90 <C> 27.29 <C> 27.32 <C> 27.53 <C> 27.69 <C> 27.72 <C> [BOLD] 27.72 <C> 27.69 <R> <C> [EMPTY] <C> SSIM <C> 0.6675 <C> 0.7087 <C> 0.7101 <C> 0.7264 <C> 0.7280 <C> 0.7337 <C> 0.7396 <C> 0.7419 <C> 0.7401 <C> [BOLD] 0.7477 <R> <C> Urban100 <C> PSNR <C> 23.14 <C> 24.32 <C> 24.52 <C> 25.18 <C> 25.21 <C> 26.05 <C> 26.21 <C> 26.61 <C> 27.08⋆ <C> [BOLD] \ \ 27.26⋆ <R> <C> [EMPTY] <C> SSIM <C> 0.6577 <C> 0.7183 <C> 0.7221 <C> 0.7553 <C> 0.7561 <C> 0.7819 <C> 0.7884 <C> 0.8028 <C> 0.7972 <C> [BOLD] 0.8041 <CAP> Table 3: Comparisons with the state-of-the-art methods by PSNR and SSIM (4×). Scores in bold denote the highest values (⋆ indicates that the input is divided into four parts and calculated due to computation limitation of large size images).
<R> <C> Level <C> Bicubic <C> LapSRN <C> RDN <C> D-DBPN <C> ADRD <R> <C> 5×10−5 <C> 28.38 <C> 30.84 <C> 31.82 <C> 31.86 <C> [BOLD] 31.90 <R> <C> 1×10−4 <C> 28.35 <C> 30.66 <C> 31.44 <C> 31.45 <C> [BOLD] 31.47 <R> <C> 2×10−4 <C> 28.27 <C> 30.24 <C> 30.77 <C> 30.86 <C> [BOLD] 30.86 <R> <C> 5×10−4 <C> 28.04 <C> 29.31 <C> 29.55 <C> 29.55 <C> [BOLD] 29.69 <CAP> Table 4: PSNR results of different noise levels on Set5.
<R> <C> Acc (%) <C> Bicubic <C> LapSRN <C> RDN <C> D-DBPN <C> ADRD <R> <C> Top-1 <C> 53.4 <C> 52.1 <C> 54.6 <C> 55.1 <C> [BOLD] 55.7 <R> <C> Top-5 <C> 82.5 <C> 82.5 <C> 83.6 <C> 83.9 <C> [BOLD] 84.2 <CAP> Table 5: Recognition accuracy on Pairs & Oxford.
<R> <C> [EMPTY] <C> User-indep. <C> Nonsuper <C> Semi-super, th=90 <C> Semi-super, th=95 <C> Superv. <R> <C> Arm / LDA <C> 9.3 <C> 7.9 <C> 4.8 (9.9) <C> 4.8 (10.1) <C> 2.7 <R> <C> Waist / LDA <C> 14.1 <C> 9.5 <C> 4.1 (14.9) <C> 3.9 (14.9) <C> 3.3 <R> <C> Wrist / LDA <C> 12.7 <C> 10.3 <C> 5.5 (10.9) <C> 4.8 (11.8) <C> 3.1 <R> <C> Arm / QDA <C> 8.6 <C> 7.0 <C> 3.7 (13.0) <C> 4.3 (12.3) <C> 2.1 <R> <C> Waist / QDA <C> 11.1 <C> 9.1 <C> 4.9 (10.7) <C> 5.0 (10.3) <C> 3.5 <R> <C> Wrist / QDA <C> 12.2 <C> 7.5 <C> 3.5 (14.9) <C> 3.5 (15.7) <C> 2.9 <R> <C> Arm / CART <C> 11.7 <C> 8.7 <C> 5.0 (23.0) <C> 4.9 (22.8) <C> 2.1 <R> <C> Waist / CART <C> 18.0 <C> 15.7 <C> 4.4 (27.4) <C> 4.3 (28.6) <C> 2.0 <R> <C> Wrist / CART <C> 12.2 <C> 9.9 <C> 2.6 (26.7) <C> 2.6 (27.0) <C> 2.5 <R> <C> Mean <C> 12.2 <C> 9.5 <C> 4.3 (16.8) <C> 4.2 (17.1) <C> 2.7 <CAP> Table 1: Average error rates of different personalization approaches. The percentage of user inputs required by the semi-supervised approach in parentheses.
<R> <C> [BOLD] Gender <C> [BOLD] NLL  [BOLD] fam. <C> [BOLD] NLL  [BOLD] unf. <C> [BOLD] Brier  [BOLD] fam. <C> [BOLD] Brier  [BOLD] unf. <C> [BOLD] Label Error  [BOLD] fam. <C> [BOLD] Label Error  [BOLD] unf. <C> [BOLD] ECE  [BOLD] fam. <C> [BOLD] ECE  [BOLD] unf. <R> <C> Baseline <C> 0.083 <C> 0.542 <C> 0.147 <C> 0.352 <C> 0.028 <C> [BOLD] 0.147 <C> 0.013 <C> 0.109 <R> <C> T-scaling <C> 12% <C> 26% <C> 2% <C> [BOLD] 4% <C> 0% <C> [BOLD] 0% <C> [BOLD] 73% <C> 20% <R> <C> Ensemble <C> [BOLD] 24% <C> 33% <C> [BOLD] 10% <C> [BOLD] 6% <C> [BOLD] 22% <C> [BOLD] 0% <C> 36% <C> [BOLD] 29% <R> <C> Distill <C> 8% <C> 33% <C> 3% <C> 4% <C> 3% <C> -7% <C> 41% <C> 21% <R> <C> G-distill <C> 13% <C> [BOLD] 38% <C> 5% <C> [BOLD] 6% <C> 9% <C> -5% <C> 31% <C> [BOLD] 31% <R> <C> Bayesian <C> 17% <C> 26% <C> 5% <C> 4% <C> 6% <C> [BOLD] 0% <C> [BOLD] 77% <C> 19% <R> <C> [BOLD] Cat vs. Dog <C> [BOLD] Cat vs. Dog <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Baseline <C> 0.053 <C> 0.423 <C> 0.112 <C> 0.290 <C> 0.016 <C> 0.095 <C> 0.010 <C> 0.078 <R> <C> T-scaling <C> 23% <C> 30% <C> 4% <C> 5% <C> 0% <C> 0% <C> 64% <C> 23% <R> <C> Ensemble <C> [BOLD] 40% <C> [BOLD] 46% <C> [BOLD] 17% <C> [BOLD] 12% <C> [BOLD] 22% <C> [BOLD] 8% <C> [BOLD] 79% <C> [BOLD] 46% <R> <C> Distill <C> -13% <C> 22% <C> -9% <C> 1% <C> -18% <C> -4% <C> 55% <C> 26% <R> <C> G-distill <C> -18% <C> 27% <C> -14% <C> 1% <C> -33% <C> -8% <C> 41% <C> 31% <R> <C> Bayesian <C> 17% <C> 26% <C> 3% <C> 5% <C> 0% <C> 3% <C> 42% <C> 21% <R> <C> [BOLD] Animals <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Baseline <C> 0.326 <C> 1.128 <C> 0.199 <C> 0.341 <C> 0.104 <C> 0.291 <C> 0.048 <C> 0.187 <R> <C> T-scaling <C> 13% <C> 23% <C> 3% <C> 5% <C> 0% <C> 0% <C> [BOLD] 75% <C> 37% <R> <C> Ensemble <C> [BOLD] 22% <C> [BOLD] 32% <C> [BOLD] 9% <C> [BOLD] 8% <C> [BOLD] 11% <C> [BOLD] 6% <C> 50% <C> [BOLD] 57% <R> <C> Distill <C> 7% <C> 24% <C> 1% <C> 5% <C> -1% <C> 0% <C> 66% <C> 45% <R> <C> G-distill <C> 14% <C> 26% <C> 5% <C> 7% <C> 7% <C> 2% <C> 56% <C> 49% <R> <C> Bayesian <C> 16% <C> 24% <C> 5% <C> 5% <C> 4% <C> 1% <C> [BOLD] 74% <C> 39% <R> <C> [BOLD] Objects <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Baseline <C> 0.086 <C> 0.128 <C> 0.154 <C> 0.186 <C> 0.195 <C> 0.455 <C> 0.005 <C> 0.010 <R> <C> T-scaling <C> 0% <C> 0% <C> 0% <C> 0% <C> 0% <C> 0% <C> 2% <C> 2% <R> <C> Ensemble <C> [BOLD] 4% <C> 4% <C> [BOLD] 2% <C> 2% <C> [BOLD] 6% <C> [BOLD] 3% <C> [BOLD] 3% <C> 7% <R> <C> Distill <C> -1% <C> [BOLD] 5% <C> 0% <C> [BOLD] 2% <C> 1% <C> 0% <C> -31% <C> [BOLD] 10% <R> <C> G-distill <C> -2% <C> 5% <C> -1% <C> 2% <C> -2% <C> -1% <C> -41% <C> 7% <R> <C> Bayesian <C> 0% <C> 0% <C> 0% <C> 0% <C> 0% <C> 0% <C> 3% <C> 1% <CAP> Table 1: Performance of baseline (single model) for several metrics and percent reduction in error for other methods. All methods except baseline use T-scaling calibration. “T-scaling” is a single calibrated model.
<R> <C> [BOLD] Gender <C> [BOLD] NLL  [BOLD] fam. <C> [BOLD] NLL  [BOLD] unf. <C> [BOLD] Brier  [BOLD] fam. <C> [BOLD] Brier  [BOLD] unf. <C> [BOLD] ECE  [BOLD] fam. <C> [BOLD] ECE  [BOLD] unf. <R> <C> Single <C> 0.083 <C> 0.542 <C> 0.148 <C> 0.352 <C> 0.013 <C> 0.109 <R> <C> Sin. T-scale <C> 0.073 <C> 0.400 <C> 0.145 <C> 0.338 <C> 0.004 <C> 0.087 <R> <C> Ensemble <C> 0.062 <C> 0.455 <C> 0.130 <C> 0.344 <C> 0.003 <C> 0.093 <R> <C> Ens. T-scale <C> 0.063 <C> 0.363 <C> 0.130 <C> 0.333 <C> 0.009 <C> 0.077 <R> <C> [BOLD] Cat vs. Dog <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Single <C> 0.053 <C> 0.423 <C> 0.110 <C> 0.290 <C> 0.010 <C> 0.078 <R> <C> Sin. T-scale <C> 0.041 <C> 0.295 <C> 0.105 <C> 0.276 <C> 0.004 <C> 0.060 <R> <C> Ensemble <C> 0.033 <C> 0.286 <C> 0.095 <C> 0.263 <C> 0.002 <C> 0.055 <R> <C> Ens. T-scale <C> 0.032 <C> 0.229 <C> 0.095 <C> 0.255 <C> 0.002 <C> 0.042 <R> <C> [BOLD] Animals <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Single <C> 0.326 <C> 1.128 <C> 0.200 <C> 0.341 <C> 0.048 <C> 0.187 <R> <C> Single T-scale <C> 0.284 <C> 0.866 <C> 0.195 <C> 0.324 <C> 0.012 <C> 0.118 <R> <C> Ensemble <C> 0.256 <C> 0.930 <C> 0.182 <C> 0.322 <C> 0.022 <C> 0.138 <R> <C> Ens. T-scale <C> 0.254 <C> 0.772 <C> 0.182 <C> 0.311 <C> 0.024 <C> 0.080 <CAP> Table 2: T-scaling calibration effectively reduces likelihood error (NLL, Brier) and calibration error (ECE) for many models across tasks for familiar and unfamiliar samples. Without calibration, using an ensemble reduces these errors, but an ensemble of calibrated models (“Ens. T-scale”) performs best. Applying T-scaling to an ensemble of uncalibrated classifiers, and creating an ensemble of calibrated classifiers produces nearly identical results.
<R> <C> [EMPTY] <C> dSprites Matthey et al. ( 2017 ) <C> 3D Faces Paysan et al. ( 2009 ) <R> <C> [ITALIC] β-VAE Higgins et al. ( 2017 ) <C> 0.22 <C> 0.54 <R> <C> [ITALIC] β-TCVAE Chen et al. ( 2018 ) <C> 0.38 <C> 0.62 <R> <C> ICP-ALL <C> 0.33 <C> 0.26 <R> <C> ICP-COM <C> 0.20 <C> 0.57 <R> <C> [BOLD] ICP <C> [BOLD] 0.48 <C> [BOLD] 0.73 <CAP> Table 3: MIG score of disentanglement.
<R> <C> [ITALIC] K <C> CARS196 1 <C> CARS196 2 <C> CARS196 4 <C> CARS196 8 <C> CUB-200-2011 1 <C> CUB-200-2011 2 <C> CUB-200-2011 4 <C> CUB-200-2011 8 <C> SOP 1 <C> SOP 10 <C> SOP 100 <R> <C> Without fine-tuning <C> 35.6 <C> 47.3 <C> 59.4 <C> 72.2 <C> 40.1 <C> 53.2 <C> 66.0 <C> 76.6 <C> 43.7 <C> 60.8 <C> 76.5 <R> <C> Fine-tuned with CCE <C> 48.8 <C> 58.5 <C> 71.0 <C> 78.4 <C> 46.0 <C> 58.0 <C> 69.3 <C> 78.3 <C> 51.7 <C> 69.8 <C> 85.3 <R> <C> Triplet Semihard <C> 51.5 <C> 63.8 <C> 73.5 <C> 82.4 <C> 42.6 <C> 55.0 <C> 66.4 <C> 77.2 <C> 66.7 <C> 82.4 <C> 91.9 <R> <C> Lifted Struct <C> 53.0 <C> 65.7 <C> 76.0 <C> 84.3 <C> 43.6 <C> 56.6 <C> 68.6 <C> 79.6 <C> 62.5 <C> 80.8 <C> 91.9 <R> <C> N-pair-mc <C> 53.9 <C> 66.8 <C> 77.8 <C> 86.4 <C> 45.4 <C> 58.4 <C> 69.5 <C> 79.5 <C> 66.4 <C> 83.2 <C> 93.0 <R> <C> Struct Clust <C> 58.1 <C> 70.6 <C> 80.3 <C> 87.8 <C> 48.2 <C> 61.4 <C> 71.8 <C> 81.9 <C> 67.0 <C> 83.7 <C> 93.2 <R> <C> Spectral Clust <C> 73.1 <C> 82.2 <C> 89.0 <C> 93.0 <C> 53.2 <C> 66.1 <C> 76.7 <C> 85.3 <C> 67.6 <C> 83.7 <C> 93.3 <R> <C> Proxy NCA <C> 73.2 <C> 82.4 <C> 86.4 <C> 88.7 <C> 49.2 <C> 61.9 <C> 67.9 <C> 72.4 <C> 73.7 <C> – <C> – <R> <C> RLL <C> 74.0 <C> 83.6 <C> 90.1 <C> 94.1 <C> 57.4 <C> [BOLD] 69.7 <C> 79.2 <C> [BOLD] 86.9 <C> 76.1 <C> 89.1 <C> 95.4 <R> <C> ICE <C> [BOLD] 77.0 <C> [BOLD] 85.3 <C> [BOLD] 91.3 <C> [BOLD] 94.8 <C> [BOLD] 58.3 <C> 69.5 <C> [BOLD] 79.4 <C> 86.7 <C> [BOLD] 77.3 <C> [BOLD] 90.0 <C> [BOLD] 95.6 <R> <C> RLL-(L,M,H) <C> 82.1 <C> 89.3 <C> 93.7 <C> 96.7 <C> 61.3 <C> 72.7 <C> 82.7 <C> 89.4 <C> 79.8 <C> 91.3 <C> 96.3 <R> <C> ICE-(L, M, H) <C> 82.8 <C> 89.5 <C> 93.7 <C> 96.4 <C> 61.4 <C> 73.2 <C> 82.5 <C> 89.2 <C> 80.1 <C> 91.8 <C> 96.6 <CAP> Table 3: Comparison with the state-of-the-art methods on CARS196, CUB-200-2011 and SOP in terms of Recall@K (%). All the compared methods use GoogLeNet V2 as the backbone architecture. ‘–’ means the results which are not reported in the original paper. The best results in the first block using single embedding are bolded.
<R> <C> [ITALIC] N=180, [ITALIC] s=64 <C> R@1 <C> R@10 <C> R@100 <R> <C> [ITALIC] C× [ITALIC] k=90×2 <C> 77.3 <C> 90.0 <C> 95.6 <R> <C> [ITALIC] C× [ITALIC] k=60×3 <C> 75.2 <C> 88.7 <C> 95.2 <R> <C> [ITALIC] C× [ITALIC] k=45×4 <C> 74.9 <C> 88.7 <C> 95.3 <R> <C> [ITALIC] C× [ITALIC] k=36×5 <C> 74.6 <C> 88.7 <C> 95.4 <CAP> Table 4: The impact of batch content C×k on SOP in terms of Recall@K (%). The batch size is N=180 and the scaling parameter is s=64.
<R> <C> [ITALIC] k=2, [ITALIC] s=64 <C> R@1 <C> R@10 <C> R@100 <R> <C> [ITALIC] N=180 <C> 77.3 <C> 90.0 <C> 95.6 <R> <C> [ITALIC] N=160 <C> 75.4 <C> 88.8 <C> 95.1 <R> <C> [ITALIC] N=140 <C> 75.1 <C> 88.7 <C> 95.2 <R> <C> [ITALIC] N=120 <C> 75.1 <C> 88.6 <C> 95.2 <R> <C> [ITALIC] N=100 <C> 74.4 <C> 88.2 <C> 95.1 <CAP> Table 5: The results of different batch size N on SOP in terms of Recall@K (%). While changing C, we fix k=2 and s=64. Therefore, N=C×2.
<R> <C> 180=90×2, [ITALIC] s=64 <C> R@1 <C> R@10 <C> R@100 <R> <C> 64 <C> 72.6 <C> 87.1 <C> 94.0 <R> <C> 128 <C> 74.3 <C> 87.9 <C> 94.5 <R> <C> 256 <C> 75.2 <C> 88.6 <C> 94.8 <R> <C> 512 <C> 77.3 <C> 90.0 <C> 95.6 <CAP> Table 6: The results of different embedding size on SOP in terms of Recall@K (%). In all experiments: s=64, C=90,k=2. N=C×k=90×2.
<R> <C> Method <C> Backbone <C> pretrained <C> sMOTSA <C> MOTSA <C> MOTSP <C> IDS <C> TP <C> FP <C> FN <R> <C> TrackR-CNN [voigtlaender2019mots] <C> TrackR-CNN/ResNet-101 <C> COCO + MOTS <C> 76.2 <C> 87.8 <C> [BOLD] 87.2 <C> 93 <C> 7276 <C> [BOLD] 134 <C> 753 <R> <C> Mask R-CNN + maskprop [voigtlaender2019mots] <C> Mask R-CNN/ResNet-101 <C> COCO + MOTS <C> 75.1 <C> 86.6 <C> 87.1 <C> – <C> – <C> – <C> – <R> <C> CAMOT [ovsep2018track] <C> TrackR-CNN/ResNet-101 <C> COCO + MOTS <C> 67.4 <C> 78.6 <C> 86.5 <C> 220 <C> 6702 <C> 172 <C> 1327 <R> <C> CIWT [osep2017combined] <C> TrackR-CNN/ResNet-101 <C> COCO + MOTS <C> 68.1 <C> 79.4 <C> 86.7 <C> 106 <C> 6815 <C> 333 <C> 1214 <R> <C> Ours <C> PANet/ResNet-50 <C> COCO <C> 66.9 <C> 79.1 <C> 85.2 <C> (0) <C> 6647 <C> 291 <C> 1382 <R> <C> Ours <C> Mask R-CNN/ResNet-101 <C> COCO <C> 66.1 <C> 78.1 <C> 85.5 <C> (0) <C> 6614 <C> 347 <C> 1415 <R> <C> Ours <C> Mask R-CNN/ResNet-101 <C> COCO + MOTS <C> 77.4 <C> 89.6 <C> 86.6 <C> (0) <C> [BOLD] 7338 <C> 142 <C> [BOLD] 691 <CAP> Table 2: Validation of our auto-annotation for video instance segmentation on KITTI MOTS validation set (car class).
<R> <C> [BOLD] Model <C> [BOLD] Approach <C> [BOLD] Acc <C> [BOLD] DSP <C> [BOLD] CPU ‡ <C> [BOLD] VPU <C> [BOLD] FLOPs <C> [BOLD] Supernet training <R> <C> [BOLD] Model <C> [BOLD] Approach <C> [BOLD] Acc <C> [BOLD] DSP <C> [BOLD] CPU ‡ <C> [BOLD] VPU <C> [BOLD] FLOPs <C> [BOLD] Time Reduction (%) <R> <C> [BOLD] Model <C> [BOLD] Approach <C> [BOLD] (%) <C> [BOLD] (ms) <C> [BOLD] (ms) <C> [BOLD] (ms) <C> [BOLD] FLOPs <C> [BOLD]  [ITALIC] Stage1 /  [ITALIC] Stage1+ [ITALIC] Stage2 † <R> <C> MobileNetV2  <C> Manual <C> 72.00 <C> 10.1 <C> 432.4 <C> 45.2 <C> 300M <C> - <R> <C> MobileNetV3-Large1.0  <C> RL  <C> 75.20 <C> 48.3 <C> 411.4 <C> 43.9 <C> 219M <C> - <R> <C> MnasNet-A1  <C> RL <C> 75.20 <C> 149.0 <C> 1056.1 <C> 52.4 <C> 312M <C> - <R> <C> FBNet-iPhoneX  <C> gradient <C> 73.20 <C> 105.0 <C> 313.0 <C> 45.6 <C> 322M <C> - <R> <C> FBNet-S8  <C> gradient <C> 73.27 <C> 293.0 <C> 369.6 <C> 45.1 <C> 293M <C> - <R> <C> Proxyless-R (mobile)  <C> gradient <C> 74.60 <C> 534.6 <C> 616.5 <C> 53.1 <C> 333M <C> - <R> <C> {Singlepath-Oneshot}⋆  <C> oneshot <C> 74.30 <C> 270.6 <C> 455.8 <C> 38.7 <C> 319M <C> 0 <R> <C> [ITALIC]  [BOLD] HURRICANE (DSP) <C> oneshot <C> [BOLD] 76.67 <C> [BOLD] 16.5 <C> 576.7 <C> 45.4 <C> 709M <C> 61.4 ( [ITALIC] 76.57) / 36.4 ( [ITALIC] 76.63) <R> <C> [ITALIC]  [BOLD] HURRICANE (CPU) <C> oneshot <C> [BOLD] 74.59 <C> 80.1 <C> [BOLD] 301.3 <C> 38.9 <C> 327M <C> 57.7 ( [ITALIC] 74.59) / 33.9 ( [ITALIC] 74.59) <R> <C> [ITALIC]  [BOLD] HURRICANE (VPU) <C> oneshot <C> [BOLD] 75.13 <C> 390.8 <C> 645.3 <C> [BOLD] 35.6 <C> 409M <C> 45.0 ( [ITALIC] 74.63) / 20.8 ( [ITALIC] 75.13) <CAP> Table 3: Compared with various state-of-the-art efficient models on ImageNet, HURRICANE is the only NAS method that achieves high accuracy and low latency on all the target hardware. Results suggest FLOPs is not the accurate metric that indicates actual inference latency. As the hardware measurement settings in related NAS works are different, we measure the latency on our hardware platforms. ‡: CPU latency is measured on a single CPU core with float32 precision. ⋆: For fair comparison, we use the block search model instead of the block search+ channel search. †: In the form ”x(y)”, where ”x” means the training time reduction and ”y” means the accuracy achieved.
<R> <C> [BOLD] Task <C> [BOLD] Dataset <C> [BOLD] Search Space <C> [BOLD] Singlepath-Oneshot  [ITALIC] (20  [ITALIC] layers) <C> [BOLD] Singlepath-Oneshot  [ITALIC] (20  [ITALIC] layers) <C> [BOLD] HURRICANE  [ITALIC] ( [ITALIC] Stage1: 12 layers) <C> [BOLD] HURRICANE  [ITALIC] ( [ITALIC] Stage1: 12 layers) <C> [BOLD] HURRICANE  [ITALIC] ( [ITALIC] Stage1+ [ITALIC] Stage2: 20 layers) <C> [BOLD] HURRICANE  [ITALIC] ( [ITALIC] Stage1+ [ITALIC] Stage2: 20 layers) <R> <C> [BOLD] Task <C> [BOLD] Dataset <C> [BOLD] Search Space <C> [BOLD] Acc <C> [BOLD] Train <C> [BOLD] Acc <C> [BOLD] Train <C> [BOLD] Acc <C> [BOLD] Train <R> <C> [BOLD] Task <C> [BOLD] Dataset <C> [BOLD] Search Space <C> [BOLD] (%) <C> [BOLD] iters (#) <C> [BOLD] (%) <C> [BOLD] iters (#) <C> [BOLD] (%) <C> [BOLD] iters (#) <R> <C> 1 <C> ImageNet <C> Manually-designed  <C> 73.72 <C> 144,360 <C> 74.01 <C> 72,180 <C> 74.16 <C> 105,864 <R> <C> 2 <C> OUI <C> Manually-designed  <C> 86.41 <C> 235,800 <C> 86.44 <C> 112,660 <C> 86.90 <C> 133,620 <R> <C> 3 <C> OUI <C> Hardware-aware (DSP) <C> 87.22 <C> 569,850 <C> 86.56 <C> 128,380 <C> 87.62 <C> 150,650 <R> <C> 4 <C> OUI <C> Hardware-aware (CPU) <C> 87.02 <C> 476,840 <C> 86.75 <C> 144,100 <C> 87.33 <C> 168,990 <R> <C> 5 <C> OUI <C> Hardware-aware (VPU) <C> 86.99 <C> 524,000 <C> 86.93 <C> 133,620 <C> 87.07 <C> 157,200 <CAP> Table 5: Compared to Singlepath-Oneshot [9], our two-stage search method achieves higher accuracy with much less search cost (26.7%-73.6%) on both manually-designed and hardware-aware search spaces. We list out the training iterations on ImageNet (batchsize=1,024) and OUI (batchsize=64) for search cost comparison.
<R> <C> Source of  [ITALIC] wi to form  [ITALIC] x={ [ITALIC] w1, [ITALIC] w2} <C> Network after the encoder <C> Accuracy [%]  [ITALIC] y<15 <C> Accuracy [%]  [ITALIC] y≥15 <R> <C> MNIST training dataset <C> SEQL <C> 92 <C> 87 <R> <C> MNIST training dataset <C> ReLU <C> 93 <C> 0.8 <R> <C> MNIST test dataset <C> SEQL <C> 91 <C> 83 <R> <C> MNIST test dataset <C> ReLU <C> 92 <C> 0.6 <CAP> TABLE II: MNIST Arithmetic Generalization Results
<R> <C> Comparison Between DGD, APC and Algorithm  1  with Optimal Parameters on  [ITALIC] “bcsstm07”; regarding (a) Number of Iterations to Attain a Relative Estimation Error 10−4, <C> Comparison Between DGD, APC and Algorithm  1  with Optimal Parameters on  [ITALIC] “bcsstm07”; regarding (a) Number of Iterations to Attain a Relative Estimation Error 10−4, <C> Comparison Between DGD, APC and Algorithm  1  with Optimal Parameters on  [ITALIC] “bcsstm07”; regarding (a) Number of Iterations to Attain a Relative Estimation Error 10−4, <C> Comparison Between DGD, APC and Algorithm  1  with Optimal Parameters on  [ITALIC] “bcsstm07”; regarding (a) Number of Iterations to Attain a Relative Estimation Error 10−4, <R> <C> and (b) Decay rate of the Instantaneous Error-norm. Here,  [ITALIC] cond( [ITALIC] ATA)=5.8∗107. <C> and (b) Decay rate of the Instantaneous Error-norm. Here,  [ITALIC] cond( [ITALIC] ATA)=5.8∗107. <C> and (b) Decay rate of the Instantaneous Error-norm. Here,  [ITALIC] cond( [ITALIC] ATA)=5.8∗107. <C> and (b) Decay rate of the Instantaneous Error-norm. Here,  [ITALIC] cond( [ITALIC] ATA)=5.8∗107. <R> <C> Algorithm <C> DGD <C> APC <C> Algo.  1  ( [ITALIC] β=5, [ITALIC] K(−1)= [ITALIC] On× [ITALIC] n) <R> <C> (a) Iterations needed <C> >105 <C> 4.85∗104 <C> 2.11∗104 <R> <C> (b) Rate of Decrease <C> 0.9999 <C> 0.9672 <C> 0.9583+4.3∗108∗(0.9999) [ITALIC] t+1 <CAP> TABLE I:
<R> <C> [EMPTY] <C> [ITALIC] LAC128 <C> [ITALIC] LAC256 <C> [ITALIC] LAC512 <C> [ITALIC] LAC1 [ITALIC] K <R> <C> AlexNet <C> 2.03 <C> 2.44 <C> 2.92 <C> 1.88 <R> <C> GoogLeNet <C> 1.84 <C> 2.32 <C> 2.76 <C> 1.75 <R> <C> VGG_S <C> 2.43 <C> 3.04 <C> 3.63 <C> 2.31 <R> <C> VGG_M <C> 2.18 <C> 2.73 <C> 3.26 <C> 2.02 <R> <C> AlexNet-Sparse <C> 2.81 <C> 2.91 <C> 3.49 <C> 2.19 <R> <C> ResNet-Sparse <C> 1.69 <C> 2.02 <C> 2.41 <C> 1.61 <R> <C> Geomean <C> 2.13 <C> 2.55 <C> 3.05 <C> 1.95 <CAP> Table 2: Laconic energy efficiency relative to BASE2K.
<R> <C> [BOLD] Method <C> [BOLD] Source →  [BOLD] Target <C> [BOLD] # labeled <C> [BOLD] Accuracy <R> <C> Standard <C> MNIST / notMNIST <C> 50 <C> 34.02% <R> <C> TE <C> MNIST / notMNIST <C> 50 <C> 37.28% <R> <C> Mk-MMD <C> MNIST / notMNIST <C> 50 <C> 46.72% <R> <C> Lautum <C> MNIST / notMNIST <C> 50 <C> 47.96% <R> <C> Lautum + TE <C> MNIST / notMNIST <C> 50 <C> 66.91% <R> <C> Standard <C> MNIST / notMNIST <C> 100 <C> 57.58% <R> <C> TE <C> MNIST / notMNIST <C> 100 <C> 61.45% <R> <C> Mk-MMD <C> MNIST / notMNIST <C> 100 <C> 63.32% <R> <C> Lautum <C> MNIST / notMNIST <C> 100 <C> 65.21% <R> <C> Lautum + TE <C> MNIST / notMNIST <C> 100 <C> 77.32% <R> <C> Standard <C> MNIST / notMNIST <C> 200 <C> 67.78% <R> <C> TE <C> MNIST / notMNIST <C> 200 <C> 74.87% <R> <C> Mk-MMD <C> MNIST / notMNIST <C> 200 <C> 80.35% <R> <C> Lautum <C> MNIST / notMNIST <C> 200 <C> 83.77% <R> <C> Lautum + TE <C> MNIST / notMNIST <C> 200 <C> 85.25% <CAP> TABLE I: target test set accuracy comparison between standard transfer learning, Temporal Ensembling (TE), Mk-MMD, Lautum regularization and both TE and Lautum regularization for different amounts of labeled training target samples, MNIST → notMNIST.
<R> <C> [BOLD] Method <C> [BOLD] Source →  [BOLD] Target <C> [BOLD] # labeled <C> [BOLD] Accuracy <R> <C> Standard <C> CIFAR-10 / 100 <C> 100 <C> 39.90% <R> <C> TE <C> CIFAR-10 / 100 <C> 100 <C> 42.20% <R> <C> Mk-MMD <C> CIFAR-10 / 100 <C> 100 <C> 45.30% <R> <C> Lautum <C> CIFAR-10 / 100 <C> 100 <C> 46.70% <R> <C> Lautum + TE <C> CIFAR-10 / 100 <C> 100 <C> 46.90% <R> <C> Standard <C> CIFAR-10 / 100 <C> 200 <C> 52.80% <R> <C> TE <C> CIFAR-10 / 100 <C> 200 <C> 54.60% <R> <C> Mk-MMD <C> CIFAR-10 / 100 <C> 200 <C> 59.30% <R> <C> Lautum <C> CIFAR-10 / 100 <C> 200 <C> 60.90% <R> <C> Lautum + TE <C> CIFAR-10 / 100 <C> 200 <C> 60.40% <R> <C> Standard <C> CIFAR-10 / 100 <C> 500 <C> 64.50% <R> <C> TE <C> CIFAR-10 / 100 <C> 500 <C> 66.50% <R> <C> Mk-MMD <C> CIFAR-10 / 100 <C> 500 <C> 68.00% <R> <C> Lautum <C> CIFAR-10 / 100 <C> 500 <C> 70.80% <R> <C> Lautum + TE <C> CIFAR-10 / 100 <C> 500 <C> 70.30% <CAP> TABLE II: target test set accuracy comparison between standard transfer learning, Temporal Ensembling (TE), Mk-MMD, Lautum regularization and both TE and Lautum regularization for different amounts of labeled training target samples, CIFAR-10 → CIFAR-100 (10 classes).
<R> <C> [EMPTY] <C> [BOLD] Simple Traffic Control (4 cars) reward <C> [BOLD] Simple Traffic Control (4 cars) delay <C> [BOLD] Simple Traffic Control (4 cars) # C <C> [BOLD] Simple Traffic Control (4 cars) message <C> [BOLD] Moderate Traffic Control (8 cars) reward <C> [BOLD] Moderate Traffic Control (8 cars) delay <C> [BOLD] Moderate Traffic Control (8 cars) # C <C> [BOLD] Moderate Traffic Control (8 cars) message <C> [BOLD] Complex Traffic Control (16 cars) reward <C> [BOLD] Complex Traffic Control (16 cars) delay <C> [BOLD] Complex Traffic Control (16 cars) # C <C> [BOLD] Complex Traffic Control (16 cars) message <R> <C> CommNet <C> -129.2 <C> 45.6 <C> 2.3 <C> 100.0% <C> -573.4 <C> 61.6 <C> 6.8 <C> 100.0% <C> -4278.8 <C> 82.1 <C> 16.5 <C> 100.0% <R> <C> AMP <C> -97.1 <C> 41.8 <C> [BOLD] 1.2 <C> 100.0% <C> -1950.6 <C> 100.0 <C> [BOLD] 0.9 <C> 100.0% <C> -6391.5 <C> 100.0 <C> [BOLD] 2.1 <C> 100.0% <R> <C> ACML <C> [BOLD] -37.6 <C> [BOLD] 31.2 <C> 1.9 <C> 100.0% <C> [BOLD] -103.5 <C> [BOLD] 43.1 <C> 1.7 <C> 100.0% <C> [BOLD] -2824.9 <C> [BOLD] 66.4 <C> 7.2 <C> 100.0% <R> <C> ACML-mean <C> -32.9 <C> 29.3 <C> 2.0 <C> 100.0% <C> -96.1 <C> 40.2 <C> 3.9 <C> 100.0% <C> -2661.5 <C> 61.4 <C> 9.4 <C> 100.0% <R> <C> ACML-attention <C> -24.5 <C> 28.8 <C> 1.6 <C> 100.0% <C> -91.8 <C> 39.6 <C> 1.3 <C> 100.0% <C> -2359.7 <C> 52.9 <C> 6.8 <C> 100.0% <R> <C> Gated-CommNet <C> -88.4 <C> 41.1 <C> 1.7 <C> 22.8% <C> -476.7 <C> 47.2 <C> 2.5 <C> 34.3% <C> -3529.4 <C> 73.0 <C> 15.7 <C> 29.3% <R> <C> Gated-AMP <C> -59.9 <C> 37.1 <C> [BOLD] 1.3 <C> [BOLD] 18.6% <C> -988.6 <C> 65.3 <C> [BOLD] 1.6 <C> [BOLD] 23.7% <C> -2870.5 <C> 65.5 <C> [BOLD] 7.9 <C> [BOLD] 19.1% <R> <C> Gated-ACML <C> [BOLD] -14.6 <C> [BOLD] 21.0 <C> 2.4 <C> 23.9% <C> [BOLD] -69.4 <C> [BOLD] 32.3 <C> 2.1 <C> 29.8% <C> [BOLD] -2101.1 <C> [BOLD] 48.6 <C> 11.3 <C> 25.8% <R> <C> ATOC <C> -19.7 <C> 25.9 <C> 1.9 <C> 37.3% <C> -77.5 <C> 35.6 <C> 2.4 <C> 63.7% <C> -2481.2 <C> 54.8 <C> 14.9 <C> [ITALIC] 112.5% <CAP> Table 1: The average results of 10 experiments on traffic control tasks. For models named as Gated-*, dynamic thresholds with β=0.8 are used. The “delay” indicates the timesteps to complete the simulation. The “# C” indicates the number of collisions.
<R> <C> [EMPTY] <C> [BOLD] Simple Routing reward <C> [BOLD] Simple Routing message <C> [BOLD] Moderate Routing reward <C> [BOLD] Moderate Routing message <C> [BOLD] Complex Routing reward <C> [BOLD] Complex Routing message <C> [BOLD] Simple WAPC. reward <C> [BOLD] Simple WAPC. message <C> [BOLD] Complex WAPC. reward <C> [BOLD] Complex WAPC. message <R> <C> CommNet <C> 0.264 <C> 100.0% <C> 0.164 <C> 100.0% <C> - <C> 100.0% <C> 0.652 <C> 100.0% <C> 0.441 <C> 100.0% <R> <C> AMP <C> 0.266 <C> 100.0% <C> 0.185 <C> 100.0% <C> - <C> 100.0% <C> 0.627 <C> 100.0% <C> 0.418 <C> 100.0% <R> <C> ACML <C> [BOLD] 0.317 <C> 100.0% <C> [BOLD] 0.263 <C> 100.0% <C> - <C> 100.0% <C> [BOLD] 0.665 <C> 100.0% <C> [BOLD] 0.480 <C> 100.0% <R> <C> ACML-mean <C> 0.321 <C> 100.0% <C> 0.267 <C> 100.0% <C> - <C> 100.0% <C> 0.673 <C> 100.0% <C> 0.493 <C> 100.0% <R> <C> ACML-attention <C> 0.329 <C> 100.0% <C> 0.271 <C> 100.0% <C> - <C> 100.0% <C> 0.689 <C> 100.0% <C> 0.506 <C> 100.0% <R> <C> Gated-CommNet <C> 0.232 <C> 35.2% <C> 0.144 <C> [BOLD] 21.7% <C> - <C> 19.8% <C> 0.595 <C> 53.1% <C> 0.386 <C> 41.8% <R> <C> Gated-AMP <C> 0.241 <C> 46.7% <C> 0.170 <C> 35.0% <C> - <C> 81.7% <C> 0.539 <C> 57.2% <C> 0.350 <C> [BOLD] 32.3% <R> <C> Gated-ACML <C> 0.288 <C> [BOLD] 33.6% <C> [BOLD] 0.239 <C> 27.9% <C> - <C> 22.6% <C> [BOLD] 0.610 <C> [BOLD] 41.9% <C> [BOLD] 0.411 <C> 37.7% <R> <C> ATOC <C> [BOLD] 0.297 <C> 73.7% <C> 0.102 <C> [ITALIC] 104.6% <C> - <C> [ITALIC] 326.1% <C> 0.418 <C> [ITALIC] 136.5% <C> 0.231 <C> [ITALIC] 393.4% <CAP> Table 2: The average results of 10 experiments on packet routing and wifi access point configuration tasks. For models named as Gated-*, we adopt dynamic thresholds with β=0.8. The “WAPC.” is the abbreviation of Wifi Access Point Configuration.
<R> <C> [ITALIC] Tm% <C> Simple Routing  [ITALIC] pruned message <C> Simple Routing reward  [ITALIC] decrease <C> Moderate Routing  [ITALIC] pruned message <C> Moderate Routing reward  [ITALIC] decrease <R> <C> 10.0% <C> 12.19% <C> [BOLD] -8.46% <C> 11.60% <C> [BOLD] -7.03% <R> <C> 20.0% <C> 24.07% <C> [BOLD] -13.59% <C> 22.77% <C> [BOLD] -12.14% <R> <C> 30.0% <C> 27.65% <C> [BOLD] -4.88% <C> 29.98% <C> [BOLD] -3.25% <R> <C> 70.0% <C> 66.73% <C> 9.27% <C> 68.54% <C> 10.06% <R> <C> 80.0% <C> [BOLD] 79.14% <C> [BOLD] 14.01% <C> 76.81% <C> 13.25% <R> <C> 90.0% <C> 87.22% <C> 18.60% <C> 85.11% <C> 19.50% <R> <C> 100.0% <C> 100.00% <C> 59.35% <C> 100.00% <C> 65.42% <CAP> Table 3: The results of Gated-ACML in packet routing scenarios. We adopt a fixed threshold T=LΔQ(oi)[K×Tm%].
<R> <C> [EMPTY] <C> BG+Hair <C> Face <C> Eyebr. <C> Eyes <C> Mouth <R> <C> Bald <C> [BOLD] 3.675 <C> 3.000 <C> 1.080 <C> 1.400 <C> [ITALIC] 0.984 <R> <C> Bangs <C> 3.051 <C> [BOLD] 3.343 <C> 0.997 <C> [ITALIC] 0.380 <C> 0.641 <R> <C> Bla. Hair <C> [BOLD] 3.227 <C> 1.494 <C> 0.980 <C> [ITALIC] 0.360 <C> 0.488 <R> <C> Blo. Hair <C> [BOLD] 5.155 <C> 2.390 <C> 1.395 <C> [ITALIC] 0.585 <C> 0.937 <R> <C> Bro. Hair <C> [BOLD] 1.576 <C> 1.249 <C> 0.423 <C> [ITALIC] 0.250 <C> 0.414 <R> <C> B. Eyebr. <C> [BOLD] 1.605 <C> 0.576 <C> 1.086 <C> [ITALIC] 0.267 <C> 0.303 <R> <C> Glasses <C> 1.421 <C> [BOLD] 2.422 <C> 1.636 <C> 2.388 <C> [ITALIC] 0.669 <R> <C> Male <C> 2.305 <C> [BOLD] 3.052 <C> 1.979 <C> 1.877 <C> [ITALIC] 0.932 <R> <C> M. Open <C> 0.416 <C> 1.035 <C> 0.663 <C> [ITALIC] 0.243 <C> [BOLD] 3.276 <R> <C> Mustache <C> 1.126 <C> [BOLD] 2.956 <C> 1.495 <C> [ITALIC] 1.057 <C> 1.557 <R> <C> No Beard <C> 1.520 <C> [BOLD] 2.549 <C> 1.543 <C> 1.144 <C> [ITALIC] 1.054 <R> <C> Pale Skin <C> 1.877 <C> [BOLD] 3.623 <C> 2.000 <C> [ITALIC] 1.292 <C> 2.609 <R> <C> Young <C> [BOLD] 1.927 <C> 1.677 <C> 0.990 <C> 1.214 <C> [ITALIC] 0.386 <CAP> Table 1: L2-norm distances between the center of samples for which an attribute is true and the center of samples for which it is not true (cmp. Fig. 8). The first 3 components of the PCA are used.
<R> <C> [EMPTY] <C> Reward <R> <C> GP-PTR-IRL <C> 9.51 ± 4.92 <R> <C> GP-ME-IRL [levine2011nonlinear] <C> 9.58 ± 4.90 <R> <C> GP-Increasing-IRL [angelov2019composing] <C> 7.39 ± 5.72 <CAP> TABLE I: Averaged total returns using VI policy trained using inferred reward from optimal demonstrations.
<R> <C> [EMPTY] <C> Reward <R> <C> GP-PTR-IRL <C> 7.42 ± 4.82 <R> <C> GP-ME-IRL [levine2011nonlinear] <C> 3.31 ± 4.24 <R> <C> GP-Increasing-IRL [angelov2019composing] <C> 2.77 ± 4.30 <CAP> TABLE II: Averaged total returns using VI policy trained using inferred reward from sub-optimal demonstrations.
<R> <C> [EMPTY] <C> Train Category <C> Train Category <C> Train Category <R> <C> [EMPTY] <C> 37.1 <C> 23.7 <C> 8.3 <R> <C> [EMPTY] <C> 32.6 <C> 33.5 <C> 8.8 <R> <C> [EMPTY] <C> 30.9 <C> 18.8 <C> 33.4 <CAP> Table 2: Cross-validation experiments for analyzing how part knowledge transfers across category boundaries.
<R> <C> Context <C> [EMPTY] <C> Seen Category <C> Seen Category <C> Seen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <R> <C> w/ <C> L1 <C> 62.7 <C> 68.9 <C> 24.7 <C> 38.1 <C> 14.4 <C> 57.5 <C> 71.3 <C> 57.4 <C> 33.9 <C> 70 <R> <C> w/ <C> L2 <C> 47.6 <C> 57.5 <C> 20.8 <C> - <C> 12.3 <C> - <C> - <C> - <C> 27.9 <C> - <R> <C> w/ <C> L3 <C> 41.5 <C> 44.5 <C> 19.7 <C> - <C> 10.9 <C> 34.6 <C> - <C> 25.6 <C> 19 <C> 60.7 <R> <C> w/ <C> Avg <C> [BOLD] 50.6 <C> [BOLD] 57 <C> [BOLD] 21.7 <C> 38.1 <C> [BOLD] 12.3 <C> 46.1 <C> 71.3 <C> 41.5 <C> 26.9 <C> 65.4 <R> <C> w/o <C> L1 <C> 59.8 <C> 67 <C> 24.4 <C> 41.6 <C> 12 <C> 61.9 <C> 72.2 <C> 57.6 <C> 40.8 <C> 71.9 <R> <C> w/o <C> L2 <C> 44.6 <C> 55.2 <C> 19.2 <C> - <C> 10.6 <C> - <C> - <C> - <C> 32.6 <C> - <R> <C> w/o <C> L3 <C> 39.1 <C> 42.9 <C> 18.1 <C> - <C> 8.7 <C> 36.5 <C> - <C> 27.1 <C> 20.1 <C> 62.1 <R> <C> w/o <C> Avg <C> 47.8 <C> 55 <C> 20.6 <C> [BOLD] 41.6 <C> 10.4 <C> [BOLD] 49.2 <C> [BOLD] 72.2 <C> [BOLD] 42.4 <C> [BOLD] 31.2 <C> [BOLD] 67 <CAP> Table 3: Quantitative evaluation of involving more context. w/ and w/o denote making decision with and without involving more context, respectively. Note that we only introduce more context in the late grouping process and the involved context is restricted in a very local region. The number is the mean recall of segmentation results. The L1, L2 and L3 refer to the three levels of segmentation defined in PartNet. Avg is the average among mean recall of three levels segmentation results.
<R> <C> [EMPTY] <C> Seen Category <C> Seen Category <C> Seen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <R> <C> no purity <C> 38.6 <C> 36.8 <C> 5.6 <C> 30.3 <C> 7.0 <C> 29.4 <C> 63 <C> 21.1 <C> 10.9 <C> 53.5 <R> <C> no rectification <C> 38.4 <C> 36.4 <C> 5.5 <C> 29.7 <C> 6.9 <C> 27.5 <C> 57.6 <C> 22.1 <C> 10.3 <C> 52.8 <R> <C> full-model <C> 38.8 <C> 37.6 <C> 5.7 <C> 33.1 <C> 7.2 <C> 32.6 <C> 66.5 <C> 23.0 <C> 10.5 <C> 55.2 <CAP> Table 4: Quantitative results of the components analysis. We train the models on the Chair, Lamp, Storage Furniture of level-3 annotations and test on the listed categories. The number is the mean recall of the most fine-grained annotations of each category.
<R> <C> [EMPTY] <C> Seen Category <C> Seen Category <C> Seen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <R> <C> PosAcc <C> 94.1 <C> 95.8 <C> 91.7 <C> 88.7 <C> 86.7 <C> 97.1 <C> 97.1 <C> 88.2 <C> 87.7 <C> 90.6 <C> 84.3 <C> 88.3 <R> <C> NegAcc <C> 66.5 <C> 61.3 <C> 73.8 <C> 59.9 <C> 64.9 <C> 12.9 <C> 20.2 <C> 20.3 <C> 42 <C> 66 <C> 60.6 <C> 31.9 <R> <C> [EMPTY] <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <C> Unseen Category <R> <C> PosAcc <C> 96.4 <C> 98.1 <C> 98.6 <C> 98.1 <C> 97 <C> 86.2 <C> 96.3 <C> 86.3 <C> 91.7 <C> 95.9 <C> 93.6 <C> 89.1 <R> <C> NegAcc <C> 39.4 <C> 40.7 <C> 3.8 <C> 33.7 <C> 77.6 <C> 42.8 <C> 45.5 <C> 46.9 <C> 62.3 <C> 67.7 <C> 31.1 <C> 36.2 <CAP> Table 5: Quantitative evaluation of the sub-part proposal module. PosAcc and NegAcc refer to positive accuracy and negative accuracy of the binary segmentation.
<R> <C> [BOLD] Algorithm <C> [BOLD] Dataset Movielens <C> [BOLD] Dataset DBLP <C> [BOLD] Dataset MIT <C> [BOLD] Dataset Yelp <C> [BOLD] Dataset Douban <R> <C> DeepWalk <C> 0.847 <C> 0.794 <C> 0.899 <C> 0.842 <C> 0.687 <R> <C> HARP(DW) <C> 0.817 <C> 0.659 <C> 0.902 <C> 0.743 <C> 0.559 <R> <C> HSRL(DW) <C> [BOLD] 0.879† <C> [BOLD] 0.847† <C> [BOLD] 0.926† <C> [BOLD] 0.901† <C> [BOLD] 0.842† <R> <C> Gain of HSRL(%) <C> [BOLD] 3.6 <C> [BOLD] 6.3 <C> [BOLD] 2.9 <C> [BOLD] 6.5 <C> [BOLD] 18.4 <R> <C> node2vec <C> 0.843 <C> 0.673 <C> 0.843 <C> 0.742 <C> 0.569 <R> <C> HARP(N2V) <C> 0.828 <C> 0.647 <C> 0.879 <C> 0.708 <C> 0.552 <R> <C> HSRL(N2V) <C> [BOLD] 0.865† <C> [BOLD] 0.840† <C> [BOLD] 0.921† <C> [BOLD] 0.892† <C> [BOLD] 0.819† <R> <C> Gain of HSRL(%) <C> [BOLD] 2.5 <C> [BOLD] 19.9 <C> [BOLD] 8.5 <C> [BOLD] 16.8 <C> [BOLD] 30.5 <R> <C> LINE <C> 0.613 <C> 0.641 <C> 0.814 <C> 0.752 <C> 0.624 <R> <C> HARP(LINE) <C> 0.220 <C> 0.387 <C> 0.702 <C> 0.306 <C> 0.399 <R> <C> HSRL(LINE) <C> [BOLD] 0.735† <C> [BOLD] 0.664† <C> [BOLD] 0.819 <C> [BOLD] 0.799† <C> [BOLD] 0.756† <R> <C> Gain of HSRL(%) <C> [BOLD] 16.6 <C> [BOLD] 3.5 <C> [BOLD] 0.5 <C> [BOLD] 5.9 <C> [BOLD] 17.5 <CAP> TABLE II: AUC of link prediction.
<R> <C> Learning algorithm <C> Maximal disturbance in  [ITALIC] Ns Sagittal <C> Maximal disturbance in  [ITALIC] Ns Lateral <R> <C> TRPO <C> 240 <C> 78 <R> <C> DDPG <C> 75 <C> 160 <R> <C> PPO <C> 192 <C> 36 <R> <C> Baseline from ( 6 ) <C> 53 <C> 78 <CAP> TABLE I: Maximal rejectable impulses for the various learning algorithms without taking steps.
<R> <C> [EMPTY] <C> A: Wieber 2006a [cite:wieber2006TrajectoryFree] <C> B: Wieber 2006b [WIEBER2006559] <C> C: Stephens 2010 [cite:stephens2010PushRecovery] <C> D: Urata 2011 [cite:urata2011OnlineDecision] <C> E: Sagittal push w/o foot stepping <C> F: Sagittal push w/ foot stepping <C> G: Lateral push w/o foot stepping <R> <C> Robot <C> HRP-2 <C> Biped model <C> Sarcos Primus <C> HRP3L-JSK <C> Valkyrie <C> Valkyrie <C> Valkyrie <R> <C> Robot height [ [ITALIC] m] <C> 1.539 <C> 1.425 <C> 1.575 <C> [EMPTY] <C> 1.8 <C> 1.8 <C> 1.8 <R> <C> CoM height [ [ITALIC] m] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 0.803 <C> 1.1 <C> 1.1 <C> 1.1 <R> <C> Mass [ [ITALIC] kg] <C> 58 <C> 40 <C> 92 <C> 53 <C> 137 <C> 137 <C> 137 <R> <C> Force [ [ITALIC] N] <C> 1500 <C> 750.0 <C> [EMPTY] <C> 597 <C> 600 <C> 2000 <C> 650 <R> <C> Interval [ [ITALIC] s] <C> 0.025 <C> 0.025 <C> [EMPTY] <C> 0.05 <C> 0.12 <C> 0.12 <C> 0.12 <R> <C> Impulse [ [ITALIC] Ns] <C> 37.5 <C> 18.8 <C> 42.0 <C> 29.9 <C> 72.0 <C> 240.0 <C> 78.0 <R> <C> Normalized impulse [ [ITALIC] Nskg] <C> 0.6 <C> 0.52 <C> 0.52 <C> 0.6 <C> 0.57 <C> 1.73 <C> 0.56 <R> <C> Stepping <C> No <C> No <C> Yes <C> Yes <C> No <C> Yes <C> No <R> <C> Simulated <C> Yes <C> Yes <C> No <C> No <C> Yes <C> Yes <C> Yes <CAP> TABLE IV: Push disturbance from various push recovery studies
<R> <C> [EMPTY] <C> Peak joint torque [ [ITALIC] N] Torso pitch <C> Peak joint torque [ [ITALIC] N] Hip pitch <C> Peak joint torque [ [ITALIC] N] Hip Roll <C> Peak joint torque [ [ITALIC] N] Knee pitch <C> Peak joint torque [ [ITALIC] N] Ankle Pitch <C> Peak joint torque [ [ITALIC] N] Ankle Roll <C> Peak joint velocity [ [ITALIC] rad/ [ITALIC] s] Torso pitch <C> Peak joint velocity [ [ITALIC] rad/ [ITALIC] s] Hip pitch <C> Peak joint velocity [ [ITALIC] rad/ [ITALIC] s] Hip Roll <C> Peak joint velocity [ [ITALIC] rad/ [ITALIC] s] Knee pitch <C> Peak joint velocity [ [ITALIC] rad/ [ITALIC] s] Ankle Pitch <C> Peak joint velocity [ [ITALIC] rad/ [ITALIC] s] Ankle Roll <R> <C> Joint limit <C> 150 <C> 350 <C> 350 <C> 350 <C> 205 <C> 205 <C> 9.00 <C> 6.11 <C> 6.11 <C> 11.00 <C> 11.00 <C> 11.00 <R> <C> Nominal standing <C> 68.4 <C> 39.5 <C> 57.1 <C> 122 <C> 44.9 <C> 46.2 <C> 0.0 <C> 0.0 <C> 0.0 <C> 0.0 <C> 0.0 <C> 0.0 <R> <C> 0.55m Drop <C> 150 <C> 221 <C> 350 <C> 350 <C> 205 <C> 205 <C> 4.69 <C> 2.01 <C> 6.11 <C> 9.95 <C> 11.0 <C> 11.0 <R> <C> 78 [ITALIC] Ns Pelvis (lateral) <C> 104 <C> 147 <C> 103 <C> 264 <C> 117 <C> 106 <C> 0.15 <C> 0.58 <C> 0.46 <C> 1.09 <C> 0.96 <C> 11.0 <R> <C> 240 [ITALIC] Ns Pelvis (sagittal) <C> 150 <C> 187 <C> 350 <C> 350 <C> 205 <C> 205 <C> 6.49 <C> 1.47 <C> 6.11 <C> 5.69 <C> 11.0 <C> 11.0 <CAP> TABLE V: Peak torques and velocities for different scenarios.
<R> <C> [ITALIC] Tpred=3.2 [ITALIC] s <C> Model \Dataset <C> ETH Hotel <C> ETH Univ <C> UCY Zara01 <C> UCY Zara02 <C> Average <R> <C> Average <C> LSTM <C> 0.039± 0.001 <C> 0.146± 0.006 <C> 0.020± 0.000 <C> [BOLD] 0.024± 0.000 <C> 0.057 ± 0.002 <R> <C> Displacement <C> S-LSTM <C> 0.041± 0.002 <C> 0.133± 0.007 <C> 0.020± 0.000 <C> 0.026± 0.000 <C> 0.055± 0.002 <R> <C> Error <C> [BOLD] RDB (ours) <C> [BOLD] 0.037± 0.001 <C> [BOLD] 0.113± 0.002 <C> [BOLD] 0.017± 0.000 <C> [BOLD] 0.024± 0.000 <C> [BOLD] 0.048± 0.001 <R> <C> Final <C> LSTM <C> 0.093± 0.003 <C> 0.041± 0.002 <C> 0.056± 0.001 <C> 0.066± 0.001 <C> 0.064 ± 0.002 <R> <C> Displacement <C> S-LSTM <C> 0.101± 0.003 <C> 0.036± 0.002 <C> 0.062± 0.002 <C> 0.071± 0.002 <C> 0.068± 0.004 <R> <C> Error <C> [BOLD] RDB (ours) <C> [BOLD] 0.086± 0.003 <C> [BOLD] 0.029± 0.001 <C> [BOLD] 0.049± 0.001 <C> 0.068 ± 0.003 <C> [BOLD] 0.058± 0.003 <R> <C> [ITALIC] Tpred=4.8 [ITALIC] s <C> Model \Dataset <C> ETH Hotel <C> ETH Univ <C> UCY Zara01 <C> UCY Zara02 <C> Average <R> <C> Average <C> LSTM <C> 0.082± 0.003 <C> 0.245± 0.021 <C> 0.053± 0.000 <C> 0.055± 0.002 <C> 0.109± 0.007 <R> <C> Displacement <C> Social LSTM <C> 0.080± 0.004 <C> 0.235± 0.019 <C> 0.049± 0.001 <C> 0.066± 0.003 <C> 0.108± 0.007 <R> <C> Error <C> [BOLD] RDB (ours) <C> [BOLD] 0.073± 0.003 <C> [BOLD] 0.182± 0.009 <C> [BOLD] 0.046± 0.000 <C> 0.063± 0.003 <C> [BOLD] 0.091± 0.004 <R> <C> Final <C> LSTM <C> 0.207± 0.009 <C> 0.051± 0.004 <C> 0.160± 0.003 <C> 0.163± 0.005 <C> 0.145± 0.005 <R> <C> Displacement <C> Social LSTM <C> 0.184± 0.011 <C> 0.049± 0.003 <C> 0.196± 0.004 <C> 0.197± 0.008 <C> 0.157± 0.007 <R> <C> Error <C> [BOLD] RDB (ours) <C> [BOLD] 0.164± 0.009 <C> [BOLD] 0.033± 0.003 <C> [BOLD] 0.136± 0.005 <C> 0.190± 0.007 <C> [BOLD] 0.131± 0.006 <CAP> Table 1: Reported results assume observation length of Tobs=1.6sec and prediction lengths of Tpred=3.2sec and Tpred=4.8sec. First 4 rows correspond to the Average Displacement Error and last 4 to the final displacement error. Each result represents an average obtained from 5 independent runs with different random seeds.
<R> <C> Dataset \Model <C> B <C> R+B <C> D+B <C> R+D+B <R> <C> ETH Hotel <C> 0.039± 0.002 <C> 0.045± 0.002 <C> 0.042± 0.001 <C> [BOLD] 0.037± 0.001 <R> <C> ETH Univ <C> 0.146± 0.006 <C> 0.136± 0.002 <C> 0.133± 0.002 <C> [BOLD] 0.113± 0.007 <R> <C> UCY Zara01 <C> 0.020± 0.000 <C> 0.031± 0.000 <C> 0.021± 0.000 <C> [BOLD] 0.017± 0.000 <R> <C> UCY Zara02 <C> [BOLD] 0.024± 0.000 <C> 0.029± 0.000 <C> [BOLD] 0.024± 0.000 <C> [BOLD] 0.024± 0.000 <R> <C> Average <C> 0.057± 0.002 <C> 0.060± 0.001 <C> 0.055± 0.001 <C> [BOLD] 0.048± 0.001 <CAP> Table 2: Ablation Table
<R> <C> Dataset <C> BP <C> DNI (3) <C> Critic (3) <C> LC (1) <C> LC (3) <C> LC (5) <R> <C> CIFAR-10 <C> 93.93 ±0.20 <C> 64.86 ±0.42 <C> 91.92 ±0.30 <C> 92.06 ±0.20 <C> 92.39 ±0.09 <C> 91.38 ±0.20 <R> <C> CIFAR-100 <C> 75.14 ±0.18 <C> 36.53 ±0.64 <C> 69.07 ±0.25 <C> 73.61 ±0.31 <C> 69.91 ±0.50 <C> 63.53 ±0.24 <CAP> TABLE I: Average test accuracy (%) of backpropagation (BP), DNI [8], critic training [3], and proposed local critic training (LC). The numbers of local networks used are shown in the parentheses. The standard deviation values are also shown.
<R> <C> Dataset <C> [1,1,1] (default) <C> [3,3,3] <C> [5,5,5] <C> [3,2,1] <C> [1,2,3] <C> [5,4,3] <C> [3,4,5] <R> <C> CIFAR-10 <C> 92.39 ±0.09 <C> 92.36 ±0.22 <C> 91.72 ±0.19 <C> 92.07 ±0.21 <C> 92.20 ±0.12 <C> 92.10 ±0.16 <C> 91.90 ±0.16 <R> <C> CIFAR-100 <C> 69.91 ±0.50 <C> 70.02 ±0.29 <C> 70.34 ±0.16 <C> 70.06 ±0.64 <C> 69.81 ±0.33 <C> 70.87 ±0.40 <C> 69.93 ±0.56 <CAP> TABLE II: Average test accuracy (%) with respect to the number of layers in the local critic networks. [a,b,c] means that the numbers of convolutional layers in LC1, LC2, and LC3 are a, b, and c, respectively.
<R> <C> model <C> FLOP <C> # of parameters <R> <C> Sub-model 1 <C> 2.85M <C> 1.42M <R> <C> Sub-model 2 <C> 1.76M <C> 0.88M <R> <C> Sub-model 3 <C> 4.52M <C> 2.26M <R> <C> Main model <C> 15.72M <C> 7.87M <CAP> TABLE V: FLOPs required for a feedforward pass and numbers of model parameters in the sub-models and main model for CIFAR-10. Note that sub-model 2 has less FLOPs and parameters than sub-model 1 due to the pooling operation in sub-model 2.
<R> <C> Dataset <C> 1/1 <C> 1/2 <C> 1/3 <C> 1/4 <C> 1/5 <R> <C> CIFAR-10 <C> 92.39 ±0.09 <C> 91.91 ±0.19 <C> 91.78 ±0.18 <C> 91.57 ±0.12 <C> 91.35 ±0.17 <R> <C> CIFAR-100 <C> 69.91 ±0.50 <C> 67.99 ±0.49 <C> 67.76±0.19 <C> 66.74 ±0.41 <C> 66.39 ±0.39 <CAP> TABLE III: Average test accuracy (%) with respect to the update frequency of local critic networks.
<R> <C> Dataset <C> BP sub 1 <C> LC sub 1 <C> BP sub 2 <C> LC sub 2 <C> BP sub 3 <C> LC sub 3 <R> <C> CIFAR-10 <C> 74.46 ±0.91 <C> 85.24 ±0.49 <C> 88.03 ±0.87 <C> 90.53 ±0.15 <C> 92.05 ±0.24 <C> 92.29 ±0.09 <R> <C> CIFAR-100 <C> 47.58 ±1.10 <C> 55.39 ±0.57 <C> 61.79 ±0.92 <C> 63.62 ±0.31 <C> 67.81 ±0.22 <C> 67.54 ±0.70 <CAP> TABLE IV: Average test accuracy (%) of the sub-models produced by local critic training and the networks trained by regular backpropagation.
<R> <C> [EMPTY] <C> FLOP <C> Accuracy (%) <R> <C> Progressive inference (0.9) <C> 2.90M <C> 91.18 ±0.10 <R> <C> Progressive inference (0.95) <C> 3.05M <C> 91.75 ±0.16 <R> <C> Main model <C> 15.72M <C> 92.39 ±0.09 <CAP> TABLE VI: Average FLOPs and accuracy of progressive inference for test data of CIFAR-10 when the threshold is set to 0.9 or 0.95.
<R> <C> Subsample size <C> 200 <C> 400 <C> 800 <C> 1200 <C> 1500 <C> 2000 <R> <C> CF <C> 0.035 <C> 0.021 <C> 0.015 <C> 0.014 <C> 0.011 <C> 0.007 <R> <C> LLCF <C> 0.027 <C> 0.017 <C> 0.013 <C> 0.013 <C> 0.011 <C> 0.006 <CAP> Table 1: Estimated in-sample MSE (13) of estimating the treatment effect on subsampled welfare data, averaged over 200 runs at each subsample size. We show estimated error from local linear causal forests (LLCF) and standard causal forests (CF). Tuning parameters were selected via cross-validation using the R-learner objective.
<R> <C> [ITALIC] d <C> [ITALIC] n <C> [ITALIC] σ <C> RF <C> Lasso- RF <C> LLF <C> BART <C> XGBoost <R> <C> 5 <C> 1000 <C> 0.1 <C> 0.10 <C> 0.06 <C> [BOLD] 0.02 <C> 0.27 <C> 0.07 <R> <C> 5 <C> 5000 <C> 0.1 <C> 0.06 <C> [BOLD] 0.02 <C> [BOLD] 0.02 <C> 0.22 <C> 0.06 <R> <C> 50 <C> 1000 <C> 0.1 <C> 0.29 <C> 0.18 <C> 0.11 <C> 0.52 <C> [BOLD] 0.07 <R> <C> 50 <C> 5000 <C> 0.1 <C> 0.18 <C> 0.10 <C> 0.07 <C> 0.62 <C> [BOLD] 0.06 <R> <C> 5 <C> 1000 <C> 1 <C> 0.21 <C> 0.24 <C> [BOLD] 0.14 <C> 0.47 <C> 0.56 <R> <C> 5 <C> 5000 <C> 1 <C> 0.15 <C> 0.11 <C> [BOLD] 0.09 <C> 0.26 <C> 0.52 <R> <C> 50 <C> 1000 <C> 1 <C> 0.41 <C> 0.39 <C> [BOLD] 0.20 <C> 0.82 <C> 0.53 <R> <C> 50 <C> 5000 <C> 1 <C> 0.23 <C> 0.21 <C> [BOLD] 0.10 <C> 0.57 <C> 0.52 <R> <C> 5 <C> 1000 <C> 2 <C> 0.31 <C> 0.55 <C> [BOLD] 0.26 <C> 0.69 <C> 1.21 <R> <C> 5 <C> 5000 <C> 2 <C> 0.25 <C> 0.28 <C> [BOLD] 0.21 <C> 0.40 <C> 1.18 <R> <C> 50 <C> 1000 <C> 2 <C> 0.47 <C> 0.27 <C> [BOLD] 0.24 <C> 0.89 <C> 1.22 <R> <C> 50 <C> 5000 <C> 2 <C> 0.33 <C> 0.27 <C> [BOLD] 0.15 <C> 0.70 <C> 0.96 <CAP> Table 5: RMSE from simulations on equation 1 on random forests, lasso-random forest, local linear forests, BART, and boosting. We vary sample size n, error variance σ, and ambient dimension d, and report test error on 1000 test points. We estimate Var[E[Y∣X]] as 3.52 over 10,000 Monte Carlo repetitions, so that signal-to-noise ratio ranges from 352 at σ=0.1 to 0.88 at σ=2. All errors are averaged over 50 runs, and minimizing errors are in bold.
<R> <C> [BOLD] Global Graph Recovery <C> [BOLD] ML <C> [BOLD] precision 86.98% <C> [BOLD] recall 90.79% <C> [BOLD] F-score  [BOLD] 88.84% <C> [BOLD] MSE  [BOLD] 1.6E-03 <R> <C> [EMPTY] <C> [BOLD] GL-informed <C> 81.26% <C> 88.91% <C> 84.48% <C> 2.6E-03 <R> <C> [EMPTY] <C> [BOLD] GL-conv <C> 63.82% <C> 100% <C> 77.41% <C> 2.1E-03 <R> <C> [BOLD] Mask Recovery <C> [BOLD] ML <C> 92.57% <C> 94.88% <C> 93.68% <C> - <CAP> TABLE I: Global Graph Recovery and Mask Recovery Performances
<R> <C> Measurement <C> GPS <C> Altitude <R> <C> Temperature <C> 36% <C> 64% <R> <C> Snowfall (cm) <C> 37% <C> 63% <R> <C> Humidity <C> 51% <C> 49% <R> <C> Precipitation (mm) <C> 52% <C> 48% <R> <C> Cloudy days <C> 65% <C> 35% <R> <C> Sunshine (h) <C> 54% <C> 46% <CAP> TABLE II: Contribution of layers on the structure of different measurements
<R> <C> Dataset <C> proposed <C> edit distance <R> <C> Strings <C> [BOLD] 1.29 ± 0.098 sec <C> 23.7 ± 0.09 sec <R> <C> Glycan_SP <C> [BOLD] 0.665 ± 0.059 sec <C> 28.4 ± 2.21 sec <R> <C> Glycan_EL <C> [BOLD] 0.249 ± 0.121 sec <C> 182.9 ± 8.86 sec <R> <C> Words <C> [BOLD] 41.3 ± 0.31 sec <C> 283.9 ± 5.18 sec <R> <C> Sentiment <C> [BOLD] 1.79 ± 0.105 sec <C> 9013 ± 770 sec <CAP> Table 3: Mean inference time of the 3-nearest neighbor classifier in each dataset. The first column specifies the dataset. The second column shows the inference time of the 3-nearest neighbor classifier using the weighted pq-gram distance. The third column shows that the inference time of the 3-nearest neighbor classifier using the tree edit distance.
<R> <C> [BOLD] Model <C> [BOLD] LSTM <C> [BOLD] LSTMD <C> [BOLD] PG <C> [BOLD] PGIS <C> [BOLD] AC <C> [BOLD] PGU <C> [BOLD] ACU <C> [BOLD] IRecGAN <R> <C> [BOLD] P@10 (%) <C> 32.89±0.50 <C> 33.42±0.40 <C> 33.28±0.71 <C> 28.13±0.45 <C> 31.93±0.17 <C> 34.12±0.52 <C> 32.43±0.22 <C> [BOLD] 35.06±0.48 <R> <C> [BOLD] P@1 (%) <C> 8.20±0.65 <C> [BOLD] 8.55±0.63 <C> 6.25±0.14 <C> 4.61±0.73 <C> 6.54±0.19 <C> 6.44±0.56 <C> 6.63± 0.29 <C> 6.79±0.44 <CAP> Table 1: Rerank evaluation on real-world dataset with random splitting.
<R> <C> [BOLD] Model <C> [BOLD] LSTM <C> [BOLD] LSTMD <C> [BOLD] PG <C> [BOLD] PGIS <C> [BOLD] AC <C> [BOLD] PGU <C> [BOLD] ACU <C> [BOLD] IRecGAN <R> <C> [BOLD] P@10 (%) <C> 28.79±0.44 <C> 31.98±0.64 <C> 32.44±1.16 <C> 30.72±0.37 <C> 29.26±0.79 <C> 30.33±0.47 <C> 28.53±0.35 <C> [BOLD] 33.45±0.71 <R> <C> [BOLD] P@1 (%, all) <C> 9.64±0.38 <C> [BOLD] 11.26±0.34 <C> 8.40±0.18 <C> 7.67±0.31 <C> 7.33±0.41 <C> 8.27±0.44 <C> 7.08±0.32 <C> 9.78±0.37 <R> <C> [BOLD] P@1 (%) <C> 9.68±0.29 <C> [BOLD] 11.06±0.23 <C> 6.83±0.38 <C> 6.09±0.19 <C> 6.11±0.18 <C> 6.67±0.51 <C> 5.86±0.26 <C> 7.84±0.25 <CAP> Table 2: Rerank evaluation on real-world recommendation dataset when split by session ID.
<R> <C> Observation rate  [ITALIC] ρ Treatment effect  [ITALIC] μ <C> Observation rate  [ITALIC] ρ Treatment effect  [ITALIC] μ <C> 0.1 1 <C> 0.1 2 <C> 0.1 5 <C> 0.3 1 <C> 0.3 2 <C> 0.3 5 <C> 0.5 1 <C> 0.5 2 <C> 0.5 5 <R> <C> MSE( [ITALIC] Y) <C> fPCA <C> 0.521 <C> 2.172 <C> 5.455 <C> 0.525 <C> 2.039 <C> 5.170 <C> 0.525 <C> 2.036 <C> 5.166 <R> <C> MSE( [ITALIC] Y) <C> SLI <C> 0.430 <C> 1.162 <C> 2.561 <C> 0.379 <C> 0.658 <C> 1.203 <C> 0.341 <C> 0.543 <C> 0.893 <R> <C> MSE( [ITALIC] Y) <C> CSI <C> 0.311 <C> 0.306 <C> 0.318 <C> 0.314 <C> 0.297 <C> 0.320 <C> 0.294 <C> 0.299 <C> 0.295 <CAP> Table 1: Comparisons between fPCA, SLI and CSI under different values of ρ and μ.
<R> <C> Type <C> Cardinality <C> Reward <C> BLER <C> SE <C> BER <R> <C> QL-AMC <C> 10 <C> BLER <C> 0.0320 <C> 3.6700 <C> 0.0088 <R> <C> QL-AMC <C> 15 <C> BLER <C> 0.0306 <C> 3.3238 <C> 0.0087 <R> <C> QL-AMC <C> 30 <C> BLER <C> 0.0302 <C> 3.5594 <C> 0.0087 <R> <C> QL-AMC <C> 60 <C> BLER <C> 0.0306 <C> 3.8783 <C> 0.0087 <R> <C> QL-AMC <C> 10 <C> SE <C> 0.0306 <C> 3.9187 <C> 0.0086 <R> <C> QL-AMC <C> 15 <C> SE <C> 0.0301 <C> 3.8207 <C> 0.0085 <R> <C> QL-AMC <C> 30 <C> SE <C> 0.0310 <C> 3.9922 <C> 0.0086 <R> <C> QL-AMC <C> 60 <C> SE <C> 0.0311 <C> 4.1553 <C> 0.0086 <R> <C> Table <C> - <C> - <C> 0.0311 <C> 3.8704 <C> 0.0088 <R> <C> OLLA 1 <C> - <C> - <C> 0.0309 <C> 3.6700 <C> 0.0088 <R> <C> OLLA 2 <C> - <C> - <C> 0.0330 <C> 1.8511 <C> 0.0090 <R> <C> OLLA 3 <C> - <C> - <C> 0.0343 <C> 0.9999 <C> 0.0092 <CAP> TABLE III: Deployment Phase Results (Average over 200 runs)
<R> <C> [EMPTY] <C> mean <C> scaled mean <C> sd <R> <C> CSI <C> 74.28 <C> 0.62 <C> 8.90 <R> <C> SLI <C> 79.92 <C> 0.66 <C> 9.22 <R> <C> fPCA <C> 127.73 <C> 1.06 <C> 13.54 <R> <C> rMean <C> 87.26 <C> 0.73 <C> 8.96 <R> <C> pMean <C> 119.80 <C> 1.00 <C> 12.84 <CAP> Figure 2: Test error on GDI dataset
<R> <C> [EMPTY] <C> [ITALIC] N=2,  [ITALIC] D=2 point <C> [ITALIC] N=2,  [ITALIC] D=2 MoG-1 <C> [ITALIC] N=2,  [ITALIC] D=2 MoG-2 <C> [ITALIC] N=2,  [ITALIC] D=3 point <C> [ITALIC] N=2,  [ITALIC] D=3 MoG-1 <C> [ITALIC] N=2,  [ITALIC] D=3 MoG-2 <C> [ITALIC] N=3,  [ITALIC] D=2 point <C> [ITALIC] N=3,  [ITALIC] D=2 MoG-1 <C> [ITALIC] N=3,  [ITALIC] D=2 MoG-2 <C> [ITALIC] N=3,  [ITALIC] D=3 point <C> [ITALIC] N=3,  [ITALIC] D=3 MoG-1 <C> [ITALIC] N=3,  [ITALIC] D=3 MoG-2 <R> <C> [BOLD] Verification AP <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.987 <C> 0.989 <C> 0.990 <C> 0.996 <C> 0.996 <C> 0.996 <C> 0.978 <C> 0.981 <C> 0.976 <C> 0.987 <C> 0.989 <C> 0.991 <R> <C> corrupt <C> 0.880 <C> 0.907 <C> 0.912 <C> 0.913 <C> 0.926 <C> 0.932 <C> 0.886 <C> 0.899 <C> 0.904 <C> 0.901 <C> 0.922 <C> 0.925 <R> <C> [BOLD] KNN Accuracy <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.871 <C> 0.879 <C> 0.888 <C> 0.942 <C> 0.953 <C> 0.939 <C> 0.554 <C> 0.591 <C> 0.540 <C> 0.795 <C> 0.770 <C> 0.766 <R> <C> corrupt <C> 0.583 <C> 0.760 <C> 0.757 <C> 0.874 <C> 0.909 <C> 0.885 <C> 0.274 <C> 0.350 <C> 0.351 <C> 0.522 <C> 0.555 <C> 0.598 <CAP> Table 1: Accuracy of pairwise verification and KNN identification tasks for point embeddings, and our hedged embeddings with a single Gaussian component (MoG-1) and two components (MoG-2). We report results for images with N digits and using D embedding dimensions.
<R> <C> [EMPTY] <C> [ITALIC] N=2,  [ITALIC] D=2 MoG-1 <C> [ITALIC] N=2,  [ITALIC] D=2 MoG-2 <C> [ITALIC] N=2,  [ITALIC] D=3 MoG-1 <C> [ITALIC] N=2,  [ITALIC] D=3 MoG-2 <C> [ITALIC] N=3,  [ITALIC] D=2 MoG-1 <C> [ITALIC] N=3,  [ITALIC] D=2 MoG-2 <C> [ITALIC] N=3,  [ITALIC] D=3 MoG-1 <C> [ITALIC] N=3,  [ITALIC] D=3 MoG-2 <R> <C> [BOLD] AP Correlation <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.74 <C> 0.43 <C> 0.68 <C> 0.48 <C> 0.63 <C> 0.28 <C> 0.51 <C> 0.39 <R> <C> corrupt <C> 0.81 <C> 0.79 <C> 0.86 <C> 0.87 <C> 0.82 <C> 0.76 <C> 0.85 <C> 0.79 <R> <C> [BOLD] KNN Correlation <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.71 <C> 0.57 <C> 0.72 <C> 0.47 <C> 0.76 <C> 0.29 <C> 0.74 <C> 0.54 <R> <C> corrupt <C> 0.47 <C> 0.43 <C> 0.55 <C> 0.52 <C> 0.49 <C> 0.50 <C> 0.67 <C> 0.34 <CAP> Table 1: Accuracy of pairwise verification and KNN identification tasks for point embeddings, and our hedged embeddings with a single Gaussian component (MoG-1) and two components (MoG-2). We report results for images with N digits and using D embedding dimensions.
<R> <C> [EMPTY] <C> [ITALIC] N=3,  [ITALIC] D=4 point <C> [ITALIC] N=3,  [ITALIC] D=4 MoG-1 <C> [ITALIC] N=3,  [ITALIC] D=4 MoG-2 <R> <C> [BOLD] Verification AP <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.996 <C> 0.996 <C> 0.995 <R> <C> corrupt <C> 0.942 <C> 0.944 <C> 0.948 <R> <C> [BOLD] KNN Accuracy <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.914 <C> 0.917 <C> 0.922 <R> <C> corrupt <C> 0.803 <C> 0.816 <C> 0.809 <CAP> Table 4: Task performance and uncertainty measure correlations with task performance for 4D embeddings with 3-digit MNIST. (a) Task accuracies for pairwise verification and KNN identification.
<R> <C> [EMPTY] <C> [ITALIC] N=3,  [ITALIC] D=4 MoG-1 <C> [ITALIC] N=3,  [ITALIC] D=4 MoG-2 <R> <C> [BOLD] AP Correlation <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.35 <C> 0.33 <R> <C> corrupt <C> 0.79 <C> 0.68 <R> <C> [BOLD] KNN Correlation <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.31 <C> 0.32 <R> <C> corrupt <C> 0.42 <C> 0.35 <CAP> Table 4: Task performance and uncertainty measure correlations with task performance for 4D embeddings with 3-digit MNIST. (b) Correlations between uncertainty, η(x), and task performances.
<R> <C> [ITALIC] β <C> [ITALIC] N=2,  [ITALIC] D=2 0 <C> [ITALIC] N=2,  [ITALIC] D=2 10−4 <C> [ITALIC] N=3,  [ITALIC] D=3 0 <C> [ITALIC] N=3,  [ITALIC] D=3 10−4 <R> <C> [BOLD] Verification AP <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.986 <C> 0.988 <C> 0.993 <C> 0.992 <R> <C> corrupt <C> 0.900 <C> 0.906 <C> 0.932 <C> 0.932 <R> <C> [BOLD] KNN Accuracy <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.867 <C> 0.891 <C> 0.858 <C> 0.861 <R> <C> corrupt <C> 0.729 <C> 0.781 <C> 0.685 <C> 0.730 <CAP> Table 5: Results for single Gaussian embeddings with and without KL divergence term. We report results for images with N digits and using D embedding dimensions. (a) Task performances.
<R> <C> [ITALIC] β <C> [ITALIC] N=2,  [ITALIC] D=2 0 <C> [ITALIC] N=2,  [ITALIC] D=2 10−4 <C> [ITALIC] N=3,  [ITALIC] D=3 0 <C> [ITALIC] N=3,  [ITALIC] D=3 10−4 <R> <C> [BOLD] AP Correlation <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.680 <C> 0.766 <C> 0.425 <C> 0.630 <R> <C> corrupt <C> 0.864 <C> 0.836 <C> 0.677 <C> 0.764 <R> <C> [BOLD] KNN Correlation <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> clean <C> 0.748 <C> 0.800 <C> -0.080 <C> 0.685 <R> <C> corrupt <C> 0.636 <C> 0.609 <C> 0.183 <C> 0.549 <CAP> Table 5: Results for single Gaussian embeddings with and without KL divergence term. We report results for images with N digits and using D embedding dimensions. (b) Uncertainty correlations.
<R> <C> [BOLD] Algorithms <C> [BOLD] AUC <R> <C> Binary Classifier <C> 50.0 <R> <C> M. Hasan  [ITALIC] et al.  <C> 50.6 <R> <C> C. Lu  [ITALIC] et al.  <C> 65.51 <R> <C> W. Sultani  [ITALIC] et al.  <C> 75.41 <R> <C> Proposed Method (3D ResNet + constr. + loss) <C> [BOLD] 75.62 <R> <C> Proposed Method (3D ResNet + constr. + new rank. loss) <C> [BOLD] 76.67 <CAP> TABLE I: Comparison of all the methods on the UCF-Crime Dataset.
<R> <C> Dataset <C> Model <C> FPR-95%-TPR <C> AUPR-Error <C> AUPR-Success <C> AUC <R> <C> [BOLD] MNIST MLP <C> Baseline (MCP)  hendrycks17baseline  <C> 14.87 <C> 37.70 <C> 99.94 <C> 97.13 <R> <C> [BOLD] MNIST MLP <C> MCDropout  Gal:2016:DBA:3045390.3045502  <C> 15.15 <C> 38.22 <C> 99.94 <C> 97.15 <R> <C> [BOLD] MNIST MLP <C> TrustScore  NIPS2018_7798  <C> 12.31 <C> 52.18 <C> 99.95 <C> 97.52 <R> <C> [BOLD] MNIST MLP <C> ConfidNet (Ours) <C> [BOLD] 11.79 <C> [BOLD] 57.37 <C> [BOLD] 99.95 <C> [BOLD] 97.83 <R> <C> [BOLD] MNIST Small ConvNet <C> Baseline (MCP)  hendrycks17baseline  <C> 5.56 <C> 35.05 <C> 99.99 <C> 98.63 <R> <C> [BOLD] MNIST Small ConvNet <C> MCDropout  Gal:2016:DBA:3045390.3045502  <C> 5.26 <C> 38.50 <C> 99.99 <C> 98.65 <R> <C> [BOLD] MNIST Small ConvNet <C> TrustScore  NIPS2018_7798  <C> 10.00 <C> 35.88 <C> 99.98 <C> 98.20 <R> <C> [BOLD] MNIST Small ConvNet <C> ConfidNet (Ours) <C> [BOLD] 3.33 <C> [BOLD] 45.89 <C> [BOLD] 99.99 <C> [BOLD] 98.82 <R> <C> [BOLD] SVHN Small ConvNet <C> Baseline (MCP)  hendrycks17baseline  <C> 31.28 <C> 48.18 <C> 99.54 <C> 93.20 <R> <C> [BOLD] SVHN Small ConvNet <C> MCDropout  Gal:2016:DBA:3045390.3045502  <C> 36.60 <C> 43.87 <C> 99.52 <C> 92.85 <R> <C> [BOLD] SVHN Small ConvNet <C> TrustScore  NIPS2018_7798  <C> 34.74 <C> 43.32 <C> 99.48 <C> 92.16 <R> <C> [BOLD] SVHN Small ConvNet <C> ConfidNet (Ours) <C> [BOLD] 28.58 <C> [BOLD] 50.72 <C> [BOLD] 99.55 <C> [BOLD] 93.44 <R> <C> [BOLD] CIFAR-10 VGG16 <C> Baseline (MCP)  hendrycks17baseline  <C> 47.50 <C> 45.36 <C> 99.19 <C> 91.53 <R> <C> [BOLD] CIFAR-10 VGG16 <C> MCDropout  Gal:2016:DBA:3045390.3045502  <C> 49.02 <C> 46.40 <C> [BOLD] 99.27 <C> 92.08 <R> <C> [BOLD] CIFAR-10 VGG16 <C> TrustScore  NIPS2018_7798  <C> 55.70 <C> 38.10 <C> 98.76 <C> 88.47 <R> <C> [BOLD] CIFAR-10 VGG16 <C> ConfidNet (Ours) <C> [BOLD] 44.94 <C> [BOLD] 49.94 <C> 99.24 <C> [BOLD] 92.12 <R> <C> [BOLD] CIFAR-100 VGG16 <C> Baseline (MCP)  hendrycks17baseline  <C> 67.86 <C> 71.99 <C> 92.49 <C> 85.67 <R> <C> [BOLD] CIFAR-100 VGG16 <C> MCDropout  Gal:2016:DBA:3045390.3045502  <C> 64.68 <C> 72.59 <C> [BOLD] 92.96 <C> 86.09 <R> <C> [BOLD] CIFAR-100 VGG16 <C> TrustScore  NIPS2018_7798  <C> 71.74 <C> 66.82 <C> 91.58 <C> 84.17 <R> <C> [BOLD] CIFAR-100 VGG16 <C> ConfidNet (Ours) <C> [BOLD] 62.96 <C> [BOLD] 73.68 <C> 92.68 <C> [BOLD] 86.28 <R> <C> [BOLD] CamVid SegNet <C> Baseline (MCP)  hendrycks17baseline  <C> 63.87 <C> 48.53 <C> 96.37 <C> 84.42 <R> <C> [BOLD] CamVid SegNet <C> MCDropout  Gal:2016:DBA:3045390.3045502  <C> 62.95 <C> 49.35 <C> 96.40 <C> 84.58 <R> <C> [BOLD] CamVid SegNet <C> TrustScore  NIPS2018_7798  <C> [EMPTY] <C> 20.42 <C> 92.72 <C> 68.33 <R> <C> [BOLD] CamVid SegNet <C> ConfidNet (Ours) <C> [BOLD] 61.52 <C> [BOLD] 50.51 <C> [BOLD] 96.58 <C> [BOLD] 85.02 <CAP> Table 1: Comparison of failure prediction methods on various datasets. All methods share the same classification network. Note that for MCDropout, test accuracy is averaged over random sampling. All values are percentages.
<R> <C> [EMPTY] <C> Cao [cao2017paf] MC∗ <C> NADS-Net (Ours) MC <C> NADS-Net (Ours) ND∗∗ <C> NADS-Net (Ours) All∗∗∗ <R> <C> Drivers <C> 80% <C> 81% <C> 75% <C> 88% <R> <C> Front Passengers <C> 85% <C> 89% <C> 78% <C> 90% <R> <C> Men <C> 84% <C> 87% <C> 79% <C> 90% <R> <C> Women <C> 79% <C> 81% <C> 73% <C> 88% <R> <C> White <C> 83% <C> 86% <C> 77% <C> 89% <R> <C> Black <C> 75% <C> 77% <C> 70% <C> 87% <R> <C> Asian <C> 85% <C> 87% <C> 80% <C> 91% <R> <C> Glasses <C> 83% <C> 83% <C> 75% <C> 89% <R> <C> Sunglasses <C> 78% <C> 82% <C> 72% <C> 85% <R> <C> Short Sleeves <C> 84% <C> 85% <C> 77% <C> 89% <R> <C> Long Sleeves <C> 85% <C> 87% <C> 78% <C> 90% <R> <C> Jacket/Coat <C> 79% <C> 81% <C> 75% <C> 88% <R> <C> Scarf <C> 82% <C> 84% <C> 78% <C> 91% <R> <C> Hat <C> 82% <C> 84% <C> 77% <C> 90% <R> <C> Beard <C> 82% <C> 87% <C> 81% <C> 90% <R> <C> Daytime <C> 85% <C> 86% <C> 77% <C> 89% <R> <C> Nighttime <C> 74% <C> 77% <C> 75% <C> 88% <R> <C> [BOLD] Overall <C> [BOLD] 82% <C> [BOLD] 84% <C> [BOLD] 77% <C> [BOLD] 89% <R> <C> ∗ Trained with MS-COCO data set only. <C> ∗ Trained with MS-COCO data set only. <C> ∗ Trained with MS-COCO data set only. <C> ∗ Trained with MS-COCO data set only. <C> ∗ Trained with MS-COCO data set only. <R> <C> ∗∗ Trained with new driving data set only. <C> ∗∗ Trained with new driving data set only. <C> ∗∗ Trained with new driving data set only. <C> ∗∗ Trained with new driving data set only. <C> ∗∗ Trained with new driving data set only. <R> <C> ∗∗∗ Trained with both data sets combined. <C> ∗∗∗ Trained with both data sets combined. <C> ∗∗∗ Trained with both data sets combined. <C> ∗∗∗ Trained with both data sets combined. <C> ∗∗∗ Trained with both data sets combined. <CAP> Table 2: Accuracy evaluation with mPCKh@0.5.
<R> <C> Model <C> QM9  [ITALIC] U0 <C> Mat.Proj. <C> OQMD <R> <C> V-RF <C> - <C> 76.8 (79.8) <C> 74.5 (75.1) <R> <C> SchNet <C> 13.6 (14.2) <C> 31.8 (33.3) <C> 27.5 (27.9) <R> <C> Proposed Model <C> [BOLD] 10.5 (11.1) <C> [BOLD] 22.7 (24.0) <C> [BOLD] 14.9 (15.2) <CAP> Table 2: Mean absolute error of formation energy predictions for V-RF, SchNet and the proposed model. For QM9 the error is in meV and for the Materials Project and OQMD the numbers are in meV/atom. The lowest error is highlighted in bold. We have obtained the V-RF results by running the implementation provided by the authors (Ward et al., 2017), while SchNet results have been obtained by running our own SchNet implementation. The numbers in parenthesis are the estimated 95th percentile, which have been obtained by sampling the test set (with replacement) 1×106 times.
<R> <C> Target <C> Unit <C> SchNet <C> enn-s2s <C> Proposed <C> (95th) <R> <C> [ITALIC] εHOMO <C> meV <C> 41 <C> 43 <C> [BOLD] 36.7 <C> (37.3) <R> <C> [ITALIC] εLUMO <C> meV <C> 34 <C> 37 <C> [BOLD] 30.8 <C> (31.3) <R> <C> Δ [ITALIC] ε <C> meV <C> 63 <C> 69 <C> [BOLD] 58.0 <C> (58.9) <R> <C> ZPVE <C> meV <C> 1.7 <C> [BOLD] 1.5 <C> [BOLD] 1.49 <C> (1.52) <R> <C> [ITALIC] μ <C> Debye <C> 0.033 <C> 0.030 <C> [BOLD] 0.029 <C> (0.029) <R> <C> [ITALIC] α <C> Bohr3 <C> 0.235 <C> 0.092 <C> [BOLD] 0.077 <C> (0.082) <R> <C> ⟨ [ITALIC] R2⟩ <C> Bohr2 <C> [BOLD] 0.073 <C> 0.180 <C> [BOLD] 0.072 <C> (0.075) <R> <C> [ITALIC] U0 <C> meV <C> 14 <C> 19 <C> [BOLD] 10.5 <C> (11.1) <R> <C> [ITALIC] U <C> meV <C> 19 <C> 19 <C> [BOLD] 10.6 <C> (11.2) <R> <C> [ITALIC] H <C> meV <C> 14 <C> 17 <C> [BOLD] 11.3 <C> (11.9) <R> <C> [ITALIC] G <C> meV <C> 14 <C> 19 <C> [BOLD] 12.2 <C> (12.7) <R> <C> [ITALIC] Cv <C> cal/molK <C> [BOLD] 0.033 <C> 0.040 <C> [BOLD] 0.032 <C> (0.033) <CAP> Table 3: Mean absolute error of predictions for different target properties of the QM9 dataset using 110k training examples. The lowest error is highlighted in bold. SchNet and enn-s2s results are from (Schütt et al., 2017c) and (Gilmer et al., 2017) respectively. The numbers in parenthesis are the estimated 95th percentile, which have been obtained by sampling the test set (with replacement) 1×106 times.
<R> <C> Choice of Interest <C> WaveNet <C> LSTM <R> <C> Number of Parameters <C> 32 <C> 2726 <R> <C> Optimization Objective <C> [ITALIC] MAE <C> [ITALIC] MAE <R> <C> Optimization Algorithm <C> [ITALIC] Adam <C> [ITALIC] Adam <R> <C> Learning Rate <C> 10−3 <C> 10−3 <R> <C> Initialization <C> [ITALIC] He <C> [ITALIC] Xavier <R> <C> L2 regularization <C> 10−3 <C> − <R> <C> Mini batch size <C> 32 <C> 32 <R> <C> Number epochs <C> 100 <C> 30 <R> <C> Training Set Size <C> 1000 <C> 1000 <CAP> Table 1: Training Choices: Unconditional Case
<R> <C> Model <C> x mean(std) <C> y mean(std) <C> z mean(std) <R> <C> Unconditional WaveNet <C> 0.00480(0.00008) <C> − <C> − <R> <C> Conditional WaveNet <C> 0.00047(0.00020) <C> 0.00750(−) <C> 0.00520(−) <R> <C> Multitask Conditional WaveNet <C> − <C> − <C> 0.00200(−) <R> <C> Conditional WaveNet - Lorenz parameters ( [ITALIC] σ=10, r=28, b=8/3) <C> 0.00110(0.00140) <C> 0.01200(0.00120) <C> 0.00950(0.00035) <R> <C> Unconditional LSTM random sampling <C> 0.00300(0.00008) <C> 0.00629(0.00043) <C> 0.00253(0.001) <R> <C> Unconditional LSTM random sampling: adjacent samples <C> 0.01200(0.0001) <C> 0.00700(−) <C> 0.00380(−) <R> <C> Conditional LSTM random sampling <C> 0.00313(0.00068) <C> 0.00176(0.00017) <C> 0.00250(0.00014) <R> <C> Conditional LSTM - Lorenz parameters ( [ITALIC] σ=10, r=28, b=8/3) <C> 0.00457(0.00045) <C> 0.005233(0.00130) <C> 0.01000(0.00082) <CAP> Table 2: Test set RMSE for one-step ahead forecast for x, y and z
<R> <C> [BOLD] Dataset <C> [BOLD] Year <C> [BOLD] Sce- nes <C> [BOLD] Size (hr) <C> [BOLD] RGB imgs <C> [BOLD] PCs lidar†† <C> [BOLD] PCs radar <C> [BOLD] Ann. frames <C> [BOLD] 3D boxes <C> [BOLD] Night / Rain <C> [BOLD] Map layers <C> [BOLD] Clas- ses <C> [BOLD] Locations <R> <C> CamVid  <C> 2008 <C> 4 <C> 0.4 <C> 18k <C> 0 <C> 0 <C> 700 <C> 0 <C> No/No <C> 0 <C> 32 <C> Cambridge <R> <C> Cityscapes  <C> 2016 <C> [EMPTY] <C> - <C> 25k <C> 0 <C> 0 <C> 25k <C> 0 <C> No/No <C> 0 <C> 30 <C> 50 cities <R> <C> Vistas  <C> 2017 <C> [EMPTY] <C> - <C> 25k <C> 0 <C> 0 <C> 25k <C> 0 <C> Yes/Yes <C> 0 <C> 152 <C> Global <R> <C> BDD100K  <C> 2017 <C> 100k <C> 1k <C> 100M <C> 0 <C> 0 <C> 100k <C> 0 <C> Yes/Yes <C> 0 <C> 10 <C> NY, SF <R> <C> ApolloScape  <C> 2018 <C> - <C> 100 <C> 144k <C> 0∗∗ <C> 0 <C> 144k <C> 70k <C> Yes/No <C> 0 <C> 8-35 <C> 4x China <R> <C> [ITALIC] D2-City  <C> 2019 <C> 1k† <C> - <C> 700k† <C> 0 <C> 0 <C> 700k† <C> 0 <C> No/Yes <C> 0 <C> 12 <C> 5x China <R> <C> KITTI  <C> 2012 <C> 22 <C> 1.5 <C> 15k <C> 15k <C> 0 <C> 15k <C> 200k <C> No/No <C> 0 <C> 8 <C> Karlsruhe <R> <C> AS lidar  <C> 2018 <C> - <C> 2 <C> 0 <C> 20k <C> 0 <C> 20k <C> 475k <C> -/- <C> 0 <C> 6 <C> China <R> <C> KAIST  <C> 2018 <C> - <C> - <C> 8.9k <C> 8.9k <C> 0 <C> 8.9k <C> 0 <C> [BOLD] Yes/No <C> 0 <C> 3 <C> Seoul <R> <C> H3D  <C> 2019 <C> 160 <C> 0.77 <C> 83k <C> 27k <C> 0 <C> 27k <C> 1.1M <C> No/No <C> 0 <C> 8 <C> SF <R> <C> nuScenes <C> 2019 <C> [BOLD] 1k <C> 5.5 <C> [BOLD] 1.4M <C> [BOLD] 400k <C> [BOLD] 1.3M <C> [BOLD] 40k <C> 1.4M <C> [BOLD] Yes/Yes <C> [BOLD] 11 <C> [BOLD] 23 <C> Boston, SG <R> <C> Argoverse  <C> 2019 <C> 113† <C> 0.6† <C> 490k† <C> 44k <C> 0 <C> 22k† <C> 993k† <C> [BOLD] Yes/Yes <C> 2 <C> 15 <C> Miami, PT <R> <C> Lyft L5  <C> 2019 <C> 366 <C> 2.5 <C> 323k <C> 46k <C> 0 <C> [BOLD] 46k <C> 1.3M <C> No/No <C> 7 <C> 9 <C> Palo Alto <R> <C> Waymo Open  <C> 2019 <C> [BOLD] 1k <C> 5.5 <C> 1M <C> 200k <C> 0 <C> [BOLD] 200k‡ <C> [BOLD] 12M‡ <C> [BOLD] Yes/Yes <C> 0 <C> 4 <C> 3x USA <R> <C> A∗3D  <C> 2019 <C> [EMPTY] <C> [BOLD] 55 <C> 39k <C> 39k <C> 0 <C> [BOLD] 39k <C> 230k <C> [BOLD] Yes/Yes <C> 0 <C> 7 <C> SG <R> <C> A2D2  <C> 2019 <C> [EMPTY] <C> - <C> - <C> - <C> 0 <C> 12k <C> - <C> -/- <C> 0 <C> 14 <C> 3x Germany <CAP> Table 1: AV dataset comparison. The top part of the table indicates datasets without range data. The middle and lower parts indicate datasets (not publications) with range data released until and after the initial release of this dataset. We use bold highlights to indicate the best entries in every column among the datasets with range data. Only datasets which provide annotations for at least car, pedestrian and bicycle are included in this comparison. (†) We report numbers only for scenes annotated with cuboids. (‡) The current Waymo Open dataset size is comparable to nuScenes, but at a 5x higher annotation frequency. (††) Lidar pointcloud count collected from each lidar. (**) [41] provides static depth maps. (-) indicates that no information is provided. SG: Singapore, NY: New York, SF: San Francisco, PT: Pittsburgh, AS: ApolloScape.
<R> <C> [BOLD] Method <C> [BOLD] NDS <C> [BOLD] mAP <C> [BOLD] mATE <C> [BOLD] mASE <C> [BOLD] mAOE <C> [BOLD] mAVE <C> [BOLD] mAAE <R> <C> (%) <C> (%) <C> (%) <C> (m) <C> (1-iou) <C> (rad) <C> (m/s) <C> (1-acc) <R> <C> OFT † <C> 21.2 <C> 12.6 <C> 0.82 <C> 0.36 <C> 0.85 <C> 1.73 <C> 0.48 <R> <C> SSD+3D† <C> 26.8 <C> 16.4 <C> 0.90 <C> 0.33 <C> 0.62 <C> 1.31 <C> 0.29 <R> <C> MDIS † <C> 38.4 <C> 30.4 <C> 0.74 <C> 0.26 <C> 0.55 <C> 1.55 <C> 0.13 <R> <C> PP  <C> 45.3 <C> 30.5 <C> 0.52 <C> 0.29 <C> 0.50 <C> 0.32 <C> 0.37 <R> <C> Megvii  <C> [BOLD] 63.3 <C> [BOLD] 52.8 <C> [BOLD] 0.30 <C> [BOLD] 0.25 <C> [BOLD] 0.38 <C> [BOLD] 0.25 <C> [BOLD] 0.14 <CAP> Table 4: Object detection results on the test set of nuScenes. PointPillars, OFT and SSD+3D are baselines provided in this paper, other methods are the top submissions to the nuScenes detection challenge leaderboard. (†) use only monocular camera images as input. All other methods use lidar. PP: PointPillars [51], MDIS: MonoDIS [70].
<R> <C> [BOLD] Lidar sweeps <C> [BOLD] Pretraining <C> [BOLD] NDS (%) <C> [BOLD] mAP (%) <C> [BOLD] mAVE (m/s) <R> <C> 1 <C> KITTI <C> 31.8 <C> 21.9 <C> 1.21 <R> <C> 5 <C> KITTI <C> 42.9 <C> 27.7 <C> 0.34 <R> <C> 10 <C> KITTI <C> [BOLD] 44.8 <C> 28.8 <C> 0.30 <R> <C> 10 <C> ImageNet <C> [BOLD] 44.9 <C> 28.9 <C> 0.31 <R> <C> 10 <C> None <C> 44.2 <C> 27.6 <C> 0.33 <CAP> Table 3: PointPillars [51] detection performance on the val set. We can see that more lidar sweeps lead to a significant performance increase and that pretraining with ImageNet is on par with KITTI.
<R> <C> [BOLD] Method <C> [BOLD] Singapore <C> [BOLD] Rain <C> [BOLD] Night <R> <C> OFT † <C> 6% <C> 10% <C> [BOLD] 55% <R> <C> MDIS † <C> 8% <C> -3% <C> [BOLD] 58% <R> <C> PP  <C> 1% <C> 6% <C> [BOLD] 36% <CAP> Table 6: Object detection performance drop evaluated on subsets of the nuScenes val set. Performance is reported as the relative drop in mAP compared to evaluating on the entire val set. We evaluate the performance on Singapore data, rain data and night data for three object detection methods. Note that the MDIS results are not directly comparable to other sections of this work, as a ResNet34 [39] backbone and a different training protocol are used. (†) use only monocular camera images as input. PP uses only lidar.
<R> <C> Device <C> CPU (FP32) <C> GPU (FP16) <R> <C> Samsung Galaxy S5 <C> 79 <C> 300 <R> <C> Samsung Galaxy S7 <C> 124 <C> 730 <R> <C> Samsung Galaxy S9 <C> 270 <C> 730 <CAP> Table 1: Example of available compute power on mobile in gigaflops (billion floating point instructions per second). FP16 and FP32 refer to 16- and 32-bit floating point arithmetic, respectively.
<R> <C> Adreno GPU Model <C> conv_2d <C> depthwise_conv <R> <C> 630 <C> (4,8,4) <C> (4,4,8) <R> <C> 540 <C> (8,2,2) <C> (8,8,2) <R> <C> 510 <C> (8,4,4) <C> (8,4,4) <R> <C> 509 <C> (8,4,8) <C> (8,4,2) <R> <C> 50X/4XX <C> (8,4,8) <C> (8,4,8) <CAP> Table 2: Optimal work group sizes for Adreno GPUs.
<R> <C> Strategy <C> MobileNet <C> MobileNetV2 <C> DeeplabV3 <R> <C> Naïve <C> 9.6 <C> 13.2 <C> 24.3 <R> <C> Greedy <C> [BOLD] 2.3 <C> 4.0 <C> [BOLD] 3.6 <R> <C> MCFP <C> 2.7 <C> [BOLD] 3.8 <C> 4.2 <CAP> Table 3: Total memory allocated (in MB) for all intermediate tensors. Naïve means no memory manager and serves as baseline. Bold number means the smallest memory footprint for each model.
<R> <C> Android Device <C> TFLite GPU <C> MACE <C> SNPE <R> <C> Samsung S9 <C> 13 <C> 12 <C> 6.9 <R> <C> (Adreno 630) <C> 13 <C> 12 <C> 6.9 <R> <C> Xiaomi Mi8 SE <C> 35.9 <C> 29.6 <C> 20 <R> <C> (Adreno 616) <C> 35.9 <C> 29.6 <C> 20 <R> <C> Huawei P20 Pro <C> 13.5 <C> 45 <C> N/A1 <R> <C> (Mali G72-MP12) <C> 13.5 <C> 45 <C> N/A1 <R> <C> Google Pixel 2 <C> 18 <C> N/A2 <C> N/A2 <R> <C> (Adreno 540) <C> 18 <C> N/A2 <C> N/A2 <R> <C> Google Pixel 3 <C> 12.5 <C> N/A2 <C> N/A2 <R> <C> 12.5 <C> N/A2 <C> N/A2 <C> [EMPTY] <R> <C> (Adreno 630) <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <CAP> Table 5: Average inference latency (in milliseconds) of Android-compatible ML frameworks on MobileNet v1. Note that TFLite GPU employs OpenGL and thus has the widest coverage with reasonable performance. MACE and SNPE employ OpenCL and may run faster on devices shipped with OpenCL, but may not run on all devices. 1 Arm Mali GPUs are not compatible with SNPE. 2 Google Pixel devices do not support OpenCL.
<R> <C> [BOLD] Algorithm/Algorithm <C> [BOLD] O_SVFDT-I <C> [BOLD] O_SVFDT-II <C> [BOLD] O_VFDT <C> [BOLD] SVFDT-I <C> [BOLD] SVFDT-II <C> [BOLD] VFDT <R> <C> [BOLD] O_SVFDT-I <C> – <C> 1 <C> 1 <C> 9 <C> 7 <C> 7 <R> <C> [BOLD] O_SVFDT-II <C> 6 <C> – <C> 1 <C> 8 <C> 9 <C> 7 <R> <C> [BOLD] O_VFDT <C> 9 <C> 8 <C> – <C> 9 <C> 8 <C> 8 <R> <C> [BOLD] SVFDT-I <C> 0 <C> 0 <C> 0 <C> – <C> 1 <C> 1 <R> <C> [BOLD] SVFDT-II <C> 0 <C> 0 <C> 0 <C> 5 <C> 0 <C> 0 <R> <C> [BOLD] VFDT <C> 3 <C> 2 <C> 1 <C> 7 <C> 6 <C> – <CAP> (a) Mean Accuracy
<R> <C> Biometric <C> Linear SVM Normal <C> Linear SVM Normal <C> Linear SVM Mitigation <C> Linear SVM Mitigation <C> Radial Svm Normal <C> Radial Svm Normal <C> Radial Svm Mitigation <C> Radial Svm Mitigation <C> Random Forest Normal <C> Random Forest Normal <C> Random Forest Mitigation <C> Random Forest Mitigation <C> Deep Neural Network Normal <C> Deep Neural Network Normal <C> Deep Neural Network Mitigation <C> Deep Neural Network Mitigation <R> <C> Modality <C> FPR <C> AR <C> FPR <C> AR <C> FPR <C> AR <C> FPR <C> AR <C> FPR <C> AR <C> FPR <C> AR <C> FPR <C> AR <C> FPR <C> AR <R> <C> Gait <C> 0.160 <C> 0.24 <C> 0.160 <C> 0.04 <C> 0.140 <C> 0.18 <C> 0.140 <C> 0.04 <C> 0.09 <C> 0.03 <C> 0.09 <C> 0.00 <C> 0.215 <C> 0.20 <C> 0.170 <C> 0.00 <R> <C> Touch <C> 0.325 <C> 0.49 <C> 0.340 <C> 0.01 <C> 0.265 <C> 0.41 <C> 0.265 <C> 0.03 <C> 0.21 <C> 0.23 <C> 0.21 <C> 0.00 <C> 0.325 <C> 0.30 <C> 0.375 <C> 0.00 <R> <C> Face <C> 0.050 <C> 0.15 <C> 0.065 <C> 0.11 <C> 0.040 <C> 0.01 <C> 0.040 <C> 0.01 <C> 0.03 <C> 0.78 <C> 0.03 <C> 0.00 <C> 0.095 <C> 0.10 <C> 0.065 <C> 0.04 <R> <C> Voice <C> 0.030 <C> 0.08 <C> 0.030 <C> 0.06 <C> 0.020 <C> 0.00 <C> 0.020 <C> 0.00 <C> 0.04 <C> 0.01 <C> 0.04 <C> 0.00 <C> 0.115 <C> 0.08 <C> 0.090 <C> 0.02 <CAP> TABLE I: Equal Error Rate and AR with and without the mitigation strategy. Green (resp., red) shades highlight improvement (resp., deterioration) in FPR and AR. Color intensity is proportional to degree of performance change.
<R> <C> Biometric <C> Linear SVM Normal <C> Linear SVM Normal <C> Linear SVM Mitigation <C> Linear SVM Mitigation <C> Linear SVM Mitigation <C> Radial Svm Normal <C> Radial Svm Normal <C> Radial Svm Mitigation <C> Radial Svm Mitigation <C> Radial Svm Mitigation <C> Random Forest Normal <C> Random Forest Normal <C> Random Forest Mitigation <C> Random Forest Mitigation <C> Random Forest Mitigation <C> Deep Neural Network Normal <C> Deep Neural Network Normal <C> Deep Neural Network Mitigation <C> Deep Neural Network Mitigation <C> Deep Neural Network Mitigation <R> <C> Modality <C> FPR <C> RAR <C> FPR <C> [ITALIC] β-RAR <C> RAR <C> FPR <C> RAR <C> FPR <C> [ITALIC] β-RAR <C> RAR <C> FPR <C> RAR <C> FPR <C> [ITALIC] β-RAR <C> RAR <C> FPR <C> RAR <C> FPR <C> [ITALIC] β-RAR <C> RAR <R> <C> Touch Raw <C> 0.325 <C> 0.45 <C> 0.345 <C> 0.44 <C> 0.00 <C> 0.265 <C> 0.40 <C> 0.265 <C> 0.36 <C> 0.01 <C> 0.21 <C> 0.18 <C> 0.215 <C> 0.05 <C> 0.00 <C> 0.325 <C> 0.32 <C> 0.38 <C> 0.26 <C> 0.00 <R> <C> Face Raw <C> 0.050 <C> 0.12 <C> 0.075 <C> 0.14 <C> 0.00 <C> 0.040 <C> 0.09 <C> 0.040 <C> 0.09 <C> 0.00 <C> 0.03 <C> 0.02 <C> 0.030 <C> 0.01 <C> 0.00 <C> 0.095 <C> 0.10 <C> 0.07 <C> 0.06 <C> 0.03 <CAP> TABLE II: Equal Error Rate and RAR with and without the mitigation strategy. The AR values remain the same as in Table I. β-RAR indicates RAR treated with only β noise. RAR indicates the inclusion of both β noise and raw random input samples.
<R> <C> [BOLD] Approaches <C> [BOLD] Accuracy (%) <R> <C> CNN using RGB data <C> 80.8±1.4 <R> <C> CNN using OC-LBCP <C> 66.6±2.2 <R> <C> Dual-stream CNN (without shared weights) <C> 82.1±1.6 <R> <C> [BOLD] Proposed network <C> [BOLD] 85.0±1.9 <CAP> Table 2: Performance analysis on rank-1 recognition accuracy. The highest accuracy is written in bold.
<R> <C> [BOLD] Approach <C> [BOLD] Ethnic-ocular (%)  [ITALIC] Rank-1 <C> [BOLD] Ethnic-ocular (%)  [ITALIC] Rank-5 <C> [BOLD] UBIPr (%)  [ITALIC] Rank-1 <C> [BOLD] UBIPr (%)  [ITALIC] Rank-5 <R> <C> AlexNet <C> 64.72±3.28 <C> 82.98±2.52 <C> 84.88±2.50 <C> 96.01±1.77 <R> <C> FaceNet <C> 78.71±3.66 <C> 92.19±1.59 <C> 90.24±1.43 <C> 97.36±0.44 <R> <C> LCNN-29 <C> 79.35±2.64 <C> 92.17±1.80 <C> 90.28±1.71 <C> 97.18±0.67 <R> <C> VGG-16 <C> 76.43±2.16 <C> 91.29±1.54 <C> 90.24±1.38 <C> 97.09±1.14 <R> <C> DeepIrisNet-A <C> 79.54±3.12 <C> 90.43±2.44 <C> 90.30±1.16 <C> 97.41±1.07 <R> <C> DeepIrisNet-B <C> 81.13±3.08 <C> 92.37±1.20 <C> 90.20±1.66 <C> 97.43±0.54 <R> <C> Multi-abstract fusion CNN <C> 81.79±3.54 <C> 93.03±1.33 <C> 90.75±1.01 <C> 97.44±0.34 <R> <C> [BOLD] Proposed network <C> [BOLD] 85.03±1.88 <C> [BOLD] 94.23±1.26 <C> [BOLD] 91.28±1.18 <C> [BOLD] 98.59±0.44 <CAP> Table 3: Evaluation of recognition performance on the Ethnic-ocular dataset and UBIPr dataset. The highest accuracy is written in bold.
<R> <C> [BOLD] Model <C> [BOLD] Params <C> [BOLD] Valid. Set <C> [BOLD] Test Set <R> <C> [BOLD] Single Models <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Large Regularized LSTM Zaremba et al. ( 2015 ) <C> 66M <C> 82.2 <C> 78.4 <R> <C> Large + BD + WT Press and Wolf ( 2016 ) <C> 51M <C> 75.8 <C> 73.2 <R> <C> Neural cache model (size = 500) Grave et al. ( 2017 ) <C> - <C> - <C> 72.1 <R> <C> Medium Pointer Sentinel-LSTM Merity et al. ( 2017 ) <C> 21M <C> 72.4 <C> 70.9 <R> <C> Attentive LM w/  [ITALIC] combined score function Salton et al. ( 2017 ) <C> 14.5M <C> 72.6 <C> 70.7 <R> <C> Attentive LM w/  [ITALIC] single score function Salton et al. ( 2017 ) <C> 14.5M <C> 71.7 <C> 70.1 <R> <C> Averaging RNN-LM <C> 14.1M <C> 71.6 <C> [BOLD] 69.9 <R> <C> [BOLD] Model Averaging <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> 2 Medium regularized LSTMs Zaremba et al. ( 2015 ) <C> 40M <C> 80.6 <C> 77.0 <R> <C> 5 Medium regularized LSTMs Zaremba et al. ( 2015 ) <C> 100M <C> 76.7 <C> 73.3 <R> <C> 10 Medium regularized LSTMs Zaremba et al. ( 2015 ) <C> 200M <C> 75.2 <C> 72.0 <R> <C> 2 Large regularized LSTMs Zaremba et al. ( 2015 ) <C> 122M <C> 76.9 <C> 73.6 <R> <C> 10 Large regularized LSTMs Zaremba et al. ( 2015 ) <C> 660M <C> 72.8 <C> 69.5 <R> <C> 38 Large regularized LSTMs Zaremba et al. ( 2015 ) <C> 2508M <C> 71.9 <C> [BOLD] 68.7 <CAP> Table 1: Perplexity results over the PTB. Symbols: WT = weight tying Press and Wolf (2016); BD = Bayesian Dropout Gal and Ghahramani (2015). Please note that we could not calculate the number of parameters for some models given missing information in the original publications.
<R> <C> [BOLD] Model <C> [BOLD] Params <C> [BOLD] Valid. Set <C> [BOLD] Test Set <R> <C> Zoneout + Variational LSTM Merity et al. ( 2017 ) <C> 20M <C> 108.7 <C> 100.9 <R> <C> LSTM-LM Grave et al. ( 2017 ) <C> - <C> - <C> 99.3 <R> <C> Variational LSTM Merity et al. ( 2017 ) <C> 20M <C> 101.7 <C> 96.3 <R> <C> Neural cache model (size = 100) Grave et al. ( 2017 ) <C> - <C> - <C> 81.6 <R> <C> Pointer LSTM (window = 100) Merity et al. ( 2017 ) <C> 21M <C> 84.8 <C> 80.8 <R> <C> Averaging RNN-LM <C> 50M <C> 74.6 <C> 71.3 <R> <C> Attentive LM w/  [ITALIC] combined score function Salton et al. ( 2017 ) <C> 51M <C> 74.3 <C> 70.8 <R> <C> Attentive LM w/  [ITALIC] single score function Salton et al. ( 2017 ) <C> 51M <C> 73.7 <C> 69.7 <R> <C> Neural cache model (size = 2000) Grave et al. ( 2017 ) <C> - <C> - <C> [BOLD] 68.9 <CAP> Table 2: Perplexity results over the wikitext2. Please note that we could not calculate the number of parameters for some models given missing information in the original publications.
<R> <C> ℓ∞ pert. <C> MNIST 0.03 <C> MNIST 0.1 <C> MNIST 0.2 <C> MNIST 0.3 <C> MNIST 0.4 <C> CIFAR-10 0.03 <C> CIFAR-10 0.1 <C> CIFAR-10 0.2 <C> CIFAR-10 0.3 <C> CIFAR-10 0.4 <R> <C> FGSM <C> 97.8% <C> 97.6% <C> 97.1% <C> 95.4% <C> 91% <C> 48.2% <C> 47.9% <C> 45.3% <C> 39.7% <C> 31.1 <R> <C> BIM <C> 97.8% <C> 97.6% <C> 96.7% <C> 95.2% <C> 91% <C> 48.2% <C> 47.7% <C> 45.2% <C> 39% <C> 30.1% <R> <C> PGD <C> 97.8% <C> 97.7% <C> 97% <C> 95.2% <C> 91.3% <C> 48.3% <C> 47.6% <C> 45.4% <C> 41.6% <C> 37.1% <R> <C> MIM <C> 97.8% <C> 97.6% <C> [BOLD] 95.8% <C> [BOLD] 87.4% <C> [BOLD] 67.5% <C> 48.2% <C> 47.5% <C> 40.4% <C> [BOLD] 26.1% <C> [BOLD] 15.6% <R> <C> Blackbox <C> [BOLD] 97.6 % <C> [BOLD] 97.4 % <C> 95.9% <C> 92.1% <C> 84.1% <C> [BOLD] 47.6% <C> [BOLD] 45.1% <C> [BOLD] 36.7% <C> 26.4% <C> 18.5% <R> <C> ℓ2 pert. <C> 0.1 <C> 0.7 <C> 1.1 <C> 3.2 <C> 4 <C> 0.3 <C> 2 <C> 4 <C> 6.5 <C> 10.5 <R> <C> FGM <C> 97.8% <C> 97.8% <C> 97.8% <C> 97.3% <C> 97.1% <C> 48.1% <C> 48.1% <C> 48% <C> 47.3% <C> 45.4% <R> <C> PGD <C> 97.8% <C> 97.8% <C> 97.8% <C> [BOLD] 97.3% <C> [BOLD] 96.7% <C> 48.3% <C> 48.3% <C> [BOLD] 47.5% <C> [BOLD] 45.7% <C> [BOLD] 39.3% <R> <C> CW <C> [BOLD] 97.7% <C> [BOLD] 97.4% <C> [BOLD] 97.7% <C> 97.7% <C> 97.8% <C> [BOLD] 48% <C> [BOLD] 48% <C> 47.9% <C> 46.5% <C> 39.5% <CAP> TABLE I: Accuracy of ensemble of 50 PPD models on ℓ∞ and ℓ2 attacks for MNIST and CIFAR-10. The lowest accuracy for each perturbation strength is in bold.
<R> <C> Time Gap <C> [BOLD] AUC LSTM+SA <C> [BOLD] AUC LSTM <R> <C> 60 <C> 0.83 <C> 0.72 <R> <C> 120 <C> 0.82 <C> 0.72 <R> <C> 180 <C> 0.81 <C> 0.72 <R> <C> 240 <C> 0.81 <C> 0.71 <CAP> Table 3: Mean AUC results of cross-validation procedure.
<R> <C> [BOLD] Layer <C> [BOLD] Output size <C> [BOLD] Stride <C> [BOLD] Repeats <R> <C> Raster image <C> 300×300×3 <C> − <C> − <R> <C> Conv 3×3 <C> 150×150×24 <C> 2 <C> 1 <R> <C> DwConv 3×3 <C> 75×75×24 <C> 2 <C> 1 <R> <C> FMNet block 1 <C> 75×75×12 <C> 1 <C> 2 <R> <C> FMNet block 2 <C> 38×38×16 <C> 2 <C> 3 <R> <C> FMNet block 3 <C> 19×19×32 <C> 2 <C> 4 <R> <C> FMNet block 4 <C> 19×19×48 <C> 1 <C> 3 <R> <C> FMNet block 5 <C> 10×10×80 <C> 2 <C> 3 <R> <C> FMNet block 6 <C> 10×10×160 <C> 1 <C> 1 <R> <C> Conv 1×1 <C> 10×10×640 <C> 1 <C> 1 <R> <C> Global average pooling <C> 1×1×640 <C> 1 <C> 1 <CAP> TABLE I: Architecture of FastMobileNet (upsample factor for all FMNet blocks is set to k=6)
<R> <C> [BOLD] Architecture <C> [BOLD] ADE [m] <C> [BOLD] Latency [ms] <C> [BOLD] FLOPS <C> [BOLD] Num. parameters <C> [BOLD] MAC <C> [BOLD] Num. ops <R> <C> AlexNet <C> 1.36 <C> 15.8 <C> 2.63G <C> 70.3M <C> 364 MB <C> [BOLD] 131 <R> <C> ResNet18 <C> 1.29 <C> 36.2 <C> 6.26G <C> 11.7M <C> 163 MB <C> 641 <R> <C> MNv2-0.5 <C> 1.27 <C> 21.3 <C> 308M <C> 598K <C> 146 MB <C> 1542 <R> <C> MnasNet-0.5 <C> 1.28 <C> 18.3 <C> 323M <C> 844K <C> 113 MB <C> 1490 <R> <C> FMNet <C> 1.28 <C> 12.1 <C> 340M <C> 565K <C> 55 MB <C> 336 <R> <C> FMNet with spatial fusion <C> [BOLD] 1.24 <C> [BOLD] 10.4 <C> [BOLD] 285M <C> [BOLD] 558K <C> [BOLD] 47 MB <C> 370 <CAP> TABLE II: Comparison of various CNN architectures (all models except the last one use the concatenation feature fusion)
<R> <C> [BOLD] Approach <C> [BOLD] Resolution <C> [BOLD] Bicyclists  [BOLD] Average <C> [BOLD] Bicyclists  [BOLD] @1s <C> [BOLD] Bicyclists  [BOLD] @5s <C> [BOLD] Pedestrians  [BOLD] Average <C> [BOLD] Pedestrians  [BOLD] @1s <C> [BOLD] Pedestrians  [BOLD] @5s <R> <C> UKF <C> − <C> 2.89 <C> 0.80 <C> 6.60 <C> 0.67 <C> 0.22 <C> 1.22 <R> <C> Social-LSTM <C> − <C> 3.79 <C> 1.85 <C> 6.61 <C> 0.53 <C> 0.29 <C> 0.95 <R> <C> RasterNet <C> 0.1 [ITALIC] m <C> 1.07 <C> 0.43 <C> 2.73 <C> [BOLD] 0.51 <C> [BOLD] 0.17 <C> [BOLD] 0.90 <R> <C> RasterNet <C> 0.2 [ITALIC] m <C> 1.07 <C> 0.44 <C> 2.72 <C> 0.52 <C> 0.18 <C> 0.93 <R> <C> RasterNet <C> 0.3 [ITALIC] m <C> 1.09 <C> 0.45 <C> 2.80 <C> 0.53 <C> 0.18 <C> 0.95 <R> <C> RasterNet w/o rotation <C> 0.2 [ITALIC] m <C> 1.29 <C> 0.49 <C> 3.30 <C> 0.58 <C> 0.20 <C> 1.02 <R> <C> RasterNet w/o traffic lights <C> 0.2 [ITALIC] m <C> 1.11 <C> 0.44 <C> 2.86 <C> 0.55 <C> 0.20 <C> 0.96 <R> <C> RasterNet w/o lane headings <C> 0.2 [ITALIC] m <C> 1.07 <C> 0.43 <C> 2.72 <C> 0.52 <C> 0.18 <C> 0.93 <R> <C> RasterNet with learned colors <C> 0.2 [ITALIC] m <C> [BOLD] 1.05 <C> [BOLD] 0.42 <C> [BOLD] 2.70 <C> 0.53 <C> 0.18 <C> 0.93 <R> <C> RasterNet vehicle model <C> 0.2 [ITALIC] m <C> 3.11 <C> 0.89 <C> 8.47 <C> 1.96 <C> 0.40 <C> 3.82 <R> <C> RasterNet vehicle fine-tuned <C> 0.2 [ITALIC] m <C> [BOLD] 1.05 <C> [BOLD] 0.42 <C> [BOLD] 2.70 <C> 0.59 <C> 0.20 <C> 1.05 <CAP> TABLE III: Comparison of prediction displacement errors (in meters) for different experimental settings
<R> <C> Model <C> Generated Images CIFAR-10 <C> Generated Images CelebA <C> Generated Images Flickr-Face <C> Reconstructed Images CIFAR-10 <C> Reconstructed Images CelebA <C> Reconstructed Images Flickr-Face <R> <C> VAE <C> 130.62 ± 0.37 <C> 57.19 ± 0.09 <C> 79.35 ± 0.32 <C> 122.54 ± 0.09 <C> 48.57 ± 0.05 <C> 73.56 ± 0.24 <R> <C> VAE-c <C> 104.35 ± 0.31 <C> 53.87 ± 0.16 <C> 80.52 ± 0.14 <C> 92.23 ± 0.21 <C> 40.78 ± 0.03 <C> 70.96 ± 0.10 <R> <C> Wavelet-VAE <C> 112.45 ± 0.17 <C> 49.96 ± 0.17 <C> [BOLD] 71.38 ± 0.14 <C> 92.40 ± 0.12 <C> 43.94 ± 0.08 <C> [BOLD] 65.72 ± 0.07 <R> <C> Wavelet-VAE-MR <C> [BOLD] 101.86 ± 0.28 <C> [BOLD] 47.92 ± 0.08 <C> 84.90 ± 0.28 <C> [BOLD] 80.65 ± 0.13 <C> [BOLD] 37.89 ± 0.07 <C> 71.21 ± 0.14 <CAP> Table 1: FID score comparison for generated and reconstructed images of the presented Wavelet-VAE and Wavelet-VAE-MR models against standard VAE trained with MSE loss and VAE trained with cross-entropy loss for the likelihood term. For each dataset, we performed 5 independent trials and report the mean and standard deviation of the FID scores.
<R> <C> URL <C> First Time Visit <C> Last Time Visit <C> URL Counts <C> Frecency <R> <C> https://web.facebook.com/ <C> 1521241972 <C> 1522351859 <C> 177 <C> 56640 <R> <C> http://localhost/phpmyadmin/ <C> 1518413861 <C> 1522075694 <C> 24 <C> 39312 <R> <C> https://mail.google.com/mail/u/ <C> 1516596003 <C> 1522352010 <C> 36 <C> 33264 <R> <C> https://github.com/ <C> 1517215489 <C> 1522352266 <C> 37 <C> 27528 <R> <C> https://www.youtube.com/ <C> 1517229227 <C> 1521978502 <C> 24 <C> 14792 <CAP> TABLE I: Sample Browser history dataset
<R> <C> Mean Square Error <C> Root Mean Square Error <C> Score <R> <C> 586430.6574 <C> 765.7876 <C> 87.62% <CAP> TABLE III: Experimental results of frecency prediction.
<R> <C> URL <C> URL Counts <C> Frecency <R> <C> http://localhost/phpmyadmin/ <C> 16 <C> 2906.7627 <R> <C> http://localhost:8888/tree <C> 15 <C> 2717.497 <R> <C> http://localhost:8000/home <C> 13 <C> 2274.1109 <CAP> TABLE IV: Predicted Frecency.
<R> <C> mean <C> standard-deviation <C> n-gram-range <C> tfidf-use-idf <C> clf-alpha <R> <C> 0.69971 <C> 0.00035 <C> (1,2) <C> True <C> 0.01 <CAP> TABLE V: Best Parameters
<R> <C> mean <C> standard-deviation <C> n-gram-range <C> tfidf-use-idf <C> clf-alpha <R> <C> 0.69245 <C> 0.00036 <C> (1,1) <C> True <C> 0.01 <R> <C> 0.69971 <C> 0.00035 <C> (1,2) <C> True <C> 0.01 <R> <C> 0.69460 <C> 0.00053 <C> (1,1) <C> False <C> 0.01 <R> <C> 0.69702 <C> 0.00047 <C> (1,2) <C> False <C> 0.01 <R> <C> 0.69153 <C> 0.00028 <C> (1,1) <C> True <C> 0.001 <R> <C> 0.69804 <C> 0.00034 <C> (1,2) <C> True <C> 0.001 <R> <C> 0.69348 <C> 0.00062 <C> (1,1) <C> True <C> 0.001 <R> <C> 0.69614 <C> 0.00047 <C> (1,2) <C> True <C> 0.001 <CAP> TABLE VI: All Parameters list by random search
<R> <C> Class <C> Precision <C> Recall <C> F1 score <C> Accuracy <R> <C> 2 <C> 84.35% <C> 83.33% <C> 83.22% <C> 83.33% <R> <C> 4 <C> 73.45% <C> 68.33% <C> 66.29% <C> 68.33% <R> <C> 15 <C> 61.66% <C> 44.01% <C> 39.74% <C> 44.01% <CAP> TABLE VII: Classification Accuracy Without Random Search (Previous Method)
<R> <C> Class <C> Precision <C> Recall <C> F1 score <C> Accuracy <R> <C> 2 <C> 85.70% <C> 84.34% <C> 84.20% <C> 84.34% <R> <C> 4 <C> 73.74% <C> 71.23% <C> 70.54% <C> 71.23% <R> <C> 15 <C> 56.34% <C> 49.87% <C> 48.66% <C> 49.87% <CAP> TABLE VIII: Classification Accuracy With Random Search (Proposed Method)
<R> <C> URL <C> URL Counts <C> Frecency <C> Category <R> <C> https://web.facebook.com/ <C> 543 <C> 102108.26 <C> Computers <R> <C> https://drive.google.com/drive/my-drive <C> 28 <C> 4873.655 <C> Computers <R> <C> http://codeforces.com/contests <C> 21 <C> 3650.896 <C> Arts <R> <C> https://www.floydhub.com/jobs <C> 4 <C> 665.371 <C> Business <R> <C> http://www.cricbuzz.com/live-cricket-scores <C> 4 <C> 579.825 <C> Games <R> <C> http://localhost/map/googlemap.php <C> 9 <C> 528.395 <C> Computers <R> <C> https://www.kaggle.com/competitions <C> 2 <C> 309.769 <C> Arts <R> <C> https://freebitco.in/ <C> 1 <C> 111.909 <C> Business <CAP> TABLE IX: Predicted sample result for frecency and category
<R> <C> Method <C> MN → US (p) <C> MN → US (f) <C> US → MN <C> SV → MN <R> <C> Source only <C> 76.0±1.8 <C> 79.3±0.7 <C> 59.5±1.9 <C> 62.1±1.2 <R> <C> MMD Long2015 <C> [EMPTY] <C> 81.1±0.3 <C> [EMPTY] <C> 71.1±0.5 <R> <C> RevGrad gradient_reverse <C> 77.1±1.8 <C> 85.1±0.8 <C> 73.0±2.0 <C> 73.9±1.2 <R> <C> CoGAN co-gan <C> 91.2±0.8 <C> [EMPTY] <C> 89.1±1.0 <C> [EMPTY] <R> <C> DRCN deep_reconstruction <C> 91.8±0.1 <C> [EMPTY] <C> 73.7±0.0 <C> 82.0±0.1 <R> <C> ADDA adda <C> 89.4±0.2 <C> [EMPTY] <C> 90.1±0.8 <C> 76.0±1.8 <R> <C> PixelDA pixel_level <C> [EMPTY] <C> 95.9±0.7 <C> [EMPTY] <C> [EMPTY] <R> <C> MSTN semantic <C> 92.9±1.1 <C> [EMPTY] <C> [EMPTY] <C> 91.7±1.5 <R> <C> GTA generate_to_adapt <C> 92.8±0.9 <C> 95.3±0.7 <C> 90.8±1.3 <C> 92.4±0.9 <R> <C> ADR adversarial_dropout <C> 93.2–––––±2.5 <C> 96.1–––––±0.3 <C> 93.1–––––±1.3 <C> 95.0–––––±1.9 <R> <C> DM-ADA (ours) <C> [BOLD] 94.8±0.7 <C> [BOLD] 96.7±0.5 <C> [BOLD] 94.2±0.9 <C> [BOLD] 95.5±1.1 <CAP> Table 1: Classification accuracy (mean ± std %) values of target domain over five independent runs on the digits datasets. The best performance is indicated in bold and the second best one is underlined.
<R> <C> [EMPTY] <C> [EMPTY] <C> Uncalibrated Freq. <C> Uncalibrated MC Dropout <C> Uncalibrated MC Dropout <C> TS Calibrated Freq. <C> TS Calibrated MC Dropout <C> TS Calibrated MC Dropout <R> <C> Data Set <C> Model <C> ECE <C> ECE <C> UCE <C> ECE <C> ECE <C> UCE <R> <C> CIFAR-10 <C> ResNet-18 <C> 8.95 <C> 8.41 <C> 7.60 <C> 1.40 <C> [BOLD] 0.47 <C> [BOLD] 5.27 <R> <C> CIFAR-100 <C> ResNet-101 <C> 29.63 <C> 24.62 <C> 30.33 <C> 3.50 <C> [BOLD] 1.92 <C> [BOLD] 2.41 <R> <C> CIFAR-100 <C> DenseNet-169 <C> 30.62 <C> 23.98 <C> 29.62 <C> 6.10 <C> [BOLD] 2.89 <C> [BOLD] 2.69 <CAP> Table 1: ECE and UCE test set results in % (M=15 bins). 0 % means perfect calibration. In TS calibration with MC dropout the same value of T was used to report both ECE and UCE.
<R> <C> [BOLD] H3.6M <C> Protocol #1 <C> Protocol #2 <C> Protocol #3 <R> <C> [BOLD] H3.6M <C> MPJPE <C> MPJPE <C> MPJPE <R> <C> Martinez (ICCV’17)  <C> 62.9 <C> 47.7 <C> 84.8 <R> <C> Fang (AAAI’18)  <C> 60.3 <C> 45.7 <C> [BOLD] 72.8 <R> <C> Rhodin (CVPR’18)  <C> 66.8 <C> - <C> - <R> <C> Yang (CVPR’18)  <C> 58.6 <C> [BOLD] 37.7 <C> - <R> <C> Hossain (ECCV’18)  <C> [BOLD] 51.9 <C> 42.0 <C> - <R> <C> Lassner (CVPR’17)  <C> 80.7 <C> - <C> - <R> <C> HMR (CVPR’18)  <C> 88.0 <C> 56.8 <C> 77.3 <R> <C> Pavlakos (CVPR’18)  <C> - <C> 75.9 <C> - <R> <C> NBF (3DV’18)  <C> - <C> 59.9 <C> - <R> <C> DenseRaC baseline <C> 82.4 <C> 53.9 <C> 77.0 <R> <C> + render-and-compare <C> 79.5 <C> 51.4 <C> 75.9 <R> <C> + synthetic data <C> 76.8 <C> 48.0 <C> 74.1 <CAP> Table 1: Quantitative comparisons of mean per joint position error (MPJPE), PCK and AUC between the estimated 3D pose and ground truth on H3.6M under Protocol #1, #2, #3 and MPI-INF-3DHP under Protocol #1, #2. - indicates results not reported. Lower MPJPE, higher PCK and AUC indicate better performance. Best scores are marked in bold.
<R> <C> [BOLD] MPI-INF-3DHP <C> Protocol #1 <C> Protocol #1 <C> Protocol #1 <C> Protocol #2 <C> Protocol #2 <C> Protocol #2 <R> <C> [BOLD] MPI-INF-3DHP <C> PCK <C> AUC <C> MPJPE <C> PCK <C> AUC <C> MPJPE <R> <C> Mehta (3DV’17)  <C> 75.7 <C> 39.3 <C> 117.6 <C> - <C> - <C> - <R> <C> Mehta (TOG’17)  <C> 76.6 <C> 40.4 <C> 124.7 <C> 83.9 <C> 47.3 <C> 98.0 <R> <C> HMR (CVPR’18)  <C> 72.9 <C> 36.5 <C> 124.2 <C> 86.3 <C> 47.8 <C> 89.8 <R> <C> DenseRaC baseline <C> 73.1 <C> 36.7 <C> 123.1 <C> 86.8 <C> 47.8 <C> 88.7 <R> <C> + render-and-compare <C> 74.7 <C> 38.6 <C> 124.9 <C> 87.5 <C> 48.3 <C> 86.7 <R> <C> + synthetic data <C> [BOLD] 76.9 <C> [BOLD] 41.1 <C> [BOLD] 114.2 <C> [BOLD] 89.0 <C> [BOLD] 49.1 <C> [BOLD] 83.5 <CAP> Table 1: Quantitative comparisons of mean per joint position error (MPJPE), PCK and AUC between the estimated 3D pose and ground truth on H3.6M under Protocol #1, #2, #3 and MPI-INF-3DHP under Protocol #1, #2. - indicates results not reported. Lower MPJPE, higher PCK and AUC indicate better performance. Best scores are marked in bold.
<R> <C> [BOLD] Dataset <C> [BOLD] Pearson <R> <C> Boston <C> 0.76 <R> <C> Diabetes <C> 0.50 <R> <C> Abalone <C> 0.76 <R> <C> Wine <C> 0.87 <CAP> Table 1: Correlation of extrapolation scores and ensemble std. deviations on 4 datasets.
<R> <C> [BOLD] Method <C> [BOLD] M/E <C> [BOLD] M/H <C> [BOLD] A/E <C> [BOLD] A/H <R> <C> MaxProb <C> 0.738 <C> [BOLD] 0.677 <C> 0.461 <C> 0.433 <R> <C> NN (Pixels) <C> 0.561 <C> 0.550 <C> [BOLD] 0.521 <C> 0.547 <R> <C> NN (Reprs) <C> 0.584 <C> 0.578 <C> [BOLD] 0.503 <C> 0.533 <R> <C> NN (Final Layer) <C> 0.589 <C> 0.517 <C> 0.480 <C> 0.497 <R> <C> LE (Loss) <C> [BOLD] 0.770 <C> [BOLD] 0.684 <C> 0.454 <C> 0.456 <R> <C> LE (Predictions) <C> 0.364 <C> 0.544 <C> [BOLD] 0.519 <C> [BOLD] 0.582 <CAP> Table 2: AUC for Latent Factors OOD detection task. Column heading denotes in-distribution definitions: labels are M (Male) and A (Attractive); spurious correlates are E (Eyeglasses) and H (Wearing Hat). Image is in-distribution iff label = spurious correlate. LE stands for local ensembles. Each Lanczos iteration uses 3000 eigenvectors. 500 examples from each test set are used. 95% CI is bolded.
<R> <C> [EMPTY] <C> 2D Supervision DRC (Mask)  <C> 2D Supervision SoftRas  <C> 2D Supervision Ours (LRGB) <C> 2.5D Supervision DRC (Depth)  <C> 2.5D Supervision Ours (LDepth) <C> 3D Supervision 3D R2N2  <C> 3D Supervision ONet  <C> 3D Supervision Pixel2Mesh  <R> <C> category <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> airplane <C> 0.659 <C> [BOLD] 0.149 <C> 0.190 <C> 0.377 <C> [BOLD] 0.143 <C> 0.215 <C> [BOLD] 0.151 <C> 0.183 <R> <C> bench <C> - <C> 0.241 <C> [BOLD] 0.210 <C> - <C> [BOLD] 0.165 <C> 0.210 <C> [BOLD] 0.171 <C> 0.191 <R> <C> cabinet <C> - <C> 0.231 <C> [BOLD] 0.220 <C> - <C> [BOLD] 0.183 <C> 0.246 <C> [BOLD] 0.189 <C> 0.194 <R> <C> car <C> 0.340 <C> 0.221 <C> [BOLD] 0.196 <C> 0.316 <C> [BOLD] 0.179 <C> 0.250 <C> 0.181 <C> [BOLD] 0.154 <R> <C> chair <C> 0.660 <C> 0.338 <C> [BOLD] 0.264 <C> 0.510 <C> [BOLD] 0.226 <C> 0.282 <C> [BOLD] 0.224 <C> 0.259 <R> <C> display <C> - <C> 0.284 <C> [BOLD] 0.255 <C> - <C> [BOLD] 0.246 <C> 0.323 <C> 0.275 <C> [BOLD] 0.231 <R> <C> lamp <C> - <C> [BOLD] 0.381 <C> 0.413 <C> - <C> [BOLD] 0.362 <C> 0.566 <C> 0.380 <C> [BOLD] 0.309 <R> <C> loudspeaker <C> - <C> 0.320 <C> [BOLD] 0.289 <C> - <C> [BOLD] 0.295 <C> 0.333 <C> 0.290 <C> [BOLD] 0.284 <R> <C> rifle <C> - <C> [BOLD] 0.155 <C> 0.175 <C> - <C> [BOLD] 0.143 <C> 0.199 <C> 0.160 <C> [BOLD] 0.151 <R> <C> sofa <C> - <C> 0.407 <C> [BOLD] 0.224 <C> - <C> [BOLD] 0.221 <C> 0.264 <C> 0.217 <C> [BOLD] 0.211 <R> <C> table <C> - <C> 0.374 <C> [BOLD] 0.280 <C> - <C> [BOLD] 0.180 <C> 0.247 <C> [BOLD] 0.185 <C> 0.215 <R> <C> telephone <C> - <C> [BOLD] 0.131 <C> 0.148 <C> - <C> [BOLD] 0.130 <C> 0.221 <C> 0.155 <C> [BOLD] 0.145 <R> <C> vessel <C> - <C> [BOLD] 0.233 <C> 0.245 <C> - <C> [BOLD] 0.206 <C> 0.248 <C> 0.220 <C> [BOLD] 0.201 <R> <C> mean <C> 0.553 <C> 0.266 <C> [BOLD] 0.239 <C> 0.401 <C> [BOLD] 0.206 <C> 0.277 <C> 0.215 <C> [BOLD] 0.210 <CAP> Table 1: Single-View Reconstruction. We report Chamfer-L1 distances wrt. the ground truth meshes for the single-view experiment. We compare against Differentiable Ray Consistency (DRC) [79] (2D and 2.5D supervision), Soft Rasterizer [44] (2D supervision), 3D-R2N2 [13], Occupancy Networks (ONet) [48], and Pixel2Mesh [80] (all 3D supervision).
<R> <C> [EMPTY] <C> Trim Param. <C> Accuracy <C> Completeness <C> Chamfer- [ITALIC] L1 <R> <C> Tola  + sPSR <C> 0 <C> 2.409 <C> 1.242 <C> 1.826 <R> <C> Furu  + sPSR <C> 0 <C> 2.146 <C> 0.888 <C> 1.517 <R> <C> Colmap  + sPSR <C> 0 <C> [BOLD] 1.881 <C> 0.726 <C> [BOLD] 1.303 <R> <C> Camp  + sPSR <C> 0 <C> 2.213 <C> [BOLD] 0.670 <C> 1.441 <R> <C> Tola  + sPSR <C> 5 <C> 1.531 <C> 1.267 <C> 1.399 <R> <C> Furu  + sPSR <C> 5 <C> 1.733 <C> 0.888 <C> 1.311 <R> <C> Colmap  + sPSR <C> 5 <C> [BOLD] 1.400 <C> 0.782 <C> [BOLD] 1.091 <R> <C> Camp  + sPSR <C> 5 <C> 1.991 <C> [BOLD] 0.670 <C> 1.331 <R> <C> Tola  + sPSR <C> 7 <C> [BOLD] 0.396 <C> 1.424 <C> 0.910 <R> <C> Furu  + sPSR <C> 7 <C> 0.723 <C> 0.955 <C> 0.839 <R> <C> Colmap  + sPSR <C> 7 <C> 0.446 <C> 1.020 <C> [BOLD] 0.733 <R> <C> Camp  + sPSR <C> 7 <C> 1.466 <C> [BOLD] 0.719 <C> 1.092 <R> <C> Ours (LRGB) <C> - <C> 1.054 <C> [BOLD] 0.760 <C> 0.907 <R> <C> Ours (LRGB + LDepth) <C> - <C> [BOLD] 0.789 <C> 0.775 <C> [BOLD] 0.782 <CAP> Table 2: Multi-View Stereo. We show quantitative results for scans 65, 106, and 118 on the DTU dataset. For the baselines, we perform screened Poisson surface reconstruction (sPSR) [34] with trim parameters 0, 5, and 7 to obtain the final output. It shows that our generic method achieves results comparable to the highly optimized MVS methods.
<R> <C> Target <C> Unit <C> PPGN <C> SchNet <C> PhysNet <C> MEGNet-s <C> Cormorant <C> [BOLD] DimeNet <R> <C> [ITALIC] μ <C> D <C> 0.047 <C> 0.033 <C> 0.0529 <C> 0.05 <C> 0.13 <C> 0.0286 <R> <C> [ITALIC] α <C> [ITALIC] a0 3 <C> 0.131 <C> 0.235 <C> 0.0615 <C> 0.081 <C> 0.092 <C> 0.0469 <R> <C> [ITALIC] ϵHOMO <C> meV <C> 40.3 <C> 41 <C> 32.9 <C> 43 <C> 36 <C> 27.8 <R> <C> [ITALIC] ϵLUMO <C> meV <C> 32.7 <C> 34 <C> 24.7 <C> 44 <C> 36 <C> 19.7 <R> <C> Δ [ITALIC] ϵ <C> meV <C> 60.0 <C> 63 <C> 42.5 <C> 66 <C> 60 <C> 34.8 <R> <C> ⟨ [ITALIC] R2⟩ <C> [ITALIC] a0 2 <C> 0.592 <C> 0.073 <C> 0.765 <C> 0.302 <C> 0.673 <C> 0.331 <R> <C> ZPVE <C> meV <C> 3.12 <C> 1.7 <C> 1.39 <C> 1.43 <C> 1.98 <C> 1.29 <R> <C> [ITALIC] U0 <C> meV <C> 36.8 <C> 14 <C> 8.15 <C> 12 <C> 28 <C> 8.02 <R> <C> [ITALIC] U <C> meV <C> 36.8 <C> 19 <C> 8.34 <C> 13 <C> - <C> 7.89 <R> <C> [ITALIC] H <C> meV <C> 36.3 <C> 14 <C> 8.42 <C> 12 <C> - <C> 8.11 <R> <C> [ITALIC] G <C> meV <C> 36.4 <C> 14 <C> 9.40 <C> 12 <C> - <C> 8.98 <R> <C> [ITALIC] cv <C> calmolK <C> 0.055 <C> 0.033 <C> 0.0280 <C> 0.029 <C> 0.031 <C> 0.0249 <R> <C> std. MAE <C> \char 37 <C> 1.84 <C> 1.76 <C> 1.37 <C> 1.80 <C> 2.14 <C> 1.05 <R> <C> logMAE <C> - <C> −4.64 <C> −5.17 <C> −5.35 <C> −5.17 <C> −4.75 <C> −5.57 <CAP> Table 1: MAE on QM9. DimeNet sets the state of the art on 11 targets, outperforming the second-best model on average by 31\char37 (mean std. MAE).
<R> <C> Method <C> A → W <C> D → W <C> W → D <C> A → D <C> D → A <C> W → A <C> Average <R> <C> AlexNet (source only) alexnet <C> 60.6±0.4 <C> 95.4±0.2 <C> 99.0±0.1 <C> 64.2±0.3 <C> 45.5±0.5 <C> 48.3±0.5 <C> 68.8 <R> <C> TCA tca <C> 59.0±0.0 <C> 90.2±0.0 <C> 88.2±0.0 <C> 57.8±0.0 <C> 51.6±0.0 <C> 47.9±0.0 <C> 65.8 <R> <C> DDC ddc <C> 61.0±0.5 <C> 95.0±0.3 <C> 98.5±0.3 <C> 64.9±0.4 <C> 47.2±0.5 <C> 49.4±0.4 <C> 69.3 <R> <C> DAN Long2015 <C> 68.5±0.3 <C> 96.0±0.1 <C> 99.0±0.1 <C> 66.8±0.2 <C> 50.0±0.4 <C> 49.8±0.3 <C> 71.7 <R> <C> RevGrad gradient_reverse <C> 73.0±0.5 <C> 96.4±0.3 <C> 99.2±0.3 <C> 72.3±0.3 <C> 52.4±0.4 <C> 50.4±0.5 <C> 74.1 <R> <C> DRCN deep_reconstruction <C> 68.7±0.3 <C> 96.4±0.3 <C> 99.0±0.2 <C> 66.8±0.5 <C> 56.0±0.5 <C> 54.9±0.5 <C> 73.6 <R> <C> MADA multi-adversarial <C> 78.5±0.2 <C> [BOLD] 99.8±0.1 <C> [BOLD] 100±0.0 <C> 74.1±0.1 <C> 56.0±0.2 <C> 54.5±0.3 <C> 77.1 <R> <C> MSTN semantic <C> 80.5±0.4 <C> 96.9±0.1 <C> 99.9–––––±0.1 <C> 74.5±0.4 <C> 62.5±0.4 <C> 60.0±0.6 <C> 79.1 <R> <C> GCAN gcan <C> 82.7–––––±0.1 <C> 97.1–––––±0.1 <C> 99.8±0.1 <C> 76.4–––––±0.5 <C> [BOLD] 64.9±0.1 <C> 62.6–––––±0.3 <C> 80.6 <R> <C> DM-ADA (ours) <C> [BOLD] 83.9±0.4 <C> [BOLD] 99.8±0.1 <C> 99.9–––––±0.1 <C> [BOLD] 77.5±0.2 <C> 64.6–––––±0.4 <C> [BOLD] 64.0±0.5 <C> [BOLD] 81.6 <CAP> Table 2: Classification accuracy (mean ± std %) values of target domain over five independent runs on the Office-31 dataset. The best performance is indicated in bold and the second best one is underlined.
<R> <C> [EMPTY] <C> prec. <C> rec. <C> F1 <R> <C> ARE <C> 0.82 <C> 0.84 <C> 0.83 <R> <C> Acordão <C> 0.71 <C> 0.89 <C> 0.79 <R> <C> Desp. <C> 0.74 <C> 0.82 <C> 0.78 <R> <C> Outro <C> 0.91 <C> 0.82 <C> 0.87 <R> <C> RE <C> 0.77 <C> 0.70 <C> 0.73 <R> <C> Sent. <C> 0.92 <C> 0.95 <C> 0.93 <R> <C> average <C> 0.85 <C> 0.84 <C> 0.84 <CAP> Figure 2: Bi-LSTM results per class.
<R> <C> [BOLD] Epochs (For 1500 data-set) <C> [BOLD] Precision <C> [BOLD] Recall <C> [BOLD] Test-accuracy <C> [ITALIC]  [BOLD] F [BOLD] 1-measure <R> <C> 30 <C> 0.8990 <C> [BOLD] 0.8732 <C> 0.8340 <C> 0.9346 <R> <C> 40 <C> 0.9334 <C> 0.8662 <C> 0.8551 <C> [BOLD] 0.9495 <R> <C> 80 <C> 0.9754 <C> 0.7246 <C> 0.9470 <C> 0.9493 <R> <C> 115 <C> [BOLD] 0.9889 <C> 0.4042 <C> [BOLD] 0.9610 <C> 0.9445 <CAP> TABLE II: Comparison of metrics across different epochs
<R> <C> [BOLD] Training data-set <C> [BOLD] Epochs <C> [BOLD] Testing Data-set <C> [BOLD] Test-accuracy <R> <C> 300 <C> 30 <C> 100 <C> 83.4 % <R> <C> 500 <C> 40 <C> 300 <C> 85.5 % <R> <C> 1500 <C> 80 <C> 500 <C> 94.7 % <R> <C> 1500 <C> 115 <C> 500 <C> 96.1 % <CAP> TABLE I: Performance of the current Segnet model
<R> <C> [EMPTY] <C> [EMPTY] <C> [ITALIC] θinit=0.5 Deterministic <C> [ITALIC] θinit=0.5 Stochastic <C> [ITALIC] θinit=0.969 Deterministic <C> [ITALIC] θinit=0.969 Stochastic <R> <C> AdaptiveLayer (a) <C> ( [ITALIC] λ=2) <C> [BOLD] 2.200 (0.125) <C> 2.218 (0.135) <C> [BOLD] 2.366 (0.901) <C> 2.375 (0.889) <R> <C> AdaptiveLayer (b) <C> ( [ITALIC] λ=2) <C> 15.69 (29.9) <C> 15.67 (29.9) <C> 35.26 (41.6) <C> 35.27 (41.7) <R> <C> [EMPTY] <C> ( [ITALIC] λ=8) <C> 2.406 (0.189) <C> 2.423 (0.189) <C> 65.74 (38.8) <C> 65.74 (38.8) <R> <C> [EMPTY] <C> ( [ITALIC] λ=32) <C> 2.439 (0.224) <C> 2.453 (0.228) <C> 80.59 (24.6) <C> 80.60 (24.6) <R> <C> [EMPTY] <C> ( [ITALIC] λ=128) <C> 2.394 (0.163) <C> 2.405 (0.173) <C> 80.58 (24.8) <C> 80.58 (24.8) <R> <C> StochasticLayer <C> [EMPTY] <C> 4.704 (0.752) <C> 4.704 (0.752) <C> 4.704 (0.752) <C> 4.704 (0.752) <CAP> Table 1: Mean test errors (%) over 30 trials at the final iteration in the experiment of selection of layers. The values in parentheses denote the standard deviation.
<R> <C> [EMPTY] <C> Test error (Deterministic) <C> Test error (Stochastic) <C> Training time (min.) <R> <C> AdaptiveActivation <C> 1.414 (0.054) <C> [BOLD] 1.407 (0.036) <C> 255 <R> <C> StochasticActivation <C> – <C> 1.452 (0.025) <C> 204 <R> <C> ReLU <C> 1.609 (0.044) <C> – <C> 120 <R> <C> tanh <C> 1.592 (0.069) <C> – <C> 120 <CAP> Table 2: Mean test errors (%) over 30 trials at the final iteration in the experiment of selection of activation functions. The values in parentheses denote the standard deviation. The training time of a typical single run is reported.
<R> <C> [EMPTY] <C> Test error (%) <C> Time (hour) <R> <C> AdaptiveNet <C> 1.645 (0.072) <C> 1.01 <R> <C> BO (budget=10) <C> 1.780 <C> 9.59 <R> <C> BO (budget=20) <C> 1.490 <C> 18.29 <CAP> Table 3: Test errors (%) and computational time of the proposed method (AdaptiveNet) and the Bayesian optimization (BO) with different budgets in the experiment of adaptation of stochastic network. The mean values over 30 trials are reported in the proposed method, and the value in parentheses denotes the standard deviation. For the Bayesian optimization, the result of a single run is reported.
<R> <C> [EMPTY] <C> CIFAR-10 Deterministic <C> CIFAR-10 Stochastic <C> CIFAR-100 Deterministic <C> CIFAR-100 Stochastic <R> <C> AdaptiveConnection <C> 5.427 (0.167) <C> 5.399 (0.153) <C> 25.461 (0.408) <C> [BOLD] 25.315 (0.409) <R> <C> Normal DenseNet (40 depth,  [ITALIC] k=12) <C> [BOLD] 5.050 (0.147) <C> – <C> 25.518 (0.380) <C> – <CAP> Table 4: Test errors (%) at the final iteration in the experiment of connection selection for DenseNets. The values in parentheses denote the standard deviation.
<R> <C> Method <C> Accuracy (%) <R> <C> ResNet-101 (source only) resnet <C> 52.4 <R> <C> RevGrad gradient_reverse <C> 57.4 <R> <C> DAN Long2015 <C> 62.8 <R> <C> JAN Long2017 <C> 65.7 <R> <C> GTA generate_to_adapt <C> 69.5 <R> <C> MCD-DA max_discrepancy <C> 71.9 <R> <C> ADR adversarial_dropout <C> 73.5 <R> <C> DM-ADA (ours) <C> [BOLD] 75.6 <CAP> Table 3: Classification accuracy on the validation set of VisDA-2017 challenge.
<R> <C> Model <C> Cardiac <C> Coronary <C> Medical <C> Surgical <C> Avg <R> <C> SVM <C> 0.627 <C> 0.572 <C> 0.503 <C> 0.532 <C> 0.558 <R> <C> LR <C> 0.629 <C> 0.601 <C> 0.510 <C> 0.517 <C> 0.564 <R> <C> RF <C> 0.610 <C> 0.578 <C> 0.587 <C> 0.623 <C> 0.599 <R> <C> TT <C> 0.821 <C> 0.769 <C> 0.722 <C> 0.727 <C> 0.759 <R> <C> LSTM <C> 0.812 <C> 0.807 <C> 0.742 <C> 0.769 <C> 0.782 <R> <C> CNN <C> 0.866 <C> 0.802 <C> 0.747 <C> 0.812 <C> 0.807 <R> <C> NT− <C> 0.876 <C> 0.833 <C> 0.737 <C> 0.801 <C> 0.812 <R> <C> NT <C> 0.876 <C> 0.837 <C> 0.757 <C> 0.812 <C> 0.820 <R> <C> [Che  [ITALIC] et al., 2015] <C> 0.853 <C> 0.802 <C> 0.760 <C> 0.785 <C> 0.800 <R> <C> [Che  [ITALIC] et al., 2018] <C> 0.868 <C> 0.824 <C> 0.775 <C> [BOLD] 0.823 <C> 0.823 <R> <C> CNN−LSTM <C> [BOLD] 0.885 <C> [BOLD] 0.848 <C> [BOLD] 0.782 <C> [BOLD] 0.827 <C> [BOLD] 0.836 <CAP> TABLE II AUC NUMBERS FOR SHALLOW AND DEEP MODELS. NUMBERS IN BOLD INDICATE THE BEST MODELS FOR EACH ICU DOMAIN.
<R> <C> Target <C> A1 <C> A2 <C> A3 <C> A4 <C> A5 <R> <C> Cardiac <C> 0.852 <C> [BOLD] 0.885 <C> 0.829 <C> 0.849 <C> 0.858 <R> <C> Coronary <C> [BOLD] 0.848 <C> 0.812 <C> 0.807 <C> 0.793 <C> 0.784 <R> <C> Medical <C> 0.754 <C> 0.763 <C> [BOLD] 0.782 <C> 0.759 <C> 0.736 <R> <C> Surgical <C> 0.822 <C> [BOLD] 0.827 <C> 0.808 <C> 0.818 <C> 0.788 <R> <C> Overall <C> 0.819 <C> [BOLD] 0.822 <C> 0.806 <C> 0.804 <C> 0.791 <CAP> TABLE III: AUC numbers for different feature transference approaches. Numbers in bold indicate the best transference approach for each target ICU domain.
<R> <C> [EMPTY] <C> GEM CGR-AP@10-S1 <C> BCGD [ITALIC] l CGR-AP@10-S1 <C> BCGD [ITALIC] g CGR-AP@10-S1 <C> Triad CGR-AP@10-S1 <C> Ours0.2,0.5 CGR-AP@10-S1 <C> GEM CGR-AP@10-S2 <C> BCGD [ITALIC] l CGR-AP@10-S2 <C> BCGD [ITALIC] g CGR-AP@10-S2 <C> Triad CGR-AP@10-S2 <C> Ours0.2,0.5 CGR-AP@10-S2 <R> <C> AS733 <C> 06.38 <C> 53.90 <C> 13.87 <C> 56.39 <C> [BOLD] 79.19 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Chess <C> 12.10 <C> 46.99 <C> 15.85 <C> 50.27 <C> [BOLD] 80.27 <C> 08.56 <C> 44.81 <C> 11.68 <C> 52.57 <C> [BOLD] 81.40 <R> <C> DNC <C> 25.55 <C> 57.50 <C> 49.02 <C> [BOLD] 67.42 <C> 65.85 <C> [EMPTY] <C> 38.03 <C> 73.67 <C> [BOLD] 83.27 <C> 81.88 <R> <C> Elec <C> [EMPTY] <C> 38.57 <C> 29.89 <C> 46.07 <C> [BOLD] 65.11 <C> 12.19 <C> 26.45 <C> 19.94 <C> 49.39 <C> [BOLD] 58.57 <R> <C> FBW <C> [EMPTY] <C> 06.66 <C> 00.22 <C> 51.60 <C> [BOLD] 85.08 <C> [EMPTY] <C> 07.16 <C> 00.22 <C> 62.97 <C> [BOLD] 86.79 <R> <C> HepPh <C> [EMPTY] <C> 74.31 <C> 56.62 <C> [EMPTY] <C> [BOLD] 84.81 <C> [EMPTY] <C> 67.20 <C> 46.90 <C> [EMPTY] <C> [BOLD] 83.50 <R> <C> [EMPTY] <C> GR-AP@10-S1 <C> GR-AP@10-S1 <C> GR-AP@10-S1 <C> GR-AP@10-S1 <C> GR-AP@10-S1 <C> GR-AP@10-S2 <C> GR-AP@10-S2 <C> GR-AP@10-S2 <C> GR-AP@10-S2 <C> GR-AP@10-S2 <R> <C> AS733 <C> 00.60 <C> 48.83 <C> 02.48 <C> 63.31 <C> [BOLD] 81.12 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Chess <C> 04.41 <C> 43.84 <C> 04.41 <C> 54.61 <C> [BOLD] 85.80 <C> 04.94 <C> 49.74 <C> 04.74 <C> 57.72 <C> [BOLD] 87.05 <R> <C> DNC <C> 03.33 <C> 34.96 <C> 22.14 <C> [BOLD] 76.93 <C> 76.02 <C> [EMPTY] <C> 12.09 <C> 75.92 <C> [BOLD] 81.72 <C> 51.26 <R> <C> Elec <C> [EMPTY] <C> 17.89 <C> 09.13 <C> 57.71 <C> [BOLD] 81.62 <C> 03.85 <C> 16.31 <C> 08.94 <C> 59.65 <C> [BOLD] 78.27 <R> <C> FBW <C> [EMPTY] <C> 03.94 <C> 00.11 <C> 58.94 <C> [BOLD] 90.20 <C> [EMPTY] <C> 04.02 <C> 00.14 <C> 71.29 <C> [BOLD] 91.42 <R> <C> HepPh <C> [EMPTY] <C> 61.34 <C> 31.40 <C> [EMPTY] <C> [BOLD] 81.27 <C> [EMPTY] <C> 55.55 <C> 27.72 <C> [EMPTY] <C> [BOLD] 80.61 <R> <C> [EMPTY] <C> CGR-AP@100-S1 <C> CGR-AP@100-S1 <C> CGR-AP@100-S1 <C> CGR-AP@100-S1 <C> CGR-AP@100-S1 <C> CGR-AP@100-S2 <C> CGR-AP@100-S2 <C> CGR-AP@100-S2 <C> CGR-AP@100-S2 <C> CGR-AP@100-S2 <R> <C> AS733 <C> 06.67 <C> 80.42 <C> 80.35 <C> 73.34 <C> [BOLD] 91.30 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Chess <C> 13.06 <C> 64.26 <C> 40.82 <C> 61.12 <C> [BOLD] 84.68 <C> 11.89 <C> 71.83 <C> 51.93 <C> 67.12 <C> [BOLD] 90.66 <R> <C> DNC <C> 29.24 <C> 82.25 <C> 75.28 <C> 83.48 <C> [BOLD] 87.14 <C> [EMPTY] <C> 73.01 <C> 79.92 <C> 95.18 <C> [BOLD] 99.31 <R> <C> Elec <C> [EMPTY] <C> 48.45 <C> 38.93 <C> 56.04 <C> [BOLD] 69.40 <C> 12.47 <C> 39.33 <C> 33.54 <C> 61.68 <C> [BOLD] 66.88 <R> <C> FBW <C> [EMPTY] <C> 06.91 <C> 00.23 <C> 63.00 <C> [BOLD] 97.00 <C> [EMPTY] <C> 11.45 <C> 02.50 <C> 76.47 <C> [BOLD] 98.68 <R> <C> HepPh <C> [EMPTY] <C> 68.70 <C> 53.88 <C> [EMPTY] <C> [BOLD] 85.51 <C> [EMPTY] <C> 62.21 <C> 45.87 <C> [EMPTY] <C> [BOLD] 84.51 <R> <C> [EMPTY] <C> GR-AP@100-S1 <C> GR-AP@100-S1 <C> GR-AP@100-S1 <C> GR-AP@100-S1 <C> GR-AP@100-S1 <C> GR-AP@100-S2 <C> GR-AP@100-S2 <C> GR-AP@100-S2 <C> GR-AP@100-S2 <C> GR-AP@100-S2 <R> <C> AS733 <C> 01.31 <C> 88.87 <C> 95.39 <C> 83.15 <C> [BOLD] 97.15 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Chess <C> 06.55 <C> 74.81 <C> 45.51 <C> 71.83 <C> [BOLD] 94.90 <C> 08.91 <C> 82.25 <C> 59.78 <C> 74.99 <C> [BOLD] 96.79 <R> <C> DNC <C> 05.77 <C> 81.45 <C> 82.84 <C> 94.38 <C> [BOLD] 97.11 <C> [EMPTY] <C> 82.51 <C> 88.54 <C> 98.42 <C> [BOLD] 99.85 <R> <C> Elec <C> [EMPTY] <C> 42.29 <C> 36.75 <C> 74.07 <C> [BOLD] 86.74 <C> 04.55 <C> 40.10 <C> 41.57 <C> 76.17 <C> [BOLD] 86.05 <R> <C> FBW <C> [EMPTY] <C> 04.88 <C> 00.17 <C> 71.42 <C> [BOLD] 98.59 <C> [EMPTY] <C> 08.60 <C> 02.69 <C> 83.52 <C> [BOLD] 99.39 <R> <C> HepPh <C> [EMPTY] <C> 58.28 <C> 30.17 <C> [EMPTY] <C> [BOLD] 84.91 <C> [EMPTY] <C> 55.84 <C> 30.96 <C> [EMPTY] <C> [BOLD] 85.83 <R> <C> [EMPTY] <C> LP-AUC-S1 <C> LP-AUC-S1 <C> LP-AUC-S1 <C> LP-AUC-S1 <C> LP-AUC-S1 <C> LP-AUC-S2 <C> LP-AUC-S2 <C> LP-AUC-S2 <C> LP-AUC-S2 <C> LP-AUC-S2 <R> <C> AS733 <C> 60.18 <C> 61.37 <C> 70.15 <C> 65.54 <C> [BOLD] 85.56 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Chess <C> 64.23 <C> [BOLD] 86.66 <C> 85.77 <C> 79.32 <C> 77.24 <C> 68.79 <C> [BOLD] 88.62 <C> 79.94 <C> 85.83 <C> 73.12 <R> <C> DNC <C> 75.90 <C> 84.18 <C> 89.34 <C> [BOLD] 90.30 <C> 78.76 <C> [EMPTY] <C> 76.52 <C> [BOLD] 94.21 <C> 92.81 <C> 89.82 <R> <C> Elec <C> 66.32 <C> 91.16 <C> 82.83 <C> [BOLD] 97.31 <C> 90.31 <C> 67.69 <C> 82.13 <C> 82.47 <C> [BOLD] 90.34 <C> 78.38 <R> <C> FBW <C> [EMPTY] <C> 82.83 <C> 82.88 <C> 81.76 <C> [BOLD] 88.00 <C> [EMPTY] <C> 84.51 <C> 85.02 <C> 83.93 <C> [BOLD] 89.69 <R> <C> HepPh <C> [EMPTY] <C> 88.39 <C> 82.37 <C> [EMPTY] <C> [BOLD] 90.25 <C> [EMPTY] <C> [BOLD] 89.99 <C> 81.17 <C> [EMPTY] <C> 89.58 <CAP> Table 2: CGR, GR and LP tasks under slicing ways S1 (left) and S2 (right): each entry (in %) is calculated by the mean over 20 time steps and over 10 runs; the best result of each half row is in bold.
<R> <C> [EMPTY] <C> GEM <C> BCGD [ITALIC] l <C> BCGD [ITALIC] g <C> Triad <C> Ours0.2,0.5 <C> Ours0.2,0.5 [ITALIC] t=0 <C> Ours0.2,0.5 [ITALIC] t≥1, [ITALIC] avg <C> Ours0.4,0.5 [ITALIC] t≥1, [ITALIC] avg <C> Ours0.6,0.5 [ITALIC] t≥1, [ITALIC] avg <R> <C> DNC <C> 696 <C> 241 <C> 939 <C> 129 <C> [BOLD] 91 <C> 11.31 <C> 3.89 <C> 6.90 <C> 9.98 <R> <C> AS733 <C> 1289 <C> 563 <C> 1800 <C> [BOLD] 111 <C> 152 <C> 16.31 <C> 6.68 <C> 11.40 <C> 16.05 <R> <C> Chess <C> 5495 <C> 1505 <C> 4108 <C> 776 <C> [BOLD] 333 <C> 47.85 <C> 14.08 <C> 25.48 <C> 36.79 <R> <C> Elec <C> 9677 <C> 1902 <C> 4829 <C> 2729 <C> [BOLD] 495 <C> 88.57 <C> 20.07 <C> 37.80 <C> 55.54 <R> <C> HepPh <C> [EMPTY] <C> 11878 <C> 16834 <C> [EMPTY] <C> [BOLD] 2128 <C> 319.02 <C> 88.71 <C> 152.12 <C> 223.54 <R> <C> FBW <C> [EMPTY] <C> 10042 <C> 23139 <C> 4896 <C> [BOLD] 2506 <C> 473.79 <C> 100.83 <C> 192.38 <C> 285.69 <CAP> Table 3: Wall-clock time under slicing way S1: the left part shows the total time over 21 time steps including I/O; the right part shows the detailed time of the offline or online stage excluding I/O.
<R> <C> Method <C> VGG-13 <C> VGG-16 <C> VGG-19 <C> WRN 52-1 <C> WRN 16-4 <C> WRN 28-10 <R> <C> SGD <C> 5.88 <C> 6.32 <C> 6.49 <C> 6.23 <C> 4.96 <C> 3.89 <R> <C> ADAM <C> 6.43 <C> 6.61 <C> 6.92 <C> 6.77 <C> 5.32 <C> 3.86 <R> <C> Cayley SGD <C> 5.90 <C> [BOLD] 5.77 <C> 5.85 <C> 6.35 <C> 5.15 <C> 3.66 <R> <C> Cayley ADAM <C> 5.93 <C> 5.88 <C> 6.03 <C> 6.44 <C> 5.22 <C> [BOLD] 3.57 <CAP> Table 1: Classification errors(%) on CIFAR10.
<R> <C> Method <C> VGG-13 <C> VGG-16 <C> VGG-19 <C> WRN 52-1 <C> WRN 16-4 <C> WRN 28-10 <R> <C> SGD <C> 26.17 <C> 26.84 <C> 27.62 <C> 27.44 <C> 23.41 <C> 18.66 <R> <C> ADAM <C> 26.58 <C> 27.10 <C> 27.88 <C> 27.89 <C> 24.45 <C> 18.45 <R> <C> Cayley SGD <C> [BOLD] 24.86 <C> 25.48 <C> 25.68 <C> 27.64 <C> 23.71 <C> 18.26 <R> <C> Cayley ADAM <C> 25.10 <C> 25.61 <C> 25.70 <C> 27.91 <C> 24.18 <C> [BOLD] 18.10 <CAP> Table 2: Classification errors(%) on CIFAR100.
<R> <C> PM <C> FM <C> Tri <C> A-distance <C> Accuracy (%) <R> <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 1.528 <C> 76.7 <R> <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> 1.519 <C> 78.1 <R> <C> ✓ <C> [EMPTY] <C> ✓ <C> 1.508 <C> 79.4 <R> <C> [EMPTY] <C> ✓ <C> [EMPTY] <C> 1.497 <C> 82.1 <R> <C> ✓ <C> ✓ <C> [EMPTY] <C> 1.492 <C> 83.2 <R> <C> ✓ <C> ✓ <C> ✓ <C> 1.489 <C> 83.9 <CAP> Table 4: Effectiveness of pixel-level mixup (PM), feature-level mixup (FM) and triplet loss (Tri).
<R> <C> [EMPTY] <C> Method <C> Error Rate(%) CIFAR10 <C> Error Rate(%) CIFAR100 <C> Training time(s) <R> <C> Baselines <C> SGD <C> 3.89 <C> 18.66 <C> 102.5 <R> <C> Baselines <C> ADAM <C> 3.85 <C> 18.52 <C> 115.2 <R> <C> Soft orthonormality <C> SO (Bansal et al.,  2018 ) <C> 3.76 <C> 18.56 <C> 297.3 <R> <C> Soft orthonormality <C> DSO (Bansal et al.,  2018 ) <C> 3.86 <C> 18.21 <C> 311.0 <R> <C> Soft orthonormality <C> SRIP (Bansal et al.,  2018 ) <C> 3.60 <C> 18.19 <C> 321.8 <R> <C> Hard orthonormality <C> OMDSM (Huang et al.,  2018a ) <C> 3.73 <C> 18.61 <C> 943.6 <R> <C> Hard orthonormality <C> DBN (Huang et al.,  2018b ) <C> 3.79 <C> 18.36 <C> 889.4 <R> <C> Hard orthonormality <C> Polar (Absil et al.,  2009 ) <C> 3.75 <C> 18.50 <C> 976.5 <R> <C> Hard orthonormality <C> QR (Absil et al.,  2009 ) <C> 3.75 <C> 18.65 <C> 469.3 <R> <C> Hard orthonormality <C> Wen&Yin (Wen & Yin,  2013 ) <C> 3.82 <C> 18.70 <C> 305.8 <R> <C> Hard orthonormality <C> Cayley closed form w/o momentum <C> 3.80 <C> 18.68 <C> 1071.5 <R> <C> Hard orthonormality <C> Cayley SGD ( [BOLD] Ours) <C> 3.66 <C> 18.26 <C> 218.7 <R> <C> Hard orthonormality <C> Cayley ADAM ( [BOLD] Ours) <C> 3.57 <C> 18.10 <C> 224.4 <CAP> Table 3: Error rate and training time per epoch comparison to baselines with WRN-28-10 on CIFAR10 and CIFAR100. All experiments are performed on one TITAN Xp GPU.
<R> <C> Model <C> Hidden Size <C> Closed-Form Acc(%) <C> Closed-Form Time(s) <C> Cayley SGD Acc(%) <C> Cayley SGD Time(s) <C> Cayley ADAM Acc(%) <C> Cayley ADAM Time(s) <R> <C> Full-uRNN <C> 116 <C> 92.8 <C> 2.10 <C> 92.6 <C> 1.42 <C> 92.7 <C> 1.50 <R> <C> Full-uRNN <C> 512 <C> 96.9 <C> 2.44 <C> 96.7 <C> 1.67 <C> [BOLD] 96.9 <C> 1.74 <CAP> Table 4: Pixel-by-pixel MNIST accuracy and training time per iteration of the closed-form Cayley Transform, Cayley SGD, and Cayley ADAM for Full-uRNNs (Wisdom et al., 2016). All experiments are performed on one TITAN Xp GPU.
<R> <C> Hidden Size <C> s=0 <C> s=1 <C> s=2 <C> s=3 <C> s=4 <C> Closed-form <R> <C> n=116 <C> 3.231e-3 <C> 2.852e-4 <C> 7.384e-6 <C> 7.353e-6 <C> 7.338e-6 <C> 8.273e-5 <R> <C> n=512 <C> 6.787e-3 <C> 5.557e-4 <C> 2.562e-5 <C> 2.547e-5 <C> 2.544e-5 <C> 3.845e-5 <CAP> Table 5: Checking unitariness by computing the error ||KHK−I||F for varying numbers of iterations in the iterative Cayley transform and the closed-form Cayley transform.
<R> <C> [EMPTY] <C> ¯¯¯¯¯¯¯¯¯¯¯¯¯SINR <C> SINR5 <C> SINR50 <C> SINR95 <R> <C> Baseline <C> 20.52 <C> 4.91 <C> 20.26 <C> 36.99 <R> <C> Opt. Simulator <C> 23.24 <C> 7.25 <C> 23.18 <C> 39.27 <R> <C> Opt. Emulator <C> 23.49 <C> 7.47 <C> 23.45 <C> 39.64 <CAP> TABLE I: Numerical results shown in Fig. 5.
<R> <C> [BOLD] Data set <C> [BOLD] instances <C> [BOLD] features <C> [BOLD] classes <C> [BOLD] #neurons <C> [BOLD] batch size <C> [BOLD] lr <C> [BOLD] epochs <C> [BOLD] min samples leaf <C> [BOLD] pruning <R> <C> 2-D parabola <C> 500 <C> 2 <C> 2 <C> 100, 100, 10 <C> 100 <C> 0.001 <C> 1000 <C> - <C> N <R> <C> Iris  <C> 150 <C> 4 <C> 3 <C> 8 <C> 10 <C> 0.01 <C> 50 <C> 5 <C> Y <R> <C> Breast Cancer Wisconsin  <C> 569 <C> 30 <C> 2 <C> 64, 32 <C> 10 <C> 0.001 <C> 10 <C> 15 <C> Y <R> <C> Pima Indians Diabetes  <C> 768 <C> 8 <C> 2 <C> 24 <C> 128 <C> 0.01 <C> 10 <C> 30 <C> Y <R> <C> Titanic  <C> 891 <C> 11 <C> 2 <C> 100, 50, 25 <C> 16 <C> 0.005 <C> 10 <C> 35 <C> Y <R> <C> Mushroom  <C> 8,124 <C> 22 <C> 2 <C> 16 <C> 10 <C> 0.005 <C> 25 <C> 45 <C> Y <R> <C> Adult  <C> 48,842 <C> 14 <C> 2 <C> 32, 16 <C> 32 <C> 0.005 <C> 10 <C> 75 <C> Y <R> <C> Diabetes  <C> 100,000 <C> 50 <C> 2 <C> 32, 16, 8 <C> 512 <C> 0.01 <C> 50 <C> 250 <C> Y <CAP> TABLE I: Data sets and training parameters used for evaluation. #neurons refers to number of neurons per hidden layer.
<R> <C> Data set <C> L1-O  [ITALIC] λ1 <C> L1-O  [ITALIC] λorth <C> L1-O  [BOLD] APL <C> L1-O  [BOLD] Consistency <C> L1-O  [BOLD] Fidelity <C> FN  [ITALIC] λ1 <C> FN  [ITALIC] λorth <C> FN  [BOLD] APL <C> FN  [BOLD] Consistency <C> FN  [BOLD] Fidelity <R> <C> Titanic <C> 0.006 <C> 0.025 <C> 2.4 <C> 0.70 <C> 0.98± 0.03 <C> 0.02 <C> 0.75 <C> 1.7 <C> 1.00 <C> 0.99± 0.00 <R> <C> [EMPTY] <C> 0.001 <C> 0.01 <C> 4.7 <C> 1.00 <C> 0.93± 0.00 <C> 0.003 <C> 0.75 <C> 4.2 <C> 0.70 <C> 0.97± 0.01 <R> <C> [EMPTY] <C> 0.001 <C> 0.001 <C> 7.9 <C> 1.00 <C> 0.91 ± 0.01 <C> 0.002 <C> 0.001 <C> 8.0 <C> 0.94 <C> 0.93± 0.01 <R> <C> Mushroom <C> 0.1 <C> 0.75 <C> 1.4 <C> 0.90 <C> 1.00± 0.00 <C> 0.1 <C> 0.75 <C> 3.8 <C> 0.53 <C> 0.99± 0.0 <R> <C> [EMPTY] <C> 0.08 <C> 1.1 <C> 6.4 <C> 0.93 <C> 0.99± 0.00 <C> 0.08 <C> 1.1 <C> 6.4 <C> 0.52 <C> 1.00± 0.00 <R> <C> [EMPTY] <C> 0.003 <C> 0.001 <C> 14 <C> 1.0 <C> 0.98± 0.00 <C> 0.003 <C> 0.001 <C> 14 <C> 1.0 <C> 0.98± 0.00 <R> <C> Adult <C> 0.09 <C> 0.5 <C> 1.7 <C> 0.82 <C> 1.00 ± 0.00 <C> 0.08 <C> 1.1 <C> 1.7 <C> 0.86 <C> 0.99 ± 0.00 <R> <C> [EMPTY] <C> 0.02 <C> 0.25 <C> 16 <C> 0.88 <C> 0.98 ± 0.00 <C> 0.04 <C> 0.75 <C> 13.6 <C> 0.97 <C> 0.99 ± 0.00 <R> <C> [EMPTY] <C> 0.0025 <C> 0.1 <C> 39 <C> 0.92 <C> 0.95 ± 0.00 <C> 0.003 <C> 0.25 <C> 37.2 <C> 0.86 <C> 0.97 ± 0.01 <R> <C> Diabetes <C> 0.04 <C> 0.75 <C> 3.9 <C> 0.84 <C> 1.00 ± 0.00 <C> 0.03 <C> 1.0 <C> 3.4 <C> 0.79 <C> 0.99 ± 0.00 <R> <C> [EMPTY] <C> 0.02 <C> 0.25 <C> 16 <C> 0.59 <C> 0.98 ± 0.01 <C> 0.02 <C> 1.1 <C> 14.1 <C> 0.94 <C> 0.99 ± 0.00 <R> <C> [EMPTY] <C> 0.0075 <C> 0.075 <C> 57 <C> 0.87 <C> 0.96 ± 0.01 <C> 0.004 <C> 0.01 <C> 57.9 <C> 0.83 <C> 0.94 ± 0.00 <CAP> TABLE III: Consistency of DT predictions.
<R> <C> Regularization <C> 2D-parabola <C> Iris <C> Breast Cancer <R> <C> L1-O <C> [BOLD] 42.72 <C> [BOLD] 0.59 <C> [BOLD] 6.44 <R> <C> Tree <C> 2,841.56 <C> 17.78 <C> 471.49 <CAP> TABLE IV: Computation time in seconds.
<R> <C> scale <C> 1 <C> 2 <C> 3 <R> <C> m=0 <C> 0.91 <C> [BOLD] 0.08 <C> 0.98 <R> <C> m=1 <C> 0.16 <C> [BOLD] 0.07 <C> 0.38 <R> <C> m=2 <C> 0.13 <C> 0.82 <C> 0.11 <CAP> TABLE I: P-value of RCMSE features of ECG signals (Left:Arousal, Right:Valence)
<R> <C> scale <C> 1 <C> 2 <C> 3 <R> <C> m=0 <C> 0.91 <C> [ITALIC]  [BOLD] 0.04 <C> [BOLD] 0.08 <R> <C> m=1 <C> 0.46 <C> [BOLD] 0.06 <C> 0.14 <R> <C> m=2 <C> 0.76 <C> [ITALIC]  [BOLD] 0.01 <C> 0.91 <CAP> TABLE I: P-value of RCMSE features of ECG signals (Left:Arousal, Right:Valence)
<R> <C> [ITALIC] Dcls <C> pseudo <C> A-distance <C> Accuracy (%) <R> <C> [EMPTY] <C> [EMPTY] <C> 1.503 <C> 80.6 <R> <C> ✓ <C> [EMPTY] <C> 1.496 <C> 82.3 <R> <C> ✓ <C> ✓ <C> 1.489 <C> 83.9 <CAP> Table 5: Effectiveness of Dcls and pseudo target labels.
<R> <C> scale <C> 1 <C> 2 <C> 3 <C> 4 <C> 5 <C> 6 <C> 7 <C> 8 <C> 9 <C> 10 <R> <C> A ( [ITALIC] m2) <C> 0.23 <C> 0.20 <C> 0.18 <C> 0.11 <C> 0.10 <C> [BOLD] 0.07 <C> [BOLD] 0.05 <C> [ITALIC]  [BOLD] 0.04 <C> [ITALIC]  [BOLD] 0.03 <C> [ITALIC]  [BOLD] 0.03 <R> <C> V ( [ITALIC] m2) <C> 0.25 <C> 0.33 <C> 0.28 <C> 0.34 <C> 0.29 <C> 0.31 <C> 0.33 <C> 0.35 <C> 0.33 <C> 0.32 <R> <C> scale <C> 11 <C> 12 <C> 13 <C> 14 <C> 15 <C> 16 <C> 17 <C> 18 <C> 19 <C> 20 <R> <C> A ( [ITALIC] m2) <C> [ITALIC]  [BOLD] 0.02 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <R> <C> V ( [ITALIC] m2) <C> 0.31 <C> 0.29 <C> 0.29 <C> 0.29 <C> 0.28 <C> 0.27 <C> 0.27 <C> 0.27 <C> 0.27 <C> 0.26 <CAP> TABLE II: P-value of RCMSE features of GSR signals (A: arousal, V: valence) (m2 means pattern length = 2)
<R> <C> scale <C> 1 <C> 2 <C> 3 <R> <C> A ( [ITALIC] m3) <C> [ITALIC]  [BOLD] 0.03 <C> [ITALIC]  [BOLD] 0.03 <C> [BOLD] 0.1 <R> <C> V ( [ITALIC] m6) <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <CAP> TABLE III: P-value of RCMPE features of ECG signals (A: arousal, V: valence) (m3 means embedding dimension = 3)
<R> <C> scale <C> 1 <C> 2 <C> 3 <C> 4 <C> 5 <C> 6 <C> 7 <C> 8 <C> 9 <C> 10 <R> <C> A ( [ITALIC] m2) <C> [ITALIC]  [BOLD] 0.01 <C> [BOLD] 0.08 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <R> <C> V ( [ITALIC] m5) <C> [BOLD] 0.06 <C> 0.13 <C> 0.18 <C> 0.22 <C> 0.25 <C> 0.28 <C> 0.31 <C> 0.32 <C> 0.34 <C> 0.36 <R> <C> scale <C> 11 <C> 12 <C> 13 <C> 14 <C> 15 <C> 16 <C> 17 <C> 18 <C> 19 <C> 20 <R> <C> A ( [ITALIC] m2) <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <R> <C> V ( [ITALIC] m5) <C> 0.37 <C> 0.38 <C> 0.39 <C> 0.39 <C> 0.40 <C> 0.40 <C> 0.41 <C> 0.41 <C> 0.41 <C> 0.41 <CAP> TABLE IV: P-value of RCMPE features of GSR signals (A: arousal, V: valence) (m2 means embedding dimension = 2)
<R> <C> scale <C> 1 <C> 2 <C> 3 <C> 4 <C> 5 <C> 6 <C> 7 <C> 8 <C> 9 <C> 10 <R> <C> A ( [ITALIC] m4) <C> 0.43 <C> 0.46 <C> 0.99 <C> 0.82 <C> 0.66 <C> 0.45 <C> 0.54 <C> 0.52 <C> 0.33 <C> 0.47 <R> <C> V ( [ITALIC] m6) <C> 0.30 <C> 0.37 <C> 0.38 <C> 0.46 <C> 0.48 <C> 0.46 <C> 0.38 <C> 0.30 <C> 0.25 <C> 0.15 <R> <C> scale <C> 11 <C> 12 <C> 13 <C> 14 <C> 15 <C> 16 <C> 17 <C> 18 <C> 19 <C> 20 <R> <C> A ( [ITALIC] m4) <C> 0.26 <C> 0.22 <C> 0.27 <C> 0.12 <C> 0.13 <C> [BOLD] 0.1 <C> 0.14 <C> 0.17 <C> [ITALIC]  [BOLD] 0.04 <C> 0.17 <R> <C> V ( [ITALIC] m4) <C> [BOLD] 0.08 <C> [ITALIC]  [BOLD] 0.03 <C> [ITALIC]  [BOLD] 0.02 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <C> [ITALIC]  [BOLD] 0.01 <CAP> TABLE V: P-value of MMPE features of EEG signals (AF3, AF4) (A: arousal, V: valence) (m4 means embedding dimension = 4)
<R> <C> Scheme (A) <C> EEG <C> ECG <C> GSR <C> Fusion <R> <C> I  <C> [BOLD] 0.592 <C> 0.550 <C> 0.548 <C> 0.585 <R> <C> II <C> 0.568 <C> 0.556 <C> 0.665 <C> 0.687 <R> <C> III <C> 0.568 <C> [BOLD] 0.561 <C> [BOLD] 0.692 <C> [BOLD] 0.706 <CAP> TABLE VI: Mean F1-score of emotion recognition on AMIGOS (up: arousal, down: valence)
<R> <C> Dataset n/k <C> Dataset n <C> Spiral M1 <C> Spiral M2 <C> Spiral M3 <C> Swiss roll M1 <C> Swiss roll M2 <C> Swiss roll M3 <R> <C> 55 <C> 1500 <C> [BOLD] 6.86E-5 ± 2E-6 <C> 6.88E-5 ± 2E-6 <C> 8.25E-5 ± 2E-5 <C> 3.71E-1 ± 9E-3 <C> [BOLD] 3.46E-1 ± 1E-2 <C> 3.77E-1 ± 2E-2 <R> <C> 55 <C> 1700 <C> 6.56E-5 ± 2E-6 <C> [BOLD] 6.53E-5 ± 3E-6 <C> 7.40E-5 ± 1E-5 <C> 3.53E-1 ± 1E-2 <C> [BOLD] 3.42E-1 ± 5E-3 <C> 3.65E-1 ± 1E-2 <R> <C> 55 <C> 1900 <C> [BOLD] 6.31E-5 ± 2E-6 <C> 6.45E-5 ± 2E-6 <C> 6.95E-5 ± 3E-6 <C> 3.50E-1 ± 1E-2 <C> [BOLD] 3.35E-1 ± 8E-3 <C> 3.65E-1 ± 2E-2 <R> <C> 55 <C> 2100 <C> [BOLD] 6.20E-5 ± 2E-6 <C> 6.35E-5 ± 2E-6 <C> 7.55E-5 ± 2E-5 <C> 3.55E-1 ± 1E-2 <C> [BOLD] 3.34E-1 ± 8E-3 <C> 3.60E-1 ± 2E-2 <R> <C> 55 <C> 2300 <C> [BOLD] 6.12E-5 ± 1E-6 <C> 6.21E-5 ± 2E-6 <C> 7.09E-5 ± 1E-5 <C> 3.47E-1 ± 9E-3 <C> [BOLD] 3.34E-1 ± 9E-3 <C> 3.51E-1 ± 1E-2 <R> <C> 65 <C> 1500 <C> 7.52E-5 ± 3E-6 <C> [BOLD] 7.44E-5 ± 3E-6 <C> 9.13E-5 ± 1E-5 <C> [BOLD] 3.54E-1 ± 1E-2 <C> 3.62E-1 ± 2E-2 <C> 3.81E-1 ± 2E-2 <R> <C> 65 <C> 1700 <C> [BOLD] 6.79E-5 ± 2E-6 <C> 6.82E-5 ± 3E-6 <C> 7.65E-5 ± 8E-6 <C> [BOLD] 3.52E-1 ± 8E-3 <C> 3.53E-1 ± 2E-2 <C> 3.95E-1 ± 4E-2 <R> <C> 65 <C> 1900 <C> [BOLD] 6.43E-5 ± 1E-6 <C> 6.64E-5 ± 2E-6 <C> 6.96E-5 ± 3E-6 <C> 3.49E-1 ± 1E-2 <C> [BOLD] 3.42E-1 ± 1E-2 <C> 3.67E-1 ± 2E-2 <R> <C> 65 <C> 2100 <C> 6.42E-5 ± 3E-6 <C> [BOLD] 6.35E-5 ± 1E-6 <C> 6.93E-5 ± 4E-6 <C> 3.54E-1 ± 1E-2 <C> [BOLD] 3.35E-1 ± 1E-2 <C> 3.59E-1 ± 2E-2 <R> <C> 65 <C> 2300 <C> [BOLD] 6.10E-5 ± 2E-6 <C> 6.32E-5 ± 2E-6 <C> 6.94E-5 ± 8E-6 <C> 3.47E-1 ± 1E-2 <C> [BOLD] 3.28E-1 ± 9E-3 <C> 3.57E-1 ± 3E-2 <R> <C> 75 <C> 1500 <C> [BOLD] 8.02E-5 ± 3E-6 <C> 8.21E-5 ± 6E-6 <C> 9.75E-5 ± 1E-5 <C> [BOLD] 3.60E-1 ± 1E-2 <C> 3.92E-1 ± 8E-2 <C> 4.11E-1 ± 3E-2 <R> <C> 75 <C> 1700 <C> [BOLD] 7.46E-5 ± 2E-6 <C> 7.53E-5 ± 3E-6 <C> 8.50E-5 ± 8E-6 <C> 3.55E-1 ± 1E-2 <C> [BOLD] 3.50E-1 ± 6E-3 <C> 3.90E-1 ± 6E-2 <R> <C> 75 <C> 1900 <C> 6.99E-5 ± 3E-6 <C> [BOLD] 6.88E-5 ± 3E-6 <C> 7.82E-5 ± 8E-6 <C> 3.50E-1 ± 1E-2 <C> [BOLD] 3.49E-1 ± 2E-2 <C> 3.92E-1 ± 4E-2 <R> <C> 75 <C> 2100 <C> [BOLD] 6.48E-5 ± 3E-6 <C> 6.59E-5 ± 2E-6 <C> 7.54E-5 ± 7E-6 <C> 3.50E-1 ± 1E-2 <C> [BOLD] 3.38E-1 ± 1E-2 <C> 3.63E-1 ± 2E-2 <R> <C> 75 <C> 2300 <C> [BOLD] 6.40E-5 ± 2E-6 <C> 6.47E-5 ± 2E-6 <C> 6.72E-5 ± 3E-6 <C> [BOLD] 3.38E-1 ± 1E-2 <C> 3.46E-1 ± 2E-2 <C> 3.83E-1 ± 5E-2 <R> <C> 85 <C> 1500 <C> [BOLD] 9.55E-5 ± 6E-6 <C> 1.01E-4 ± 8E-6 <C> 1.34E-4 ± 3E-5 <C> 4.33E-1 ± 1E-1 <C> [BOLD] 4.22E-1 ± 1E-1 <C> 4.24E-1 ± 5E-2 <R> <C> 85 <C> 1700 <C> 8.10E-5 ± 5E-6 <C> [BOLD] 7.89E-5 ± 4E-6 <C> 1.06E-4 ± 2E-5 <C> 3.81E-1 ± 9E-2 <C> [BOLD] 3.65E-1 ± 1E-2 <C> 3.94E-1 ± 3E-2 <R> <C> 85 <C> 1900 <C> [BOLD] 7.37E-5 ± 3E-6 <C> 7.43E-5 ± 4E-6 <C> 8.76E-5 ± 1E-5 <C> 3.50E-1 ± 9E-3 <C> [BOLD] 3.49E-1 ± 1E-2 <C> 3.91E-1 ± 5E-2 <R> <C> 85 <C> 2100 <C> 7.13E-5 ± 2E-6 <C> [BOLD] 6.94E-5 ± 1E-6 <C> 7.71E-5 ± 4E-6 <C> 3.49E-1 ± 9E-3 <C> [BOLD] 3.49E-1 ± 8E-3 <C> 3.71E-1 ± 2E-2 <R> <C> 85 <C> 2300 <C> 6.72E-5 ± 2E-6 <C> [BOLD] 6.62E-5 ± 2E-6 <C> 6.92E-5 ± 4E-6 <C> 3.44E-1 ± 1E-2 <C> [BOLD] 3.33E-1 ± 5E-3 <C> 3.65E-1 ± 1E-2 <R> <C> 95 <C> 1500 <C> [BOLD] 1.13E-4 ± 1E-5 <C> 1.21E-4 ± 1E-5 <C> 1.52E-4 ± 2E-5 <C> 5.45E-1 ± 2E-1 <C> [BOLD] 4.74E-1 ± 1E-1 <C> 4.91E-1 ± 1E-1 <R> <C> 95 <C> 1700 <C> [BOLD] 8.98E-5 ± 4E-6 <C> 9.62E-5 ± 7E-6 <C> 1.33E-4 ± 4E-5 <C> 4.97E-1 ± 2E-1 <C> [BOLD] 4.33E-1 ± 1E-1 <C> 4.90E-1 ± 1E-1 <R> <C> 95 <C> 1900 <C> 7.97E-5 ± 5E-6 <C> [BOLD] 7.75E-5 ± 3E-6 <C> 9.70E-5 ± 1E-5 <C> 3.59E-1 ± 9E-3 <C> [BOLD] 3.55E-1 ± 1E-2 <C> 3.92E-1 ± 3E-2 <R> <C> 95 <C> 2100 <C> 7.58E-5 ± 4E-6 <C> [BOLD] 7.16E-5 ± 2E-6 <C> 9.23E-5 ± 1E-5 <C> 3.48E-1 ± 9E-3 <C> [BOLD] 3.46E-1 ± 9E-3 <C> 3.80E-1 ± 2E-2 <R> <C> 95 <C> 2300 <C> 7.03E-5 ± 2E-6 <C> [BOLD] 6.87E-5 ± 1E-6 <C> 7.50E-5 ± 5E-6 <C> [BOLD] 3.43E-1 ± 6E-3 <C> 3.49E-1 ± 1E-2 <C> 4.00E-1 ± 3E-2 <CAP> Table 1: Mean +- 1 standard deviations in expected reconstruction error for the Spiral and Swiss roll datasets, as a function of n and n/k.
<R> <C> [BOLD] Dataset <C> [BOLD] Model <C> [BOLD] Batch Size <C> [BOLD] Dropout <C> [ITALIC] ηUCB <C> [ITALIC] ηCB <C> [ITALIC] ηS <R> <C> MNIST <C> LR <C> 128 <C> NO <C> 0.01 <C> 0.001 <C> 0.0001 <R> <C> MNIST <C> MLP <C> 128 <C> NO <C> 0.1 <C> 0.001 <C> 0.005 <R> <C> MNIST <C> MLP <C> 128 <C> YES <C> 0.1 <C> 0.0005 <C> 0.005 <R> <C> MNIST <C> MLP <C> 16 <C> NO <C> 0.3 <C> 0.0001 <C> 0.05 <R> <C> CIFAR-10 <C> CNN <C> 128 <C> NO <C> 0.01 <C> 5×10−5 <C> 0.0001 <R> <C> CIFAR-10 <C> CNN <C> 128 <C> YES <C> 0.05 <C> 0.0001 <C> 0.0001 <R> <C> CIFAR-10 <C> CNN <C> 16 <C> NO <C> 0.3 <C> 1×10−5 <C> 0.005 <CAP> Table 1: Best hyperparameters η obtained for AdamUCB, AdamCB and AdamS algorithms when training MNIST and CIFAR-10 on various architectures.
<R> <C> [EMPTY] <C> #quasi-adv / #tested <C> NNC,M <C> NNC,C <C> NNG,M <C> NNG,C <C> NNG,CWG <R> <C> MNIST <C> 18 / 32 <C> 2 <C> 3 <C> 1 <C> 3 <C> 7 <R> <C> CIFAR10 <C> 26 / 32 <C> 16 <C> 12 <C> 7 <C> 6 <C> 25 <CAP> Table 1: Number of Successful Adversarial Attacks for Different Implementations
<R> <C> MNIST <C> # attack <C> NNC,M 4 <C> NNC,C 5 <C> NNG,M 2 <C> NNG,C 3 <C> NNG,CWG 17 <R> <C> MNIST <C> min test acc <C> 98.40% <C> 97.83% <C> 98.57% <C> 97.83% <C> 97.83% <R> <C> CIFAR10 <C> # attack <C> 20 <C> 16 <C> 14 <C> 8 <C> 26 <R> <C> CIFAR10 <C> min test acc <C> 58.74% <C> 58.74% <C> 58.74% <C> 58.74% <C> 58.74% <CAP> Table 2: Adversarial Attacks for Different Implementations Allowing Modifying Softmax Bias
<R> <C> Model  [ITALIC] f( [ITALIC] X) Noise <C> Model  [ITALIC] f( [ITALIC] X) Noise <C> [ITALIC] X2  [ITALIC] ε∼ [ITALIC] Exp(1) <C> sin( [ITALIC] πX)  [ITALIC] ε∼ [ITALIC] ChiSqr(3) <C> [ITALIC] e2 [ITALIC] X  [ITALIC] ε∼ [ITALIC] Rayl(4) <C> [ITALIC] sigmoid(5 [ITALIC] X)  [ITALIC] ε∼ [ITALIC] BioNom(20,0.3) <R> <C> [EMPTY] <C> SVR <C> 8.320e-01 <C> 5.651e+00 <C> 6.320e+00 <C> 3.849e+00 <R> <C> [EMPTY] <C> HSIC-reg <C> 8.419e-01 <C> 5.688e+00 <C> 6.386e+00 <C> 3.878e+00 <R> <C> [EMPTY] <C> NN-MSE <C> 8.373e-01 <C> 5.548e+00 <C> 6.226e+00 <C> 3.707e+00 <R> <C> MSE <C> GP <C> 8.262e-01 <C> 5.586e+00 <C> 6.228e+00 <C> 3.846e+00 <R> <C> MSE <C> AdOSE <C> 8.301e-01 <C> 7.658e+00 <C> 9.708e+00 <C> 5.112e+00 <R> <C> MSE <C> AdOR <C> 9.299e-01 <C> 9.740e+00 <C> 1.209e+01 <C> 4.073e+00 <R> <C> MSE <C> SVR <C> 6.945e-01 <C> 1.926e+00 <C> 2.031e+00 <C> 1.555e+00 <R> <C> MSE <C> HSIC-reg <C> 7.049e-01 <C> 1.933e+00 <C> 2.051e+00 <C> 1.561e+00 <R> <C> MSE <C> NN-MSE <C> 7.061e-01 <C> 1.909e+00 <C> 2.037e+00 <C> 1.531e+00 <R> <C> MAE <C> GP <C> 6.975e-01 <C> 1.918e+00 <C> 2.035e+00 <C> 1.559e+00 <R> <C> MAE <C> AdOSE <C> 7.008e-01 <C> 2.071e+00 <C> 2.406e+00 <C> 1.527e+00 <R> <C> MAE <C> AdOR <C> 7.426e-01 <C> 2.492e+00 <C> 2.768e+00 <C> 1.626e+00 <R> <C> MAE <C> SVR <C> 1.160e-02 <C> 1.363e-01 <C> 2.197e-01 <C> 1.669e-02 <R> <C> MAE <C> HSIC-reg <C> 2.666e-02 <C> 1.985e-01 <C> 2.551e-01 <C> 1.209e-01 <R> <C> MAE <C> NN-MSE <C> 8.430e-03 <C> 2.634e-01 <C> 1.078e-01 <C> 2.866e-01 <R> <C> ISE <C> GP <C> 5.247e-03 <C> 1.422e-01 <C> 3.491e-02 <C> 2.059e-02 <R> <C> ISE <C> AdOSE <C> 5.109e-03 <C> 6.633e-02 <C> 8.289e-02 <C> 1.554e-02 <R> <C> ISE <C> AdOR <C> [BOLD] 1.734e-03 <C> [BOLD] 4.974e-02 <C> [BOLD] 1.908e-02 <C> [BOLD] 2.232e-03 <CAP> Table 1: Comparison of Different methods.
<R> <C> [EMPTY] <C> FALL <C> Network Lasso <C> KNN <C> KRR <C> Ridge <C> Lasso <R> <C> [BOLD] Concrete data <C> 42.16 (± 19.38) <C> 49.85 (± 22.12) <C> 58.14 (± 26.85) <C> 110.80 (± 33.57) <C> 111.05 (± 33.92) <C> 111.10 (± 33.88) <R> <C> [BOLD] Superconduct data <C> 129.66 (± 28.33) <C> [EMPTY] <C> 117.48 (± 18.77) <C> 312.11 (± 25.82) <C> 308.52 (± 22.56) <C> 345.25 (± 99.80) <R> <C> [BOLD] Aquatic toxicity data <C> 1.46 (± 0.74) <C> 1.72 (± 1.01) <C> 1.81 (± 0.74) <C> 1.92 (± 0.75) <C> 1.58 (± 0.72) <C> 1.58 (± 0.71) <R> <C> [BOLD] Fish toxicity data <C> 0.92 (± 0.48) <C> 0.98 (± 0.53) <C> 0.91 (± 0.48) <C> 1.14 (± 0.57) <C> 0.99 (± 0.44) <C> 0.99 (± 0.44) <R> <C> [BOLD] P.T. motor UPDRS data <C> 20.76 (± 4.51) <C> 24.63 (± 6.89)* <C> 20.88 (± 4.29) <C> 58.30 (± 5.50) <C> 56.69 (± 5.26) <C> 56.81 (± 5.20) <CAP> Table 1: Averaged mean squared error on the real-world datasets over 50 runs. For each method, we select the best parameters by using 3-fold cross-validation. N/A means that a memory problem occurred when computing the model on the dataset. The asterisk * means that the results were computed without cross-validation but with fixed parameters (because of a too long runtime).
<R> <C> [BOLD] Concrete data <C> Train <C> FALL 0.06 (± 0.05) <C> Network Lasso 16.58 (± 3.41) <C> KNN 0.00 (± 0.00) <C> KRR 0.09 (± 0.08) <C> Ridge 0.00 (± 0.00) <C> Lasso 0.01 (± 0.00) <R> <C> [BOLD] Concrete data <C> Test <C> 0.01 (± 0.00) <C> 0.19 (± 0.03) <C> 0.00 (± 0.00) <C> 0.01 (± 0.02) <C> 0.00 (± 0.00) <C> 0.00 (± 0.00) <R> <C> [BOLD] Superconduct data <C> Train <C> 1.24 (± 1.33) <C> [EMPTY] <C> 0.11 (± 0.02) <C> 124.61 (± 109.20) <C> 0.02 (± 0.01) <C> 121.04 (± 125.75) <R> <C> [BOLD] Superconduct data <C> Test <C> 5.90 (± 0.71) <C> [EMPTY] <C> 0.22 (± 0.08) <C> 0.23 (± 0.13) <C> 0.00 (± 0.01) <C> 0.01 (± 0.01) <R> <C> [BOLD] Aquatic toxicity data <C> Train <C> 0.02 (± 0.05) <C> 5.31 (± 1.00) <C> 0.00 (± 0.00) <C> 0.01 (± 0.01) <C> 0.00 (± 0.00) <C> 0.00 (± 0.00) <R> <C> [BOLD] Aquatic toxicity data <C> Test <C> 0.00 (± 0.00) <C> 0.07 (± 0.01) <C> 0.00 (± 0.00) <C> 0.00 (± 0.01) <C> 0.00 (± 0.00) <C> 0.00 (± 0.00) <R> <C> [BOLD] Fish toxicity data <C> Train <C> 0.05 (± 0.05) <C> 13.23 (± 1.78) <C> 0.00 (± 0.00) <C> 0.03 (± 0.04) <C> 0.00 (± 0.00) <C> 0.00 (± 0.00) <R> <C> [BOLD] Fish toxicity data <C> Test <C> 0.01 (± 0.00) <C> 0.14 (± 0.02) <C> 0.00 (± 0.00) <C> 0.00 (± 0.01) <C> 0.00 (± 0.00) <C> 0.00 (± 0.00) <R> <C> [BOLD] P.T. motor UPDRS data <C> Train <C> 0.25 (± 0.99) <C> ∼ 30 min* <C> 0.00 (± 0.00) <C> 1.39 (± 0.51) <C> 0.00 (± 0.00) <C> 0.01 (± 0.01) <R> <C> [BOLD] P.T. motor UPDRS data <C> Test <C> 0.27 (± 0.02) <C> ∼ 4 seconds* <C> 0.01 (± 0.00) <C> 0.02 (± 0.01) <C> 0.00 (± 0.01) <C> 0.01 (± 0.01) <CAP> Table 2: Training time and testing time (in seconds) on real-world datasets over 50 runs. For FALL, the training time is the sum of the creation of the anchor models and the final model. N/A means that a memory problem occurred when computing the model on the dataset. The asterisk * means that the training time and testing time were averaged with few samples (because of a too long runtime).
<R> <C> Target <C> (LOO) <C> TrgOnly <C> [BOLD] Prop <C> SrcOnly <C> S&TV <C> TrAda <C> GDM <C> Copula <C> IW(.0) <C> IW(.5) <C> IW(.95) <R> <C> AUT <C> 1 <C> 5.88 (1.60) <C> [BOLD] 5.39 (1.86) <C> 9.67 (0.57) <C> 9.84 (0.62) <C> 5.78 (2.15) <C> 31.56 (1.39) <C> 27.33 (0.77) <C> 39.72 (0.74) <C> 39.45 (0.72) <C> 39.18 (0.76) <R> <C> BEL <C> 1 <C> 10.70 (7.50) <C> [BOLD] 7.94 (2.19) <C> 8.19 (0.68) <C> 9.48 (0.91) <C> 8.10 (1.88) <C> 89.10 (4.12) <C> 119.86 (2.64) <C> 105.15 (2.96) <C> 105.28 (2.95) <C> 104.30 (2.95) <R> <C> CAN <C> 1 <C> 5.16 (1.36) <C> [BOLD] 3.84 (0.98) <C> 157.74 (8.83) <C> 156.65 (10.69) <C> 51.94 (30.06) <C> 516.90 (4.45) <C> 406.91 (1.59) <C> 592.21 (1.87) <C> 591.21 (1.84) <C> 589.87 (1.91) <R> <C> DNK <C> 1 <C> 3.26 (0.61) <C> [BOLD] 3.23 (0.63) <C> 30.79 (0.93) <C> 28.12 (1.67) <C> 25.60 (13.11) <C> 16.84 (0.85) <C> 14.46 (0.79) <C> 22.15 (1.10) <C> 22.11 (1.10) <C> 21.72 (1.07) <R> <C> FRA <C> 1 <C> 2.79 (1.10) <C> [BOLD] 1.92 (0.66) <C> 4.67 (0.41) <C> 3.05 (0.11) <C> 52.65 (25.83) <C> 91.69 (1.34) <C> 156.29 (1.96) <C> 116.32 (1.27) <C> 116.54 (1.25) <C> 115.29 (1.28) <R> <C> DEU <C> 1 <C> 16.99 (8.04) <C> [BOLD] 6.71 (1.23) <C> 229.65 (9.13) <C> 210.59 (14.99) <C> 341.03 (157.80) <C> 739.29 (11.81) <C> 929.03 (4.85) <C> 817.50 (4.60) <C> 818.13 (4.55) <C> 812.60 (4.57) <R> <C> GRC <C> 1 <C> 3.80 (2.21) <C> [BOLD] 3.55 (1.79) <C> 5.30 (0.90) <C> 5.75 (0.68) <C> 11.78 (2.36) <C> 26.90 (1.89) <C> 23.05 (0.53) <C> 47.07 (1.92) <C> 45.50 (1.82) <C> 45.72 (2.00) <R> <C> IRL <C> 1 <C> [BOLD] 3.05 (0.34) <C> 4.35 (1.25) <C> 135.57 (5.64) <C> 12.34 (0.58) <C> 23.40 (17.50) <C> 3.84 (0.22) <C> 26.60 (0.59) <C> 6.38 (0.13) <C> 6.31 (0.14) <C> 6.16 (0.13) <R> <C> ITA <C> 1 <C> [BOLD] 13.00 (4.15) <C> 14.05 (4.81) <C> 35.29 (1.83) <C> 39.27 (2.52) <C> 87.34 (24.05) <C> 226.95 (11.14) <C> 343.10 (10.04) <C> 244.25 (8.50) <C> 244.84 (8.58) <C> 242.60 (8.46) <R> <C> JPN <C> 1 <C> 10.55 (4.67) <C> 12.32 (4.95) <C> [BOLD] 8.10 (1.05) <C> 8.38 (1.07) <C> 18.81 (4.59) <C> 95.58 (7.89) <C> 71.02 (5.08) <C> 135.24 (13.57) <C> 134.89 (13.50) <C> 134.16 (13.43) <R> <C> NLD <C> 1 <C> 3.75 (0.80) <C> 3.87 (0.79) <C> [BOLD] 0.99 (0.06) <C> 0.99 (0.05) <C> 9.45 (1.43) <C> 28.35 (1.62) <C> 29.53 (1.58) <C> 33.28 (1.78) <C> 33.23 (1.77) <C> 33.14 (1.77) <R> <C> NOR <C> 1 <C> 2.70 (0.51) <C> 2.82 (0.73) <C> 1.86 (0.29) <C> [BOLD] 1.63 (0.11) <C> 24.25 (12.50) <C> 23.36 (0.88) <C> 31.37 (1.17) <C> 27.86 (0.94) <C> 27.86 (0.93) <C> 27.52 (0.91) <R> <C> ESP <C> 1 <C> 5.18 (1.05) <C> 6.09 (1.53) <C> 5.17 (1.14) <C> [BOLD] 4.29 (0.72) <C> 14.85 (4.20) <C> 33.16 (6.99) <C> 152.59 (6.19) <C> 53.53 (2.47) <C> 52.56 (2.42) <C> 52.06 (2.40) <R> <C> SWE <C> 1 <C> 6.44 (2.66) <C> 5.47 (2.63) <C> 2.48 (0.23) <C> [BOLD] 2.02 (0.21) <C> 2.18 (0.25) <C> 15.53 (2.59) <C> 2706.85 (17.91) <C> 118.46 (1.64) <C> 118.23 (1.64) <C> 118.27 (1.64) <R> <C> CHE <C> 1 <C> 3.51 (0.46) <C> [BOLD] 2.90 (0.37) <C> 43.59 (1.77) <C> 7.48 (0.49) <C> 38.32 (9.03) <C> 8.43 (0.24) <C> 29.71 (0.53) <C> 9.72 (0.29) <C> 9.71 (0.29) <C> 9.79 (0.28) <R> <C> TUR <C> 1 <C> 1.65 (0.47) <C> 1.06 (0.15) <C> 1.22 (0.18) <C> [BOLD] 0.91 (0.09) <C> 2.19 (0.34) <C> 64.26 (5.71) <C> 142.84 (2.04) <C> 159.79 (2.63) <C> 157.89 (2.63) <C> 157.13 (2.69) <R> <C> GBR <C> 1 <C> 5.95 (1.86) <C> [BOLD] 2.66 (0.57) <C> 15.92 (1.02) <C> 10.05 (1.47) <C> 7.57 (5.10) <C> 50.04 (1.75) <C> 68.70 (1.25) <C> 70.98 (1.01) <C> 70.87 (0.99) <C> 69.72 (1.01) <R> <C> USA <C> 1 <C> 4.98 (1.96) <C> [BOLD] 1.60 (0.42) <C> 21.53 (3.30) <C> 12.28 (2.52) <C> 2.06 (0.47) <C> 308.69 (5.20) <C> 244.90 (1.82) <C> 462.51 (2.14) <C> 464.75 (2.08) <C> 465.88 (2.16) <R> <C> #Best <C> - <C> 2 <C> 10 <C> 2 <C> 4 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <CAP> Table 2: Results of the real-world data experiments for different choices of the target domain. The evaluation score is MSE normalized by that of LOO (the lower the better). All experiments were repeated 10 times with different train-test splits of target domain data, and the average performance is reported with the standard errors in the brackets. The target column indicates abbreviated country names. Bold-face indicates the best score (Prop: proposed method, TrAda: TrAdaBoost, the numbers in the brackets of IW indicate the value of α). The proposed method often improves upon the baseline TrgOnly or is relatively more resistant to negative transfer, with notable improvements in DEU, GBR, and USA.
<R> <C> [BOLD] Model <C> [BOLD] Embedding <C> [BOLD] 5-Way Accuracy(%) 1-shot <C> [BOLD] 5-Way Accuracy(%) 5-shot <R> <C> [BOLD] Proto Net <C> [ITALIC] Resnet <C> 51.15±0.85 <C> 69.02±0.75 <R> <C> [BOLD] Proto Net <C> [ITALIC] Conv <C> 49.42±0.78 <C> 68.20±0.66 <R> <C> [BOLD] Relation Net <C> [ITALIC] Resnet <C> 52.13±0.82 <C> 64.72±0.72 <R> <C> [BOLD] Relation Net <C> [ITALIC] Conv <C> 50.44±0.82 <C> 65.32±0.70 <R> <C> [BOLD] R2D2 <C> [ITALIC] Resnet <C> 51.80±0.20 <C> 68.70±0.20 <R> <C> [BOLD] R2D2 <C> [ITALIC] Conv <C> 49.50±0.20 <C> 65.40±0.20 <R> <C> [BOLD] DN4 <C> [ITALIC] Resnet <C> 54.37±0.36 <C> 74.44±0.29 <R> <C> [BOLD] DN4 <C> [ITALIC] Conv <C> 51.24±0.74 <C> 71.02±0.64 <R> <C> [BOLD] Dynamic-Net <C> [ITALIC] Resnet <C> 55.45±0.89 <C> 70.13±0.68 <R> <C> [BOLD] Dynamic-Net <C> [ITALIC] Conv <C> [BOLD] 56.20±0.86 <C> 72.81±0.62 <R> <C> [BOLD] Ours <C> [ITALIC] Resnet <C> [BOLD] 58.12±0.92 <C> [BOLD] 78.39±0.58 <R> <C> [BOLD] Ours <C> [ITALIC] Conv <C> [BOLD] 53.30±0.32 <C> [BOLD] 73.22±0.45 <R> <C> [BOLD] Methods with Conv Embedding <C> [BOLD] Methods with Conv Embedding <C> [BOLD] Methods with Conv Embedding <C> [BOLD] Methods with Conv Embedding <R> <C> [BOLD] Matching Nets <C> [ITALIC] Conv <C> 43.56±0.84 <C> 55.31±0.73 <R> <C> [BOLD] Meta-Learn LSTM <C> [ITALIC] Conv <C> 43.44±0.77 <C> 60.60±0.71 <R> <C> [BOLD] MAML <C> [ITALIC] Conv <C> 48.70±1.84 <C> 63.11±0.92 <R> <C> [BOLD] CovaMNet <C> [ITALIC] Conv <C> 51.19±0.76 <C> 67.65±0.63 <R> <C> [BOLD] SalNet <C> [ITALIC] Conv <C> [BOLD] 57.45±0.88 <C> 72.01±0.67 <CAP> Table 1: The mean accuracies of the 5-way 1-shot and 5-shot tasks on the miniImageNet dataset, with 95% confidence intervals.
<R> <C> Dataset Stanford Dog <C> Dataset 1shot <C> Proto Net 31.54±0.41 <C> Relation Net 31.24±0.61 <C> K-tuplet loss 37.33±0.65 <C> [BOLD] ours  [BOLD] 43.69±0.72 <R> <C> Stanford Dog <C> 5shot <C> 47.84±0.48 <C> 42.47±0.68 <C> 49.97±0.66 <C> [BOLD] 61.50±0.73 <R> <C> Stanford Car <C> 1shot <C> 29.19±0.40 <C> 28.83±0.55 <C> 31.20±0.58 <C> [BOLD] 32.87±0.57 <R> <C> Stanford Car <C> 5shot <C> 38.00±0.42 <C> 35.43±0.58 <C> 47.10±0.62 <C> [BOLD] 50.10±0.69 <R> <C> CUB200 <C> 1shot <C> 37.55±0.51 <C> 38.30±0.71 <C> 40.16±0.68 <C> [BOLD] 43.30±0.75 <R> <C> CUB200 <C> 5shot <C> 55.03±0.49 <C> 50.89±0.69 <C> 56.96±0.65 <C> [BOLD] 62.21±0.73 <CAP> Table 2: The mean accuracies of the 5-way 1-shot and 5-shot accuracies (%) on three fined-grained datasets using the model trained on miniImageNet, with 95% confidence intervals. All the experiments are conducted with the same network for fair comparison.
<R> <C> [BOLD] Algorithms <C> [BOLD] False Alarm Rate (Normal Videos) <R> <C> M. Hasan  [ITALIC] et al.  <C> 27.2 <R> <C> C. Lu  [ITALIC] et al.  <C> 3.1 <R> <C> W. Sultani  [ITALIC] et al.  <C> 1.9 <R> <C> Proposed Method(3D ResNet+constr.+loss) <C> 0.83 <R> <C> Proposed Method(3D ResNet+constr.+new rank.loss) <C> [BOLD] 0.80 <CAP> TABLE II: Comparison of false alarm rate on normal videos of UCF-Crime testing dataset.
<R> <C> [BOLD] Model <C> [BOLD] Embedding <C> [BOLD] 5-Way accuracy(%)  [ITALIC] Stanford Dogs <C> [BOLD] 5-Way accuracy(%)  [ITALIC] Stanford Dogs <C> [BOLD] 5-Way accuracy(%)  [ITALIC] Stanford Cars <C> [BOLD] 5-Way accuracy(%)  [ITALIC] Stanford Cars <C> [BOLD] 5-Way accuracy(%)  [ITALIC] CUB-200 <C> [BOLD] 5-Way accuracy(%)  [ITALIC] CUB-200 <R> <C> [EMPTY] <C> [EMPTY] <C> 1-shot <C> 5-shot <C> 1-shot <C> 5-shot <C> 1-shot <C> 5-shot <R> <C> [BOLD] Baseline K-NN <C> [ITALIC] Conv <C> 26.14±0.91 <C> 43.14±1.02 <C> 23.50±0.88 <C> 34.45±0.98 <C> 25.81±0.90 <C> 45.34±1.03 <R> <C> [BOLD] Proto Net <C> [ITALIC] Conv <C> 37.59±1.00 <C> 48.19±1.03 <C> 40.90±1.01 <C> 52.93±1.03 <C> 37.36±1.00 <C> 45.28±1.03 <R> <C> [BOLD] GNN <C> [ITALIC] Conv <C> 46.98±0.98 <C> 62.27±0.95 <C> 55.85±0.97 <C> 71.25±0.89 <C> 51.83±0.98 <C> 63.69±0.94 <R> <C> [BOLD] CovaMNet <C> [ITALIC] Conv <C> 49.10±0.76 <C> 63.04±0.65 <C> 56.65±0.86 <C> 71.33±0.62 <C> 52.42±0.76 <C> 63.76±0.64 <R> <C> [BOLD] DN4 <C> [ITALIC] Conv <C> 45.41±0.76 <C> 63.51±0.62 <C> [BOLD] 59.84±0.80 <C> [BOLD] 88.65±0.44 <C> 46.84±0.81 <C> 74.92±0.64 <R> <C> [BOLD] Ours <C> [ITALIC] Conv <C> [BOLD] 52.50±0.90 <C> [BOLD] 67.37±0.76 <C> [BOLD] 46.46±0.89 <C> [BOLD] 82.28±1.02 <C> [BOLD] 55.31±0.78 <C> [BOLD] 75.03±0.64 <R> <C> [BOLD] Ours <C> [ITALIC] Resnet <C> [BOLD] 54.45±0.95 <C> [BOLD] 73.63±0.92 <C> [BOLD] 72.71±0.43 <C> [BOLD] 93.94±0.33 <C> [BOLD] 60.21±0.87 <C> [BOLD] 78.70±0.62 <CAP> Table 3: The mean accuracies of the 5-way 1-shot and 5-shot tasks on three fine-grained datasets, with 95% confidence intervals.
<R> <C> [EMPTY] <C> [BOLD] Without training  [BOLD] RBM-NQS-CS <C> [BOLD] Without training  [BOLD] RBM-NQS-I <C> [BOLD] With training  [BOLD] RBM-NQS-CS <C> [BOLD] With training  [BOLD] RBM-NQS-I <C> [BOLD] Tensor network <R> <C> [BOLD] Energy <C> -127.9799 (0.0029) <C> -127.9799 (0.0029) <C> -127.9799 (0.0029) <C> -127.9799 (0.0029) <C> -128.00000 <R> <C> [ITALIC] M2 [ITALIC] F <C> 0.0079 (0.0001) <C> 0.0079 (0.0001) <C> 0.0079 (0.0001) <C> 0.0079 (0.0001) <C> 0.00781 <R> <C> [ITALIC] M2 [ITALIC] A <C> 0.0078 (0.0001) <C> 0.0078 (0.0001) <C> 0.0078 (0.0001) <C> 0.0078 (0.0001) <C> 0.00781 <R> <C> [ITALIC] CF, [ITALIC] i, [ITALIC] d <C> 0.0003 (0.0007) <C> 0.0003 (0.0007) <C> 0.0003 (0.0007) <C> 0.0003 (0.0007) <C> 0.00000 <R> <C> [ITALIC] CA, [ITALIC] i, [ITALIC] d <C> -0.0003 (0.0007) <C> -0.0003 (0.0007) <C> -0.0003 (0.0007) <C> -0.0003 (0.0007) <C> 0.00000 <R> <C> [BOLD] Iterations <C> - <C> - <C> 0 <C> 0 <C> - <CAP> Table 1: The performance evaluation of the RBM-NQS-CS and RBM-NQS-I for one-dimensional system in Ising model where the system size is 128 and parameter of the system J/|h|=0.0. The reported value is average value over 20 realisations. The value inside the parentheses is the standard deviation.
<R> <C> [EMPTY] <C> [BOLD] Without training  [BOLD] RBM-NQS-CS <C> [BOLD] Without training  [BOLD] RBM-NQS-I <C> [BOLD] With training  [BOLD] RBM-NQS-CS <C> [BOLD] With training  [BOLD] RBM-NQS-I <C> [BOLD] Tensor network <R> <C> [BOLD] Energy <C> -127.9061 (0.2577) <C> -217.5726 (0.3152) <C> -372.2911 (4.7748) <C> -391.7046 (0.0182) <C> -391.91198 <R> <C> [ITALIC] M2 [ITALIC] F <C> 0.0078 (0.0001) <C> 0.2934 (0.0009) <C> 0.0981 (0.1041) <C> 0.9658 (0.0005) <C> 0.96980 <R> <C> [ITALIC] M2 [ITALIC] A <C> 0.0078 (0.0001) <C> 0.0056 (0.0001) <C> 0.0006 (0.0001) <C> 0.0003 (0.0000) <C> 0.00023 <R> <C> [ITALIC] CF, [ITALIC] i, [ITALIC] d <C> -0.0002 (0.0011) <C> 0.2897 (0.0059) <C> 0.0360 (0.2928) <C> 0.9362 (0.0051) <C> 0.92871 <R> <C> [ITALIC] CA, [ITALIC] i, [ITALIC] d <C> 0.0001 (0.0010) <C> -0.0020 (0.0009) <C> -0.0025 (0.0032) <C> -0.0072 (0.0002) <C> -0.00704 <R> <C> [BOLD] Iterations <C> - <C> - <C> 1621.7250 (1271.7007) <C> 20.8500 (0.4770) <C> - <CAP> Table 2: The performance evaluation of RBM-NQS-CS and RBM-NQS-I for one-dimensional system in Ising model where the system size is 128 and parameter of the system J/|h|=3.0. The reported value is average value over 20 realisations. The value inside the parentheses is the standard deviation.
<R> <C> [EMPTY] <C> [BOLD] Without training  [BOLD] RBM-NQS-CS <C> [BOLD] Without training  [BOLD] RBM-NQS-I <C> [BOLD] With training  [BOLD] RBM-NQS-CS <C> [BOLD] With training  [BOLD] RBM-NQS-I <C> [BOLD] Exact Diagonalization <R> <C> [BOLD] Energy <C> -16.0000 (0.0001) <C> -16.0000 (0.0001) <C> -16.0000 (0.0001) <C> -16.0000 (0.0001) <C> -16.0000 <R> <C> [ITALIC] M2 [ITALIC] F <C> 0.0624 (0.0007) <C> 0.0624 (0.0007) <C> 0.0624 (0.0007) <C> 0.0624 (0.0007) <C> 0.0625 <R> <C> [ITALIC] M2 [ITALIC] A <C> 0.0624 (0.0009) <C> 0.0624 (0.0009) <C> 0.0624 (0.0009) <C> 0.0624 (0.0009) <C> 0.0625 <R> <C> [ITALIC] CF, [ITALIC] i, [ITALIC] d <C> 0.2503 (0.0041) <C> 0.2503 (0.0041) <C> 0.2503 (0.0041) <C> 0.2503 (0.0041) <C> 0.2500 <R> <C> [ITALIC] CA, [ITALIC] i, [ITALIC] d <C> 0.2490 (0.0037) <C> 0.2490 (0.0037) <C> 0.2490 (0.0037) <C> 0.2490 (0.0037) <C> 0.2500 <R> <C> [BOLD] Iterations <C> - <C> - <C> 0 <C> 0 <C> - <CAP> Table 6: The performance evaluation of RBM-NQS-CS and RBM-NQS-I for two-dimensional system in Ising model where the system size is 4×4 and parameter of the system J/|h|=0.0. The reported value is average value over 20 realisations. The value inside the parentheses is the standard deviation.
<R> <C> [EMPTY] <C> [BOLD] Without training  [BOLD] RBM-NQS-CS <C> [BOLD] Without training  [BOLD] RBM-NQS-I <C> [BOLD] With training  [BOLD] RBM-NQS-CS <C> [BOLD] With training  [BOLD] RBM-NQS-I <C> [BOLD] Exact Diagonalization <R> <C> [BOLD] Energy <C> -8.0000 (0.0000) <C> -8.0000 (0.0000) <C> -8.0000 (0.0000) <C> -8.0000 (0.0000) <C> -8 <R> <C> [ITALIC] M2 [ITALIC] F <C> 0.1244 (0.0022) <C> 0.1244 (0.0022) <C> 0.1244 (0.0022) <C> 0.1244 (0.0022) <C> 0.125 <R> <C> [ITALIC] M2 [ITALIC] A <C> 0.1250 (0.0028) <C> 0.1250 (0.0028) <C> 0.1250 (0.0028) <C> 0.1250 (0.0028) <C> 0.125 <R> <C> [ITALIC] CF, [ITALIC] i, [ITALIC] d <C> 0.4999 (0.0059) <C> 0.4999 (0.0059) <C> 0.4999 (0.0059) <C> 0.4999 (0.0059) <C> 0.5 <R> <C> [ITALIC] CA, [ITALIC] i, [ITALIC] d <C> 0.5000 (0.0059) <C> 0.5000 (0.0059) <C> 0.5000 (0.0059) <C> 0.5000 (0.0059) <C> 0.5 <R> <C> [BOLD] Iterations <C> - <C> - <C> 0.0000 (0.0000) <C> 0.0000 (0.0000) <C> - <CAP> Table 9: The performance evaluation of RBM-NQS-CS and RBM-NQS-I for three-dimensional system in Ising model where the system size is 2×2×2 and parameter of the system J/|h|=0.0. The reported value is average value over 20 realisations. The value inside the parentheses is the standard deviation.
<R> <C> [EMPTY] <C> [BOLD] Without training  [BOLD] RBM-NQS-CS <C> [BOLD] Without training  [BOLD] RBM-NQS-I <C> [BOLD] With training  [BOLD] RBM-NQS-CS <C> [BOLD] With training  [BOLD] RBM-NQS-I <C> [BOLD] Exact Diagonalization <R> <C> [BOLD] Energy <C> -15.9808 (0.1652) <C> -52.1501 (0.1441) <C> -72.9401 (0.0035) <C> -72.9397 (0.0039) <C> -72.9455 <R> <C> [ITALIC] M2 [ITALIC] F <C> 0.0625 (0.0008) <C> 0.6064 (0.0023) <C> 0.9856 (0.0005) <C> 0.9861 (0.0005) <C> 0.9860 <R> <C> [ITALIC] M2 [ITALIC] A <C> 0.0624 (0.0007) <C> 0.0263 (0.0003) <C> 0.0010 (0.0000) <C> 0.0009 (0.0000) <C> 0.0009 <R> <C> [ITALIC] CF, [ITALIC] i, [ITALIC] d <C> 0.2483 (0.0042) <C> 0.6863 (0.0056) <C> 0.9924 (0.0009) <C> 0.9924 (0.0009) <C> 0.9934 <R> <C> [ITALIC] CA, [ITALIC] i, [ITALIC] d <C> 0.2520 (0.0045) <C> 0.1042 (0.0036) <C> 0.0022 (0.0004) <C> 0.0024 (0.0006) <C> 0.0017 <R> <C> [BOLD] Iterations <C> - <C> - <C> 180.4000 (4.8311) <C> 126.0500 (1.7741) <C> - <CAP> Table 7: The performance evaluation of RBM-NQS-CS and RBM-NQS-I for two-dimensional system in Ising model where the system size is 4×4 and parameter of the system J/|h|=3.0. The reported value is average value over 20 realisations. The value inside the parentheses is the standard deviation.
<R> <C> [BOLD] System size <C> [BOLD] RBM-NQS-CS <C> [BOLD] RBM-NQS-IT <C> [BOLD] Tensor network <C> [BOLD] Exact diag. <R> <C> 8 <C> 1.114 (0.009) <C> 1.105 (0.006) <C> 1.11 <C> 1.109 <R> <C> 16 <C> 1.007 (0.008) <C> 1.040 (0.005) <C> 1.08 <C> 1.090 <R> <C> 32 <C> 1.011 (0.009) <C> 1.013 (0.001) <C> 1.05 <C> - <R> <C> 64 <C> 1.004 (0.009) <C> 1 (0.001) <C> 1.02 <C> - <R> <C> 128 <C> 0.646 (0.38) <C> 1 (0.001) <C> 1.01 <C> - <R> <C> 2×2 <C> 0.662 (0.04) <C> 0.673 (0.05) <C> - <C> 0.69 <R> <C> 4×4 <C> 0.5 (0.0) <C> 0.501 (0.003) <C> - <C> 0.51 <R> <C> 2×2×2 <C> 0.505 (0.012) <C> 0.502 (0.004) <C> - <C> 0.527 <CAP> Table 4: The value of the inflection point for one-, two- and three-dimensional systems of given sizes with RBM-NQS-CS, RBM-NQS-IT, tensor network and exact diagonalization method with ferromagnetic magnetisation M2F order parameter. The value inside the parentheses is the standard deviation.
<R> <C> net <C> weights <C> mse <C> time [min] <R> <C> gru-64-fft <C> 46k <C> 7.4⋅10−4 <C> 172 <R> <C> cgRNN-32-fft <C> 23k <C> 9.3⋅10−4 <C> 275 <R> <C> cgRNN-54-fft <C> 46k <C> 5.2⋅10−4 <C> 230 <R> <C> cgRNN-64-fft <C> 58k <C> 3.4⋅10−4 <C> 272 <CAP> Table 1: Real and complex valued architecture comparison on the mackey-glass data.
<R> <C> Network <C> mse [MW] <C> weights <C> run [min] <R> <C> time-RNN <C> 1.3⋅107 <C> 13k <C> 772 <R> <C> time-RNN-windowed <C> 8.8⋅105 <C> 28k <C> 12 <R> <C> fRNN <C> 8.3⋅105 <C> 44k <C> 13 <R> <C> fRNN-lowpass-1/4 <C> 7.6⋅105 <C> 20k <C> 13 <R> <C> fRNN-lowpass-1/8 <C> 1.3⋅106 <C> 16k <C> 13 <CAP> Table 2: 60 day ahead power load prediction and ground truth. Power prediction results using various different architectures
<R> <C> [BOLD] Dataset <C> Cora <C> Cite. <C> Pubm. <C> Cham. <C> Squi. <C> Actor <C> Corn. <C> Texa. <C> Wisc. <R> <C> GCN <C> 85.77 <C> 73.68 <C> 88.13 <C> 28.18 <C> 23.96 <C> 26.86 <C> 52.70 <C> 52.16 <C> 45.88 <R> <C> GAT <C> [BOLD] 86.37 <C> 74.32 <C> 87.62 <C> 42.93 <C> 30.03 <C> 28.45 <C> 54.32 <C> 58.38 <C> 49.41 <R> <C> Geom-GCN-I <C> 85.19 <C> [BOLD] 77.99 <C> [BOLD] 90.05 <C> 60.31 <C> 33.32 <C> 29.09 <C> 56.76 <C> 57.58 <C> 58.24 <R> <C> Geom-GCN-P <C> 84.93 <C> 75.14 <C> 88.09 <C> [BOLD] 60.90 <C> [BOLD] 38.14 <C> [BOLD] 31.63 <C> [BOLD] 60.81 <C> [BOLD] 67.57 <C> [BOLD] 64.12 <R> <C> Geom-GCN-S <C> 85.27 <C> 74.71 <C> 84.75 <C> 59.96 <C> 36.24 <C> 30.30 <C> 55.68 <C> 59.73 <C> 56.67 <CAP> Table 3: Mean Classification Accuracy (Percent)
<R> <C> [BOLD] Dataset <C> Cora <C> Cite. <C> Pumb. <C> Cham. <C> Squi. <C> Actor <C> Corn. <C> Texa. <C> Wisc. <R> <C> [ITALIC] β <C> 0.83 <C> 0.71 <C> 0.79 <C> 0.25 <C> 0.22 <C> 0.24 <C> 0.11 <C> 0.06 <C> 0.16 <R> <C> Geom-GCN-I-g <C> 86.26 <C> [BOLD] 80.64 <C> [BOLD] 90.72 <C> [BOLD] 68.00 <C> [BOLD] 46.01 <C> 31.96 <C> 65.40 <C> 72.51 <C> 68.23 <R> <C> Geom-GCN-I-g <C> ↑0.48 <C> ↑6.96 <C> ↑2.59 <C> ↑39.82 <C> ↑22.05 <C> ↑4.04 <C> ↑12.70 <C> ↑21.35 <C> ↑22.35 <R> <C> Geom-GCN-I-s <C> 77.34 <C> 72.22 <C> 85.02 <C> 61.64 <C> 37.98 <C> 30.59 <C> 62.16 <C> 60.54 <C> 64.90 <R> <C> Geom-GCN-I-s <C> ↓8.34 <C> ↓1.46 <C> ↓3.11 <C> ↑33.46 <C> ↑14.02 <C> ↑2.67 <C> ↑9.46 <C> ↑8.38 <C> ↑19.01 <R> <C> Geom-GCN-P-g <C> 86.30 <C> 75.45 <C> 88.40 <C> 63.07 <C> 38.41 <C> 31.55 <C> 64.05 <C> 73.05 <C> 69.41 <R> <C> Geom-GCN-P-g <C> ↑0.52 <C> ↑1.76 <C> ↑0.27 <C> ↑34.89 <C> ↑14.45 <C> ↑3.63 <C> ↑11.35 <C> ↑21.89 <C> ↑23.53 <R> <C> Geom-GCN-P-s <C> 73.14 <C> 71.65 <C> 86.95 <C> 43.20 <C> 30.47 <C> [BOLD] 34.59 <C> [BOLD] 75.40 <C> [BOLD] 73.51 <C> [BOLD] 80.39 <R> <C> Geom-GCN-P-s <C> ↓12.63 <C> ↓2.04 <C> ↓1.18 <C> ↑15.02 <C> ↑6.51 <C> ↑6.67 <C> ↑22.70 <C> ↑21.35 <C> ↑34.51 <R> <C> Geom-GCN-S-g <C> [BOLD] 87.00 <C> 75.73 <C> 88.44 <C> 67.04 <C> 44.92 <C> 31.27 <C> 67.02 <C> 71.62 <C> 69.41 <R> <C> Geom-GCN-S-g <C> ↑1.23 <C> ↑2.04 <C> ↑0.31 <C> ↑38.86 <C> ↑20.96 <C> ↑3.35 <C> ↑14.32 <C> ↑19.46 <C> ↑23.52 <R> <C> Geom-GCN-S-s <C> 66.92 <C> 66.03 <C> 79.41 <C> 49.21 <C> 31.27 <C> 30.32 <C> 62.43 <C> 63.24 <C> 64.51 <R> <C> Geom-GCN-S-s <C> ↓18.85 <C> ↓7.65 <C> ↓8.72 <C> ↑21.03 <C> ↑7.31 <C> ↑2.40 <C> ↑9.73 <C> ↑11.08 <C> ↑18.63 <CAP> Table 4: Mean Classification Accuracy (Percent)
<R> <C> [ITALIC] tvar <C> [BOLD] Correctly classified  [BOLD] without a8 <C> [BOLD] Correctly classified  [BOLD] with a8 <R> <C> 0.05 <C> 72.0% <C> 63.3% <R> <C> 0.10 <C> 77.4% <C> 63.8% <R> <C> 0.15 <C> 74.4% <C> 67.9% <R> <C> 0.20 <C> 76.2% <C> 66.8% <CAP> Table 2: Percentage of correctly classified gestures for different variance thresholds tvar
<R> <C> [EMPTY] <C> Velocity control <C> Position control <R> <C> Controllability <C> Better <C> Worse <R> <C> Guidance reactivity <C> Faster <C> Slower <R> <C> Complexity <C> 2 <C> 1 <CAP> TABLE I: Pros and cons of the Offboard velocity and position control
<R> <C> [BOLD] PASCAL3D+ Classification under Occlusion Occ. Area <C> [BOLD] PASCAL3D+ Classification under Occlusion  [BOLD] Level-3: 60-80% <C> [BOLD] PASCAL3D+ Classification under Occlusion  [BOLD] Level-3: 60-80% <C> [BOLD] PASCAL3D+ Classification under Occlusion  [BOLD] Level-3: 60-80% <C> [BOLD] PASCAL3D+ Classification under Occlusion  [BOLD] Level-3: 60-80% <C> [BOLD] PASCAL3D+ Classification under Occlusion Mean <R> <C> Occ. Type <C> w <C> n <C> t <C> o <C> - <R> <C> 1 prototype, 1 recurrence <C> 79.1 <C> 84.8 <C> 77.9 <C> 75.1 <C> 90.9 <R> <C> 1 prototype, 2 recurrence <C> 78.9 <C> 85.2 <C> 78.2 <C> 75.5 <C> 91.0 <R> <C> 1 prototype, 3 recurrence <C> 79.7 <C> 85.2 <C> 79 <C> 76.9 <C> 91.2 <R> <C> 4 prototype, 1 recurrence <C> 81.1 <C> 87.6 <C> 81.2 <C> 76.8 <C> 92.3 <R> <C> 4 prototype, 2 recurrence <C> 81.5 <C> 87.7 <C> 81.9 <C> 77.1 <C> 92.4 <R> <C> 4 prototype, 3 recurrence <C> 82.1 <C> 88.1 <C> 82.7 <C> [BOLD] 79.8 <C> 92.8 <R> <C> 8 prototype, 1 recurrence <C> 81.1 <C> 87.6 <C> 80.9 <C> 74.7 <C> 92.1 <R> <C> 8 prototype, 2 recurrence <C> [BOLD] 82.5 <C> [BOLD] 88.7 <C> 82.5 <C> 78.6 <C> 92.8 <R> <C> 8 prototype, 3 recurrence <C> 82.4 <C> 88.2 <C> [BOLD] 83 <C> 78.6 <C> [BOLD] 92.9 <CAP> Table 2: Comparison for different prototype numbers of TDAPNet on PASCAL3D+. We just list Level-3 and Mean here, the complete results are in the Supplementary Material.
<R> <C> Method <C> PSNR <C> SSIM <R> <C> LIME <C> 12.38 <C> 0.611 <R> <C> SRIE <C> 14.09 <C> 0.659 <R> <C> DeepFlash <C> 15.39 <C> 0.671 <R> <C> Ours <C> [BOLD] 15.67 <C> [BOLD] 0.684 <CAP> Table 1: Reporting the mean PSNR and the mean SSIM with SRIE [7], LIME [9], and DeepFlash [3].
<R> <C> [EMPTY] <C> [BOLD] diabetes train <C> [BOLD] diabetes test <C> [BOLD] boston train <C> [BOLD] boston test <C> [BOLD] concrete train <C> [BOLD] concrete test <C> [BOLD] airfoil train <C> [BOLD] airfoil test <C> [BOLD] wine quality train <C> [BOLD] wine quality test <R> <C> [ITALIC] RR <C> 0.541 <C> [BOLD] 0.383 <C> 0.736 <C> 0.748 <C> 0.625 <C> 0.564 <C> 0.517 <C> 0.508 <C> 0.293 <C> 0.310 <R> <C> [ITALIC] SVR <C> 0.580 <C> 0.320 <C> 0.959 <C> [BOLD] 0.882 <C> 0.933 <C> 0.881 <C> 0.884 <C> 0.851 <C> 0.572 <C> 0.411 <R> <C> [ITALIC] RF <C> [BOLD] 0.598 <C> 0.354 <C> [BOLD] 0.983 <C> 0.870 <C> [BOLD] 0.985 <C> [BOLD] 0.892 <C> [BOLD] 0.991 <C> [BOLD] 0.934 <C> [BOLD] 0.931 <C> [BOLD] 0.558 <R> <C> [ITALIC] AFR1 <C> 0.553 <C> 0.400 <C> 0.825 <C> 0.810 <C> 0.847 <C> 0.818 <C> 0.569 <C> 0.560 <C> 0.320 <C> 0.341 <R> <C> [ITALIC] AFR2 <C> 0.591 <C> 0.353 <C> 0.893 <C> 0.791 <C> 0.913 <C> 0.868 <C> 0.863 <C> 0.842 <C> 0.397 <C> 0.384 <R> <C> [ITALIC] AFR3 <C> 0.638 <C> -12.4 <C> 0.932 <C> 0.048 <C> 0.867 <C> 0.824 <C> 0.884 <C> 0.883 <C> 0.350 <C> 0.342 <CAP> Table 2: R2 scores on the training and test folds of different datasets for ridge regression (RR), support vector regression (SVR), random forests (RF), and the autofeat regression model with one, two, or three feature engineering steps (AFR1-3). Best results per column are in boldface (existing methods) and underlined (AFR).
<R> <C> [EMPTY] <C> [BOLD] diabetes eng <C> [BOLD] diabetes sel <C> [BOLD] boston eng <C> [BOLD] boston sel <C> [BOLD] concrete eng <C> [BOLD] concrete sel <C> [BOLD] airfoil eng <C> [BOLD] airfoil sel <C> [BOLD] wine quality eng <C> [BOLD] wine quality sel <R> <C> [ITALIC] AFR1 <C> 45 <C> 2 <C> 60 <C> 6 <C> 34 <C> 5 <C> 21 <C> 6 <C> 59 <C> 11 <R> <C> [ITALIC] AFR2 <C> 5950 <C> 8 <C> 10528 <C> 15 <C> 3456 <C> 40 <C> 530 <C> 42 <C> 9959 <C> 80 <R> <C> [ITALIC] AFR3 <C> 32161 <C> 16 <C> 54631 <C> 21 <C> 14485 <C> 16 <C> 2355 <C> 44 <C> 55648 <C> 26 <CAP> Table 3: Number of engineered (eng) and selected (sel) additional features for each dataset from an autofeat regression model with one, two, or three feature engineering steps (AFR1-3).
<R> <C> Models <C> #Visible Image Gallery/Subject 1/subject <C> #Visible Image Gallery/Subject 2/subject <C> #Visible Image Gallery/Subject all/subject <R> <C> Deep Perceptual Mapping  <C> 56.33% <C> 60.08% <C> 71% <R> <C> Partial Least Squares  <C> 31.75% <C> 34.66% <C> 51.58% <R> <C> Model with Bilinear Upsample <C> 40.2% <C> 45.8% <C> 75.5% <R> <C> Model with Bilinear Upsample (Aligned) <C> 42% <C> 48.75% <C> 77.25% <R> <C> Model with Up Convolution <C> 41% <C> 49.75% <C> 80.2% <R> <C> Model with Up Convolution (Aligned) <C> 43.75% <C> 52.5% <C> 82.5% <R> <C> [BOLD] Model with Up Convolution + DoG Filter <C> [BOLD] 46.8% <C> [BOLD] 58.5% <C> [BOLD] 82.5% <R> <C> [BOLD] Model with Up Convolution + DoG Filter (Aligned) <C> [BOLD] 48% <C> [BOLD] 60.25% <C> [BOLD] 85% <CAP> TABLE I: Rank-1 recognition accuracies on the Carl dataset
<R> <C> Models <C> #Visible Image Gallery/Subject 1/subject <C> #Visible Image Gallery/Subject 2/subject <C> #Visible Image Gallery/Subject all/subject <R> <C> Deep Perceptual Mapping  <C> 55.36% <C> 60.83% <C> 83.73% <R> <C> Partial Least Squares  <C> 44.75% <C> 50.89% <C> 69.86% <R> <C> Model with Bilinear Upsample <C> 42% <C> 50.25% <C> 75.4% <R> <C> Model with Up Convolution <C> 49.25% <C> 57.5% <C> 82% <R> <C> [BOLD] Model with Up Convolution + DoG Filter <C> [BOLD] 58.75% <C> [BOLD] 65.25% <C> [BOLD] 87.2% <CAP> TABLE II: Rank-1 recognition accuracies on the UND-X1 dataset
<R> <C> [BOLD] Dataset <C> [BOLD] Mean Runtime for 200 Samples (s) SGAN  <C> [BOLD] Mean Runtime for 200 Samples (s) Ours (Full) <C> [BOLD] Mean Runtime for 200 Samples (s) Ours ( [ITALIC] zbest) <R> <C> ETH <C> 6.98 (1x) <C> [BOLD] 0.13 (54x) <C> [BOLD] 0.13 (54x) <R> <C> Hotel <C> 6.46 (1x) <C> [BOLD] 0.08 (81x) <C> [BOLD] 0.08 (81x) <R> <C> Univ <C> 46.71 (1x) <C> 2.00 (23x) <C> [BOLD] 1.96 (24x) <R> <C> Zara 1 <C> 6.47 (1x) <C> [BOLD] 0.16 (40x) <C> [BOLD] 0.16 (40x) <R> <C> Zara 2 <C> 9.56 (1x) <C> 0.37 (26x) <C> [BOLD] 0.36 (27x) <CAP> Table 2: Mean time to generate 200 samples in scenes from each dataset, benchmarked on a computer with a 2.7 GHz Intel Core i5 CPU and 8 GB of RAM. Speedup factors are indicated in brackets.
<R> <C> Condition <C> PSNR <C> SSIM <R> <C> 1.  [BOLD] Default ( [BOLD] RM+ [BOLD] AM) <C> [BOLD] 15.67 <C> [BOLD] 0.684 <R> <C> 2.  [BOLD] R+ [BOLD] A <C> 15.55 <C> 0.676 <R> <C> 3.  [BOLD] R <C> 15.64 <C> 0.681 <R> <C> 4. U-Net <C> 14.81 <C> 0.643 <CAP> Table 2: This table reports the mean PSNR and the mean SSIM for some configurations of the loss function, the use of our attention mechanism, and the network architecture. Default configuration represents the model that we use to compare with the state-of-the-art literature.
<R> <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> AB Accuracy <C> AB  [ITALIC] F1 <C> AB ROC AUC <C> RT Accuracy <C> RT  [ITALIC] F1 <C> RT ROC AUC <C> RF-Treant Accuracy <C> RF-Treant Accuracy <C> RF-Treant  [ITALIC] F1 <C> RF-Treant  [ITALIC] F1 <C> RF-Treant ROC AUC <C> RF-Treant ROC AUC <R> <C> census <C> Budget <C> 30 <C> [BOLD] 0.850 <C> [BOLD] 0.783 <C> [BOLD] 0.902 <C> 0.813 <C> 0.692 <C> 0.883 <C> [BOLD] 0.850 <C> +0.0% <C> 0.773 <C> -1.3% <C> 0.897 <C> -0.6% <R> <C> census <C> Budget <C> 60 <C> 0.783 <C> 0.690 <C> 0.827 <C> 0.810 <C> 0.698 <C> 0.871 <C> [BOLD] 0.845 <C> +4.3% <C> [BOLD] 0.766 <C> +9.7% <C> [BOLD] 0.894 <C> +2.6% <R> <C> census <C> Budget <C> 90 <C> 0.798 <C> 0.705 <C> 0.825 <C> 0.775 <C> 0.607 <C> 0.855 <C> [BOLD] 0.845 <C> +5.9% <C> [BOLD] 0.769 <C> +9.1% <C> [BOLD] 0.893 <C> +4.4% <R> <C> census <C> Budget <C> 120 <C> 0.788 <C> 0.694 <C> 0.793 <C> 0.744 <C> 0.558 <C> 0.528 <C> [BOLD] 0.842 <C> +6.9% <C> [BOLD] 0.762 <C> +9.8% <C> [BOLD] 0.887 <C> +11.9% <R> <C> wine <C> Budget <C> 20 <C> 0.762 <C> 0.737 <C> [BOLD] 0.824 <C> 0.734 <C> 0.703 <C> 0.795 <C> [BOLD] 0.764 <C> +0.3% <C> [BOLD] 0.739 <C> +0.3% <C> 0.821 <C> -0.4% <R> <C> wine <C> Budget <C> 40 <C> 0.723 <C> [BOLD] 0.689 <C> 0.788 <C> 0.623 <C> 0.548 <C> 0.662 <C> [BOLD] 0.728 <C> +0.7% <C> [BOLD] 0.689 <C> +0.0% <C> [BOLD] 0.802 <C> +1.8% <R> <C> wine <C> Budget <C> 60 <C> 0.718 <C> [BOLD] 0.687 <C> 0.788 <C> 0.552 <C> 0.418 <C> 0.522 <C> [BOLD] 0.720 <C> +0.3% <C> 0.680 <C> -1.0% <C> [BOLD] 0.798 <C> +1.3% <R> <C> wine <C> Budget <C> 80 <C> 0.715 <C> 0.680 <C> 0.773 <C> 0.566 <C> 0.443 <C> 0.561 <C> [BOLD] 0.728 <C> +1.8% <C> [BOLD] 0.688 <C> +1.2% <C> [BOLD] 0.800 <C> +3.5% <R> <C> wine <C> Budget <C> 100 <C> 0.702 <C> 0.668 <C> 0.761 <C> 0.559 <C> 0.429 <C> 0.553 <C> [BOLD] 0.727 <C> +3.6% <C> [BOLD] 0.687 <C> +2.8% <C> [BOLD] 0.796 <C> +4.6% <R> <C> wine <C> Budget <C> 120 <C> 0.677 <C> 0.636 <C> 0.732 <C> 0.568 <C> 0.431 <C> 0.544 <C> [BOLD] 0.728 <C> +7.5% <C> [BOLD] 0.688 <C> +8.2% <C> [BOLD] 0.801 <C> +9.4% <R> <C> credit <C> Budget <C> 10 <C> 0.811 <C> 0.644 <C> 0.749 <C> 0.799 <C> 0.610 <C> 0.748 <C> [BOLD] 0.816 <C> +0.6% <C> [BOLD] 0.656 <C> +1.9% <C> [BOLD] 0.765 <C> +2.1% <R> <C> credit <C> Budget <C> 30 <C> 0.786 <C> 0.544 <C> 0.661 <C> 0.763 <C> 0.457 <C> 0.655 <C> [BOLD] 0.810 <C> +3.1% <C> [BOLD] 0.617 <C> +13.4% <C> [BOLD] 0.745 <C> +12.7% <R> <C> credit <C> Budget <C> 40 <C> 0.784 <C> 0.554 <C> 0.660 <C> 0.759 <C> 0.438 <C> 0.632 <C> [BOLD] 0.808 <C> +3.1% <C> [BOLD] 0.618 <C> +11.6% <C> [BOLD] 0.744 <C> +12.7% <R> <C> credit <C> Budget <C> 60 <C> 0.777 <C> 0.533 <C> 0.622 <C> 0.759 <C> 0.436 <C> 0.613 <C> [BOLD] 0.809 <C> +4.1% <C> [BOLD] 0.616 <C> +15.6% <C> [BOLD] 0.744 <C> +19.6% <CAP> TABLE III: Comparison of adversarial learning techniques trained and attacked under the same budget. The table also shows the performance difference between RF-Treant and the best competitor.
<R> <C> Problem Class <C> R <C> R+Advisor <C> PPO <C> PPO+Advisor <C> MAML <R> <C> Pole-balance (d) <C> 20.32±3.15 <C> 28.52±7.6 <C> 27.87±6.17 <C> [BOLD] 46.29± [BOLD] 6.30 <C> 39.29±5.74 <R> <C> Animat <C> −779.62±110.28 <C> [BOLD] −387.27± [BOLD] 162.33 <C> −751.40±68.73 <C> −631.97±155.5 <C> −669.93±92.32 <R> <C> Pole-balance (c) <C> — <C> — <C> 29.95±7.90 <C> [BOLD] 438.13± [BOLD] 35.54 <C> 267.76±163.05 <R> <C> Hopper <C> — <C> — <C> 13.82±10.53 <C> [BOLD] 164.43± [BOLD] 48.54 <C> 39.41±7.95 <R> <C> Ant <C> — <C> — <C> −42.75±24.35 <C> 83.76±20.41 <C> [BOLD] 113.33± [BOLD] 64.48 <CAP> Table 1: Average performance (and standard deviations) on discrete and continuous control unseen tasks over the last 50 episodes.
<R> <C> [BOLD] Method <C> [BOLD] Acc (%) <C> [BOLD] DR (%) <C> [BOLD] FAR (%) <C> [BOLD] F1 Score <C> [BOLD] Execution Time (S) <R> <C> KNN  <C> 97.4 <C> 96.3 <C> 5.3 <C> 0.934 <C> 911.6 <R> <C> SVM  <C> 96.5 <C> 95.7 <C> 4.8 <C> 0.933 <C> 13765.6 <R> <C> DT <C> 99.99 <C> 99.99 <C> 0.006 <C> 0.999 <C> 328 <R> <C> RF <C> 99.99 <C> 99.99 <C> 0.0003 <C> 0.999 <C> 506.8 <R> <C> ET <C> 99.99 <C> 99.99 <C> 0.0005 <C> 0.999 <C> 216.3 <R> <C> XGBoost <C> 99.98 <C> 99.98 <C> 0.012 <C> 0.999 <C> 3499.1 <R> <C> Stacking <C> 100 <C> 100 <C> 0.0 <C> 1.0 <C> 1237.1 <R> <C> FS RF <C> 99.99 <C> 99.99 <C> 0.0013 <C> 0.999 <C> 99.6 <R> <C> FS Stacking <C> 99.99 <C> 99.99 <C> 0.0006 <C> 0.999 <C> 325.6 <CAP> TABLE III: Performance Evaluation of IDS on CAN-intrusion Dataset
<R> <C> [BOLD] Method <C> [BOLD] Acc (%) <C> [BOLD] DR (%) <C> [BOLD] FAR (%) <C> [BOLD] F1 Score <C> [BOLD] Execution Time (S) <R> <C> KNN  <C> 96.6 <C> 96.4 <C> 5.6 <C> 0.966 <C> 9243.6 <R> <C> SVM  <C> 98.01 <C> 97.58 <C> 1.48 <C> 0.978 <C> 49953.1 <R> <C> DT <C> 99.72 <C> 99.3 <C> 0.029 <C> 0.998 <C> 126.7 <R> <C> RF <C> 98.37 <C> 98.29 <C> 0.039 <C> 0.983 <C> 2421.6 <R> <C> ET <C> 93.43 <C> 93.35 <C> 0.001 <C> 0.934 <C> 2349.6 <R> <C> XGBoost <C> 99.78 <C> 99.76 <C> 0.069 <C> 0.997 <C> 1637.2 <R> <C> Stacking <C> 99.86 <C> 99.8 <C> 0.012 <C> 0.998 <C> 4519.3 <R> <C> FS XGBoost <C> 99.7 <C> 99.55 <C> 0.077 <C> 0.996 <C> 995.9 <R> <C> FS Stacking <C> 99.82 <C> 99.75 <C> 0.011 <C> 0.997 <C> 2774.8 <CAP> TABLE IV: Performance Evaluation of IDS on CICIDS2017 Dataset
<R> <C> [BOLD] Label <C> [BOLD] Feature <C> [BOLD] Weight <R> <C> [EMPTY] <C> Bwd Packet Length Std <C> 0.1723 <R> <C> DoS <C> Average Packet Size <C> 0.1211 <R> <C> [EMPTY] <C> Destination Port <C> 0.0785 <R> <C> [EMPTY] <C> Total Length of Fwd Packets <C> 0.3020 <R> <C> Port-Scan <C> Average Packet Size <C> 0.1045 <R> <C> [EMPTY] <C> PSH Flag Count <C> 0.1019 <R> <C> [EMPTY] <C> Destination Port <C> 0.3728 <R> <C> Brute-Force <C> Fwd Packet Length Min <C> 0.1022 <R> <C> [EMPTY] <C> Packet Length Variance <C> 0.0859 <R> <C> [EMPTY] <C> Init_Win_bytes_backward <C> 0.2643 <R> <C> Web-Attack <C> Average Packet Size <C> 0.1650 <R> <C> [EMPTY] <C> Destination Port <C> 0.0616 <R> <C> [EMPTY] <C> Destination Port <C> 0.2364 <R> <C> Botnet <C> Bwd Packet Length Mean <C> 0.1240 <R> <C> [EMPTY] <C> Avg Bwd Segment Size <C> 0.1104 <R> <C> [EMPTY] <C> Total Length of Fwd Packets <C> 0.2298 <R> <C> Infiltration <C> Subflow Fwd Bytes <C> 0.1345 <R> <C> [EMPTY] <C> Destination Port <C> 0.1149 <CAP> TABLE V: Top-3 Feature Importance by Each Attack
<R> <C> [BOLD] Conditions Map <C> [BOLD] Conditions Weather <C> [BOLD] Conditions Agents <C> [BOLD] Median Uncertainty Value Follow <C> [BOLD] Median Uncertainty Value Left <C> [BOLD] Median Uncertainty Value Right <C> [BOLD] Median Uncertainty Value Straight <R> <C> Town1 <C> Seen <C> No <C> 0.694 <C> 0.827 <C> 0.868 <C> 0.667 <R> <C> Town1 <C> Seen <C> Yes <C> 0.739 <C> 0.823 <C> 0.854 <C> 0.717 <R> <C> Town1 <C> Unseen <C> Yes <C> 0.737 <C> 0.870 <C> 0.903 <C> 0.757 <R> <C> Town2 <C> Seen <C> Yes <C> 0.759 <C> 0.852 <C> 0.881 <C> 0.815 <R> <C> Town2 <C> Unseen <C> Yes <C> 0.740 <C> 0.809 <C> 0.952 <C> 0.753 <R> <C> Map Town1 Avg. <C> Map Town1 Avg. <C> Map Town1 Avg. <C> 0.788 <C> 0.788 <C> 0.788 <C> 0.788 <R> <C> Map Town2 Avg. <C> Map Town2 Avg. <C> Map Town2 Avg. <C> 0.820 <C> 0.820 <C> 0.820 <C> 0.820 <R> <C> Seen Weather Avg. <C> Seen Weather Avg. <C> Seen Weather Avg. <C> 0.791 <C> 0.791 <C> 0.791 <C> 0.791 <R> <C> Unseen Weather Avg. <C> Unseen Weather Avg. <C> Unseen Weather Avg. <C> 0.815 <C> 0.815 <C> 0.815 <C> 0.815 <CAP> TABLE I: Median Uncertainty Value in Different Scenarios
<R> <C> [BOLD] Dataset <C> [BOLD] Infraction  [BOLD] Rate <C> [BOLD] Success Rate Town1 <C> [BOLD] Success Rate Town2 <C> [BOLD] Km per Infraction Town1 <C> [BOLD] Km per Infraction Town2 <R> <C> Passive (full) <C> - <C> 0.55 <C> 0.40 <C> 0.69 <C> 0.55 <R> <C> Baseline <C> - <C> 0.52 <C> 0.34 <C> 0.90 <C> 0.47 <R> <C> Starter Set <C> - <C> 0.41 <C> 0.24 <C> 0.65 <C> 0.56 <R> <C> Active Filter <C> - <C> 0.68 <C> 0.51 <C> 0.90 <C> 0.67 <R> <C> Stochastic Mix <C> 20.05 % <C> 0.58 <C> 0.44 <C> 0.83 <C> 0.47 <R> <C> Random Noise <C> 19.54 % <C> 0.73 <C> 0.51 <C> 0.75 <C> 0.51 <R> <C> UAIL <C> [BOLD] 13.83 % <C> [BOLD] 0.74 <C> [BOLD] 0.61 <C> 0.88 <C> 0.63 <CAP> TABLE II: Performance Comparison on Intersections Benchmark. Avg success rate and distance traveled between infractions are reported. Distance traveled between infractions can be higher for a model with lower success rate due to its failure in learning turning behaviors.
<R> <C> [BOLD] Method <C> [BOLD] Raster <C> [BOLD] State <C> [BOLD] Loss <C> [BOLD] Displacement <C> [BOLD] Along-track <C> [BOLD] Cross-track <R> <C> UKF <C> – <C> yes <C> – <C> 1.46 <C> 1.21 <C> 0.57 <R> <C> Linear model <C> – <C> yes <C> ( 2 ) <C> 1.19 <C> 1.03 <C> 0.43 <R> <C> Lane-assoc <C> – <C> yes <C> – <C> 1.09 <C> 1.09 <C> 0.19 <R> <C> AlexNet <C> w/o fading <C> no <C> ( 2 ) <C> 3.14 <C> 3.11 <C> 0.35 <R> <C> AlexNet <C> w/ fading <C> no <C> ( 2 ) <C> 1.24 <C> 1.23 <C> 0.22 <R> <C> AlexNet <C> w/o fading <C> yes <C> ( 2 ) <C> 0.97 <C> 0.94 <C> 0.21 <R> <C> AlexNet <C> w/ fading <C> yes <C> ( 2 ) <C> 0.86 <C> 0.83 <C> 0.20 <R> <C> VGG-19 <C> w/ fading <C> yes <C> ( 2 ) <C> 0.77 <C> 0.75 <C> 0.19 <R> <C> ResNet-50 <C> w/ fading <C> yes <C> ( 2 ) <C> 0.76 <C> 0.74 <C> 0.18 <R> <C> MobileNet-v2 <C> w/ fading <C> yes <C> ( 2 ) <C> 0.73 <C> 0.70 <C> 0.18 <R> <C> MobileNet-v2 <C> w/ fading <C> yes <C> ( 5 ) <C> 0.71 <C> 0.68 <C> 0.18 <R> <C> MobileNet-v2 LSTM <C> w/ fading <C> yes <C> ( 5 ) <C> [BOLD] 0.62 <C> [BOLD] 0.60 <C> [BOLD] 0.14 <CAP> Table 1: Comparison of average prediction errors for competing methods (in meters)
<R> <C> [BOLD] Farm Name <C> [BOLD] Access via <C> [BOLD] #Downloads <C> [BOLD] Source <C> [BOLD] Price(USD/10k) <C> [BOLD] IP Address <C> [BOLD] Device ID <C> [BOLD] Duration(hours) <C> [BOLD] Date <R> <C> Farm 1 <C> Website <C> 10,000 <C> Portal site <C> 4 <C> Distinct <C> None <C> 12 <C> 06/06/2018 <R> <C> Farm 2 <C> Taobao <C> 15,000 <C> Update <C> 6 <C> Distinct <C> Normal <C> 2 <C> 07/31/2018 <R> <C> Farm 3 <C> QQ <C> 10,000 <C> Null <C> 6 <C> Distinct <C> Abnormal <C> 0.2 <C> 08/05/2018 <R> <C> Farm 4 <C> Website <C> 20,000 <C> Portal site <C> 3 <C> Distinct <C> Abnormal <C> 1 <C> 09/15/2018 <CAP> TABLE II: Comparison between purchased fake downloads injection services on our honeypot App. Portal website: download comes from App market portal website. Update: download comes from updating the App. Null: no download source record.
<R> <C> [BOLD] Feature Type <C> [BOLD] Precision <C> [BOLD] Recall <C> [BOLD] F1 <C> [BOLD] AUC <C> [BOLD] Accuracy <R> <C> Device <C> 0.955 <C> 0.988 <C> 0.963 <C> 0.977 <C> 0.992 <R> <C> App <C> 0.978 <C> 0.972 <C> 0.976 <C> 0.965 <C> 0.993 <R> <C> New <C> 0.974 <C> 0.940 <C> 0.951 <C> 0.969 <C> 0.993 <R> <C> Previous <C> 0.974 <C> 0.977 <C> 0.975 <C> 0.996 <C> 0.987 <R> <C> All <C> [BOLD] 0.994 <C> [BOLD] 0.992 <C> [BOLD] 0.993 <C> [BOLD] 0.998 <C> [BOLD] 0.997 <CAP> TABLE III: Testing results of different types of features with XGBoost.
<R> <C> data set <C> Size,  [ITALIC] N <C> Num. orbits <C> Iso. graphs,  [ITALIC] I <C> [ITALIC] I% <C> [ITALIC] IP% <C> Mismatched % <R> <C> SYNTHETIC <C> 300 <C> 2 <C> 300 <C> 100 <C> 100 <C> 100 <R> <C> Cuneiform <C> 267 <C> 8 <C> 267 <C> 100 <C> 20.46 <C> 100 <R> <C> Letter-low <C> 2250 <C> 32 <C> 2245 <C> 99.78 <C> 8.72 <C> 96.22 <R> <C> DHFR_MD <C> 393 <C> 25 <C> 392 <C> 99.75 <C> 6.87 <C> 94.91 <R> <C> COIL-RAG <C> 3900 <C> 20 <C> 3890 <C> 99.74 <C> 25.22 <C> 99.31 <R> <C> COX2_MD <C> 303 <C> 13 <C> 301 <C> 99.34 <C> 11.83 <C> 98.68 <R> <C> ER_MD <C> 446 <C> 31 <C> 442 <C> 99.1 <C> 5.57 <C> 82.74 <R> <C> Fingerprint <C> 2800 <C> 69 <C> 2774 <C> 99.07 <C> 16.86 <C> 89.29 <R> <C> BZR_MD <C> 306 <C> 22 <C> 303 <C> 99.02 <C> 7.16 <C> 95.75 <R> <C> Letter-med <C> 2250 <C> 39 <C> 2226 <C> 98.93 <C> 8.05 <C> 92.93 <CAP> Table 2: Isomorphic metrics for Top-10 data sets based on the proportion of isomorphic graphs I%. IP% is the proportion of isomorphic pairs of graphs, Mismatched % is the proportion of mismatched labels.
<R> <C> data set <C> Size,  [ITALIC] N <C> Num. orbits <C> Iso. graphs,  [ITALIC] I <C> [ITALIC] I% <C> [ITALIC] IP% <C> Mismatched % <R> <C> SYNTHETIC <C> 300 <C> 2 <C> 300 <C> 100 <C> 100 <C> 100 <R> <C> Cuneiform <C> 267 <C> 8 <C> 267 <C> 100 <C> 20.46 <C> 100 <R> <C> DHFR_MD <C> 393 <C> 25 <C> 392 <C> 99.75 <C> 6.87 <C> 94.91 <R> <C> COX2_MD <C> 303 <C> 13 <C> 301 <C> 99.34 <C> 11.83 <C> 98.68 <R> <C> ER_MD <C> 446 <C> 31 <C> 442 <C> 99.1 <C> 5.57 <C> 82.74 <R> <C> BZR_MD <C> 306 <C> 22 <C> 303 <C> 99.02 <C> 7.16 <C> 95.75 <R> <C> MUTAG <C> 188 <C> 17 <C> 36 <C> 19.15 <C> 0.14 <C> 0 <R> <C> PTC_FM <C> 349 <C> 22 <C> 54 <C> 15.47 <C> 0.08 <C> 10.89 <R> <C> PTC_MM <C> 336 <C> 22 <C> 50 <C> 14.88 <C> 0.07 <C> 7.74 <R> <C> DHFR <C> 756 <C> 39 <C> 98 <C> 12.96 <C> 0.04 <C> 3.97 <CAP> Table 3: Isomorphic metrics with node labels for Top-10 data sets based on the proportion of isomorphic graphs I%. IP% is the proportion of isomorphic pairs of graphs, Mismatched % is the proportion of mismatched labels.
<R> <C> [EMPTY] <C> MUTAG <C> IMDB-B <C> IMDB-M <C> COX2 <C> AIDS <C> PROTEINS <R> <C> NN <C> 0.829 (0.840) <C> 0.737 (0.733) <C> 0.501 (0.488) <C> 0.82 (0.872) <C> 0.996 (0.998) <C> 0.737 (0.834) <R> <C> NN-PH <C> 0.867 (1.000) <C> [BOLD] 0.756 (1.000) <C> [BOLD] 0.522 (1.000) <C> [BOLD] 0.838 (1.000) <C> [BOLD] 0.996 (1.000) <C> 0.742 (1.000) <R> <C> NN-P <C> 0.856 (0.847) <C> 0.737 (0.731) <C> 0.499 (0.486) <C> 0.795 (0.83) <C> 0.996 (0.999) <C> 0.729 (0.709) <R> <C> WL <C> 0.862 (0.867) <C> 0.734 (0.990) <C> 0.502 (0.953) <C> 0.800 (0.974) <C> 0.993 (0.999) <C> 0.747 (0.950) <R> <C> WL-PH <C> [BOLD] 0.907 (1.000) <C> 0.736 (1.000) <C> 0.504 (1.000) <C> 0.810 (1.000) <C> 0.994 (1.000) <C> [BOLD] 0.749 (1.000) <R> <C> WL-P <C> 0.870 (0.838) <C> 0.724 (0.715) <C> 0.495 (0.487) <C> 0.794 (0.844) <C> 0.994 (0.999) <C> 0.740 (0.742) <R> <C> V <C> 0.836 (0.902) <C> 0.707 (0.820) <C> 0.503 (0.732) <C> 0.781 (0.966) <C> 0.994 (0.997) <C> 0.726 (0.946) <R> <C> V-PH <C> 0.859 (1.000) <C> 0.750 (1.000) <C> 0.517 (1.000) <C> 0.794 (1.000) <C> [BOLD] 0.996 (1.000) <C> 0.729 (1.000) <R> <C> V-P <C> 0.827 (0.844) <C> 0.724 (0.728) <C> 0.496 (0.481) <C> 0.768 (0.852) <C> 0.996 (0.999) <C> 0.719 (0.741) <CAP> Table 4: Mean classification accuracy for test sets Ytest and Yiso (in brackets) in 10-fold cross-validation. Top-1 result in bold.
<R> <C> Methods <C> Random Classes ImageNet <C> Random Classes ImageNet <C> Random Classes LSUN <C> Random Classes LSUN <C> Random Classes Places365 <C> Random Classes Places365 <C> Completely Overlapping Classes ImageNet <C> Completely Overlapping Classes ImageNet <C> Completely Overlapping Classes LSUN <C> Completely Overlapping Classes LSUN <C> Completely Overlapping Classes Places365 <C> Completely Overlapping Classes Places365 <R> <C> [EMPTY] <C> VGG16 <C> ResNet34 <C> VGG16 <C> ResNet34 <C> VGG16 <C> ResNet34 <C> VGG16 <C> ResNet34 <C> VGG16 <C> ResNet34 <C> VGG16 <C> ResNet34 <R> <C> SPV (Benchmark) <C> .7212 <C> .6953 <C> .6664 <C> .6760 <C> .5525 <C> .5870 <C> .7345 <C> .7490 <C> .6769 <C> .7017 <C> .5960 <C> .6460 <R> <C> SD <C> .5543 <C> .5562 <C> .5310 <C> .5350 <C> .4390 <C> .4564 <C> [BOLD] .7275 <C> [BOLD] .7292 <C> .7004 <C> [BOLD] .7041 <C> [BOLD] .6163 <C> [BOLD] .6402 <R> <C> [BOLD] (A)  [ITALIC] Estimate  [ITALIC] q methods <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> CE-E <C> [BOLD] .6911 <C> [BOLD] .6852 <C> .6483 <C> [BOLD] .6445 <C> [BOLD] .5484 <C> [BOLD] .5643 <C> [BOLD] .7276 <C> [BOLD] .7290 <C> .7002 <C> .7036 <C> [BOLD] .6162 <C> [BOLD] .6406 <R> <C> MF-P-E <C> .6819 <C> .6747 <C> .6443 <C> .6406 <C> .5349 <C> .5488 <C> [BOLD] .7280 <C> [BOLD] .7297 <C> [BOLD] .7012 <C> [BOLD] .7052 <C> [BOLD] .6167 <C> [BOLD] .6406 <R> <C> MF-LV-E <C> .6660 <C> .6609 <C> .6348 <C> .6330 <C> .5199 <C> .5414 <C> .7231 <C> .7242 <C> [BOLD] .7031 <C> [BOLD] .7043 <C> .6129 <C> .6374 <R> <C> MF-LF-E <C> .6886 <C> [BOLD] .6833 <C> .6490 <C> [BOLD] .6458 <C> .5441 <C> .5609 <C> .7265 <C> [BOLD] .7279 <C> [BOLD] .7015 <C> [BOLD] .7057 <C> [BOLD] .6161 <C> [BOLD] .6397 <R> <C> [BOLD] (B)  [ITALIC] Backprop. methods <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> CE-BP <C> [BOLD] .6902 <C> [BOLD] .6869 <C> [BOLD] .6520 <C> .6439 <C> .5466 <C> [BOLD] .5669 <C> [BOLD] .7275 <C> [BOLD] .7288 <C> .7003 <C> [BOLD] .7040 <C> [BOLD] .6161 <C> [BOLD] .6400 <R> <C> MF-P-BP <C> [BOLD] .6945 <C> [BOLD] .6872 <C> .6480 <C> [BOLD] .6417 <C> [BOLD] .5471 <C> .5609 <C> [BOLD] .7277 <C> [BOLD] .7287 <C> .6999 <C> [BOLD] .7019 <C> .6146 <C> .6384 <R> <C> MF-LV-BP <C> .6889 <C> [BOLD] .6847 <C> [BOLD] .6495 <C> .6389 <C> .5467 <C> [BOLD] .5681 <C> .7229 <C> .7225 <C> .7001 <C> [BOLD] .7046 <C> .6113 <C> .6369 <R> <C> MF-LF-BP <C> .6842 <C> [BOLD] .6840 <C> [BOLD] .6523 <C> [BOLD] .6445 <C> .5383 <C> [BOLD] .5624 <C> .7239 <C> .7252 <C> [BOLD] .7020 <C> .7034 <C> .6104 <C> .6366 <R> <C> [BOLD] (C)  [ITALIC] Balanced soft labels <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> SD-BS <C> .6629 <C> .6574 <C> .6343 <C> .6345 <C> .5283 <C> .5433 <C> .7217 <C> .7214 <C> .6979 <C> .7017 <C> .6094 <C> .6320 <R> <C> CE-BS <C> [BOLD] .6928 <C> [BOLD] .6856 <C> .6513 <C> [BOLD] .6464 <C> [BOLD] .5548 <C> [BOLD] .5687 <C> .7215 <C> .7213 <C> .6979 <C> .7018 <C> .6094 <C> .6323 <R> <C> MF-P-BS <C> .6851 <C> .6756 <C> .6474 <C> [BOLD] .6450 <C> .5455 <C> .5546 <C> .7243 <C> .7252 <C> .6996 <C> .7041 <C> .6124 <C> .6355 <R> <C> MF-LV-BS <C> .6772 <C> .6682 <C> .6388 <C> .6357 <C> .5346 <C> .5497 <C> .7168 <C> .7173 <C> .7014 <C> .7028 <C> .6063 <C> .6301 <R> <C> MF-LF-BS <C> [BOLD] .6935 <C> [BOLD] .6865 <C> [BOLD] .6549 <C> [BOLD] .6485 <C> [BOLD] .5544 <C> [BOLD] .5692 <C> .7210 <C> .7215 <C> .6998 <C> .7035 <C> .6101 <C> .6330 <CAP> Table 2: Average accuracy of UHC methods over different combinations of HC configurations, datasets, and unified classifier models. (Underline bold: Best method. Bold: Methods which are not statistically significantly different from the best method.)
<R> <C> Data augmentation <C> mIoU ( [ITALIC] f=200) <C> mIoU ( [ITALIC] f=250) <C> mIoU ( [ITALIC] f=300) <C> mIoU ( [ITALIC] f=350) <C> mIoU ( [ITALIC] f=400) <R> <C> Fixed z-aug <C> 0.5562 <C> 0.5773 <C> 0.5869 <C> 0.5948 <C> 0.5930 <R> <C> Random z-aug <C> 0.5979 <C> 0.6089 <C> 0.6117 <C> 0.6116 <C> 0.6070 <R> <C> Six-DoF aug <C> 0.5938 <C> 0.6082 <C> [BOLD] 0.6146 <C> 0.6156 <C> 0.6143 <R> <C> Seven-DoF aug <C> [BOLD] 0.6093 <C> [BOLD] 0.6150 <C> 0.6134 <C> [BOLD] 0.6166 <C> [BOLD] 0.6154 <CAP> TABLE I: performance of different data augmentation
<R> <C> Hand Skin Region <C> First band <C> Second Band <C> Third Band <R> <C> Proximal Interphalangeal Joints <C> 1270 <C> 1350 <C> 1685 <R> <C> Metacarpal <C> 1270 <C> 1360 <C> 1690 <R> <C> Proximal Phalanges <C> 1270 <C> 1360 <C> - <CAP> Table 1: Rounded most important bandwidth means for classification per region in nanometers
<R> <C> [BOLD] Method <C> [BOLD] MNIST∗ <C> [BOLD] FEMNIST <C> [BOLD] P-MNIST <C> [BOLD] VSN <C> [BOLD] HAR <R> <C> [ITALIC] Global∗ <C> [BOLD] 0.9678±0.0007 <C> 0.44±0.02 <C> 0.919±0.004 <C> 0.926±0.005 <C> 0.797±0.006 <R> <C> [ITALIC] Local <C> 0.9511±0.0020 <C> 0.51±0.01 <C> [BOLD] 0.950±0.003 <C> [BOLD] 0.960±0.003 <C> 0.940±0.001 <R> <C> FedAvg <C> [BOLD] 0.9675±0.0004 <C> 0.45±0.05 <C> 0.905±0.002 <C> 0.916±0.007 <C> [BOLD] 0.944±0.004 <R> <C> Virtual <C> [BOLD] 0.9666±0.0017 <C> [BOLD] 0.56±0.01 <C> [BOLD] 0.949±0.001 <C> [BOLD] 0.960±0.002 <C> [BOLD] 0.944±0.001 <CAP> Table 2: Multi-task average test accuracy. Mean and standard deviation over 5 train-test splits.
<R> <C> Unconstrained T (s) <C> Unconstrained AVG T (s) <C> Unconstrained AVG # itr <C> Constrained (ours) T (s) <C> Constrained (ours) AVG T (s) <C> Constrained (ours) AVG # itr <R> <C> 207.98 <C> 2.08 <C> 35.61 <C> 37.15 <C> 0.56 <C> 2.52 <R> <C> 216.00 <C> 2.16 <C> 37.40 <C> 35.36 <C> 0.54 <C> 2.33 <R> <C> 212.10 <C> 2.12 <C> 36.72 <C> 34.16 <C> 0.52 <C> 2.26 <R> <C> 210.71 <C> 2.11 <C> 36.39 <C> 37.03 <C> 0.58 <C> 2.52 <R> <C> 210.72 <C> 2.11 <C> 36.24 <C> 36.05 <C> 0.55 <C> 2.40 <CAP> Table 1: Results of constrained one-pixel adversarial perturbations on 100 images from CIFAR-10 dataset. For both constrained and unconstrained perturbations, the total time in seconds, average time in seconds, and the average number of DE iterations are presented. Five runs for constrained and unconstrained one-pixel adversarial perturbations show that constrained perturbations converge faster.
<R> <C> Constrained (ours) T (s) <C> Constrained (ours) AVG T (s) <C> Constrained (ours) AVG # itr <C> Unconstrained T (s) <C> Unconstrained AVG T (s) <C> Unconstrained AVG # itr <R> <C> 355.69 <C> 6.03 <C> 6.44 <C> 445.55 <C> 8.25 <C> 8.80 <R> <C> 392.21 <C> 6.88 <C> 7.63 <C> 523.31 <C> 8.58 <C> 9.70 <R> <C> 446.09 <C> 7.31 <C> 8.13 <C> 516.71 <C> 8.62 <C> 9.52 <R> <C> 344.90 <C> 5.95 <C> 6.45 <C> 459.81 <C> 7.79 <C> 8.75 <R> <C> 416.18 <C> 7.19 <C> 7.86 <C> 559.48 <C> 9.32 <C> 10.60 <CAP> Table 2: Results of constrained one-pixel adversarial perturbations on the NIPS-W dataset. For both constrained and unconstrained successful attacks, the total time in seconds, average time in seconds, and average number of DE iterations are presented. Five runs for constrained and unconstrained one-pixel adversarial perturbations show that constrained perturbations converge faster.
<R> <C> [BOLD]  MNIST <C> [BOLD] 10 Clients  [BOLD] Clean <C> [BOLD] 10 Clients  [BOLD] Byzantine <C> [BOLD] 10 Clients  [BOLD] Flipping <C> [BOLD] 10 Clients  [BOLD] Noisy <C> [BOLD] 100 Clients  [BOLD] Clean <C> [BOLD] 100 Clients  [BOLD] Byzantine <C> [BOLD] 100 Clients  [BOLD] Flipping <C> [BOLD] 100 Clients  [BOLD] Noisy <R> <C> AFA <C> 2.80±0.12 <C> [BOLD] 2.99± [BOLD] 0.12 <C> [BOLD] 2.96± [BOLD] 0.15 <C> [BOLD] 3.04± [BOLD] 0.14 <C> [BOLD] 3.82± [BOLD] 0.09 <C> [BOLD] 4.03± [BOLD] 0.09 <C> [BOLD] 3.98± [BOLD] 0.08 <C> [BOLD] 3.97± [BOLD] 0.08 <R> <C> FA <C> [BOLD] 2.56± [BOLD] 0.11 <C> 90.03±0.59 <C> 8.48±1.58 <C> 3.79±0.17 <C> [BOLD] 3.86± [BOLD] 0.14 <C> 89.70±0.73 <C> 90.20±0.00 <C> 4.81±0.09 <R> <C> MKRUM <C> 3.96±0.18 <C> 4.01±0.13 <C> 78.98±23.39 <C> 3.94±0.13 <C> 4.68±0.11 <C> 4.63±0.14 <C> 4.62±0.13 <C> 4.61±0.13 <R> <C> COMED <C> 2.82±0.09 <C> 3.17±0.16 <C> 11.55±0.93 <C> 3.56±0.09 <C> 4.08±0.11 <C> 4.21±0.13 <C> 7.32±0.20 <C> 4.51±0.10 <CAP> Table 1: Averaged test error over 10 random training data splits for AFA, FA, MKRUM and COMED in different scenarios: clean datasets for all clients, Byzantine adversaries, label flipping attacks, and noisy clients. For each scenario we considered two settings with 10 and 100 clients with 3 and 30 bad/malicious clients respectively. Best results with statistical significance at the 5% level, according to a Wilcoxon Rank-Sum test, are highlighted in bold.
<R> <C> [BOLD]  FMNIST <C> [BOLD] 10 Clients  [BOLD] Clean <C> [BOLD] 10 Clients  [BOLD] Byzantine <C> [BOLD] 10 Clients  [BOLD] Flipping <C> [BOLD] 10 Clients  [BOLD] Noisy <C> [BOLD] 100 Clients  [BOLD] Clean <C> [BOLD] 100 Clients  [BOLD] Byzantine <C> [BOLD] 100 Clients  [BOLD] Flipping <C> [BOLD] 100 Clients  [BOLD] Noisy <R> <C> AFA <C> 14.72±1.89 <C> 14.11±1.16 <C> [BOLD] 15.45± [BOLD] 1.88 <C> 15.27±1.89 <C> 15.72±2.11 <C> 16.08±1.88 <C> [BOLD] 15.99± [BOLD] 2.00 <C> 17.48±1.32 <R> <C> FA <C> [BOLD] 13.60± [BOLD] 1.62 <C> 89.27±0.81 <C> 24.52±11.23 <C> 15.55±1.80 <C> 16.96±1.50 <C> 89.55±1.18 <C> 48.46±21.44 <C> 18.95±0.15 <R> <C> MKRUM <C> 14.23±0.21 <C> 14.28±0.27 <C> 34.79±3.12 <C> 14.21±0.24 <C> 15.05±0.36 <C> 15.00±0.20 <C> [BOLD] 15.14± [BOLD] 0.30 <C> [BOLD] 15.25± [BOLD] 0.52 <R> <C> COMED <C> [BOLD] 12.68± [BOLD] 0.22 <C> [BOLD] 13.33± [BOLD] 0.23 <C> 24.02±0.76 <C> 14.43±0.32 <C> 17.05±1.37 <C> 15.95±1.63 <C> 18.11±0.35 <C> 18.38±0.13 <CAP> Table 1: Averaged test error over 10 random training data splits for AFA, FA, MKRUM and COMED in different scenarios: clean datasets for all clients, Byzantine adversaries, label flipping attacks, and noisy clients. For each scenario we considered two settings with 10 and 100 clients with 3 and 30 bad/malicious clients respectively. Best results with statistical significance at the 5% level, according to a Wilcoxon Rank-Sum test, are highlighted in bold.
<R> <C> Method <C> [BOLD] CIFAR100 IS <C> [BOLD] CIFAR100 FID <R> <C> Real data <C> 14.79 (± .18) <C> [EMPTY] <R> <C> Baseline <C> 10.88 (± .19) <C> [BOLD] 11.53 <R> <C> MHingeGAN <C> [BOLD] 14.36 (± .17) <C> 17.3 <R> <C> MHingeGAN CSC <C> 8.79 (± .08) <C> 21.03 <R> <C> MHingeGAN FM <C> 7.86 (± .03) <C> 31.55 <R> <C> SNGAN  <C> 9.30 (± .08) <C> 15.6 <R> <C> MSGAN†  <C> - <C> 19.74 <CAP> Table 1: Inception Scores and FIDs for supervised image generation. Each row corresponds to a single trained model. The models we trained were chosen by minimizing the IS within 100,000 iterations. Methods that are not class conditional are indicated by the †. The best number per column is bold faced.
<R> <C> Model <C> Generator Arch. <C> [ITALIC] Gb Score <C> Best  [ITALIC] Ei Score <C> ∼Params <R> <C> 1 <C> Small DCGAN ( [ITALIC] d=256) <C> 5.02±0.05 <C> [EMPTY] <C> 700,000 <R> <C> 2 <C> [BOLD] Tiny DCGAN ( [ITALIC] d=128) + Editors <C> [BOLD] 5.00±0.09 <C> [BOLD] 5.67±0.07 (Edit 3) <C> [BOLD] 866,000 <R> <C> 3 <C> [BOLD] Small DCGAN + Editors (one Critic) <C> [BOLD] 5.24±0.04 <C> [BOLD] 6.05±0.08 (Edit 2) <C> [BOLD] 1,250,000 <R> <C> 4 <C> [BOLD] Small DCGAN + Editors (multi Critic) <C> [BOLD] 5.63±0.06 <C> [BOLD] 5.86±0.05 (Edit 2) <C> [BOLD] 1,250,000 <R> <C> 5 <C> Small DCGAN + Editors (end-to-end) <C> [EMPTY] <C> 2.56±0.02 <C> 1,250,000 <R> <C> 6 <C> DCGAN - WGAN+GP ( [ITALIC] d=512) <C> 5.18±0.05 <C> [EMPTY] <C> 1,730,000 <R> <C> 7 <C> Small ResNet <C> 5.75±0.05 <C> [EMPTY] <C> 720,000 <R> <C> 8 <C> [BOLD] Small ResNet + Editors <C> [BOLD] 6.35±0.09 <C> [BOLD] 6.70±0.03 (Edit 3) <C> [BOLD] 1,000,000 <R> <C> 9 <C> ResNet - WGAN+GP <C> 6.86±0.04 <C> [EMPTY] <C> 1,220,000 <CAP> Table 1: Inception scores on unlabelled CIFAR with and without the chain generator approach trained with WGAN+GP. d refers to the depth of the first conv layer in DCGAN architectures. See section 7.4 for details about architecture.
<R> <C> Method <C> PSNR (mean ± std) <R> <C> Semantic Inpainting <C> 33.85 ± 4.67 <R> <C> Context Encoders <C> 26.31 ± 4.48 <R> <C> Contextual Attention <C> 31.80 ± 5.19 <CAP> Table 1: Comparison of PSNR mean and standard deviation on the 880 healthy inpainted patches.
<R> <C> [BOLD] Algorithms <C> [BOLD] False Alarm Rate Abnormal Videos <R> <C> Proposed Method(3D ResNet+constr.+loss) <C> 0.72 <R> <C> Proposed Method(3D ResNet+constr.+new rank.loss) <C> [BOLD] 0.67 <CAP> TABLE III: Comparison of false alarm rate on abnormal videos of UCF-Crime testing dataset.
<R> <C> Method <C> error_rate <R> <C> Genetic DCNN  <C> 5.4 <R> <C> CNN  <C> 7.46 <R> <C> Soft <C> 6.30 <R> <C> [BOLD] Arc <C> [BOLD] 6.04 <R> <C> ArcFace <C> 6.27 <R> <C> Center <C> [BOLD] 6.04 <CAP> Table 5: The error rate (%) on Fashion-MNIST dataset.
<R> <C> Methods <C> Observer accuracy in 2AFC test <R> <C> Semantic Inpainting <C> 66.66% <R> <C> Context Encoders <C> 59.45% <R> <C> Contextual Attention <C> 37.03 % <CAP> Table 3: Human observer performance for the task of choosing the real x-ray. An accuracy of 50% corresponds to chance behavior; an accuracy of 100% indicates the observer can perfectly identify the unaltered chest x-ray in a pair.
<R> <C> [BOLD] Approach <C> #  [BOLD] of encrypted model copies <C> [BOLD] Ciphertext size (dimension) <R> <C> Threshold HE [asharov2012multiparty] <C> [BOLD] P <C> 1×2 <R> <C> Multi-Key HE [chen2017batched] <C> 1 <C> ( [BOLD] N+1)×2 <R> <C> This work <C> 1 <C> [BOLD] 2×2 <CAP> TABLE I: A comparison of different approaches.
<R> <C> Mechanism <C> [ITALIC] λ <C> [ITALIC] η <C> [ITALIC] εpos [m] <C> [ITALIC] εori [rad] <R> <C> 3-DoF <C> 0 <C> 12.81% <C> 8.76e-3±8.25e-3 <C> 1.20e-2±1.41e-2 <R> <C> [EMPTY] <C> 1 <C> 1.27% <C> 1.38e-2±2.67e-2 <C> 1.61e-2±3.09e-2 <R> <C> [EMPTY] <C> 2 <C> 0.97% <C> 1.42e-2±2.60e-2 <C> 1.57e-2±2.91e-2 <R> <C> 6-DoF <C> 0 <C> 71.22% <C> 8.39e-3±6.80e-3 <C> 3.15e-2±5.03e-2 <R> <C> [EMPTY] <C> 1 <C> 3.30% <C> 3.50e-2±4.57e-2 <C> 1.27e-1±1.53e-1 <R> <C> [EMPTY] <C> 2 <C> 1.89% <C> 3.72e-2±5.28e-2 <C> 1.19e-1±1.55e-1 <R> <C> [EMPTY] <C> 5 <C> 1.16% <C> 3.95e-2±5.47e-2 <C> 1.45e-1±2.22e-1 <R> <C> 15-DoF <C> 0 <C> 100% <C> 6.93e-3±9.67e-3 <C> 1.80e-2±3.46e-2 <R> <C> [EMPTY] <C> 1 <C> 6.12% <C> 1.82e-2±3.80e-2 <C> 5.56e-2±1.47e-1 <R> <C> [EMPTY] <C> 2 <C> 3.02% <C> 1.65e-2±3.01e-2 <C> 4.95e-2±1.20e-1 <R> <C> [EMPTY] <C> 5 <C> 1.59% <C> 1.31e-2±2.67e-2 <C> 4.13e-2±1.13e-1 <CAP> TABLE II: Percentage of configurations with at least one infeasible joint angle η and the mean and standard deviations of the position error εpos and orientation error εori for different penalty factors λ in DT. The number of training samples is 800 (3-DoF) or 32000 (6-DoF and 15-DoF).
<R> <C> Mecha- nism <C> Test Set <C> Analy- tical <C> Numerical TRAC-IK <C> DT (800) <C> DT (6400) <R> <C> 3-DoF <C> Uniform <C> 100% <C> 100% <C> 62.88% <C> 98.08% <R> <C> [EMPTY] <C> Singular <C> 100% <C> 100% <C> 61.81% <C> 99.08% <R> <C> [EMPTY] <C> Nonsingular <C> 100% <C> 100% <C> 59.17% <C> 97.25% <R> <C> Mecha- <C> Test Set <C> Analy- <C> Numerical <C> DT <C> DT <R> <C> nism <C> [EMPTY] <C> tical <C> TRAC-IK <C> (32000) <C> (256000) <R> <C> 6-DoF <C> Uniform <C> 100% <C> 98.44% <C> 53.58% <C> 94.53% <R> <C> [EMPTY] <C> Singular <C> 100% <C> 86.95% <C> 52.27% <C> 95.26% <R> <C> [EMPTY] <C> Nonsingular <C> 100% <C> 99.08% <C> 51.58% <C> 95.98% <R> <C> 15-DoF <C> Uniform <C> - <C> 93.23% <C> 82.96% <C> 97.73% <R> <C> [EMPTY] <C> Near-sing. <C> - <C> 89.96% <C> 78.21% <C> 96.60% <R> <C> [EMPTY] <C> Nonsingular <C> - <C> 95.34% <C> 82.96% <C> 98.12% <CAP> TABLE III: Solve rates for error thresholds εpos<0.01m and εori<0.03rad and different test sets. Numbers in brackets below DT denote the number of training samples.
<R> <C> Method <C> LEN-CHANGE NLL <C> LEN-CHANGE MSE <C> VAR-CHANGE NLL <C> VAR-CHANGE MSE <C> Gazebo:Env1 NLL <C> Gazebo:Env1 MSE <C> Gazebo:Env2 NLL <C> Gazebo:Env2 MSE <C> Gazebo:Env3 NLL <C> Gazebo:Env3 MSE <R> <C> BOCPD <C> 0.99±0.38 <C> 0.47±0.32 <C> 1.13±0.61 <C> 0.55±0.58 <C> 2.07±0.51 <C> 0.14±0.05 <C> 2.24±0.48 <C> 0.57±0.26 <C> 0.28±0.12 <C> 0.11±0.03 <R> <C> CS-BOCPD <C> 0.95±0.32 <C> 0.43±0.30 <C> 1.05±0.42 <C> 0.48±0.40 <C> -0.11±0.33 <C> 0.12±0.04 <C> 1.82±1.51 <C> 0.55±0.27 <C> 0.25±0.16 <C> 0.10±0.02 <R> <C> CBOCPD <C> [BOLD] 0.79±0.33 <C> [BOLD] 0.34±0.24 <C> [BOLD] 0.89±0.36 <C> [BOLD] 0.41±0.34 <C> [BOLD] -0.31±0.34 <C> [BOLD] 0.11±0.04 <C> [BOLD] 0.69±0.36 <C> [BOLD] 0.45±0.19 <C> [BOLD] -0.99±0.47 <C> 0.10±0.04 <CAP> Table 1: Comparison of BOCPD, CS-BOCPD, and CBOCPD with NLL and MSE on synthetic and Gazebo robot simulation datasets.
<R> <C> Method Nile Data (200 training points, 463 test points) <C> NLL Nile Data (200 training points, 463 test points) <C> p-value Nile Data (200 training points, 463 test points) <C> MSE Nile Data (200 training points, 463 test points) <C> p-value Nile Data (200 training points, 463 test points) <R> <C> ARGP <C> 1.07±0.64 <C> <0.0001 <C> 5.06±0.86 <C> 0.0005 <R> <C> ARGP-BOCPD <C> 0.78±0.72 <C> <0.0001 <C> 4.94±0.87 <C> 0.0017 <R> <C> GPTS <C> 0.86±0.64 <C> <0.0001 <C> 4.78±0.81 <C> 0.0100 <R> <C> BOCPD <C> 0.57±0.77 <C> 0.0014 <C> 4.73±0.82 <C> 0.0115 <R> <C> CBOCPD <C> [BOLD] 0.00±0.80 <C> [EMPTY] <C> [BOLD] 4.32±0.74 <C> [EMPTY] <R> <C> Well Log Data (500 training points, 3050 test points) <C> Well Log Data (500 training points, 3050 test points) <C> Well Log Data (500 training points, 3050 test points) <C> Well Log Data (500 training points, 3050 test points) <C> Well Log Data (500 training points, 3050 test points) <R> <C> ARGP <C> 7.20±0.60 <C> <0.0001 <C> 17.3±2.6 <C> <0.0001 <R> <C> ARGP-BOCPD <C> [BOLD] 0.00±0.30 <C> [EMPTY] <C> [BOLD] 4.68±0.46 <C> [EMPTY] <R> <C> GPTS <C> 3.73±0.42 <C> <0.0001 <C> 8.27±0.61 <C> <0.0001 <R> <C> BOCPD <C> 4.35±0.31 <C> <0.0001 <C> 19.2±1.3 <C> <0.0001 <R> <C> CBOCPD <C> 0.30±0.27 <C> 0.0010 <C> 4.92±0.44 <C> 0.2124 <R> <C> Snow Data (500 training points, 13380 test points) <C> Snow Data (500 training points, 13380 test points) <C> Snow Data (500 training points, 13380 test points) <C> Snow Data (500 training points, 13380 test points) <C> Snow Data (500 training points, 13380 test points) <R> <C> ARGP <C> 17.48±0.82 <C> <0.0001 <C> 14.82±0.57 <C> <0.0001 <R> <C> ARGP-BOCPD <C> 0.06±0.39 <C> <0.0001 <C> 9.65±0.39 <C> <0.0001 <R> <C> GPTS <C> 16.60±0.22 <C> <0.0001 <C> 8.76±0.36 <C> <0.0001 <R> <C> BOCPD <C> [BOLD] 0.00±0.39 <C> [EMPTY] <C> 9.43±0.38 <C> [EMPTY] <R> <C> CBOCPD <C> 1.92±0.37 <C> <0.0001 <C> [BOLD] 6.34±0.27 <C> <0.0001 <CAP> Table 2: Results of predictive performance on Nile data, Well Log Data and Snow Data. The results are provided with 95% of confidence interval and the p-value of the null hypothesis that a method is equivalent to the best performing method according to NLL, using a one sided t-test.
<R> <C> model <C> RMS <C> average <C> std. dev. <C> max <R> <C> MLP <C> 0.76 <C> -0.29 <C> 0.70 <C> -4.94 <R> <C> CNN <C> 0.60 <C> -0.39 <C> 0.46 <C> -2.33 <CAP> Table 2: Comparison of the longitudinal performances of the MLP and CNN controllers (in m/s).
<R> <C> Method <C> Params(M) <C> CIFAR10 <C> CIFAR10+ <R> <C> EM-Softmax  <C> 15.2 <C> - <C> 6.69 <R> <C> Maxout  <C> - <C> 9.38 <C> - <R> <C> All-CNN  <C> 1.3 <C> 9.08 <C> 7.25 <R> <C> Softmax <C> 11.22 <C> 13.16±0.31 <C> 5.73±0.22 <R> <C> Center <C> 11.22 <C> 12.22±0.45 <C> 5.40±0.21 <R> <C> [BOLD] Arc <C> 11.22 <C> [BOLD] 11.77±0.31 <C> [BOLD] 5.23±0.19 <R> <C> ArcFace <C> 11.22 <C> 12.11±0.45 <C> 5.34±0.12 <CAP> Table 6: Recognition error rate (mean±std%) on CIFAR10 without data augmentation and CIFAR10+ with data augmentation. Every result is evaluated five times.
<R> <C> [BOLD] City <C> [BOLD] Venues <C> [BOLD] Unique Movements <R> <C> Chicago <C> 13,904 <C> 5,396,723 <R> <C> New York <C> 32,971 <C> 5,296,809 <CAP> TABLE I: Number of Venues and Venue Movements for each city
<R> <C> Feature Name <C> Chicago Morning <C> Chicago Midday <C> Chicago A'noon <C> Chicago Night <C> Chicago O’Night <C> New York Morning <C> New York Midday <C> New York A'noon <C> New York Night <C> New York O’Night <R> <C> Check-in Entropy <C> [BOLD] 0.365 <C> [BOLD] 0.277 <C> [BOLD] 0.273 <C> [BOLD] 0.360 <C> 0.326 <C> [BOLD] 0.387 <C> [BOLD] 0.264 <C> [BOLD] 0.304 <C> [BOLD]  0.300 <C> 0.250 <R> <C> In Check-in Density <C> 0.025 <C> 0.043 <C> 0.031 <C> 0.006 <C> -0.011 <C> 0.109 <C> 0.059 <C> 0.035 <C> 0.178 <C> 0.021 <R> <C> Out Check-in Density <C> 0.051 <C> 0.006 <C> 0.027 <C> 0.048 <C> -0.022 <C> 0.088 <C> -0.025 <C> 0.075 <C> 0.055 <C> 0.017 <R> <C> Stationary Density <C> -0.064 <C> -0.047 <C> -0.056 <C> -0.047 <C> 0.025 <C> -0.158 <C> -0.025 <C> -0.089 <C> -0.157 <C> -0.027 <R> <C> Mean <C> 0.133 <C> 0.025 <C> 0.021 <C> 0.088 <C> 0.362 <C> 0.058 <C> 0.022 <C> 0.053 <C> 0.158 <C> 0.352 <R> <C> Median <C> 0.124 <C> 0.015 <C> 0.015 <C> 0.079 <C> 0.348 <C> -0.007 <C> -0.026 <C> 0.017 <C> 0.112 <C> 0.336 <R> <C> Risk Count <C> [BOLD] 0.210 <C> 0.088 <C> 0.077 <C> 0.095 <C> [BOLD] 0.611 <C> [BOLD] 0.402 <C> [BOLD] 0.424 <C> [BOLD] 0.512 <C> 0.282 <C> [BOLD] 0.421 <R> <C> Risk Ratio <C> 0.113 <C> -0.010 <C> 0.002 <C> 0.042 <C> 0.326 <C> -0.018 <C> -0.036 <C> 0.000 <C> 0.037 <C> 0.249 <R> <C> Self Risk <C> 0.154 <C> 0.095 <C> 0.070 <C> 0.116 <C> [BOLD] 0.422 <C> 0.113 <C> 0.050 <C> 0.076 <C> 0.225 <C> [BOLD] 0.355 <R> <C> Neighbourhood Crimes <C> 0.001 <C> 0.039 <C> -0.026 <C> 0.035 <C> 0.322 <C> 0.357 <C> 0.074 <C> 0.053 <C> [BOLD] 0.309 <C> 0.040 <R> <C> Historical Density <C> [BOLD] 0.637 <C> [BOLD] 0.867 <C> [BOLD] 0.872 <C> [BOLD] 0.671 <C> [BOLD] 0.794 <C> [BOLD] 0.936 <C> [BOLD] 0.983 <C> [BOLD] 0.723 <C> [BOLD] 0.961 <C> [BOLD] 0.921 <R> <C> Arts & Entertainment <C> -0.018 <C> -0.030 <C> -0.021 <C> 0.005 <C> 0.084 <C> 0.161 <C> 0.137 <C> 0.174 <C> 0.149 <C> 0.055 <R> <C> College & University <C> -0.072 <C> -0.063 <C> -0.054 <C> -0.042 <C> 0.041 <C> 0.054 <C> 0.058 <C> 0.066 <C> 0.049 <C> 0.255 <R> <C> Event <C> -0.059 <C> -0.023 <C> -0.012 <C> -0.009 <C> 0.031 <C> -0.02 <C> -0.028 <C> -0.024 <C> -0.035 <C> -0.067 <R> <C> Food <C> 0.175 <C> [BOLD] 0.116 <C> [BOLD] 0.119 <C> [BOLD] 0.228 <C> 0.262 <C> 0.034 <C> 0.016 <C> 0.018 <C> 0.031 <C> 0.233 <R> <C> Nightlife Spot <C> 0.047 <C> 0.007 <C> -0.009 <C> 0.120 <C> 0.351 <C> 0.086 <C> 0.149 <C> 0.146 <C> 0.153 <C> 0.221 <R> <C> Outdoors & Rec. <C> -0.072 <C> -0.087 <C> -0.077 <C> -0.117 <C> -0.095 <C> -0.128 <C> -0.128 <C> -0.131 <C> -0.128 <C> -0.127 <R> <C> Professional & Other <C> -0.038 <C> 0.017 <C> 0.007 <C> -0.061 <C> -0.123 <C> 0.107 <C> 0.077 <C> 0.148 <C> 0.105 <C> -0.052 <R> <C> Residence <C> 0.068 <C> 0.016 <C> -0.010 <C> -0.021 <C> 0.020 <C> 0.180 <C> 0.183 <C> 0.154 <C> 0.185 <C> 0.158 <R> <C> Shops & Service <C> 0.050 <C> 0.031 <C> 0.047 <C> 0.077 <C> 0.162 <C> -0.045 <C> 0.022 <C> 0.019 <C> -0.031 <C> 0.104 <R> <C> Travel & Transport <C> -0.086 <C> -0.056 <C> -0.059 <C> -0.165 <C> -0.269 <C> -0.06 <C> -0.103 <C> -0.122 <C> -0.087 <C> -0.276 <R> <C> Total POI <C> [BOLD] 0.517 <C> [BOLD] 0.651 <C> [BOLD] 0.631 <C> [BOLD] 0.638 <C> [BOLD] 0.451 <C> [BOLD] 0.509 <C> [BOLD] 0.655 <C> [BOLD] 0.673 <C> [BOLD] 0.586 <C> [BOLD] 0.524 <R> <C> Venue Diversity <C> [BOLD] 0.318 <C> [BOLD] 0.287 <C> [BOLD] 0.255 <C> [BOLD] 0.366 <C> [BOLD] 0.428 <C> [BOLD] 0.410 <C> [BOLD] 0.367 <C> [BOLD] 0.356 <C> [BOLD] 0.375 <C> [BOLD] 0.361 <CAP> TABLE II: Feature Correlation Analysis for the New York and Chicago
<R> <C> [BOLD] Time of Day <C> [BOLD] Error <C> [BOLD] Chicago 1 <C> [BOLD] Chicago 2 <C> [BOLD] New York 1 <C> [BOLD] New York 2 <R> <C> Morning <C> MAE <C> 1.068 <C> 1.082 <C> 7.755 <C> 7.649 <R> <C> Morning <C> RMSE <C> 1.557 <C> 1.490 <C> 11.109 <C> 10.736 <R> <C> Midday <C> MAE <C> 1.764 <C> 1.817 <C> 12.376 <C> 12.399 <R> <C> Midday <C> RMSE <C> 2.791 <C> 2.792 <C> 16.362 <C> 15.764 <R> <C> Afternoon <C> MAE <C> 1.846 <C> 1.850 <C> 21.287 <C> 22.021 <R> <C> Afternoon <C> RMSE <C> 3.074 <C> 3.046 <C> 42.552 <C> 44.461 <R> <C> Night <C> MAE <C> 1.961 <C> 1.997 <C> 12.628 <C> 13.986 <R> <C> Night <C> RMSE <C> 2.946 <C> 2.966 <C> 16.558 <C> 17.515 <R> <C> Overnight <C> MAE <C> 1.821 <C> 2.029 <C> 13.390 <C> 18.104 <R> <C> Overnight <C> RMSE <C> 2.772 <C> 3.061 <C> 17.509 <C> 21.933 <R> <C> 1. All Features Present <C> 1. All Features Present <C> 1. All Features Present <C> 1. All Features Present <C> 1. All Features Present <C> 1. All Features Present <R> <C> 2.  [ITALIC] Region Risk Features Omitted <C> 2.  [ITALIC] Region Risk Features Omitted <C> 2.  [ITALIC] Region Risk Features Omitted <C> 2.  [ITALIC] Region Risk Features Omitted <C> 2.  [ITALIC] Region Risk Features Omitted <C> 2.  [ITALIC] Region Risk Features Omitted <CAP> TABLE III: MAE and RMSE for different times of the day for Chicago and New York after applying Linear Regression
<R> <C> [BOLD] Dataset % <C> [BOLD] Office Products & Movies and TV 80 <C> [BOLD] Office Products & Movies and TV 90 <C> [BOLD] Sports and Outdoors & CDs and Vinyl 80 <C> [BOLD] Sports and Outdoors & CDs and Vinyl 90 <C> [BOLD] Android Apps & Video Games 80 <C> [BOLD] Android Apps & Video Games 90 <C> [BOLD] Toys and Games & Automotive 80 <C> [BOLD] Toys and Games & Automotive 90 <R> <C> CMF <C> 1.0825 <C> 1.0583 <C> 2.1043 <C> 2.0578 <C> 2.0784 <C> 2.1295 <C> 2.2636 <C> 2.1855 <R> <C> CDTF <C> 1.0577 <C> 1.0389 <C> 2.0702 <C> 2.0126 <C> 2.0461 <C> 1.9965 <C> 2.2234 <C> 2.1680 <R> <C> FM-CDCF <C> 1.0272 <C> 0.9925 <C> 2.0580 <C> 1.9942 <C> 1.9963 <C> 1.9722 <C> 2.1908 <C> 2.1534 <R> <C> CoNet <C> 0.9782 <C> 0.9689 <C> 1.9835 <C> 1.9587 <C> 1.9744 <C> 1.9562 <C> 2.1507 <C> 2.1356 <R> <C> U-DARec <C> 0.9985 <C> 0.9821 <C> 2.0123 <C> 1.9808 <C> 1.9876 <C> 1.9550 <C> 2.1734 <C> 2.1405 <R> <C> [BOLD] I-DARec <C> [BOLD] 0.9665 <C> [BOLD] 0.9582 <C> [BOLD] 1.9673 <C> [BOLD] 1.9408 <C> [BOLD] 1.9546 <C> [BOLD] 1.9318 <C> [BOLD] 2.1152 <C> [BOLD] 2.0723 <CAP> Table 2: Comparison with Baselines (%: percentage of training data)
<R> <C> [EMPTY] <C> [BOLD] Loudness ( [ITALIC] L1) <C> [BOLD] F0 ( [ITALIC] L1) <C> [BOLD] F0 Outliers <R> <C> [BOLD] Supervised <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> WaveRNN (Hantrakul et al.,  2019 ) <C> 0.10 <C> 1.00 <C> 0.07 <R> <C> DDSP Autoencoder <C> [BOLD] 0.07 <C> [BOLD] 0.02 <C> [BOLD] 0.003 <R> <C> [BOLD] Unsupervised <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> DDSP Autoencoder <C> 0.09 <C> 0.80 <C> 0.04 <CAP> Table 1: Resynthesis accuracies. Comparison of DDSP models to SOTA WaveRNN model provided the same conditioning information. The supervised DDSP Autoencoder and WaveRNN models use the fundamental frequency from a pretrained CREPE model, while the unsupervised DDSP autoencoder learns to infer the frequency from the audio during training.
<R> <C> [EMPTY] <C> NMF <C> RPCA <C> KAM <C> Proposed DAP <R> <C> [EMPTY] <C> (spiertz2009source__) <C> (huang2012singing) <C> yela2018does <C> [EMPTY] <R> <C> SDR <C> -6.369 <C> -5.395 <C> -3.375 <C> [BOLD] -1.581 <R> <C> SIR <C> -1.934 <C> -0.227 <C> -0.753 <C> [BOLD] 3.859 <R> <C> LSD <C> 2.301 <C> 2.011 <C> 2.321 <C> [BOLD] 1.959 <CAP> Table 1: Comparison between DAP/NMF/RPCA/KAM on numerical metrics: SDR/SIR/LSD. For SDR/SIR, higher is better and for LSD, smaller is better. The best results on the three metrics are from our method, DAP.
<R> <C> Methods <C> Number of raw images for averaging 1 <C> Number of raw images for averaging 2 <C> Number of raw images for averaging 4 <C> Number of raw images for averaging 8 <C> Number of raw images for averaging 16 <C> Time <R> <C> Raw <C> 27.22 / 0.5442 <C> 30.08 / 0.6800 <C> 32.86 / 0.7981 <C> 36.03 / 0.8892 <C> 39.70 / 0.9487 <C> - <R> <C> VST+NLM  <C> 31.25 / 0.7503 <C> 32.85 / 0.8116 <C> 34.92 / 0.8763 <C> 37.09 / 0.9208 <C> 40.04 / 0.9540 <C> 137.10 s <R> <C> VST+BM3D  <C> 32.71 / 0.7922 <C> 34.09 / 0.8430 <C> 36.05 / 0.8970 <C> 38.01 / 0.9336 <C> 40.61 / 0.9598 <C> 5.67 s <R> <C> VST+KSVD  <C> 32.02 / 0.7746 <C> 33.69 / 0.8327 <C> 35.84 / 0.8933 <C> 37.79 / 0.9314 <C> 40.36 / 0.9585 <C> 341.21 s <R> <C> VST+KSVD(D)  <C> 31.77 / 0.7712 <C> 33.45 / 0.8292 <C> 35.67 / 0.8908 <C> 37.69 / 0.9300 <C> 40.32 / 0.9579 <C> 67.96 s <R> <C> VST+KSVD(G)  <C> 31.98 / 0.7752 <C> 33.64 / 0.8327 <C> 35.83 / 0.8930 <C> 37.82 / 0.9312 <C> 40.44 / 0.9584 <C> 58.82 s <R> <C> VST+EPLL  <C> 32.61 / 0.7876 <C> 34.07 / 0.8414 <C> 36.08 / 0.8970 <C> 38.12 / 0.9349 <C> 40.83 / 0.9618 <C> 288.63 s <R> <C> VST+WNNM  <C> 32.52 / 0.7880 <C> 34.04 / 0.8419 <C> 36.04 / 0.8973 <C> 37.95 / 0.9334 <C> 40.45 / 0.9587 <C> 451.89 s <R> <C> PURE-LET  <C> 31.95 / 0.7664 <C> 33.49 / 0.8270 <C> 35.29 / 0.8814 <C> 37.25 / 0.9212 <C> 39.59 / 0.9450 <C> [BOLD] 2.61 s <R> <C> DnCNN  <C> 34.88 / 0.9063 <C> 36.02 /  [BOLD] 0.9257 <C> 37.57 / 0.9460 <C> 39.28 / 0.9588 <C> [BOLD] 41.57 / 0.9721 <C> 3.07 s† <R> <C> Noise2Noise  <C> [BOLD] 35.40 /  [BOLD] 0.9187 <C> [BOLD] 36.40 / 0.9230 <C> [BOLD] 37.59 / 0.9481 <C> [BOLD] 39.43 / 0.9601 <C> 41.45 /  [BOLD] 0.9724 <C> 2.94 s† <CAP> Table 2: Denoising performance using the mixed test set, which includes confocal, two-photon, and wide-field microscopy images. PSNR (dB), SSIM, and denoising time (seconds) are obtained by averaging over 48 noise realizations in the mixed test set for each of 5 noise levels. Results of DnCNN and Noise2Noise are obtained by training on dataset with all noise levels. All 50 captures of each FOV (except the 19-th FOV which is reserved for test) are included in the training set, with 1 (DnCNN) or 2 (Noise2Noise) samples of which randomly selected from each FOV when forming mini-batches during training for 400 epochs. †Note that test time for deep learning models on GPU is faster in orders of magnitude, i.e. 0.62 ms for DnCNN and 0.99 ms for Noise2Noise on single GPU in our experiment.
<R> <C> [EMPTY] <C> DAP vs. NMF <C> DAP vs. RPCA <C> DAP vs. KAM <R> <C> SDR <C> 75.3 <C> 66.0 <C> 56.0 <R> <C> SIR <C> 76.7 <C> 62.7 <C> 66.7 <R> <C> LSD <C> 71.4 <C> 58.0 <C> 71.4 <CAP> Table 2: Better sample ratio (%) comparing with NMF/RPCA/KAM in terms of numerical metrics: SDR/SIR/LSD on Universal-150. All results are larger than 50%, which shows that our DAP can achieve better results than the compared methods on a majority of testing samples.
<R> <C> [EMPTY] <C> NMF <C> RPCA <C> KAM <C> Proposed DAP <R> <C> [EMPTY] <C> (spiertz2009source__) <C> (huang2012singing) <C> yela2018does <C> [EMPTY] <R> <C> SDR <C> -3.36 <C> -4.49 <C> -2.16 <C> [BOLD] -1.37 <R> <C> SIR <C> -0.93 <C> -1.00 <C> -0.32 <C> [BOLD] 0.82 <R> <C> LSD <C> 0.56 <C> 0.57 <C> 2.19 <C> [BOLD] 0.48 <CAP> Table 3: Comparison between DAP/NMF/RPCA/KAM in terms of numerical metrics: SDR/SIR/LSD on a standard source separation benchmark (vincent2007oracle). For SDR/SIR, higher is better and for LSD, smaller is better. The best results on the three metrics are from our method, DAP.
<R> <C> [EMPTY] <C> DAP vs. NMF <C> DAP vs. RPCA <C> DAP vs. KAM <R> <C> SDR <C> 60.0 <C> 70.0 <C> 50.0 <R> <C> SIR <C> 55.0 <C> 40.0 <C> 55.0 <R> <C> LSD <C> 70.0 <C> 65.0 <C> 95.0 <CAP> Table 4: Better sample ratio (%) comparing with NMF/RPCA/KAM in terms of numerical metrics: SDR/SIR/LSD on the source separation benchmark (vincent2007oracle). Most ratio results are larger than 50%, which shows that our DAP can achieve overall better results than the compared methods.
<R> <C> Model <C> Network Prediction <C> Evaluation Ground Truth <C> [ITALIC] Fmean <C> MR <R> <C> CNN  <C> Single activity label <C> Last sample’s label <C> 0.890 <C> 87.4% <R> <C> CNN  <C> Single activity label <C> Actual labels <C> 0.793 <C> 54.7% <CAP> TABLE I: Performance evaluation of the baseline CNN architecture [2] trained with multi-class formulated objective against both the approximated ground truth (equivalent to the last observed sample annotation) as well as the actual ground-truth for Opportunity dataset.
<R> <C> Dataset <C> Model <C> MR <C> MR0 <C> MR1 <C> MR2 <C> MR3 <R> <C> Actitracker <C> (Baseline) Deep-BCE <C> 90.1% <C> - <C> 91.1% <C> 60.2% <C> - <R> <C> Actitracker <C> (Ours) Auto-BCE <C> 92.9% <C> - <C> 93.9% <C> 62.7% <C> - <R> <C> Actitracker <C> (Ours) Deep-Set <C> 93.2% <C> - <C> 93.9% <C> 71.5% <C> - <R> <C> Actitracker <C> [BOLD] (Ours) Auto-Set <C> [BOLD] 94.9% <C> - <C> [BOLD] 95.5% <C> [BOLD] 75.1% <C> - <R> <C> Opportunity (locomotions) <C> (Baseline) Deep-BCE <C> 82.0% <C> 70.7% <C> 85.0% <C> 84.9% <C> 68.3% <R> <C> Opportunity (locomotions) <C> (Ours) Auto-BCE <C> 83.1% <C> 73.7% <C> 85.1% <C> 85.3% <C> 69.9% <R> <C> Opportunity (locomotions) <C> (Ours) Deep-Set <C> 83.9% <C> 78.2% <C> 86.8% <C> 84.9% <C> 68.7% <R> <C> Opportunity (locomotions) <C> [BOLD] (Ours) Auto-Set <C> [BOLD] 84.9% <C> [BOLD] 80.2% <C> [BOLD] 87.1% <C> [BOLD] 85.6% <C> [BOLD] 75.6% <CAP> TABLE II: Comparison of our proposed Deep Auto-Set network against the baselines according to the obtained exact match ratio for each dataset. The best results are highlighted with boldface. Note that for the Actitracker dataset, sensor segments with cardinality of 0 (corresponding to Null segments) and 3 do not exist.
<R> <C> [BOLD] Method <C> [BOLD] Position  [BOLD] ℓ2 [m]  [BOLD] @3s <C> [BOLD] Position  [BOLD] ℓ2 [m]  [BOLD] @6s <C> [BOLD] Heading [deg]  [BOLD] @3s <C> [BOLD] Heading [deg]  [BOLD] @6s <C> [BOLD] Infeasible  [BOLD] [%] <R> <C> UKF <C> 3.99 <C> 10.58 <C> 7.50 <C> 18.88 <C> [BOLD] 0.0 <R> <C> S-LSTM  <C> 4.72 <C> 8.20 <C> - <C> - <C> - <R> <C> poly-1 <C> 1.71 <C> 5.79 <C> 3.97 <C> 8.00 <C> [BOLD] 0.0 <R> <C> poly-2 <C> 1.37 <C> 4.39 <C> 10.19 <C> 31.44 <C> 20.8 <R> <C> poly-3 <C> 1.45 <C> 4.66 <C> 10.16 <C> 16.09 <C> 15.5 <R> <C> UM <C> [BOLD] 1.34 <C> 4.25 <C> 4.82 <C> 7.69 <C> 26.0 <R> <C> UM-velo <C> 1.37 <C> 4.28 <C> 4.76 <C> 7.55 <C> 27.3 <R> <C> UM-LSTM <C> 1.35 <C> 4.25 <C> 4.22 <C> 7.20 <C> 22.9 <R> <C> UM-heading <C> 1.37 <C> 4.32 <C> 4.65 <C> 7.09 <C> 20.7 <R> <C> CTRA <C> 1.56 <C> 4.61 <C> 3.60 <C> 8.68 <C> [BOLD] 0.0 <R> <C> DKM <C> [BOLD] 1.34 <C> [BOLD] 4.21 <C> [BOLD] 3.38 <C> [BOLD] 4.92 <C> [BOLD] 0.0 <CAP> TABLE I: Comparison of prediction errors (lower is better)
<R> <C> [BOLD] Feature <C> [BOLD] LSTM Autoencoder  <C> [BOLD] Our Approach <R> <C> Steer Angle <C> 0.0005 <C> 0.0003 <R> <C> Steer Speed <C> 0.0004 <C> 0.0003 <R> <C> Speed <C> 0.0004 <C> 0.0003 <R> <C> Yaw <C> 0.0004 <C> 0.0003 <R> <C> Pedal Angle <C> 0.0012 <C> 0.0012 <R> <C> Pedal Pressure <C> 0.0012 <C> 0.0003 <R> <C> Combined <C> 0.3043 <C> 0.2082 <CAP> TABLE II: Comparison of normalized reconstruction MSE losses.
<R> <C> [BOLD] Category <C> [BOLD] LSTM Autoencoder  <C> [BOLD] Our Approach <C> [BOLD] Our Approach (Scaled Scores) <R> <C> Speed <C> 21.7% <C> 21.7% <C> 30.4% <R> <C> K-turns <C> 13.0% <C> 8.8% <C> 17.4% <R> <C> U-turns <C> 4.4% <C> - <C> - <R> <C> Lane Change <C> 34.8% <C> 47.8% <C> 39.1% <R> <C> Normal <C> 26.1% <C> 21.7% <C> 13.1% <R> <C> Total <C> 100% (23) <C> 100% (23) <C> 100% (23) <CAP> TABLE III: Comparison of qualitative results by analyzing top 0.01% scores.
<R> <C> [BOLD] Feature <C> [BOLD] Multi-class LSTM Autoencoder <C> [BOLD] Our Approach <R> <C> Steer Angle <C> 0.0007 <C> 0.0004 <R> <C> Steer Speed <C> 0.0005 <C> 0.0004 <R> <C> Speed <C> 0.0006 <C> 0.0004 <R> <C> Yaw <C> 0.0006 <C> 0.0003 <R> <C> Pedal Angle <C> 0.0014 <C> 0.0013 <R> <C> Pedal Pressure <C> 0.0012 <C> 0.0004 <R> <C> Combined <C> 0.4058 <C> 0.2456 <CAP> TABLE IV: Comparison of normalized reconstruction MSE losses (without u-turn data).
<R> <C> [BOLD] Percentile Top Scores <C> [BOLD] Multi-class LSTM Autoencoder <C> [BOLD] Our Approach <C> [BOLD] Our Approach (Scaled Scores) <R> <C> 0.001 <C> 0.39% (3/765) <C> 1.70% (13/765) <C> 7.97% (61/765) <R> <C> 0.01 <C> 1.96% (15/765) <C> 7.97% (61/765) <C> 29.02% (222/765) <R> <C> 0.1 <C> 13.33% (102/765) <C> 17.25% (132/765) <C> 48.63% (372/765) <R> <C> 0.5 <C> 73.46% (562/765) <C> 52.68% (403/765) <C> 84.44% (646/765) <R> <C> 1 <C> 100.00% (765/765) <C> 99.87% (764/765) <C> 100.00% (765/765) <CAP> TABLE V: Comparison of percentage of u-turns detected (qualitative results) by analyzing top anomaly scores.
<R> <C> Dataset <C> SRC <C> KSRC <C> AE-SRC <C> VGG19-SRC <C> InceptionV3-SRC <C> Resnet50-SRC <C> Denesnet169-SRC <C> DSRC (ours) <R> <C> USPS <C> 87.78 <C> 91.34 <C> 88.65 <C> 91.27 <C> 93.51 <C> 95.75 <C> 95.26 <C> [BOLD] 96.25 <R> <C> SVHN <C> 15.71 <C> 27.42 <C> 18.69 <C> 52.86 <C> 41.14 <C> 47.88 <C> 37.65 <C> [BOLD] 67.75 <R> <C> UMDAA-01 <C> 79.00 <C> 81.37 <C> 86.70 <C> 82.68 <C> 86.15 <C> 91.84 <C> 86.35 <C> [BOLD] 93.39 <CAP> TABLE II: Sparse representation-based classification accuracy of different methods.
<R> <C> [EMPTY] <C> DSRC <C> DSC-SRC <C> DSRC0.5 <C> DSRC1.5 <C> DSRC2 <R> <C> USPS <C> [BOLD] 96.25 <C> 78.25 <C> N/C <C> 95.75 <C> [BOLD] 96.25 <CAP> TABLE III: The classification accuracy corresponding to the ablation study. N/C refers to the cases where the learning process did not converge.
<R> <C> Class <C> Avg.  [ITALIC] K- [ITALIC] α <C> Drop Antr 1 <C> Drop Antr 2 <C> Drop Antr 3 <C> Drop Antr 4 <R> <C> Stanford Drone <C> Stanford Drone <C> Stanford Drone <C> Stanford Drone <C> Stanford Drone <C> Stanford Drone <R> <C> Person <C> 0.463 <C> -0.124 <C> 0.029 <C> -0.004 <C> 0.050 <R> <C> Vehicle <C> 0.675 <C> 0.010 <C> 0.048 <C> -0.095 <C> 0.049 <R> <C> Bicycle <C> 0.408 <C> -0.045 <C> 0.056 <C> 0.015 <C> -0.023 <R> <C> VIRAT <C> VIRAT <C> VIRAT <C> VIRAT <C> VIRAT <C> VIRAT <R> <C> Person <C> 0.817 <C> -0.010 <C> 0.007 <C> 0.003 <C> 0.009 <R> <C> Vehicle <C> 0.897 <C> -0.004 <C> -0.004 <C> 0.011 <C> -0.006 <R> <C> Bicycle <C> 0.197 <C> 0.036 <C> -0.051 <C> 0.012 <C> 0.145 <CAP> Table 4: Average Vitality score of each annotator calculated on individual classes
<R> <C> [ITALIC] K- [ITALIC] α <C> Expert <C> Experienced <C> Novice <R> <C> Average <C> 0.310 <C> 0.371 <C> 0.086 <R> <C> Median <C> 0.269 <C> 0.392 <C> 0.059 <CAP> Table 5: Average and median K-α rating of MTurk workers for Stanford Drone images annotated by both the professional team and MTurk workers
<R> <C> Methods <C> mAP <C> Coverage <R> <C> MV3D(BV+FV) <C> 0.118 <C> 0.15 <R> <C> Frustum-Pointnet-v1 <C> 0.407 <C> 0.45 <R> <C> Frustum-Pointnet-v2 <C> 0.425 <C> 0.48 <R> <C> 3D-VGG+RoIpool8 <C> 0.360 <C> 0.32 <R> <C> 3D-VGG+RoIpool8(w/o maxpool) <C> 0.423 <C> 0.41 <R> <C> 3D-ResNet+RoIpool8 <C> 0.416 <C> 0.44 <R> <C> 3D-ResNet+RoIpool8(Raw volume) <C> 0.610 <C> 0.55 <R> <C> [ITALIC] A2-Net (APRoI8) <C> 0.711 <C> 0.67 <R> <C> [ITALIC] A2-Net w/o Neighbor Loss <C> 0.865 <C> 0.72 <R> <C> [ITALIC] A2-Net <C> [BOLD] 0.891 <C> [BOLD] 0.91 <CAP> Table 1: The results of detection and threading comparing with other 3D object detection methods.
<R> <C> Training Dataset for RetinaNet <C> Prec. <C> Rec. <C> F1 <C> mis-class. <R> <C> Drop Antr 1 <C> 0.65 <C> 0.56 <C> 0.60 <C> 380 <R> <C> Drop Antr 2 <C> 0.60 <C> 0.67 <C> 0.63 <C> 781 <R> <C> Drop Antr 3 <C> 0.55 <C> 0.64 <C> 0.59 <C> 838 <R> <C> Drop Antr 4 <C> 0.58 <C> 0.66 <C> 0.62 <C> 738 <CAP> Table 7: RetinaNet trained with 4 datasets (Drop Antr 1, Drop Antr 2, Drop Antr 3, and Drop Antr 4) performance measured against custom ground truth gt1 dataset. Precision, recall, F1-score and number of mis-classified predictions for RetinaNet trained on four different sets of data.
<R> <C> Training Dataset for RetinaNet <C> Prec. <C> Rec. <C> F1 <C> mis-class. <R> <C> Drop Antr 1 <C> 0.70 <C> 0.57 <C> 0.63 <C> 375 <R> <C> Drop Antr 2 <C> 0.60 <C> 0.66 <C> 0.63 <C> 847 <R> <C> Drop Antr 3 <C> 0.59 <C> 0.65 <C> 0.62 <C> 814 <R> <C> Drop Antr 4 <C> 0.63 <C> 0.67 <C> 0.65 <C> 711 <CAP> Table 8: RetinaNet trained with 4 datasets (Drop Antr 1, Drop Antr 2, Drop Antr 3, and Drop Antr 4) performance measured against custom ground truth gt2 dataset. Precision, recall, F1-score and number of mis-classified predictions for RetinaNet trained on four different sets of data.
<R> <C> Training Dataset for RetinaNet <C> Prec. <C> Rec. <C> F1 <C> mis-class. <R> <C> Drop Antr 1 <C> 0.66 <C> 0.56 <C> 0.61 <C> 380 <R> <C> Drop Antr 2 <C> 0.62 <C> 0.56 <C> 0.59 <C> 456 <R> <C> Drop Antr 3 <C> 0.58 <C> 0.52 <C> 0.55 <C> 474 <R> <C> Drop Antr 4 <C> 0.61 <C> 0.54 <C> 0.57 <C> 422 <CAP> Table 9: RetinaNet trained with 4 datasets (Drop Antr 1, Drop Antr 2, Drop Antr 3, and Drop Antr 4) performance measured against custom ground truth gt1 dataset. Precision, recall, F1-score and number of misclassified predictions.
<R> <C> Approachs <C> PSNR <C> MS-SSIM <C> BPP <R> <C> BPG <C> 31.47 <C> 0.94824 <C> 0.144 <R> <C> BPG+Post <C> 32.01 <C> 0.95712 <C> 0.148 <R> <C> H.266 <C> 31.72 <C> 0.96097 <C> 0.149 <R> <C> H.266 + Post <C> 32.09 <C> 0.96104 <C> 0.147 <R> <C> H.266 + Post + Rotation <C> 32.10 <C> 0.96124 <C> 0.149 <CAP> Table 1: Evaluation results on CLIC 2019 validation dataset
<R> <C> [BOLD] Dataset  [BOLD] (m,n) <C> [BOLD] Vote  [BOLD] (232 (124,108), 16) <C> [BOLD] Vote  [BOLD] (232 (124,108), 16) <C> [BOLD] SPECT  [BOLD] (267(212,55),22) <C> [BOLD] SPECT  [BOLD] (267(212,55),22) <C> [BOLD] KR-vs-KP  [BOLD] (3196(1569,1527),35) <C> [BOLD] KR-vs-KP  [BOLD] (3196(1569,1527),35) <R> <C> [EMPTY] <C> [BOLD] Mean <C> [BOLD] SD <C> [BOLD] Mean <C> [BOLD] SD <C> [BOLD] Mean <C> [BOLD] SD <R> <C> [BOLD] p <C> 0.969 <C> 0.0218 <C> 0.732 <C> 0.0589 <C> 0.940 <C> 0.0109 <R> <C> [BOLD] 0 <C> 0.966 <C> 0.0203 <C> 0.693 <C> 0.0746 <C> 0.938 <C> 0.0096 <R> <C> [BOLD] 0.1 <C> 0.955 <C> 0.0363 <C> 0.680 <C> 0.0681 <C> 0.924 <C> 0.0106 <R> <C> [BOLD] 0.2 <C> 0.865 <C> 0.0839 <C> 0.638 <C> 0.0797 <C> 0.900 <C> 0.0150 <R> <C> [BOLD] 0.3 <C> 0.821 <C> 0.0941 <C> 0.625 <C> 0.0664 <C> 0.866 <C> 0.0193 <R> <C> [BOLD] 0.35 <C> 0.694 <C> 0.0919 <C> 0.579 <C> 0.0955 <C> 0.795 <C> 0.0263 <R> <C> [BOLD] 0.4 <C> 0.573 <C> 0.1041 <C> 0.505 <C> 0.0793 <C> 0.706 <C> 0.0393 <CAP> Table 2: Average (Mean) test accuracy along with standard deviation (SD) over 15 trials obtained by using squared loss based linear classifier learnt on Sy-De (noise rate p) attribute noise corrupted data. Even though squared loss is theoretically shown to be Sy-De noise robust, it doesn’t show good performance at high noise rates. This could be because the result in Theorem 1 is in expectation. In particular, finite sample size starts showing its effect at high noise rates and the performance deteriorates.
<R> <C> [BOLD] Dataset  [BOLD] (m,n) <C> [BOLD] Vote  [BOLD] (232 (124,108), 16) <C> [BOLD] Vote  [BOLD] (232 (124,108), 16) <C> [BOLD] SPECT  [BOLD] (267(212,55),22) <C> [BOLD] SPECT  [BOLD] (267(212,55),22) <C> [BOLD] KR-vs-KP  [BOLD] (3196(1569,1527),35) <C> [BOLD] KR-vs-KP  [BOLD] (3196(1569,1527),35) <R> <C> [EMPTY] <C> [BOLD] Mean <C> [BOLD] SD <C> [BOLD] Mean <C> [BOLD] SD <C> [BOLD] Mean <C> [BOLD] SD <R> <C> [BOLD] p <C> 0.970 <C> 0.0207 <C> 0.665 <C> 0.0639 <C> 0.940 <C> 0.0111 <R> <C> [BOLD] 0 <C> 0.967 <C> 0.0193 <C> 0.613 <C> 0.1214 <C> 0.937 <C> 0.0097 <R> <C> [BOLD] 0.1 <C> 0.956 <C> 0.0373 <C> 0.605 <C> 0.1338 <C> 0.923 <C> 0.0109 <R> <C> [BOLD] 0.2 <C> 0.868 <C> 0.0839 <C> 0.568 <C> 0.1353 <C> 0.899 <C> 0.0152 <R> <C> [BOLD] 0.3 <C> 0.823 <C> 0.0950 <C> 0.586 <C> 0.1188 <C> 0.866 <C> 0.0186 <R> <C> [BOLD] 0.35 <C> 0.698 <C> 0.0903 <C> 0.544 <C> 0.1542 <C> 0.794 <C> 0.0261 <R> <C> [BOLD] 0.4 <C> 0.575 <C> 0.1045 <C> 0.540 <C> 0.1472 <C> 0.706 <C> 0.0399 <CAP> Table 3: Average (Mean) test AM value along with standard deviation (SD) over 15 trials obtained by using squared loss based linear classifier learnt on Sy-De (noise rate p) attribute noise corrupted data. Due to the imbalanced nature of SPECT dataset, AM is a more suitable evaluation metric.
<R> <C> [EMPTY] <C> NODE <C> ANODE <R> <C> MNIST <C> 96.4% ± 0.5 <C> [BOLD] 98.2% ±  [BOLD] 0.1 <R> <C> CIFAR10 <C> 53.7% ± 0.2 <C> [BOLD] 60.6% ±  [BOLD] 0.4 <R> <C> SVHN <C> 81.0% ± 0.6 <C> [BOLD] 83.5% ±  [BOLD] 0.5 <CAP> Table 1: Test accuracies and their standard deviation over 5 runs on various image datasets.
<R> <C> [BOLD] Sound Class <C> [BOLD] Avg. Normalized Correlation Value  [BOLD] Model 1 <C> [BOLD] Avg. Normalized Correlation Value  [BOLD] Model 2 <R> <C> Break <C> 0.76 <C> 0.93 <R> <C> Car <C> 0.68 <C> 0.65 <R> <C> Clock <C> 0.92 <C> 0.73 <R> <C> Cutting <C> 0.58 <C> 0.89 <R> <C> Fire <C> 0.88 <C> 0.72 <R> <C> Footstep <C> 0.68 <C> 0.95 <R> <C> Gunshot <C> 0.65 <C> 0.82 <R> <C> Horse <C> 0.87 <C> 0.63 <R> <C> Rain <C> 0.90 <C> 0.81 <R> <C> Thunder <C> 0.71 <C> 0.58 <R> <C> Typing <C> 0.69 <C> 0.60 <R> <C> Waterfall <C> 0.86 <C> 0.69 <R> <C> [BOLD] Average <C> [BOLD] 0.77 <C> [BOLD] 0.75 <CAP> Table I: Sound Quality Matrix Analysis Results: Average normalized cross-correlation value obtained from comparing the original and generated audio signals for model 1 and 2 in all sound classes
<R> <C> Methods <C> Coverage <C> RMSD <R> <C> DFS [ITALIC] o <C> 0.65 <C> 3.5 <R> <C> DFS [ITALIC] d <C> 0.68 <C> 3.1 <R> <C> DFS [ITALIC] d+PBNet <C> 0.89 <C> 2.6 <R> <C> MCTS <C> 0.72 <C> 2.9 <R> <C> MCTS+PBNet <C> [BOLD] 0.91 <C> [BOLD] 2.0 <CAP> Table 2: The results of threading by DFS-based methods and the proposed MCTS+PBNet.
<R> <C> [BOLD] Existing Model <C> [BOLD] Avg. Acc. <R> <C> Owens et al.[owens2016visually] (ResNet + spectrogram + GHD dataset) <C> 22.70% <R> <C> POCAN [zhangvisually] (ResNet + spectrogram + GHD dataset) <C> 36.32% <R> <C> Zhuo [zhou2017visual] (Flow method + VEGAS dataset) <C> 45.47% <CAP> Table II: Top 1 sound class prediction accuracy of existing models
<R> <C> [BOLD] Proposed Model <C> [BOLD] Avg. Accuracy <R> <C> AutoFoley (Frame-Sequence Network) <C> [BOLD] 65.79% <R> <C> AutoFoley (Frame-Relation Network) <C> [BOLD] 63.40% <R> <C> AutoFoley (Real sound tracks) <C> 78.32% <CAP> Table III: Top 1 sound class prediction accuracy of proposed models with AutoFoley Dataset
<R> <C> [BOLD] Average <C> [BOLD] Train  [BOLD] Model 1 <C> [BOLD] Train  [BOLD] Model 2 <C> [BOLD] Test  [BOLD] Model 1 <C> [BOLD] Test  [BOLD] Model 2 <R> <C> Log Loss <C> 0.002 <C> 0.035 <C> 0.166 <C> 0.194 <R> <C> Accuracy <C> 0.989 <C> 0.962 <C> 0.834 <C> 0.806 <CAP> Table IV: Loss and Accuracy Calculation Result
<R> <C> [BOLD] Model <C> [BOLD] Description <C> [BOLD] Average Accuracy (%) <R> <C> Ablation Model 1 <C> Direct raw image frame (no SP) +VGG19 + simple LSTM <C> 43.18 <R> <C> Ablation Model 2 <C> Direct raw image (no SP) + ResNet-50 + simple LSTM <C> 44.52 <R> <C> Ablation Model 3 <C> SP+ VGG19 + simple LSTM <C> 56.04 <R> <C> Ablation Model 4 <C> SP + VGG19 + FS-LSTM <C> 63.88 <R> <C> Frame Sequence Network <C> SP + ResNet50 + FS-LSTM <C> 65.79 <CAP> Table V: Comparison of the average accuracy (%) among the Ablation Models and our proposed method 1 (Frame Sequence Network) on AutoFoley Dataset.
<R> <C> [BOLD] Model <C> [BOLD] Description <C> [BOLD] Average Accuracy (%) <R> <C> Ablation Model 1 <C> TRN (for 4 frame relations) + VGG19 (base CNN) <C> 41.64 <R> <C> Ablation Model 2 <C> TRN (for 4 frame relations) + ResNet-50 (base CNN) <C> 42.01 <R> <C> Ablation Model 3 <C> TRN (for 8 frame relations) +VGG19 (base CNN) <C> 60.98 <R> <C> Ablation Model 4 <C> TRN (for 16 frame relations) +ResNet-50 (base CNN) <C> 64.27 <R> <C> Frame Relation Network <C> TRN (for 8 frame relations) +ResNet-50 (base CNN) <C> 63.40 <CAP> Table VI: Comparison of the average accuracy (%) among the Ablation Models and our proposed method 2 (Frame Relation Network) on AutoFoley Dataset.
<R> <C> [BOLD] Class <C> [BOLD] Query 1  [BOLD] Method 1 <C> [BOLD] Query 1  [BOLD] Method 2 <C> [BOLD] Query 2  [BOLD] Method 1 <C> [BOLD] Query 2  [BOLD] Method 2 <R> <C> Break <C> 52.40% <C> 56.10% <C> 32.30% <C> 67.70% <R> <C> Car <C> 71.53% <C> 65.40% <C> 55.76% <C> 44.24% <R> <C> Clock <C> 90.91% <C> 73.80% <C> 70.90% <C> 29.10% <R> <C> Cutting <C> 50.17% <C> 45.35% <C> 62.89% <C> 37.11% <R> <C> Fire <C> 85.43% <C> 75.40% <C> 57.70% <C> 42.30% <R> <C> Footstep <C> 61.72% <C> 50.57% <C> 72.13% <C> 27.87% <R> <C> Gunshot <C> 68.33% <C> 61.84% <C> 64.60% <C> 35.40% <R> <C> Horse <C> 89.38% <C> 78.20% <C> 53.80% <C> 46.20% <R> <C> Rain <C> 88.62% <C> 75.80% <C> 50.00% <C> 50.00% <R> <C> Thunder <C> 76.25% <C> 72.17% <C> 59.35% <C> 40.65% <R> <C> Typing <C> 64.27% <C> 62.39% <C> 66.20% <C> 33.80% <R> <C> Waterfall <C> 85.55% <C> 74.40% <C> 66.78% <C> 33.22% <R> <C> [BOLD] Average <C> [BOLD] 73.71% <C> [BOLD] 65.95% <C> [BOLD] 59.37% <C> [BOLD] 40.63% <CAP> Table VIII: Human Evaluation Results: Selection percentage of each sound category for the first and second human survey questions
<R> <C> [BOLD] Class <C> [BOLD] Query 3  [BOLD] Method 1 <C> [BOLD] Query 3  [BOLD] Method 2 <C> [BOLD] Query 4  [BOLD] Method 1 <C> [BOLD] Query 4  [BOLD] Method 2 <R> <C> Break <C> 29.17% <C> 70.83% <C> 29.00% <C> 71.00% <R> <C> Car <C> 36.02% <C> 63.08% <C> 57.32% <C> 42.68% <R> <C> Clock <C> 57.69% <C> 42.30% <C> 61.50% <C> 38.50% <R> <C> Cutting <C> 62.50% <C> 37.50% <C> 55.41% <C> 44.59% <R> <C> Fire <C> 34.61% <C> 65.38% <C> 53.80% <C> 46.20% <R> <C> Footstep <C> 65.37% <C> 34.62% <C> 68.55% <C> 31.45% <R> <C> Gunshot <C> 75.81% <C> 24.19% <C> 74.60% <C> 25.40% <R> <C> Horse <C> 36.18% <C> 63.82% <C> 53.80% <C> 46.20% <R> <C> Rain <C> 33.33% <C> 66.67% <C> 55.80% <C> 44.20% <R> <C> Thunder <C> 76.92% <C> 23.08% <C> 51.62% <C> 48.38% <R> <C> Typing <C> 67.24% <C> 32.76% <C> 68.50% <C> 31.50% <R> <C> Waterfall <C> 51.85% <C> 48.15% <C> 52.43% <C> 47.57% <R> <C> [BOLD] Average <C> [BOLD] 52.23% <C> [BOLD] 47.70% <C> [BOLD] 52.86% <C> [BOLD] 43.14% <CAP> Table IX: Human Evaluation Results: Selection percentage of each sound category for the third and fourth human survey questions
<R> <C> Paper <C> Yelp’15 <C> IMDB <C> Amazon <R> <C> Zhang et al., 2015 <C> 59.9% <C> - <C> 55.3% <R> <C> Tang et al., 2015 <C> 67.6% <C> 45.3% <C> - <R> <C> Yang et al., 2016 <C> 71.0% <C> 49.4% <C> 63.6% <CAP> Table 1: State of the art accuracies on multi-class classification, results taken from [12].
<R> <C> Architecture <C> Top-1 Error <C> # Param <C> MACs <R> <C> [EMPTY] <C> [EMPTY] <C> (M) <C> (G) <R> <C> ResNet-50 <C> [BOLD] 24.0% <C> 26 <C> 4.1 <R> <C> MorphNet <C> 24.8% <C> 15.5 <C> - <R> <C> MobileNetV1 <C> 29.4% <C> 4.2 <C> 0.569 <R> <C> MobileNetV2 <C> 25.3% <C> 6.9 <C> 0.585 <R> <C> MnasNet-A <C> 24.4% <C> 4.8 <C> [BOLD] 0.340 <R> <C> EfficientNet-B0 <C> 23.7% <C> 5.3 <C> 0.391 <R> <C> DARTS <C> 26.7% <C> 4.7 <C> 0.574 <R> <C> RandWire-WS <C> 25.3% <C> 5.6 <C> 0.583 <R> <C> ShrinkCNN-A <C> 26.1% <C> [BOLD] 3.6 <C> 0.385 <R> <C> ShrinkCNN-B <C> 24.9% <C> [BOLD] 3.6 <C> 0.385 <CAP> Table 2: Performance comparison of various CNN architectures on ImageNet-1K dataset. All the evaluations are based on 50,000 images of ImageNet-1K validation dataset. The input resolution is set to 224×224.
<R> <C> Topology <C> Nodes <C> Accuracy <C> MAC <R> <C> [EMPTY] <C> [EMPTY] <C> (%) <C> (M) <R> <C> Complete-DAG <C> 8 <C> 91.56 <C> 105.61 <R> <C> WS <C> 15 <C> 90.5±0.41 <C> 16.04±2.71 <R> <C> ER <C> 15 <C> 92.1±0.38 <C> 34.40±16.43 <R> <C> BA <C> 15 <C> 90.0±0.34 <C> 32.61±5.96 <R> <C> ShrinkCNN <C> 8 <C> 93.22 <C> 38.20 <CAP> Table 4: Comparison with ShrinkCNN topology with prior graph topology. We use N=8 nodes when crafting CNN architectures with complete-DAG-based topology, and N=15 nodes when crafting CNN architectures with random graph priors. Experiments on random graph priors are conducted 10 times to reduce randomness as much as possible.
<R> <C> Cell Topology <C> Edges <C> Perplexity <C> # Param (M) <R> <C> Complete-DAG <C> 15 <C> 63.1 <C> 33 <R> <C> ShrinkRNN <C> 8 <C> 56.5 <C> 23 <CAP> Table 5: Demonstration of efficient RNN cell structures found by AutoShrink algorithm on full Penn Treebank dataset. We used N=6 nodes when crafting RNN architectures with complete-DAG-based topology.
<R> <C> split <C> #samples <C> STCNN-T <C> STCNN-T+I <C> LSTM <R> <C> 0 <C> 3184 <C> 25.7 <C> 24.4 <C> 25.8 <R> <C> 1 <C> 1637 <C> 24.1 <C> 21.3 <C> 24.0 <R> <C> 2 <C> 2509 <C> 24.6 <C> 21.7 <C> 25.7 <R> <C> 3 <C> 4532 <C> 23.5 <C> 20.7 <C> 25.9 <R> <C> 4 <C> 3835 <C> 20.8 <C> 19.3 <C> 23.4 <R> <C> avg <C> 15697 <C> 23.5 ± 0.8 <C> 21.3 ± 0.8 <C> 25.0 ± 0.5 <CAP> Table 1: Quantitative results. Left: negative cross-entropy (mean and standard error over five-fold cross-validation) of the proposed model on SDD with only trajectory information (STCNN-T) or with additional reference images (STCNN-T+I). LSTM is a baseline architecture, see the main text. Right: top 10%-oracle error at different time points of the forecast, see main text for details.
<R> <C> [EMPTY] <C> region <C> landscape <C> dbl.-page <C> no text <C> leading <R> <C> CVS <C> 90.89 <C> 100 <C> 94.74 <C> 97.37 <C> 81.58 <R> <C> Test <C> 90.21 <C> 99.29 <C> 95.93 <C> 94.19 <C> 73.85 <CAP> TABLE I: Evaluation of simple document analysis (% GT).
<R> <C> [BOLD] Robot Joint Error <C> [BOLD] Robot Joint Error <C> [BOLD] Robot Joint Error  [BOLD] Ball <C> [BOLD] Robot Joint Error  [BOLD] Shoe, IMU <C> [BOLD] Robot Joint Error  [BOLD] Shoe, IMU Head <C> [BOLD] Robot Joint Error  [BOLD] Shoe, IMU Head, Ball <C> [BOLD] Robot Joint Error  [BOLD] All <R> <C> 43% <C> BIP <C> - <C> 3.91×1015 <C> 1.48×1014 <C> 9.56×1014 <C> 3.97×1016 <R> <C> 43% <C> PF <C> - <C> 0.37 <C> 0.28 <C> 0.28 <C> 0.26 <R> <C> 43% <C> eBIP− <C> - <C> 5.62×106 <C> 9.98×106 <C> 1.08×107 <C> 6.00×107 <R> <C> 43% <C> eBIP <C> - <C> 0.18 <C> 0.19 <C> 0.18 <C> 0.14 <R> <C> 82% <C> BIP <C> 1.04×1015 <C> 1.59×1017 <C> 4.22×1015 <C> 3.66×1015 <C> 6.52×1017 <R> <C> 82% <C> PF <C> 0.11 <C> 0.37 <C> 0.28 <C> 0.28 <C> 0.26 <R> <C> 82% <C> eBIP− <C> 10.52 <C> 9.46×106 <C> 1.36×107 <C> 1.68×107 <C> 7.66×107 <R> <C> 82% <C> eBIP <C> 0.05 <C> 0.20 <C> 0.19 <C> 0.11 <C> 0.09 <CAP> TABLE I: The left table indicates the mean squared error values for the first three joints of the robot at the time the ball is caught while the right table is the mean absolute error for the inferred ball position. A green box represents the best method and a gray box represents methods which are not statistically worse than the best method (Mann-Whitney U, p<0.05). The values 43% and 82% indicate inference is performed after 43% of the interaction is observed (corresponding to before the ball is thrown) and 82% is observed (the ball is partway through its trajectory). The ball itself is not visible for the first 43% as this is when it is occluded by the participant’s hand. The standard error for eBIP is less than ±0.01 in all cases for the joint MSE and ±0.015 for the ball MAE.
<R> <C> [EMPTY] <C> [BOLD] Method F# <C> [BOLD] Method messytables <C> [BOLD] Method readr <C> [BOLD] Method TDDA <C> [BOLD] Method Trifacta <C> [BOLD] Method ptype-hc <C> [BOLD] Method ptype <R> <C> Overall <C> 0.73 <C> 0.72 <C> 0.69 <C> 0.61 <C> 0.90 <C> 0.92 <C> [BOLD] 0.93 <R> <C> Accuracy <C> 0.73 <C> 0.72 <C> 0.69 <C> 0.61 <C> 0.90 <C> 0.92 <C> [BOLD] 0.93 <R> <C> Boolean <C> 0.55 <C> 0.56 <C> 0.00 <C> 0.00 <C> 0.49 <C> 0.75 <C> [BOLD] 0.83 <R> <C> Date <C> 0.35 <C> 0.17 <C> 0.10 <C> 0.00 <C> [BOLD] 0.68 <C> 0.67 <C> 0.67 <R> <C> Float <C> 0.60 <C> 0.57 <C> 0.59 <C> 0.42 <C> 0.87 <C> [BOLD] 0.93 <C> 0.91 <R> <C> Integer <C> 0.55 <C> 0.55 <C> 0.57 <C> 0.46 <C> [BOLD] 0.88 <C> 0.85 <C> [BOLD] 0.88 <R> <C> String <C> 0.61 <C> 0.61 <C> 0.58 <C> 0.51 <C> 0.83 <C> [BOLD] 0.90 <C> 0.89 <CAP> Table 2: Performance of the methods using the Jaccard index and overall accuracy, for the types Boolean, Date, Float, Integer and String.
<R> <C> Method <C> FPs <C> FNs <C> TPs <R> <C> Trifacta <C> 0.67 <C> 3.96 <C> 1.57 <R> <C> ptype <C> 1.13 <C> 0.20 <C> 5.34 <CAP> Table 3: The percentages of FPs, FNs, and TPs for Trifacta and ptype on type/non-type detection.
<R> <C> Experiment <C> Min <C> Max <C> Avg <C> S.D. <R> <C> Not Learnable <C> 99.71 <C> [BOLD] 99.79 <C> 0.997500 <C> 0.0002190 <R> <C> Random Init. <C> 99.72 <C> [BOLD] 99.78 <C> 0.997512 <C> 0.0001499 <R> <C> Ones Init. <C> 99.70 <C> 99.77 <C> 0.997397 <C> 0.0001885 <CAP> Table 2: Individual Models
<R> <C> [EMPTY] <C> [BOLD] Mean RMSE <C> [BOLD] Mean RMSE <R> <C> [BOLD] Model Type <C> [BOLD] Lanes Known <C> [BOLD] Lanes Unknown <R> <C> GP  [ITALIC] τ=8 <C> 13.928 <C> 23.676 <R> <C> DNN  [ITALIC] h=2, [ITALIC] g=10 <C> 6.328 <C> 9.145 <R> <C> LR <C> 6.290 <C> 8.878 <CAP> TABLE III: Best performing model of each type. Values closer to zero are better, best values are highlighted in bold.
<R> <C> [BOLD] Conditions <C> [ITALIC] U [BOLD]  and  [ITALIC] D <C> [BOLD] MSD <C> [BOLD] MAE <C> [BOLD] RMSE <R> <C> Normal <C> with <C> −0.183 <C> 3.555 <C> 4.839 <R> <C> Normal <C> w/o <C> −0.025 <C> 3.693 <C> 5.259 <R> <C> Incident <C> with <C> 3.040 <C> 6.862 <C> 9.513 <R> <C> Incident <C> w/o <C> 0.440 <C> 5.913 <C> 9.085 <CAP> TABLE IV: Performance of Mordinary under normal vs. incident conditions
<R> <C> Methods <C> 0.1% <C> 1% <C> 10% <C> 30% <C> 50% <C> 70% <C> 90% <R> <C> Peephole  <C> 0.4556 <C> 0.4769 <C> 0.4963 <C> 0.4977 <C> 0.4972 <C> 0.4975 <C> 0.4951 <R> <C> E2EPP  <C> 0.5038 <C> 0.6734 <C> 0.7009 <C> 0.6997 <C> 0.7011 <C> 0.6992 <C> 0.6997 <R> <C> ReNAS-1 (type matrix + MSE) <C> 0.3465 <C> 0.5911 <C> 0.7914 <C> 0.8229 <C> 0.8277 <C> 0.8344 <C> 0.8350 <R> <C> ReNAS-2 (tensor + MSE) <C> 0.4856 <C> 0.6090 <C> 0.8103 <C> 0.8430 <C> 0.8399 <C> 0.8504 <C> 0.8431 <R> <C> ReNAS-3 (type matrix + L1) <C> 0.6039 <C> 0.7943 <C> 0.8752 <C> 0.8894 <C> 0.8949 <C> 0.8976 <C> 0.8995 <R> <C> ReNAS-4 (tensor + L1) <C> 0.6335 <C> 0.8136 <C> 0.8762 <C> [BOLD] 0.8900 <C> [BOLD] 0.8957 <C> [BOLD] 0.8979 <C> [BOLD] 0.8997 <R> <C> ReNAS-5 (type matrix + L) <C> 0.6096 <C> 0.7949 <C> 0.8756 <C> 0.8854 <C> 0.8898 <C> 0.8911 <C> 0.8918 <R> <C> ReNAS-6 (tensor + L) <C> [BOLD] 0.6574 <C> [BOLD] 0.8161 <C> [BOLD] 0.8763 <C> 0.8873 <C> 0.8910 <C> 0.8923 <C> 0.8954 <CAP> Table 2: The Kendall’s Tau (KTau) of Peephole, E2EPP and the proposed algorithms on the NASBench dataset with different proportions of training samples.
<R> <C> Method <C> accuracy(%) <C> ranking(%) <R> <C> Peephole  <C> 92.63 ± 0.31 <C> 12.32 <R> <C> E2EPP  <C> 93.47 ± 0.44 <C> 1.23 <R> <C> Proposed v1 <C> 92.36 ± 0.27 <C> 16.93 <R> <C> Proposed v2 <C> 93.03 ± 0.21 <C> 6.09 <R> <C> Proposed v3 <C> 93.43 ± 0.26 <C> 1.50 <R> <C> Proposed v4 <C> 93.90 ± 0.21 <C> 0.04 <R> <C> Proposed v5 <C> 93.48 ± 0.18 <C> 1.21 <R> <C> Proposed v6 <C> [BOLD] 93.95 ± 0.11 <C> [BOLD] 0.02 <CAP> Table 3: The classification accuracy (%) on CIFAR-10 dataset and the ranking (%) among different architectures in NASBench dataset using EA algorithm with the proposed predictor and the peer competitors. Predictors are trained with 0.1% samples randomly selected from NASBench dataset.
<R> <C> Method <C> Peephole  <C> E2EPP  <C> Proposed <R> <C> top-1 acc (%) <C> 73.58 <C> 75.49 <C> [BOLD] 78.56 <R> <C> top-5 acc (%) <C> 91.97 <C> 92.77 <C> [BOLD] 94.17 <CAP> Table 4: The classification accuracy (%) on CIFAR-100 dataset among different architectures in NASBench using EA algorithm with the proposed predictor and the peer competitors. Predictors are trained with 424 samples randomly selected from NASBench.
<R> <C> Dataset <C> Classes <C> [ITALIC] n <C> [ITALIC] ntest <C> [ITALIC] d <C> Base Error <C> Input Constraints <R> <C> MNIST-1-7 <C> 2 <C> 13007 <C> 2163 <C> 784 <C> 0.7% ( [ITALIC] λ=0.01) <C> [0,1] <R> <C> Dogfish <C> 2 <C> 1800 <C> 600 <C> 2048 <C> 1.3% ( [ITALIC] λ=1.10) <C> [BOLD] R <R> <C> Enron <C> 2 <C> 4137 <C> 1035 <C> 5116 <C> 2.9% ( [ITALIC] λ=0.09) <C> [BOLD] Z≥0 <R> <C> IMDB <C> 2 <C> 25000 <C> 25000 <C> 89527 <C> 11.9% ( [ITALIC] λ=0.01) <C> [BOLD] Z≥0 <R> <C> MNIST <C> 10 <C> 60000 <C> 10000 <C> 784 <C> 7.5% \lx @ [ITALIC] notemarkfootnote <C> [0,1] <CAP> Table 1: Characteristics of the datasets we consider, together with the base test errors that an SVM achieves on them (with regularization parameters λ selected by validation). The input covariates for Enron and IMDB must be non-negative integers.
<R> <C> [EMPTY] <C> kNN <C> CelebA 28.00 <C> LSUN 36.30 <R> <C> Accuracy <C> Eigenface  <C> 53.28 <C> - <R> <C> (%) <C> PRNU  <C> 86.61 <C> 67.84 <R> <C> [EMPTY] <C> Ours <C> [BOLD] 99.43 <C> [BOLD] 98.58 <R> <C> FD ratio <C> Inception  <C> 2.36 <C> 5.27 <R> <C> [EMPTY] <C> Our fingerprint <C> [BOLD] 454.76 <C> [BOLD] 226.59 <CAP> Table 1: Evaluation on {real, ProGAN, SNGAN, CramerGAN, MMDGAN}. The best performance is highlighted in bold.
<R> <C> [EMPTY] <C> kNN <C> CelebA 10.88 <C> LSUN 10.58 <R> <C> Accuracy <C> Eigenface  <C> 23.12 <C> - <R> <C> (%) <C> PRNU  <C> 89.40 <C> 69.73 <R> <C> [EMPTY] <C> Ours <C> [BOLD] 99.14 <C> [BOLD] 97.04 <R> <C> [EMPTY] <C> Our visNet <C> 97.07 <C> 96.58 <R> <C> FD ratio <C> Inception  <C> 1.10 <C> 1.29 <R> <C> [EMPTY] <C> Our fingerprint <C> [BOLD] 80.28 <C> [BOLD] 36.48 <CAP> Table 3: Evaluation on {real, ProGAN_seed_v#i}. The best performance is highlighted in bold. “Our visNet” row indicates our fingerprint visualization network described in Section 3.3 and evaluated in Section 4.5.
<R> <C> [BOLD] Layer <C> [BOLD] Shapes <R> <C> conv2d_1 <C> 5×5×1×32 <R> <C> conv2d_1 <C> 32 <R> <C> conv2d_2 <C> 5×5×32×64 <R> <C> conv2d_2 <C> 64 <R> <C> dense_1 <C> 1024×512 <R> <C> dense_1 <C> 512 <R> <C> dense_2 <C> 512×10 <R> <C> dense_2 <C> 10 <CAP> TABLE II: Parameters settings for the CNN.
<R> <C> [BOLD] Layer <C> [BOLD] Shapes <R> <C> lstm_1 <C> 9×100 <R> <C> lstm_1 <C> 25×100 <R> <C> lstm_1 <C> 100 <R> <C> lstm_2 <C> 25×100 <R> <C> lstm_2 <C> 25×100 <R> <C> lstm_2 <C> 100 <R> <C> dense_1 <C> 25×256 <R> <C> dense_1 <C> 256 <R> <C> dense_2 <C> 256×6 <R> <C> dense_2 <C> 6 <CAP> TABLE III: Parameter settings for the LSTM.
<R> <C> [ITALIC]  [BOLD] freq <C> [BOLD] Accuracy* <C> [BOLD] Round** <R> <C> 3/15 <C> 96.72% (0.0037) <C> 115.74 (32.19) <R> <C> 5/15 <C> 97.08% (0.0037) <C> 87.82 (20.03) <R> <C> 7/15 <C> 97.12% (0.0046) <C> 95.43 (14.64) <CAP> TABLE IV: Experimental results on freq.
<R> <C> [ITALIC]  [BOLD] a <C> [BOLD] Accuracy* <C> [BOLD] Round** <R> <C> e*** <C> 96.92% (0.0041) <C> 75.26 (2.09) <R> <C> e/2 <C> 97.08% (0.0037) <C> 87.82 (20.03) <CAP> TABLE V: Experimental results on a.
<R> <C> [BOLD] Scalability  [ITALIC]  [BOLD] K  [BOLD] m <C> [BOLD] FedAVG <C> [BOLD] TWAFL <R> <C> 20 2 <C> 96.83% (0.0097) <C> 97.16% (0.0096) <R> <C> 10 1 <C> 94.26% (0.0083) <C> 94.76% (0.0102) <R> <C> 10 2 <C> 96.16% (0.0167) <C> 96.11% (0.0909) <CAP> TABLE VI: Experimental results on the scalability of the algorithm.
<R> <C> [BOLD] Dataset_ID@Task <C> [BOLD] FedAVG  [ITALIC]  [BOLD] Round (Accuracy)⋆  [BOLD] C. Cost⋆⋆ <C> [BOLD] TEFL  [ITALIC]  [BOLD] Round (Accuracy)⋆  [BOLD] C. Cost⋆⋆ <C> [BOLD] TWAFL  [ITALIC]  [BOLD] Round (Accuracy)⋆  [BOLD] C. Cost⋆⋆ <C> [BOLD] AFL  [ITALIC]  [BOLD] Round (Accuracy)⋆  [BOLD] C. Cost⋆⋆ <R> <C> 1@MNIST* <C> 75 (97.2%) 6.16 <C> [BOLD] 31 (97.9%) 0.74 <C> 106 (97.7%) 1 <C> 175 (95.4%) 2.46 <R> <C> 2@MNIST* <C> 85 (97.2%) 6.76 <C> [BOLD] 32 (98.5%) 1.33 <C> 61 (98.1%)  [BOLD] 1 <C> —(94.8%)† —† <R> <C> 3@MNIST* <C> 73 (97.7%) 5.99 <C> [BOLD] 31 (98.7%) 1.13 <C> 70 (97.9%)  [BOLD] 1 <C> —(94.9%)† —† <R> <C> 4@MNIST* <C> 196 (95.2%) 8.18 <C> [BOLD] 61 (98.0%) 1.14 <C> 136 (96.1%)  [BOLD] 1 <C> —(93.1%)† —† <R> <C> 5@MNIST* <C> 98 (97.1%) 3.28 <C> [BOLD] 76 (97.8%) 3.17 <C> 61 (96.1%)  [BOLD] 1 <C> 109 (96.7%) 2.66 <R> <C> 1@HAR** <C> 526 (92.3%) 4.72 <C> [BOLD] 166 (94.0%)  [BOLD] 0.69 <C> 358  [BOLD] (94.6%) 1 <C> —(89.2%) ‡ —‡ <R> <C> 2@HAR** <C> 451 (94.7%) 5.65 <C> [BOLD] 119 (95.4%)  [BOLD] 0.57 <C> 313  [BOLD] (95.9%) 1 <C> —(82.9%) ‡ —‡ <R> <C> 3@HAR** <C> —(87.3%) ‡ —‡ <C> [BOLD] 174 (94.4%) 0.69 <C> 376 (93.2%) 1 <C> —(88.5%) ‡ —‡ <R> <C> 4@HAR** <C> 856 (90.2%) 7.05 <C> [BOLD] 181 (95.1%) 1.28 <C> 211 (94.1%)  [BOLD] 1 <C> 751 (91.2%) 5.30 <R> <C> 5@HAR** <C> 571 (92.6%) 5.49 <C> [BOLD] 155 (93.6%) 0.57 <C> 404 (93.1%) 1 <C> 646 (92.5%) 2.38 <CAP> TABLE VII: Experiments on Performance .
<R> <C> [EMPTY] <C> LSUN  [ITALIC] Noise <C> LSUN  [ITALIC] Noise <C> LSUN  [ITALIC] Blur <C> LSUN  [ITALIC] Blur <C> LSUN  [ITALIC] Cropping <C> LSUN  [ITALIC] Cropping <C> LSUN  [ITALIC] Compression <C> LSUN  [ITALIC] Compression <C> LSUN  [ITALIC] Relighting <C> LSUN  [ITALIC] Relighting <C> LSUN  [ITALIC] Combination <C> LSUN  [ITALIC] Combination <R> <C> [EMPTY] <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <R> <C> PRNU  <C> [BOLD] 39.59 <C> 40.97 <C> 26.92 <C> 30.79 <C> 9.30 <C> 9.42 <C> 18.27 <C> 23.66 <C> 60.86 <C> 63.31 <C> 16.54 <C> 16.89 <R> <C> Ours <C> 11.80 <C> [BOLD] 95.30 <C> [BOLD] 74.48 <C> [BOLD] 96.68 <C> [BOLD] 86.20 <C> [BOLD] 97.30 <C> [BOLD] 24.73 <C> [BOLD] 92.40 <C> [BOLD] 62.21 <C> [BOLD] 97.36 <C> [BOLD] 24.44 <C> [BOLD] 83.42 <CAP> Table 8: Classification accuracy (%) of our network w.r.t. different perturbation attacks before or after immunization on LSUN bedroom {real, ProGAN_seed_v#i}. The best performance is highlighted in bold.
<R> <C> BSD-68 Methods <C> BSD-68 BM3D <C> BSD-68 DnCNN-SURE <C> BSD-68 DnCNN-SURE* <C> BSD-68 DnCNN-N2N <C> BSD-68 DnCNN-eSURE <C> BSD-68 DnCNN-MSE <R> <C> [ITALIC] σ=25 <C> 28.56 <C> 28.92 <C> 29.00 <C> [BOLD] 29.08 <C> [BOLD] 29.08 <C> 29.20 <R> <C> [ITALIC] σ=50 <C> 25.62 <C> 26.00 <C> 26.07 <C> 26.13 <C> [BOLD] 26.15 <C> 26.22 <R> <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <R> <C> [ITALIC] σ=25 <C> 29.97 <C> 30.04 <C> 30.13 <C> 30.30 <C> [BOLD] 30.31 <C> 30.42 <R> <C> [ITALIC] σ=50 <C> 26.67 <C> 26.87 <C> 26.97 <C> [BOLD] 27.07 <C> [BOLD] 27.07 <C> 27.16 <R> <C> Noisy dataset <C> - <C> 1 <C> 2 <C> 2 <C> 2 <C> ∞ <CAP> Table 1: PSNR results of blind denoisers on BSD68 and Set12 datasets.
<R> <C> BSD-68  [ITALIC] σnoisy <C> BSD-68 25 <C> BSD-68 25 <C> BSD-68 25 <C> BSD-68 50 <C> BSD-68 50 <C> BSD-68 50 <C> BSD-68 50 <R> <C> [ITALIC] σgt <C> 1 <C> 5 <C> 10 <C> 1 <C> 5 <C> 10 <C> 20 <R> <C> BM3D <C> 28.56 <C> 28.56 <C> 28.56 <C> 25.62 <C> 25.62 <C> 25.62 <C> 25.62 <R> <C> DnCNN-SURE <C> 29.05 <C> 29.01 <C> 29.02 <C> 25.95 <C> 25.97 <C> 25.90 <C> 25.92 <R> <C> DnCNN-N2N <C> 29.23 <C> 29.15 <C> 28.37 <C> [BOLD] 26.28 <C> 26.24 <C> 25.91 <C> 24.69 <R> <C> DnCNN-eSURE <C> [BOLD] 29.23 <C> [BOLD] 29.23 <C> [BOLD] 29.21 <C> 26.27 <C> [BOLD] 26.24 <C> [BOLD] 26.27 <C> [BOLD] 26.25 <R> <C> DnCNN-MSE <C> 29.23 <C> 29.23 <C> 29.23 <C> 26.28 <C> 26.28 <C> 26.28 <C> 26.28 <R> <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <C> Set 12 <R> <C> BM3D <C> 29.97 <C> 29.97 <C> 29.97 <C> 26.67 <C> 26.67 <C> 26.67 <C> 26.67 <R> <C> DnCNN-SURE <C> 30.23 <C> 30.19 <C> 30.19 <C> 26.77 <C> 26.85 <C> 26.73 <C> 26.74 <R> <C> DnCNN-N2N <C> 30.41 <C> 30.39 <C> 29.46 <C> [BOLD] 27.28 <C> 27.20 <C> 27.08 <C> 25.39 <R> <C> DnCNN-eSURE <C> [BOLD] 30.47 <C> [BOLD] 30.48 <C> [BOLD] 30.44 <C> 27.27 <C> [BOLD] 27.27 <C> [BOLD] 27.25 <C> [BOLD] 27.23 <R> <C> DnCNN-MSE <C> 30.47 <C> 30.47 <C> 30.47 <C> 27.28 <C> 27.28 <C> 27.28 <C> 27.28 <CAP> Table 2: Results of denoising methods on BSD68 and Set 12 datasets (Performance in dB).
<R> <C> RGB BSD-68  [ITALIC] σnoisy <C> RGB BSD-68 25 <C> RGB BSD-68 25 <C> RGB BSD-68 25 <C> RGB BSD-68 50 <C> RGB BSD-68 50 <C> RGB BSD-68 50 <C> RGB BSD-68 50 <R> <C> [ITALIC] σgt <C> 1 <C> 5 <C> 10 <C> 1 <C> 5 <C> 10 <C> 20 <R> <C> CBM3D <C> 30.70 <C> 30.70 <C> 30.70 <C> 27.38 <C> 27.38 <C> 27.38 <C> 27.38 <R> <C> CDnCNN-SURE <C> 30.97 <C> 30.98 <C> 30.99 <C> 27.63 <C> 27.68 <C> 27.64 <C> 27.63 <R> <C> CDnCNN-N2N <C> 31.18 <C> 31.08 <C> 29.83 <C> 27.89 <C> 27.87 <C> 27.61 <C> 25.62 <R> <C> CDnCNN-eSURE <C> [BOLD] 31.20 <C> [BOLD] 31.18 <C> [BOLD] 31.19 <C> [BOLD] 27.94 <C> [BOLD] 27.91 <C> [BOLD] 27.90 <C> [BOLD] 27.78 <R> <C> DnCNN-MSE <C> 31.20 <C> 31.20 <C> 31.20 <C> 27.93 <C> 27.93 <C> 27.93 <C> 27.93 <CAP> Table 3: Results of denoising methods on RGB color BSD68 dataset(Performance in dB).
<R> <C> Method <C> ML-100k <C> ML-1M <R> <C> GCMC (original) <C> 0.910 <C> 0.832 <R> <C> GCMC (new split) <C> 1.2259±0.0001 <C> 1.1414±0.0002 <R> <C> GCMC-LSTM† <C> 1.2556±0.0509 <C> 1.1857±0.0193 <R> <C> GCMC-GRU† <C> 1.2446±0.0404 <C> 1.2056±0.0171 <R> <C> GCMC-LSTM‡ <C> 1.0725±0.0217 <C> [BOLD] 1.0394±0.0230 <R> <C> GCMC-GRU‡ <C> [BOLD] 1.0630±0.0141 <C> 1.0407±0.0336 <CAP> Table 1: RMSE values for all models on the ML-100k and ML-1M datasets using the new training and test sets, averaged over 5 different runs, along with standard deviations. GCMC (original) results are the same as those reported in previous work [1]. The † symbol denotes experiments using disjoint edge sets in every M(i); ‡ denotes the representation where every step contains all edges from previous steps.
<R> <C> [EMPTY] <C> CelebA  [ITALIC] Noise <C> CelebA  [ITALIC] Noise <C> CelebA  [ITALIC] Blur <C> CelebA  [ITALIC] Blur <C> CelebA  [ITALIC] Cropping <C> CelebA  [ITALIC] Cropping <C> CelebA  [ITALIC] Compression <C> CelebA  [ITALIC] Compression <C> CelebA  [ITALIC] Relighting <C> CelebA  [ITALIC] Relighting <C> CelebA  [ITALIC] Combination <C> CelebA  [ITALIC] Combination <R> <C> [EMPTY] <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <C> Atk <C> Dfs <R> <C> PRNU  <C> [BOLD] 57.88 <C> 63.82 <C> 27.37 <C> 42.43 <C> 9.84 <C> 10.68 <C> [BOLD] 26.15 <C> 44.55 <C> 86.59 <C> 87.02 <C> [BOLD] 19.93 <C> 21.77 <R> <C> Ours <C> 9.14 <C> [BOLD] 93.02 <C> [BOLD] 49.64 <C> [BOLD] 97.20 <C> [BOLD] 46.80 <C> [BOLD] 98.28 <C> 8.77 <C> [BOLD] 88.02 <C> [BOLD] 94.02 <C> [BOLD] 98.66 <C> 19.31 <C> [BOLD] 72.64 <CAP> Table 7: Classification accuracy (%) of our network w.r.t. different perturbation attacks before or after immunization on CelebA {real, ProGAN_seed_v#i}. The best performance is highlighted in bold.
<R> <C> [EMPTY] <C> [EMPTY] <C> Uncalibrated Freq. <C> Uncalibrated MC Dropout <C> Uncalibrated MC Dropout <C> TS Calibrated Freq. <C> TS Calibrated MC Dropout <C> TS Calibrated MC Dropout <R> <C> Data Set <C> Model <C> ECE <C> ECE <C> UCE <C> ECE <C> ECE <C> UCE <R> <C> CIFAR-10 <C> ResNet-18 <C> 8.95 <C> 8.41 <C> 7.60 <C> 1.40 <C> [BOLD] 0.47 <C> [BOLD] 5.27 <R> <C> CIFAR-100 <C> ResNet-101 <C> 29.63 <C> 24.62 <C> 30.33 <C> 3.50 <C> [BOLD] 1.92 <C> [BOLD] 2.41 <R> <C> CIFAR-100 <C> DenseNet-169 <C> 30.62 <C> 23.98 <C> 29.62 <C> 6.10 <C> [BOLD] 2.89 <C> [BOLD] 2.69 <CAP> Table 1: ECE and UCE test set results in % (M=15 bins). 0 % means perfect calibration. In TS calibration with MC dropout the same value of T was used to report both ECE and UCE.
<R> <C> [BOLD] Attempt <C> [BOLD] Response Time <C> [BOLD] Error Rate <C> [BOLD] Score <R> <C> [BOLD] First <C> 0.802(0.113) <C> 0.069(0.054) <C> 0.395(0.373) <R> <C> [BOLD] Second <C> 0.844(0.168) <C> 0.096(0.066) <C> 0.010(0.500) <R> <C> [BOLD] p-value <C> 0.0075 <C> 0.0006 <C> <0.0001 <CAP> TABLE III: Mean value and standard deviation for the critical blocks of first and second attempts; p-value indicating the significance of the difference between the first and second attempts
<R> <C> [BOLD] ML Method <C> [BOLD] Unpruned ( [ITALIC] n=154) <C> [BOLD] Pruned ( [ITALIC] n=102) <R> <C> Naive Bayes <C> 0.721 <C> 0.735 <R> <C> SVM <C> 0.728 <C> 0.779 <R> <C> Logistic <C> 0.747 <C> 0.716 <R> <C> Multilayer Perceptron <C> 0.719 <C> 0.812 <R> <C> Simple Logistic <C> 0.700 <C> 0.764 <R> <C> JRip <C> 0.675 <C> 0.712 <R> <C> Random Forest <C> 0.678 <C> 0.745 <CAP> TABLE IV: Results of various machine learning methods. Pruning the data entailed of removing deception attempts that resulted in a <1 SD score change.
<R> <C> [BOLD] Model <C> [BOLD] F1 Unpruned <C> [BOLD] F1 Pruned <R> <C> MLP <C> 0.78 <C> 0.81 <R> <C> Ratio <C> 0.64 <C> 0.58 <CAP> TABLE V: F1 scores for TensorFlow MLP and ratio-based method from [1]
<R> <C> Dataset Models <C> Cora GCN <C> Cora SGC <C> Cora DeepWalk <C> Cora LINE <C> Citeseer GCN <C> Citeseer SGC <C> Citeseer DeepWalk <C> Citeseer LINE <C> Pubmed GCN <C> Pubmed SGC <C> Pubmed DeepWalk <C> Pubmed LINE <R> <C> (unattacked) <C> 80.20 <C> 78.82 <C> 77.23 <C> 76.75 <C> 72.50 <C> 69.68 <C> 69.68 <C> 65.15 <C> 80.40 <C> 80.21 <C> 78.69 <C> 72.12 <R> <C> [ITALIC] Random <C> -1.90 <C> -1.22 <C> -1.76 <C> -1.84 <C> -2.86 <C> -1.47 <C> -6.62 <C> -1.78 <C> -1.75 <C> -1.77 <C> -1.25 <C> -1.01 <R> <C> [ITALIC] Degree <C> -2.21 <C> -4.42 <C> -3.08 <C> -12.40 <C> -4.68 <C> -5.21 <C> -9.67 <C> -12.55 <C> -3.86 <C> -4.44 <C> -2.43 <C> -13.05 <R> <C> [ITALIC] RL-S2V <C> -5.20 <C> -5.62 <C> -5.24 <C> -10.38 <C> -6.50 <C> -4.08 <C> -12.13 <C> -20.10 <C> -6.40 <C> -6.11 <C> -6.10 <C> -13.21 <R> <C> A [ITALIC] class <C> -3.62 <C> -2.96 <C> [BOLD] -6.29 <C> -7.55 <C> -3.48 <C> -2.83 <C> [BOLD] -12.56 <C> -10.28 <C> -4.21 <C> -2.25 <C> -3.05 <C> -6.75 <R> <C> [ITALIC] GF-Attack <C> [BOLD] -7.60 <C> [BOLD] -9.73 <C> -5.31 <C> [BOLD] -13.27 <C> [BOLD] -7.78 <C> [BOLD] -6.19 <C> -12.50 <C> [BOLD] -22.11 <C> [BOLD] -7.96 <C> [BOLD] -7.20 <C> [BOLD] -7.43 <C> [BOLD] -14.16 <CAP> Table 1: Summary of the change in classification accuracy (in percent) compared to the clean/original graph. Single edge perturbation under RBA setting. Lower is better.
<R> <C> [EMPTY] <C> BPE–BPE <C> BPE–char <C> char–char <R> <C> source vocab <C> 83,227 <C> 24,440 <C> 304 <R> <C> target vocab <C> 91,000 <C> 302 <C> 302 <R> <C> source emb. <C> 512 <C> 512 <C> 128 <R> <C> source conv. <C> - <C> - <C>  <R> <C> target emb. <C> 512 <C> 512 <C> 512 <R> <C> encoder <C> gru <C> gru <C> gru <R> <C> encoder size <C> 1024 <C> 512 <C> 512 <R> <C> decoder <C> gru_cond <C> two_layer_gru_decoder <C> two_layer_gru_decoder <R> <C> decoder size <C> 1024 <C> 1024 <C> 1024 <R> <C> minibatch size <C> 128 <C> 128 <C> 64 <R> <C> optmizer <C> adam <C> adam <C> adam <R> <C> learning rate <C> 0.0001 <C> 0.0001 <C> 0.0001 <R> <C> beam size <C> 12 <C> 20 <C> 20 <R> <C> training time <C> ≈ 1 week <C> ≈ 2 weeks <C> ≈ 2 weeks <R> <C> (minibatches) <C> 240,000 <C> 510,000 <C> 540,000 <CAP> Table 2: NMT hyperparameters. ‘decoder’ refers to function implemented in Nematus (for BPE-to-BPE) and dl4mt-c2c (for *-to-char).
<R> <C> system <C> 2014 <C> 2015 <C> 2016 <R> <C> (test set and size→) <C> 3003 <C> 2169 <C> 2999 <R> <C> BPE-to-BPE <C> 20.1 (21.0) <C> 23.2 (23.0) <C> 26.7 (26.5) <R> <C> BPE-to-char <C> 19.4 (20.5) <C> 22.7 (22.6) <C> 26.0 (25.9) <R> <C> char-to-char <C> 19.7 (20.7) <C> 22.9 (22.7) <C> 26.2 (26.1) <R> <C>  <C> 25.4 (26.5) <C> 28.1 (28.3) <C> 34.2 (34.2) <CAP> Table 3: Case-sensitive Bleu scores (EN-DE) on WMT newstest. We report scores with detokenized NIST Bleu (mteval-v13a.pl), and in brackets, tokenized Bleu with multi-bleu.perl.
<R> <C> system <C> agreement noun phrase <C> agreement subject-verb <C> verb particle <C> polarity (negation) insertion <C> polarity (negation) deletion <C> transliteration <R> <C> (category and size→) <C> 21813 <C> 35105 <C> 2450 <C> 22760 <C> 4043 <C> 3490 <R> <C> BPE-to-BPE <C> [BOLD] 95.6 <C> [BOLD] 93.4 <C> [BOLD] 91.1 <C> 97.9 <C> [BOLD] 91.5 <C> 96.1 <R> <C> BPE-to-char <C> 93.9 <C> 91.2 <C> 88.0 <C> [BOLD] 98.5 <C> 88.4 <C> [BOLD] 98.6 <R> <C> char-to-char <C> 93.9 <C> 91.5 <C> 86.7 <C> [BOLD] 98.5 <C> 89.3 <C> [BOLD] 98.3 <R> <C>  <C> 98.7 <C> 96.6 <C> 96.1 <C> 98.7 <C> 92.7 <C> 96.4 <R> <C> human <C> 99.4 <C> 99.8 <C> 99.8 <C> 99.9 <C> 98.5 <C> 99.0 <CAP> Table 4: Accuracy (in percent) of models on different categories of contrastive errors. Best single model result in bold (multiple bold results indicate that difference to best system is not statistically significant).
<R> <C> system <C> negation insertion  [ITALIC] nicht <C> negation insertion  [ITALIC] kein <C> negation insertion  [ITALIC] un- <C> negation deletion  [ITALIC] nicht <C> negation deletion  [ITALIC] kein <C> negation deletion  [ITALIC] un- <R> <C> (category and size →) <C> 1297 <C> 10219 <C> 11244 <C> 2919 <C> 538 <C> 586 <R> <C> BPE-to-BPE <C> [BOLD] 94.8 <C> [BOLD] 99.1 <C> 97.1 <C> [BOLD] 93.0 <C> [BOLD] 88.7 <C> [BOLD] 86.5 <R> <C> BPE-to-char <C> 92.7 <C> [BOLD] 98.9 <C> [BOLD] 98.7 <C> 91.0 <C> 85.1 <C> 78.8 <R> <C> char-to-char <C> 92.1 <C> [BOLD] 98.9 <C> [BOLD] 98.8 <C> 91.5 <C> 86.4 <C> 80.5 <R> <C>  <C> 97.1 <C> 99.7 <C> 98.0 <C> 93.6 <C> 92.0 <C> 88.4 <CAP> Table 5: Accuracy (in percent) of models on different categories of contrastive errors related to polarity. Best single model result in bold.
<R> <C> system <C> sentence <C> cost <R> <C> source <C> Since then we have only played in the Swedish  [BOLD] league which is not the same level. <C> [EMPTY] <R> <C> reference <C> Seitdem haben wir nur in der Schwedischen  [BOLD] Liga gespielt,  [BOLD] die nicht das gleiche Niveau  [BOLD] hat. <C> 0.149 <R> <C> contrastive <C> Seitdem haben wir nur in der Schwedischen  [BOLD] Liga gespielt,  [BOLD] die nicht das gleiche Niveau  [BOLD] haben. <C> 0.137 <R> <C> 1-best <C> Seitdem haben wir nur in der schwedischen  [BOLD] Liga gespielt,  [BOLD] die nicht die gleiche Stufe  [BOLD] sind. <C> 0.090 <R> <C> source <C> FriendsFest: the  [BOLD] comedy show that taught us serious lessons about male friendship. <C> [EMPTY] <R> <C> reference <C> FriendsFest: die  [BOLD] Comedy-Show, die uns ernsthafte Lektionen über Männerfreundschaften  [BOLD] erteilt <C> 0.276 <R> <C> contrastive <C> FriendsFest: die  [BOLD] Comedy-Show, die uns ernsthafte Lektionen über Männerfreundschaften  [BOLD] erteilen <C> 0.262 <R> <C> 1-best <C> FriendsFest: die  [BOLD] Komödie zeigt,  [BOLD] dass uns ernsthafte Lehren aus männlichen Freundschaften <C> 0.129 <R> <C> source <C> Robert Lewandowski  [BOLD] had the best opportunities in the first half. <C> [EMPTY] <R> <C> reference <C> Die besten Gelegenheiten in Hälfte eins  [BOLD] hatte Robert Lewandowski. <C> 0.551 <R> <C> contrastive <C> Die besten Gelegenheiten in Hälfte eins  [BOLD] hatten Robert Lewandowski. <C> 0.507 <R> <C> 1-best <C> Robert Lewandowski  [BOLD] hatte in der ersten Hälfte die besten Möglichkeiten. <C> 0.046 <CAP> Table 6: Examples where char-to-char model prefers contrastive translation (subject-verb agreement errors). 1-best translation can make error of same type (example 1), different type (translation of taught is missing in example 2), or no error (example 3).
<R> <C> Approach <C> People <C> Clothing <C> Body <C> Animals <C> Vehicles <C> Instruments <C> Scene <C> Other <C> All <R> <C> [BOLD] Non-scalable methods <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> GroundeR Rohrbach et al. ( 2016 ) <C> 61.00 <C> 38.12 <C> 10.33 <C> 62.55 <C> 68.75 <C> 36.42 <C> 58.18 <C> 29.08 <C> 47.81 <R> <C> Multimodal compact bilinear Fukui et al. ( 2016 ) <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> 48.69 <R> <C> PGN+QRN Chen et al. ( 2017 ) <C> 75.08 <C> 55.90 <C> 20.27 <C> 73.36 <C> 68.95 <C> 45.68 <C> 65.27 <C> 38.80 <C> 60.21 <R> <C> [BOLD] Non-scalable and joint localization methods <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Structured matching Wang et al. ( 2016b ) <C> 57.89 <C> 34.61 <C> 15.87 <C> 55.98 <C> 52.25 <C> 23.46 <C> 34.22 <C> 26.23 <C> 42.08 <R> <C> SPC+PPC Plummer et al. ( 2017a ) <C> 71.69 <C> 50.95 <C> 25.24 <C> 76.25 <C> 66.50 <C> 35.80 <C> 51.51 <C> 35.98 <C> 55.85 <R> <C> QRC net Chen et al. ( 2017 ) <C> 76.32 <C> 59.58 <C> 25.24 <C> [BOLD] 80.50 <C> [BOLD] 78.25 <C> 50.62 <C> 67.12 <C> 43.60 <C> 65.14 <R> <C> [BOLD] Scalable methods <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> Structure-preserving embedding Wang et al. ( 2016a ) <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> 43.89 <R> <C> CCA+Detector+Size+Color Plummer et al. ( 2017b ) <C> 64.73 <C> 46.88 <C> 17.21 <C> 65.83 <C> 68.75 <C> 37.65 <C> 51.39 <C> 31.77 <C> 50.89 <R> <C> [BOLD] Query-Adaptive R-CNN (proposed) <C> [BOLD] 78.17 <C> [BOLD] 61.99 <C> [BOLD] 35.25 <C> 74.41 <C> 76.16 <C> [BOLD] 56.69 <C> [BOLD] 68.07 <C> [BOLD] 47.42 <C> [BOLD] 65.21 <CAP> Table 1: Phrase localization accuracy on Flickr30k Entities dataset.
<R> <C> Architecture <C> Params <C> IoU 0.5 <C> IoU 0.6 <C> IoU 0.7 <C> IoU 0.8 <C> IoU 0.9 <R> <C> w/o regression <C> - <C> [BOLD] 65.21 <C> 53.19 <C> 35.70 <C> 14.32 <C> 1.88 <R> <C> 300–16(–4096) <C> [BOLD] 0.3M <C> 64.14 <C> 57.66 <C> 48.22 <C> 33.04 <C> 9.29 <R> <C> 300–64(–4096) <C> 1.1M <C> 63.87 <C> 57.43 <C> [BOLD] 49.05 <C> 33.84 <C> [BOLD] 10.55 <R> <C> 300–256(–4096) <C> 4.3M <C> 63.84 <C> 57.70 <C> 48.71 <C> 33.87 <C> 10.05 <R> <C> 300–1024(–4096) <C> 17M <C> 64.29 <C> [BOLD] 58.05 <C> 48.49 <C> [BOLD] 33.94 <C> 10.09 <R> <C> 300(–256–4096) <C> 4.5M <C> 62.82 <C> 56.28 <C> 48.02 <C> 32.71 <C> 9.89 <R> <C> 300–4096 <C> 1.2M <C> 63.23 <C> 56.92 <C> 48.17 <C> 32.66 <C> 9.20 <CAP> Table 2: Comparison of various bounding box regressors on Flickr30k Entities for different IoU thresholds. The number of parameters in Gr is also shown.
<R> <C> [EMPTY] <C> NPA <C> WN <C> VG <C> [BOLD] Visual Genome mAP <C> [BOLD] Visual Genome PR@10 <C> [BOLD] Visual Genome PR@100 <C> [BOLD] VOC mAP <R> <C> CCA <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 3.18 <C> 20.40 <C> 15.64 <C> 28.23 <R> <C> [BOLD] Query- Adaptive R-CNN <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 9.15 <C> 52.60 <C> 36.85 <C> 29.14 <R> <C> [BOLD] Query- Adaptive R-CNN <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> 10.90 <C> 60.10 <C> 43.21 <C> 36.74 <R> <C> [BOLD] Query- Adaptive R-CNN <C> ✓ <C> ✓ <C> [EMPTY] <C> 11.53 <C> 61.80 <C> 45.91 <C> 37.07 <R> <C> [BOLD] Query- Adaptive R-CNN <C> ✓ <C> [EMPTY] <C> ✓ <C> 11.65 <C> 65.40 <C> 46.85 <C> 41.32 <R> <C> [BOLD] Query- Adaptive R-CNN <C> ✓ <C> ✓ <C> ✓ <C> [BOLD] 12.19 <C> [BOLD] 65.70 <C> [BOLD] 48.45 <C> [BOLD] 42.81 <CAP> Table 3: Open-vocabulary object detection performance on Visual Genome and PASCAL VOC 2007 datasets. WN and VG are the strategies to remove mutually non-exclusive phrases.
<R> <C> Query girl <C> Most confusing class man <C> Most confusing class 19 <C> Most confusing class → <C> Most confusing class 3 <C> 2nd most confusing class boy <C> 2nd most confusing class 4 <C> 2nd most confusing class → <C> 2nd most confusing class 2 <R> <C> skateboard <C> surfboard <C> 12 <C> → <C> 0 <C> snowboard <C> 11 <C> → <C> 0 <R> <C> train <C> bus <C> 17 <C> → <C> 1 <C> oven <C> 3 <C> → <C> 0 <R> <C> helmet <C> hat <C> 18 <C> → <C> 1 <C> cap <C> 6 <C> → <C> 4 <R> <C> elephant <C> bear <C> 14 <C> → <C> 0 <C> horse <C> 6 <C> → <C> 0 <CAP> Table 4: Number of false alarms in top 100 results for five queries (w/o NPA → w/ NPA). The top 2 confusing categories are shown for each query.
<R> <C> Database size <C> 10K <C> 50K <C> 100K <C> 500K <C> 1M <R> <C> Time (ms) <C> 183±16 <C> 196±21 <C> 242±28 <C> 314±90 <C> 484±165 <R> <C> Memory (GB) <C> 0.46 <C> 1.23 <C> 2.19 <C> 9.87 <C> 19.47 <CAP> Table 5: Speed/memory in large-scale experiments.
<R> <C> # of Objs. <C> Ep.1 9 <C> Ep.1 9 <C> Ep.2 15 <C> Ep.2 15 <C> Ep.3 20 <C> Ep.3 20 <C> Ep.4 25 <C> Ep.4 25 <R> <C> duration <C> 277(s) <C> 277(s) <C> 328(s) <C> 328(s) <C> 510(s) <C> 510(s) <C> 520(s) <C> 520(s) <R> <C> # of  [ITALIC] Hyp. <C> 130 <C> 130 <C> 353 <C> 353 <C> 694 <C> 694 <C> 759 <C> 759 <R> <C> # pnp tasks <C> 3 <C> 3 <C> 4 <C> 4 <C> 6 <C> 6 <C> 10 <C> 10 <R> <C> filters <C> Off <C> On <C> Off <C> On <C> Off <C> On <C> Off <C> On <R> <C> # objs. in bs. <C> 15 <C> 9 <C> 26 <C> 20 <C> 49 <C> 28 <C> 54 <C> 31 <CAP> Table II: Summary of episodes of the conducted experiments
<R> <C> [BOLD] Algorithm <C> | [ITALIC] A| [BOLD]  = 25  [BOLD] P = 0.1 <C> | [ITALIC] A| [BOLD]  = 25  [BOLD] P = 0.6 <C> | [ITALIC] A| [BOLD]  = 50  [BOLD] P = 0.1 <C> | [ITALIC] A| [BOLD]  = 50  [BOLD] P = 0.6 <C> | [ITALIC] A| [BOLD]  = 75  [BOLD] P = 0.1 <C> | [ITALIC] A| [BOLD]  = 75  [BOLD] P = 0.6 <R> <C> DSA-C <C> 432 <C> 5725 <C> 2605 <C> 27163 <C> 7089 <C> 65519 <R> <C> DSA-SDP <C> 325 <C> 5635 <C> 2365 <C> 27210 <C> 6701 <C> 65600 <R> <C> GDBA <C> 386 <C> 5465 <C> 2475 <C> 26950 <C> 6867 <C> 65156 <R> <C> MGM-2 <C> 352 <C> 5756 <C> 2481 <C> 27421 <C> 6962 <C> 65988 <R> <C> PD-Gibbs <C> 398 <C> 5875 <C> 2610 <C> 27350 <C> 7178 <C> 65650 <R> <C> MS_ADVP <C> 400 <C> 5805 <C> 2550 <C> 27400 <C> 7058 <C> 66008 <R> <C> DSAN <C> 408 <C> 5802 <C> 2639 <C> 27413 <C> 7224 <C> 66085 <R> <C> [BOLD] DPSA <C> [BOLD] 268 <C> [BOLD] 5358 <C> [BOLD] 2136 <C> [BOLD] 26240 <C> [BOLD] 6276 <C> [BOLD] 63998 <CAP> Table 1: Comparison of DPSA and the benchmarking algorithms on difference configuration of random DCOPs.
<R> <C> [BOLD] Method <C> [BOLD] Direct. <C> [BOLD] Discuss <C> [BOLD] Eating <C> [BOLD] Greet <C> [BOLD] Phone <C> [BOLD] Photo <C> [BOLD] Pose <C> [BOLD] Purch. <R> <C> Zhou et al.  <C> 54.8 <C> 60.7 <C> 58.2 <C> 71.4 <C> 62.0 <C> 53.8 <C> 55.6 <C> 75.2 <R> <C> Dabral et al.  <C> 44.8 <C> 50.4 <C> 44.7 <C> 49.0 <C> 52.9 <C> 61.4 <C> 43.5 <C> 45.5 <R> <C> Yang et al.  <C> 51.5 <C> 58.9 <C> 50.4 <C> 57.0 <C> 62.1 <C> 65.4 <C> 49.8 <C> 52.7 <R> <C> Luo et al.  <C> 49.2 <C> 57.5 <C> 53.9 <C> 55.4 <C> 62.2 <C> 73.9 <C> 52.1 <C> 60.9 <R> <C> Sun et al.  <C> 42.1 <C> 44.3 <C> 45.0 <C> 45.4 <C> 51.5 <C> [BOLD] 43.2 <C> [BOLD] 41.3 <C> 59.3 <R> <C> Martinez et al. (GT)  <C> 37.7 <C> 44.4 <C> 40.3 <C> 42.1 <C> 48.2 <C> 54.9 <C> 44.4 <C> 42.1 <R> <C> Ours (GT) <C> [BOLD] 35.74 <C> [BOLD] 42.39 <C> [BOLD] 39.06 <C> [BOLD] 40.55 <C> [BOLD] 44.37 <C> 52.54 <C> 42.86 <C> [BOLD] 38.83 <R> <C> [BOLD] Method <C> [BOLD] Sitting <C> [BOLD] SittingD <C> [BOLD] Smoke <C> [BOLD] Wait <C> [BOLD] WalkD <C> [BOLD] Walk <C> [BOLD] WalkT <C> [BOLD] Avg. <R> <C> Zhou et al.  <C> 111.6 <C> 64.1 <C> 65.5 <C> 66.0 <C> 51.4 <C> 63.2 <C> 55.3 <C> 64.9 <R> <C> Dabral et al.  <C> 63.1 <C> 87.3 <C> 51.7 <C> 48.5 <C> 52.2 <C> 37.6 <C> 41.9 <C> 52.1 <R> <C> Yang et al.  <C> 69.2 <C> 85.2 <C> 57.4 <C> 58.4 <C> 43.6 <C> 60.1 <C> 47.7 <C> 58.6 <R> <C> Luo et al.  <C> 73.8 <C> 96.5 <C> 60.4 <C> 55.6 <C> 69.5 <C> 46.6 <C> 52.4 <C> 61.3 <R> <C> Sun et al.  <C> 73.3 <C> [BOLD] 51.0 <C> 53.0 <C> 44.0 <C> [BOLD] 38.3 <C> 48.0 <C> 44.8 <C> 48.3 <R> <C> Martinez et al. (GT) <C> 54.6 <C> 58.0 <C> 45.1 <C> 46.4 <C> 47.6 <C> 36.4 <C> 40.4 <C> 45.5 <R> <C> Ours (GT) <C> [BOLD] 53.08 <C> 53.90 <C> [BOLD] 42.10 <C> [BOLD] 43.36 <C> 43.92 <C> [BOLD] 33.31 <C> [BOLD] 36.54 <C> [BOLD] 42.84 <CAP> TABLE I: MPJE (Mean Per Joint Error, mm) metric on Human3.6m dataset under defined protocol i.e. no rigid alignment of predicted 3d pose with ground truth 3d pose. GT denotes training on ground-truth 2d pose labels. Except Martinez et al. all other state-of-the-art methods use images for training instead of 2d pose labels. Our model achieves least MPJE for majority of the actions.
<R> <C> [BOLD] Method <C> [BOLD] Training Data <C> [BOLD] PCK GS <C> [BOLD] PCK NoGS <C> [BOLD] PCK Outdoor <C> [BOLD] PCK ALL <C> [BOLD] AUC ALL <R> <C> Zhou et al.  <C> H36m <C> 45.6 <C> 45.1 <C> 14.4 <C> 37.7 <C> 20.9 <R> <C> Martinez et al. <C> H36m <C> 62.8* <C> 58.5* <C> 62.2* <C> 62.2* <C> 27.7* <R> <C> Mehta et al. <C> H36m <C> 70.8 <C> 62.3 <C> 58.5 <C> 64.7 <C> 31.7 <R> <C> Luo et al.  <C> H36m <C> 71.3* <C> 59.4* <C> 65.7* <C> 65.6* <C> 33.2* <R> <C> Yang et al. <C> H36M+MPII <C> - <C> - <C> - <C> 69.0 <C> 32.0 <R> <C> Zhou et al. <C> H36m+MPII <C> 71.1 <C> 64.7 <C> [BOLD] 72.7 <C> 69.2 <C> 32.5 <R> <C> Ours (Model I) <C> H36m <C> 66.9* <C> 63.0* <C> 67.4* <C> 65.8* <C> 31.2* <R> <C> Ours (Model II) <C> H36m+MPII <C> [BOLD] 74.2* <C> [BOLD] 66.9* <C> 71.4* <C> [BOLD] 70.8* <C> [BOLD] 34.5* <CAP> TABLE II: Results on MPI-INF-3DHP test-set by scene. Higher PCK(%) and AUC indicates better performance. − means values are not given in original paper. ∗ denotes re-targeting of predicted 3d pose using ground truth limb length. Our model shows best performance among state-of-the-art methods while fine tuned on MPII dataset.
<R> <C> [BOLD] Method <C> [BOLD] Training Data <C> [BOLD] Walk PCK <C> [BOLD] Exer. PCK <C> [BOLD] Sit PCK <C> [BOLD] Reach PCK <C> [BOLD] Floor PCK <C> [BOLD] Sport PCK <C> [BOLD] Misc. PCK <C> [BOLD] Total PCK <C> [BOLD] Total AUC <C> [BOLD] Total MPJE <R> <C> Mehta et al.  <C> (MPII+LSP)H3.6M+3DHP [ITALIC] a <C> 86.6 <C> 75.3 <C> 74.8 <C> 73.7 <C> 52.2 <C> 82.1 <C> 77.5 <C> 75.7 <C> 39.3 <C> 117.6 <R> <C> Mehta et al. <C> (MPII+LSP)H3.6M+3DHP [ITALIC] a <C> 87.7 <C> 77.4 <C> 74.7 <C> 72.9 <C> 51.3 <C> 83.3 <C> 80.1 <C> 76.6 <C> 40.4 <C> 124.7 <R> <C> Dabral et al. <C> H3.6M+3DHP <C> - <C> - <C> - <C> - <C> - <C> - <C> - <C> 76.7 <C> 39.1 <C> 103.8 <R> <C> Luo et al. <C> (MPII)H3.6M+3DHP <C> 90.5* <C> 80.9* <C> 90.0* <C> 85.6* <C> 70.2* <C> 93.0* <C> 92.9* <C> 83.8* <C> 47.7* <C> 85.0* <R> <C> Ours <C> H3.6M+3DHP <C> [BOLD] 97.3* <C> [BOLD] 93.0* <C> [BOLD] 92.3* <C> [BOLD] 95.3* <C> [BOLD] 86.4* <C> [BOLD] 94.6* <C> [BOLD] 94.3* <C> [BOLD] 85.4* <C> [BOLD] 55.8* <C> [BOLD] 71.40* <CAP> TABLE III: Activity-wise performance on MPI-INF-3DHP test-set using standard metrics PCK (%), AUC and MPJE (mm). (MPII) means pretrained on MPII dataset. a denotes background augmentation in training data. − means values are not given in original paper. ∗ denotes the re-targeting of predicted 3d pose using ground truth limb length. Higher PCK, AUC and lower MPJE indicates better performance. We have achieved significantly better performance than the state-of-the-art methods on all the actions in terms of all the metrics.
<R> <C> [BOLD] Method <C> [BOLD] PCK <C> [BOLD] AUC <R> <C> 2d-to-3d (supervised loss)  <C> 62.2 <C> 27.7 <R> <C> Ours 2d-to-3d+3d-to-2d (re-projection loss) <C> 64.2 <C> 29.7 <R> <C> Ours 2d-to-3d+3d-to-2d (re-projection loss+ bone symmetry loss) <C> 65.8 <C> 31.2 <CAP> TABLE IV: Ablation Study for different losses on MPI-INF-3DHP dataset.
<R> <C> [BOLD] Method <C> [BOLD] Re-projection error <C> Δ <R> <C> w/o batch normalization <C> 36.2 <C> 30.7 <R> <C> w/o dropout <C> 6.49 <C> 0.99 <R> <C> w/o dropout + w/o batch normalization <C> 34.79 <C> 29.29 <CAP> TABLE V: Ablation study on different network parameters for our (3d-to-2d re-projection module) in terms of re-projection error on Human3.6m. Δ defines re-projection error differences between current training setup (as mentioned in section IV-D) and the above setups.
<R> <C> Dataset <C> Length (mins) <C> Missing Obs. <C> Accuracy <R> <C> 1 <C> 2.0 <C> 11% <C> 83% <R> <C> 2 <C> 3.7 <C> 18% <C> 74% <R> <C> 3 <C> 4.8 <C> 6% <C> 83% <R> <C> 4 <C> 4.4 <C> 9% <C> 95% <R> <C> 5 <C> 3.5 <C> 30% <C> 81% <R> <C> 6 <C> 5.7 <C> 20% <C> 73% <CAP> TABLE I: Location estimation results
<R> <C> [ITALIC] PE  [ITALIC] Kσ <C> [ITALIC] PE  [ITALIC] Kσ <C> 0.9 1 <C> 0.9 2 <C> 0.9 3 <C> 0.7 1 <C> 0.7 2 <C> 0.7 3 <C> 0.5 1 <C> 0.5 2 <C> 0.5 3 <R> <C> [ITALIC] PM <C> 0.9 <C> 96 <C> 95 <C> 92 <C> 94 <C> 88 <C> 83 <C> 83 <C> 78 <C> 72 <R> <C> [ITALIC] PM <C> 0.8 <C> 87 <C> 85 <C> 80 <C> 84 <C> 79 <C> 72 <C> 63 <C> 60 <C> 54 <R> <C> [ITALIC] PM <C> 0.7 <C> 75 <C> 74 <C> 72 <C> 66 <C> 65 <C> 61 <C> 55 <C> 50 <C> 50 <R> <C> [ITALIC] PM <C> 0.6 <C> 66 <C> 63 <C> 63 <C> 62 <C> 63 <C> 59 <C> 51 <C> 48 <C> 49 <CAP> TABLE II: Local topological structure estimation accuracy. Results are reported as the percent of timesteps during which the correct topological structure was estimated with highest probability (lowest entropy). PM is probability of sampling from the correct topology. PE is the probability of emitting observations. Kσ is the amount by which the variance is scaled. Each entry in the table was computed from performance over 1000 timesteps.
<R> <C> [BOLD] Algorithm <C> [BOLD] Metric <C> [ITALIC]  [BOLD] DS1 <C> [ITALIC]  [BOLD] DS2 <C> [ITALIC]  [BOLD] DS3 <R> <C> [ITALIC] Random Forest <C> Acc. <C> 1.0 <C> 0.99970 <C> 0.99997 <R> <C> [ITALIC] Random Forest <C> F1 <C> 1.0 <C> 0.99985 <C> 0.99999 <R> <C> [ITALIC] SVM <C> Acc. <C> 1.0 <C> 1.0 <C> 0.99994 <R> <C> [ITALIC] SVM <C> F1 <C> 1.0 <C> 1.0 <C> 0.99997 <R> <C> [ITALIC] k-nearest Neighbour <C> Acc. <C> 0.99710 <C> 0.99912 <C> 0.99941 <R> <C> [ITALIC] k-nearest Neighbour <C> F1 <C> 0.99853 <C> 0.99956 <C> 0.99971 <R> <C> [ITALIC] k Means Clustering <C> Acc. <C> 0.98102 <C> 0.55624 <C> 0.63362 <R> <C> [ITALIC] k Means Clustering <C> F1 <C> 0.99038 <C> 0.71485 <C> 0.77573 <CAP> TABLE III: Results of Packet-based Anomaly Detection
<R> <C> Model <C> Removed Pixels <C> ADE20k mIoU <C> ADE20k Acc <R> <C> Upernet <C> - <C> 0.377 <C> 78.31 <R> <C> DA (random) <C> Ignore <C> 0.320 <C> 75.2 <R> <C> DA (sizebased) <C> Ignore <C> 0.379 <C> 78.31 <R> <C> DA (hard negative) <C> Ignore <C> 0.375 <C> 77.8 <R> <C> DA (sizebased) <C> Negative <C> 0.377 <C> 78.25 <R> <C> DA (hard negative) <C> Negative <C> [BOLD] 0.385 <C> [BOLD] 78.47 <CAP> Table 3: Data augmentation results on ADE20k dataset
<R> <C> Model <C> all (407 images) Road <C> all (407 images) Sidewalk <C> with car (258) Road <C> with car (258) Sidewalk <C> without car (149) Road <C> without car (149) Sidewalk <R> <C> Upernet <C> 0.81 <C> 0.59 <C> [BOLD] 0.86 <C> [BOLD] 0.67 <C> 0.68 <C> 0.40 <R> <C> DataAug <C> [BOLD] 0.82 <C> [BOLD] 0.60 <C> [BOLD] 0.86 <C> 0.65 <C> [BOLD] 0.72 <C> [BOLD] 0.46 <CAP> Table 2: Comparing the performance of road and sidewalk segmentation on natural images with and without cars.
<R> <C> Model <C> Training Data <C> Full <C> Only Cooccur <C> Only Single <R> <C> Upernet <C> Full (5k) <C> 0.774 <C> 0.797 <C> 0.670 <R> <C> Data Aug <C> Full (5k) <C> 0.742 <C> 0.754 <C> [BOLD] 0.675 <R> <C> Upernet <C> Co-occur (3.3k) <C> 0.680 <C> 0.713 <C> 0.520 <R> <C> Data Aug <C> Co-occur (3.3k) <C> [BOLD] 0.82 <C> [BOLD] 0.86 <C> 0.646 <CAP> Table 4: Experiments in three class setting on ADE20k
<R> <C> dataset <C> | [ITALIC] X| <C> | [ITALIC] S| <C> | [ITALIC] P| <C> #leaves <C> #edges <C> #layers <C> setup (s) 32b <C> setup (s) 64b <C> setup (GB) 32b <C> setup (GB) 64b <C> online (s) 32b <C> online (s) 64b <C> online (MB) 32b <C> online (MB) 64b <R> <C> accidents <C> 111 <C> 22 <C> 4420 <C> 11100 <C> 27161 <C> 7 <C> 364.790 <C> 824.759 <C> 4.344846884 <C> 9.827901661 <C> 22.483 <C> 55.546 <C> 15.476771 <C> 30.949928 <R> <C> baudio <C> 100 <C> 22 <C> 4420 <C> 10000 <C> 26061 <C> 7 <C> 359.144 <C> 811.645 <C> 4.278353718 <C> 9.672070918 <C> 22.116 <C> 53.575 <C> 14.350017 <C> 28.696772 <R> <C> bbc <C> 1058 <C> 2 <C> 880 <C> 42320 <C> 44721 <C> 5 <C> 247.946 <C> 577.277 <C> 2.945730031 <C> 6.868429682 <C> 18.644 <C> 41.921 <C> 43.779831 <C> 87.525628 <R> <C> bnetflix <C> 100 <C> 2 <C> 4400 <C> 20000 <C> 32001 <C> 5 <C> 264.369 <C> 604.219 <C> 3.145345198 <C> 7.196644400 <C> 17.079 <C> 40.841 <C> 22.531776 <C> 45.060293 <R> <C> book <C> 500 <C> 2 <C> 880 <C> 20000 <C> 22401 <C> 5 <C> 134.476 <C> 311.635 <C> 1.596517534 <C> 3.706472180 <C> 9.806 <C> 22.328 <C> 20.906229 <C> 41.796343 <R> <C> c20ng <C> 910 <C> 2 <C> 880 <C> 36400 <C> 38801 <C> 5 <C> 217.939 <C> 523.526 <C> 2.587875051 <C> 6.029774956 <C> 16.381 <C> 37.619 <C> 37.712999 <C> 75.396714 <R> <C> cr52 <C> 889 <C> 10 <C> 1768 <C> 35560 <C> 41985 <C> 7 <C> 304.390 <C> 700.521 <C> 3.619301009 <C> 8.340147404 <C> 21.114 <C> 49.053 <C> 38.085061 <C> 76.141513 <R> <C> cwebkb <C> 839 <C> 10 <C> 1768 <C> 33560 <C> 39985 <C> 7 <C> 294.29858 <C> 676.65497 <C> 3.4984 <C> 8.0568 <C> 20.6358 <C> 46.8293 <C> 36.035452 <C> 72.043907 <R> <C> dna <C> 180 <C> 22 <C> 4420 <C> 18000 <C> 34061 <C> 7 <C> 400.175 <C> 906.7995 <C> 4.76194 <C> 10.80538 <C> 24.4088 <C> 59.44160 <C> 22.5445 <C> 45.083 <R> <C> jester <C> 100 <C> 2 <C> 4400 <C> 20000 <C> 32001 <C> 5 <C> 264.355 <C> 604.262 <C> 3.14534 <C> 7.1966 <C> 17.10386 <C> 40.8777 <C> 22.5317 <C> 45.0602 <R> <C> kdd <C> 64 <C> 10 <C> 1768 <C> 2560 <C> 8985 <C> 7 <C> 136.70284 <C> 307.8906 <C> 1.6245 <C> 3.6652 <C> 8.5308 <C> 20.8365 <C> 4.266557 <C> 8.531005 <R> <C> kosarek <C> 190 <C> 2 <C> 2200 <C> 19000 <C> 25001 <C> 5 <C> 178.182 <C> 409.5368 <C> 2.11687 <C> 4.87362 <C> 12.3329875 <C> 28.7319 <C> 20.4866 <C> 40.967 <R> <C> msnbc <C> 17 <C> 10 <C> 1768 <C> 680 <C> 7105 <C> 7 <C> 126.9435 <C> 285.3938 <C> 1.5108 <C> 3.3989 <C> 7.96834 <C> 19.07186 <C> 2.339926 <C> 4.679258 <R> <C> msweb <C> 294 <C> 22 <C> 4420 <C> 29400 <C> 45461 <C> 7 <C> 457.6946 <C> 1042.26683 <C> 5.451 <C> 12.420 <C> 29.0565 <C> 68.9942 <C> 34.221849 <C> 68.434206 <R> <C> plants <C> 69 <C> 2 <C> 4400 <C> 13800 <C> 25801 <C> 5 <C> 233.0806 <C> 530.5189 <C> 2.770567 <C> 6.318326 <C> 14.73527 <C> 35.330077 <C> 16.181983 <C> 32.361699 <R> <C> pumsb_star <C> 163 <C> 2 <C> 4400 <C> 32600 <C> 44601 <C> 5 <C> 328.2498 <C> 754.047 <C> 3.9069 <C> 8.9816 <C> 22.075988 <C> 52.048611 <C> 35.436199 <C> 70.867117 <R> <C> tmovie <C> 500 <C> 10 <C> 1768 <C> 20000 <C> 26425 <C> 7 <C> 225.16933 <C> 515.2254 <C> 2.6787 <C> 6.1358 <C> 14.937111 <C> 35.160811 <C> 22.139125 <C> 44.262135 <R> <C> tretail <C> 135 <C> 2 <C> 4400 <C> 27000 <C> 39001 <C> 5 <C> 299.88872 <C> 687.527 <C> 3.56848 <C> 8.1882965 <C> 19.84694 <C> 47.23953 <C> 29.7009 <C> 59.3974 <R> <C> nltcs <C> 16 <C> 2 <C> 880 <C> 640 <C> 3041 <C> 5 <C> 36.0104 <C> 81.1858 <C> 0.4262 <C> 0.9636 <C> 2.6949 <C> 5.8308 <C> 1.066 <C> 2.1315 <R> <C> nltcs <C> 16 <C> 2 <C> 2200 <C> 1600 <C> 7601 <C> 5 <C> 89.586 <C> 202.298 <C> 1.065 <C> 2.4087 <C> 5.857 <C> 13.845 <C> 2.664 <C> 5.426 <R> <C> nltcs <C> 16 <C> 2 <C> 4400 <C> 3200 <C> 15201 <C> 5 <C> 178.932 <C> 404.3435 <C> 2.1298 <C> 4.8166 <C> 11.312 <C> 27.351 <C> 5.3258 <C> 10.651193 <R> <C> nltcs <C> 16 <C> 10 <C> 1768 <C> 640 <C> 7065 <C> 7 <C> 126.802 <C> 284.8314 <C> 1.50844 <C> 3.39321 <C> 7.9706 <C> 19.55636 <C> 2.298934 <C> 4.597 <R> <C> nltcs <C> 16 <C> 22 <C> 4420 <C> 1600 <C> 17661 <C> 7 <C> 316.42786 <C> 711.7047 <C> 3.7706 <C> 8.4821 <C> 19.258 <C> 47.6545 <C> 5.746 <C> 11.491 <R> <C> nips <C> 100 <C> 7 <C> 17 <C> 1061 <C> 1084 <C> 11 <C> 26.04271 <C> 71.28372 <C> 0.2977530 <C> 0.83463 <C> 2.06278 <C> 5.0131688 <C> 1.300823 <C> 2.601594 <R> <C> nips <C> 100 <C> 7 <C> 17 <C> 1061 <C> 1084 <C> 11 <C> 28.54619† <C> 76.21134† <C> 0.327307† <C> 0.89374† <C> 2.16724† <C> 5.252681† <C> 1.762611† <C> 3.063386† <R> <C> nips <C> 100 <C> 15 <C> 43 <C> 2750 <C> 2807 <C> 15 <C> 65.803 <C> 182.21 <C> 0.77022 <C> 2.160 <C> 4.55309 <C> 12.382 <C> 3.043669 <C> 6.087289 <R> <C> nips <C> 100 <C> 15 <C> 43 <C> 2750 <C> 2807 <C> 15 <C> 72.702458† <C> 196.289† <C> 0.854092† <C> 2.32806† <C> 4.822130† <C> 12.872† <C> 4.354196† <C> 7.397817† <CAP> Table 1: Benchmarks of private SPN inference with CryptoSPN in a WAN network. The SPN has |X| RVs, |S| sum nodes, and |P| product nodes. Setup and online runtime as well as communication are measured for both 32- and 64-bit precision. All SPNs are RAT-SPNs with Bernoulli leaves except the ones for nips, which are regular SPNs with Poisson leaves. † indicates usage of a selection network for hiding RV assignments.
<R> <C> Alg. <C> Acc. <C> Prec. <C> Rec. <C> F-score <C> AUC <R> <C> RF-A <C> [BOLD] 0.9987 <C> [BOLD] 0.9965 <C> [BOLD] 0.9971 <C> [BOLD] 0.9968 <C> [BOLD] 0.9997 <R> <C> RF-S <C> 0.9986 <C> 0.9962 <C> 0.9966 <C> 0.9964 <C> [BOLD] 0.9997 <R> <C> [ITALIC] Difference <C> 0.0002 <C> 0.0003 <C> 0.0006 <C> 0.0005 <C> 0.0000 <R> <C> ET-A <C> 0.9981 <C> 0.9951 <C> 0.9951 <C> 0.9951 <C> 0.9994 <R> <C> ET-S <C> 0.9980 <C> 0.9950 <C> 0.9950 <C> 0.9950 <C> 0.9994 <R> <C> [ITALIC] Difference <C> 0.0001 <C> 0.0002 <C> 0.0001 <C> 0.0001 <C> 0.0000 <R> <C> ANN-A <C> 0.9802 <C> 0.9155 <C> 0.9908 <C> 0.9516 <C> 0.9984 <R> <C> ANN-S <C> 0.9740 <C> 0.8929 <C> 0.9860 <C> 0.9372 <C> 0.9968 <R> <C> [ITALIC] Difference <C> 0.0062 <C> 0.0226 <C> 0.0047 <C> 0.0145 <C> 0.0017 <R> <C> SVM-A <C> 0.9109 <C> 0.6996 <C> 0.9595 <C> 0.8092 <C> 0.9780 <R> <C> SVM-S <C> 0.8869 <C> 0.6433 <C> 0.9565 <C> 0.7692 <C> 0.9746 <R> <C> [ITALIC] Difference <C> 0.0239 <C> 0.0563 <C> 0.0030 <C> 0.0400 <C> 0.0034 <R> <C> GB-A <C> 0.9960 <C> 0.9854 <C> 0.9944 <C> 0.9899 <C> 0.9995 <R> <C> GB-S <C> 0.9957 <C> 0.9840 <C> 0.9945 <C> 0.9892 <C> 0.9996 <R> <C> [ITALIC] Difference <C> 0.0003 <C> 0.0014 <C> (0.0001) <C> 0.0007 <C> (0.0001) <R> <C> NB-A <C> 0.7753 <C> 0.4371 <C> 0.4888 <C> 0.4615 <C> 0.8601 <R> <C> NB-S <C> 0.7621 <C> 0.4144 <C> 0.5019 <C> 0.4539 <C> 0.8508 <R> <C> [ITALIC] Difference <C> 0.0132 <C> 0.0228 <C> (0.0131) <C> 0.0076 <C> 0.0093 <CAP> Table 3: Performance using all features vs selected features
<R> <C> Alg. <C> Acc. <C> Prec. <C> Rec. <C> F-score <C> AUC <R> <C> RF-D1 <C> [BOLD] 0.9973 <C> [BOLD] 0.9920 <C> [BOLD] 0.9945 <C> [BOLD] 0.9932 <C> [BOLD] 0.9993 <R> <C> RF-D2 <C> 0.9511 <C> 0.9446 <C> 0.7985 <C> 0.8654 <C> 0.9572 <R> <C> [ITALIC] Difference <C> 0.0463 <C> 0.0475 <C> 0.1960 <C> 0.1278 <C> 0.0421 <R> <C> ET-D1 <C> 0.9969 <C> 0.9913 <C> 0.9932 <C> 0.9923 <C> 0.9989 <R> <C> ET-D2 <C> 0.9756 <C> 0.9321 <C> 0.9448 <C> 0.9384 <C> 0.9954 <R> <C> [ITALIC] Difference <C> 0.0214 <C> 0.0592 <C> 0.0483 <C> 0.0538 <C> 0.0036 <R> <C> ANN-D1 <C> 0.9497 <C> 0.8300 <C> 0.9362 <C> 0.8799 <C> 0.9865 <R> <C> ANN-D2 <C> 0.5952 <C> 0.3241 <C> 0.9721 <C> 0.4862 <C> 0.7921 <R> <C> [ITALIC] Difference <C> 0.3544 <C> 0.5059 <C> (0.0359) <C> 0.3937 <C> 0.1945 <R> <C> SVM-D1 <C> 0.8489 <C> 0.5747 <C> 0.8968 <C> 0.7005 <C> 0.9252 <R> <C> SVM-D2 <C> 0.7195 <C> 0.3739 <C> 0.6281 <C> 0.4687 <C> 0.7886 <R> <C> [ITALIC] Difference <C> 0.1294 <C> 0.2008 <C> 0.2687 <C> 0.2318 <C> 0.1366 <R> <C> GB-D1 <C> 0.9881 <C> 0.9513 <C> 0.9904 <C> 0.9705 <C> 0.9986 <R> <C> GB-D2 <C> 0.9230 <C> 0.7692 <C> 0.8701 <C> 0.8165 <C> 0.9789 <R> <C> [ITALIC] Difference <C> 0.0652 <C> 0.1821 <C> 0.1204 <C> 0.1539 <C> 0.0198 <R> <C> NB-D1 <C> 0.7982 <C> 0.4881 <C> 0.5028 <C> 0.4953 <C> 0.8553 <R> <C> NB-D2 <C> 0.5591 <C> 0.2687 <C> 0.7195 <C> 0.3913 <C> 0.6591 <R> <C> [ITALIC] Difference <C> 0.2391 <C> 0.2194 <C> (0.2167) <C> 0.1040 <C> 0.1962 <CAP> Table 4: Performance using domain features vs constructed features
<R> <C> Attack <C> Count <C> All(%) <C> Sel.(%) <C> Dom.(%) <C> Cons.(%) <R> <C> Ddos <C> 4184 <C> 99.90 <C> 99.90 <C> 99.90 <C> 62.86 <R> <C> PortScan <C> 4973 <C> 99.90 <C> 99.94 <C> 99.94 <C> 66.28 <R> <C> Bot <C> 54 <C> 77.78 <C> 77.78 <C> 75.93 <C> 22.22 <R> <C> Infiltration <C> 1 <C> 100 <C> 100 <C> 100 <C> 0.00 <R> <C> Web Attack-BF <C> 49 <C> 95.92 <C> 95.92 <C> 91.84 <C> 75.51 <R> <C> Web Attack-XSS <C> 23 <C> 95.65 <C> 95.65 <C> 91.30 <C> 65.22 <R> <C> Web Attack-Sql <C> 1 <C> [BOLD] 0.00 <C> [BOLD] 0.00 <C> [BOLD] 100 <C> [BOLD] 0.00 <R> <C> FTP-Patator <C> 251 <C> 99.20 <C> 100 <C> 99.20 <C> 81.67 <R> <C> SSH-Patator <C> 198 <C> 98.99 <C> 99.49 <C> 96.97 <C> 75.76 <R> <C> DoS slowloris <C> 188 <C> 99.47 <C> 99.47 <C> 98.94 <C> 61.70 <R> <C> DoS Slowloris <C> 174 <C> 99.43 <C> 99.43 <C> 96.55 <C> 31.61 <R> <C> Dos Hulk <C> 7319 <C> 99.71 <C> 99.73 <C> 99.34 <C> 96.19 <R> <C> DoS GoldenEye <C> 314 <C> 99.36 <C> 99.68 <C> 98.41 <C> 85.03 <R> <C> Heartbleed <C> 1 <C> 100 <C> 100 <C> 100 <C> 100 <CAP> Table 6: Performance of unseen attack detection using RF
<R> <C> [BOLD] Metric <C> [BOLD] Direct <C> [BOLD] Hierarchical <R> <C> Average Total time (in seconds) <C> 51.908 <C> 10.695 <R> <C> Average Final Error <C> [−0.168,0.172] [ITALIC] T <C> [0.086,0.198] [ITALIC] T <R> <C> Average Final Maximum Belief Uncertainty <C> 0.696 <C> 0.625 <CAP> Table 1: Comparison of direct and hierarchical planning. Values are averaged over 5 runs. Planning horizon: 20 steps. Belief start: [5,5]T. actual start: [3.5,2.0]T. Termination condition: Maximum likelihood estimate of belief converged within a ball of 0.2 unit radius around the goal ([0,0]T) with max covariance of 1 unit.
<R> <C> Embedding <C> Distance ℓ1 <C> Distance ℓ2 <C> Distance Cosine <R> <C> FACSNet-CL-F <C> 47.1 <C> 47.1 <C> 40.7 <R> <C> FACSNet-CL-P <C> 45.3 <C> 44.2 <C> 48.3 <R> <C> AFFNet-CL-F <C> 49.0 <C> 47.7 <C> 49.0 <R> <C> AFFNet-CL-P <C> 52.4 <C> 51.6 <C> 53.3 <R> <C> AFFNet-TL <C> - <C> 49.6 <C> - <R> <C> FECNet-16d <C> - <C> 81.8 <C> - <CAP> Table 2: Triplet prediction accuracy on the FEC test set.
<R> <C> Dataset <C> Male <C> Female <C> Organization <C> Total <R> <C> ILLAE <C> 353 <C> 451 <C> 630 <C> [BOLD] 1,434 <R> <C> ILLAE <C> [ITALIC] 24.62% <C> [ITALIC] 31.45% <C> [ITALIC] 43.93% <C> [ITALIC] 100% <R> <C> CrowdFlower <C> 3,698 <C> 4,024 <C> 2,464 <C> [BOLD] 10,186 <R> <C> CrowdFlower <C> [ITALIC] 36.30% <C> [ITALIC] 39.51% <C> [ITALIC] 24.19% <C> [ITALIC] 100% <CAP> Table 1: Datasets with user distributions
<R> <C> [BOLD] Methods  [BOLD] Baselines <C> [BOLD] Methods  [BOLD] Majority (female) <C> [BOLD] Methods  [BOLD] Majority (female) <C> [BOLD] Accuracy(%) 39.51 <C> [ITALIC] F1 [BOLD] -Org(%) 0 <C> [ITALIC] F1 [BOLD] -Female(%) 56.63 <C> [ITALIC] F1 [BOLD] -Male(%) 0 <R> <C> [BOLD] Baselines <C> [BOLD] Organization/Individual <C> [BOLD] Organization/Individual <C> 14.50 <C> 68.74 <C> 0 <C> 0 <R> <C> [BOLD] Baselines <C> [BOLD] Name database <C> [BOLD] Name database <C> 46.67 <C> 0 <C> 68.66 <C> 70.11 <R> <C> [BOLD] Framework <C> [BOLD] Text <C> SVM <C> 62.02 <C> 70.90 <C> 65.02 <C> 52.10 <R> <C> [BOLD] Framework <C> [BOLD] Text <C> RF <C> 61.43 <C> 70.53 <C> 64.45 <C> 51.66 <R> <C> [BOLD] Framework <C> [BOLD] Image <C> SVM <C> 63.42 <C> 72.94 <C> 62.78 <C> 57.30 <R> <C> ≠≠≠≠≠≠≠≠≠±±±± <C> [BOLD] Image <C> RF <C> 64.55 <C> 75.71 <C> 64.83 <C> 56.63 <R> <C> [EMPTY] <C> [BOLD] Metadata <C> SVM <C> 48.70 <C> 52.07 <C> 56.47 <C> 34.36 <R> <C> [EMPTY] <C> [BOLD] Metadata <C> RF <C> 47.17 <C> 51.95 <C> 50.68 <C> 39.85 <R> <C> [EMPTY] <C> [BOLD] Proposed <C> [BOLD] SVM <C> [BOLD] 78.61 <C> [BOLD] 81.27 <C> [BOLD] 79.83 <C> [BOLD] 75.40 <R> <C> [EMPTY] <C> [BOLD] Proposed <C> RF <C> 76.56 <C> 78.86 <C> 78.72 <C> 72.64 <CAP> Table 3: Classifiers results in different feature sets for CrowdFlower dataset
<R> <C> [BOLD] Methods  [BOLD] Baselines <C> [BOLD] Methods  [BOLD] Majority (org) <C> [BOLD] Methods  [BOLD] Majority (org) <C> [BOLD] Accuracy(%) 43.93 <C> [ITALIC] F1 [BOLD] -Org(%) 61.01 <C> [ITALIC] F1 [BOLD] -Female(%) 0 <C> [ITALIC] F1 [BOLD] -Male(%) 0 <R> <C> [BOLD] Baselines <C> [BOLD] Organization/Individual <C> [BOLD] Organization/Individual <C> 37.31 <C> 84.85 <C> 0 <C> 0 <R> <C> [BOLD] Baselines <C> [BOLD] Name database <C> [BOLD] Name database <C> 45.08 <C> 0 <C> 71.41 <C> 73.20 <R> <C> [BOLD] Framework <C> [BOLD] Text <C> SVM <C> 67.50 <C> 82.41 <C> 63.37 <C> 37.14 <R> <C> [BOLD] Framework <C> [BOLD] Text <C> RF <C> 66.39 <C> 81.26 <C> 61.78 <C> 34.11 <R> <C> [BOLD] Framework <C> [BOLD] Image <C> SVM <C> 70.00 <C> 87.77 <C> 57.90 <C> 49.02 <R> <C> [BOLD] Framework <C> [BOLD] Image <C> RF <C> 72.24 <C> 91.65 <C> 63.53 <C> 44.54 <R> <C> [BOLD] Framework <C> [BOLD] Metadata <C> SVM <C> 57.67 <C> 70.02 <C> 50.62 <C> 38.85 <R> <C> [BOLD] Framework <C> [BOLD] Metadata <C> RF <C> 52.65 <C> 67.24 <C> 39.89 <C> 39.87 <R> <C> [BOLD] Framework <C> [BOLD] Proposed <C> SVM <C> 83.34 <C> 89.55 <C> 79.00 <C> 75.32 <R> <C> [BOLD] Framework <C> [BOLD] Proposed <C> [BOLD] RF <C> [BOLD] 85.99 <C> [BOLD] 92.21 <C> [BOLD] 83.13 <C> [BOLD] 77.25 <CAP> Table 2: Classifiers results in different feature sets for ILLAE dataset
<R> <C> [EMPTY] <C> Male <C> Female <C> Organization <C> Total <R> <C> User <C> 2,222 <C> 6,362 <C> 4,686 <C> [BOLD] 13,270 <R> <C> User <C> [ITALIC] 16.74% <C> [ITALIC] 47.95% <C> [ITALIC] 35.31% <C> [ITALIC] 100% <CAP> Table 4: User type distribution in entire ILLAE dataset
<R> <C> [EMPTY] <C> Male <C> Female <C> Organization <C> Total <R> <C> Tweet <C> 2,995 <C> 8,993 <C> 7,504 <C> [BOLD] 19,492 <R> <C> Tweet <C> [ITALIC] 15.36% <C> [ITALIC] 46.14% <C> [ITALIC] 38.50% <C> [ITALIC] 100% <R> <C> Retweet <C> 8,464 <C> 47,764 <C> 33,422 <C> [BOLD] 89,650 <R> <C> Retweet <C> [ITALIC] 9.44% <C> [ITALIC] 53.28% <C> [ITALIC] 37.28% <C> [ITALIC] 100% <R> <C> Favorite <C> 15,830 <C> 82,009 <C> 45,019 <C> [BOLD] 142,858 <R> <C> Favorite <C> [ITALIC] 11.08% <C> [ITALIC] 57.41% <C> [ITALIC] 31.51% <C> [ITALIC] 100% <CAP> Table 5: Tweet, retweet and favorite distribution in entire ILLAE dataset
<R> <C> Triplet type <C> AFFNet-CL-P <C> FECNet-16d <C> Median rater <R> <C> One-class <C> 49.2 <C> 77.1 <C> 85.3 <R> <C> Two-class <C> 59.8 <C> 85.1 <C> 89.3 <R> <C> Three-class <C> 50.4 <C> 82.6 <C> 87.2 <R> <C> All triplets <C> 53.3 <C> 81.8 <C> 87.5 <CAP> Table 3: Triplet prediction accuracy for different types of triplets in the FEC test set.
<R> <C> [EMPTY] <C> KL-D <C> CC <R> <C> Predicted attention weights <C> 0.49 <C> 0.74 <R> <C> Distance related weights <C> 0.99 <C> 0.61 <R> <C> Self-attention weights in  <C> 0.92 <C> 0.63 <CAP> TABLE I: Similarity of attention estimates. KL-D denotes Kullback-Leibler divergence and CC denotes Correlation Coefficient.
<R> <C> [EMPTY] <C> Success Rate Student003 <C> Success Rate NYC-GC <C> Success Rate Zara2 <C> Success Rate Hotel <C> Success Rate ETH <C> Success Rate  [BOLD] AVG <C> Navigation Time Student003 <C> Navigation Time NYC-GC <C> Navigation Time Zara2 <C> Navigation Time Hotel <C> Navigation Time ETH <C> Navigation Time  [BOLD] AVG <R> <C> SARL <C> 0.692 <C> 0.358 <C> 0.815 <C> 0.581 <C> 0.657 <C> 0.621 <C> 13.1 <C> 13.8 <C> 12.9 <C> 13.4 <C> 13.9 <C> 13.4 <R> <C> SA-GCNRL <C> 0.616 <C> 0.431 <C> 0.838 <C> 0.683 <C> 0.782 <C> 0.670 <C> 12.0 <C> 12.0 <C> 13.2 <C> 12.8 <C> 13.0 <C> 12.6 <R> <C> G-GCNRL <C> [BOLD] 0.753 <C> [BOLD] 0.453 <C> [BOLD] 0.936 <C> [BOLD] 0.703 <C> [BOLD] 0.831 <C> [BOLD] 0.735 <C> [BOLD] 11.2 <C> [BOLD] 11.8 <C> [BOLD] 10.9 <C> [BOLD] 11.1 <C> [BOLD] 11.1 <C> [BOLD] 11.2 <CAP> TABLE II: Comparison to the state-of-the-art, SARL.
<R> <C> [EMPTY] <C> Success Rate Student003 <C> Success Rate NYC-GC <C> Success Rate Zara2 <C> Success Rate Hotel <C> Success Rate ETH <C> Success Rate  [BOLD] AVG <C> Navigation Time Student003 <C> Navigation Time NYC-GC <C> Navigation Time Zara2 <C> Navigation Time Hotel <C> Navigation Time ETH <C> Navigation Time  [BOLD] AVG <R> <C> G-GCNRL <C> [BOLD] 0.753 <C> [BOLD] 0.453 <C> [BOLD] 0.936 <C> [BOLD] 0.703 <C> [BOLD] 0.831 <C> [BOLD] 0.735 <C> [BOLD] 11.2 <C> [BOLD] 11.8 <C> 10.9 <C> 11.1 <C> 11.1 <C> 11.2 <R> <C> SA-GCNRL <C> 0.616 <C> 0.431 <C> 0.838 <C> 0.683 <C> 0.782 <C> 0.670 <C> 12.0 <C> 12.0 <C> 13.2 <C> 12.8 <C> 13.0 <C> 12.6 <R> <C> D-GCNRL <C> 0.556 <C> 0.405 <C> 0.876 <C> 0.699 <C> 0.790 <C> 0.665 <C> 12.7 <C> 13.8 <C> 11.5 <C> 9.3 <C> 10.3 <C> 11.5 <R> <C> U-GCNRL <C> 0.671 <C> 0.387 <C> 0.928 <C> 0.687 <C> 0.827 <C> 0.700 <C> 11.2 <C> 12.0 <C> [BOLD] 10.1 <C> [BOLD] 9.3 <C> [BOLD] 10.2 <C> [BOLD] 10.6 <CAP> TABLE III: Additional ablation study to show the advantage of the attention weights trained based on human gaze data.
<R> <C> [EMPTY] <C> Success Rate Student003 <C> Success Rate NYC-GC <C> Success Rate Zara2 <C> Success Rate Hotel <C> Success Rate ETH <C> Success Rate AVG <C> Navigation Time Student003 <C> Navigation Time NYC-GC <C> Navigation Time Zara2 <C> Navigation Time Hotel <C> Navigation Time ETH <C> Navigation Time AVG <R> <C> SA-GCNRL <C> 0.616 <C> [BOLD] 0.431 <C> [BOLD] 0.838 <C> [BOLD] 0.683 <C> [BOLD] 0.782 <C> [BOLD] 0.670 <C> [BOLD] 12.0 <C> [BOLD] 12.0 <C> 13.2 <C> [BOLD] 12.8 <C> [BOLD] 13.0 <C> [BOLD] 12.6 <R> <C> SARL <C> [BOLD] 0.692 <C> 0.358 <C> 0.815 <C> 0.581 <C> 0.657 <C> 0.621 <C> 13.1 <C> 13.8 <C> [BOLD] 12.9 <C> 13.4 <C> 13.9 <C> 13.4 <R> <C> U-GCNRL <C> [BOLD] 0.671 <C> [BOLD] 0.387 <C> [BOLD] 0.928 <C> [BOLD] 0.687 <C> [BOLD] 0.827 <C> [BOLD] 0.700 <C> [BOLD] 11.2 <C> [BOLD] 12.0 <C> [BOLD] 10.1 <C> [BOLD] 9.3 <C> [BOLD] 10.2 <C> [BOLD] 10.6 <R> <C> UARL <C> 0.591 <C> 0.310 <C> 0.816 <C> 0.477 <C> 0.636 <C> 0.566 <C> 12.7 <C> 13.1 <C> 14.0 <C> 14.0 <C> 15.0 <C> 13.8 <CAP> TABLE IV: Additional ablation study to show the advantage of the graph structure.
<R> <C> Album <C> BO <C> CB <C> DT <C> GB <C> HC <C> JL <C> JC <C> KM <C> LJ <C> LS <R> <C> FECNet-16d vs AFFNet-CL-P <C> 5-2 <C> 9-1 <C> 5-1 <C> 9-0 <C> 10-0 <C> 9-0 <C> 7-1 <C> 10-0 <C> 1-4 <C> 1-6 <CAP> Table 4: Number of votes received by the summaries generated by the FECNet-16d and AFFNet-CL-P embeddings.
<R> <C> dataset <C> train #imgs <C> train #sents <C> validation #imgs <C> validation #sents <C> test #imgs <C> test #sents <C> #objs per sent <C> #rels per sent <C> #attrs per obj <C> #words per sent <R> <C> VisualGenome <C> 96,738 <C> 3,397,459 <C> 4,925 <C> 172,290 <C> 4,941 <C> 171,759 <C> 2.09 <C> 0.95 <C> 0.47 <C> 5.30 <R> <C> MSCOCO <C> 112,742 <C> 475,117 <C> 4,970 <C> 20,851 <C> 4,979 <C> 20,825 <C> 2.93 <C> 1.56 <C> 0.51 <C> 10.28 <CAP> Table 1: Statistics of VisualGenome and MSCOCO datasets for controllable image captioning with ASGs.
<R> <C> Method <C> VisualGenome B4 <C> VisualGenome M <C> VisualGenome R <C> VisualGenome C <C> VisualGenome S <C> VisualGenome G <C> VisualGenome G [ITALIC] o <C> VisualGenome G [ITALIC] a <C> VisualGenome G [ITALIC] r <C> MSCOCO B4 <C> MSCOCO M <C> MSCOCO R <C> MSCOCO C <C> MSCOCO S <C> MSCOCO G <C> MSCOCO G [ITALIC] o <C> MSCOCO G [ITALIC] a <C> MSCOCO G [ITALIC] r <R> <C> ST  <C> 11.1 <C> 17.0 <C> 34.5 <C> 139.9 <C> 31.1 <C> 1.2 <C> 0.5 <C> 0.7 <C> 0.5 <C> 10.5 <C> 16.8 <C> 36.2 <C> 100.6 <C> 24.1 <C> 1.8 <C> 0.8 <C> 1.1 <C> 1.0 <R> <C> BUTD  <C> 10.9 <C> 16.9 <C> 34.5 <C> 139.4 <C> 31.4 <C> 1.2 <C> 0.5 <C> 0.7 <C> 0.5 <C> 11.5 <C> 17.9 <C> 37.9 <C> 111.2 <C> 26.4 <C> 1.8 <C> 0.8 <C> 1.1 <C> 1.0 <R> <C> C-ST <C> 12.8 <C> 19.0 <C> 37.6 <C> 157.6 <C> 36.6 <C> 1.1 <C> 0.4 <C> 0.7 <C> 0.4 <C> 14.4 <C> 20.1 <C> 41.4 <C> 135.6 <C> 32.9 <C> 1.6 <C> 0.6 <C> 1.0 <C> 0.8 <R> <C> C-BUTD <C> 12.7 <C> 19.0 <C> 37.9 <C> 159.5 <C> 36.8 <C> 1.1 <C> 0.4 <C> 0.7 <C> 0.4 <C> 15.5 <C> 20.9 <C> 42.6 <C> 143.8 <C> 34.9 <C> 1.5 <C> 0.6 <C> 1.0 <C> 0.8 <R> <C> Ours <C> [BOLD] 17.6 <C> [BOLD] 22.1 <C> [BOLD] 44.7 <C> [BOLD] 202.4 <C> [BOLD] 40.6 <C> [BOLD] 0.7 <C> [BOLD] 0.3 <C> [BOLD] 0.3 <C> [BOLD] 0.3 <C> [BOLD] 23.0 <C> [BOLD] 24.5 <C> [BOLD] 50.1 <C> [BOLD] 204.2 <C> [BOLD] 42.1 <C> [BOLD] 0.7 <C> [BOLD] 0.4 <C> [BOLD] 0.3 <C> [BOLD] 0.3 <CAP> Table 2: Comparison with carefully designed baselines for controllable image caption generation conditioning on ASGs.
<R> <C> # <C> Enc role <C> Enc rgcn <C> Dec ctn <C> Dec flow <C> Dec gupdt <C> Dec bs <C> VisualGenome B4 <C> VisualGenome M <C> VisualGenome R <C> VisualGenome C <C> VisualGenome S <C> MSCOCO B4 <C> MSCOCO M <C> MSCOCO R <C> MSCOCO C <C> MSCOCO S <R> <C> 1 <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 11.2 <C> 18.3 <C> 36.7 <C> 146.9 <C> 35.6 <C> 13.6 <C> 19.7 <C> 41.3 <C> 130.2 <C> 32.6 <R> <C> 2 <C> [EMPTY] <C> [EMPTY] <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 10.7 <C> 18.2 <C> 36.9 <C> 146.3 <C> 35.5 <C> 14.5 <C> 20.4 <C> 42.2 <C> 135.7 <C> 34.6 <R> <C> 3 <C> ✓ <C> [EMPTY] <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 14.2 <C> 20.5 <C> 40.9 <C> 176.9 <C> 38.1 <C> 18.2 <C> 22.5 <C> 44.9 <C> 166.9 <C> 37.8 <R> <C> 4 <C> ✓ <C> ✓ <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> 15.7 <C> 21.4 <C> 43.6 <C> 191.7 <C> 40.0 <C> 21.6 <C> 23.7 <C> 48.6 <C> 190.5 <C> 40.9 <R> <C> 5 <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> [EMPTY] <C> [EMPTY] <C> 15.9 <C> 21.5 <C> 44.0 <C> 193.1 <C> 40.1 <C> 22.3 <C> 24.0 <C> 49.4 <C> 196.2 <C> 41.5 <R> <C> 6 <C> ✓ <C> ✓ <C> ✓ <C> [EMPTY] <C> ✓ <C> [EMPTY] <C> 15.8 <C> 21.4 <C> 43.5 <C> 191.6 <C> 39.9 <C> 21.8 <C> 24.1 <C> 49.1 <C> 194.2 <C> 41.4 <R> <C> 7 <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> [EMPTY] <C> 16.1 <C> 21.6 <C> 44.1 <C> 194.4 <C> 40.1 <C> 22.6 <C> 24.4 <C> 50.0 <C> 199.8 <C> 41.8 <R> <C> 8 <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> ✓ <C> [BOLD] 17.6 <C> [BOLD] 22.1 <C> [BOLD] 44.7 <C> [BOLD] 202.4 <C> [BOLD] 40.6 <C> [BOLD] 23.0 <C> [BOLD] 24.5 <C> [BOLD] 50.1 <C> [BOLD] 204.2 <C> [BOLD] 42.1 <CAP> Table 3: Ablation study to demonstrate contributions from different proposed components. (role: role-aware node embedding; rgcn: MR-GCN; ctn: graph content attention; flow: graph flow attention; gupdt: graph updating; bs: beam search)
<R> <C> [EMPTY] <C> Method <C> Div-1 <C> Div-2 <C> SelfCIDEr <R> <C> Visual Genome <C> Region <C> 0.41 <C> 0.43 <C> 0.47 <R> <C> Visual Genome <C> Ours <C> [BOLD] 0.54 <C> [BOLD] 0.63 <C> [BOLD] 0.75 <R> <C> MS COCO <C> BS  <C> 0.21 <C> 0.29 <C> - <R> <C> MS COCO <C> POS  <C> 0.24 <C> 0.35 <C> - <R> <C> MS COCO <C> SeqCVAE  <C> 0.25 <C> 0.54 <C> - <R> <C> MS COCO <C> BUTD-BS <C> 0.29 <C> 0.39 <C> 0.58 <R> <C> MS COCO <C> Ours <C> [BOLD] 0.43 <C> [BOLD] 0.56 <C> [BOLD] 0.76 <CAP> Table 4: Comparison with state-of-the-art approaches for diverse image caption generation.
<R> <C> [BOLD] System <C> [BOLD] Input type <C> [BOLD] Offline <C> [BOLD] Online <C> [BOLD] Hybrid <R> <C> ESN-Oja rule <C> Feature <C> 59.77% <C> 49.22% <C> 60.01% <R> <C> ESN-Oja rule <C> Signal <C> 54.30% <C> 58.98% <C> [BOLD] 60.29% <R> <C> ESN-BCM rule <C> Feature <C> 61.72% <C> 54.14% <C> [BOLD] 62.17% <R> <C> ESN-BCM rule <C> Signal <C> 56.25% <C> 50.00% <C> 59.34% <R> <C> ESN-IP rule <C> Feature <C> 61.21% <C> 59.11% <C> 62.39% <R> <C> ESN-IP rule <C> Signal <C> 68.28% [fourati2017optimized] <C> 62.98% <C> [BOLD] 69.23% <R> <C> SVM with PSD features [wichakam2014evaluation] <C> Feature <C> 63.40% <C> 63.40% <C> 63.40% <R> <C> HMM [torres2014comparative] <C> Signal <C> 55.00±4.5% <C> 55.00±4.5% <C> 55.00±4.5% <CAP> TABLE IV: Arousal Discrimination Results
<R> <C> [BOLD] System <C> [BOLD] Input type <C> [BOLD] Offline <C> [BOLD] Online <C> [BOLD] Hybrid <R> <C> ESN-Oja rule <C> Feature <C> 59.77% <C> 52.73% <C> 60.81% <R> <C> ESN-Oja rule <C> Signal <C> 61.26% <C> 54.92% <C> [BOLD] 62.13% <R> <C> ESN-BCM rule <C> Feature <C> 57.42% <C> 46.88% <C> 58.26% <R> <C> ESN-BCM rule <C> Signal <C> 56.25% <C> 41.67% <C> [BOLD] 59.31% <R> <C> ESN-IP rule <C> Feature <C> 53.52% <C> 55.86% <C> 57.94% <R> <C> ESN-IP rule <C> Signal <C> 71.03% [fourati2017optimized] <C> 66.23% <C> [BOLD] 71.25% <R> <C> SVM with bandpower features [wichakam2014evaluation] <C> Feature <C> 62.30% <C> 62.30% <C> 62.30% <R> <C> HMM [torres2014comparative] <C> Signal <C> 58.75±3.8% <C> 58.75±3.8% <C> 58.75±3.8% <CAP> TABLE V: Valence Discrimination Results
<R> <C> [BOLD] System <C> [BOLD] Input type <C> [BOLD] Offline <C> [BOLD] Online <C> [BOLD] Hybrid <R> <C> ESN-Oja rule <C> Feature <C> 35.49% <C> 42.23% <C> 48.29% <R> <C> ESN-Oja rule <C> Signal <C> 54.29% <C> 58.12 <C> [BOLD] 59.29% <R> <C> ESN-BCM rule <C> Feature <C> 32.42% <C> 33.98% <C> 41.58% <R> <C> ESN-BCM rule <C> Signal <C> 56.69% <C> 59.81% <C> [BOLD] 60.23% <R> <C> ESN-IP rule <C> Feature <C> 38.22% <C> 44.65% <C> 49.58% <R> <C> ESN-IP rule <C> Signal <C> 68.79% [fourati2017optimized] <C> 69.25% <C> [BOLD] 69.95% <R> <C> SVM with FD features[liu2013eeg] <C> Feature <C> 69.53% <C> 69.53% <C> 69.53% <CAP> TABLE VI: Emotional states Discrimination Results
<R> <C> [BOLD] System <C> [BOLD] Input type <C> [BOLD] Offline <C> [BOLD] Online <C> [BOLD] Hybrid <R> <C> ESN-Oja rule <C> Feature <C> 65.45% <C> 47.27% <C> 60.36% <R> <C> ESN-Oja rule <C> Signal <C> 61.82% <C> 65.45% <C> [BOLD] 67.27% <R> <C> ESN-BCM rule <C> Feature <C> [BOLD] 65.45% <C> 50.91% <C> 64.63% <R> <C> ESN-BCM rule <C> Signal <C> 49.09% <C> 54.55% <C> 58.29% <R> <C> ESN-IP rule <C> Feature <C> 69.06% <C> 65.45% <C> [BOLD] 76.15% <R> <C> ESN-IP rule <C> Signal <C> 41.82% <C> 49.09% <C> 61.27% <R> <C> SVM with entropy features[garcia2017symbolic] <C> Feature <C> 81.31% <C> 81.31% <C> 81.31% <CAP> TABLE VII: Stress/Calm Discrimination Results
<R> <C> [EMPTY] <C> [EMPTY] <C> [BOLD] Ep.1  [BOLD] A <C> [BOLD] Ep.1  [BOLD] P <C> [BOLD] Ep.1  [BOLD] R <C> [BOLD] Ep.2  [BOLD] A <C> [BOLD] Ep.2  [BOLD] P <C> [BOLD] Ep.2  [BOLD] R <C> [BOLD] Ep.3  [BOLD] A <C> [BOLD] Ep.3  [BOLD] P <C> [BOLD] Ep.3  [BOLD] R <C> [BOLD] Ep.4  [BOLD] A <C> [BOLD] Ep.4  [BOLD] P <C> [BOLD] Ep.4  [BOLD] R <C> [BOLD] Average  [BOLD] A <C> [BOLD] Average  [BOLD] P <C> [BOLD] Average  [BOLD] R <R> <C> Shape <C> One-shot <C> 0.68 <C> 0.82 <C> 0.69 <C> 0.65 <C> 0.67 <C> 0.65 <C> 0.66 <C> 0.67 <C> 0.66 <C> 0.63 <C> 0.64 <C> 0.64 <C> 0.65 <C> 0.7 <C> 0.66 <R> <C> Shape <C> Amortized <C> 0.76 <C> 0.83 <C> 0.76 <C> 0.68 <C> 0.71 <C> 0.69 <C> 0.73 <C> 0.75 <C> 0.73 <C> 0.68 <C> 0.68 <C> 0.68 <C> 0.71 <C> 0.74 <C> 0.71 <R> <C> Color <C> One-shot <C> 0.87 <C> 1.0 <C> 0.87 <C> 0.91 <C> 0.95 <C> 0.92 <C> 0.82 <C> 0.9 <C> 0.83 <C> 0.84 <C> 0.92 <C> 0.84 <C> 0.86 <C> 0.94 <C> 0.86 <R> <C> Color <C> Amortized <C> 0.89 <C> 1.0 <C> 0.89 <C> 0.98 <C> 0.99 <C> 0.99 <C> 0.86 <C> 0.93 <C> 0.87 <C> 0.85 <C> 0.91 <C> 0.85 <C> 0.89 <C> 0.95 <C> 0.9 <R> <C> Class <C> One-shot <C> 0.93 <C> 0.95 <C> 0.93 <C> 0.98 <C> 0.98 <C> 0.98 <C> 0.95 <C> 0.96 <C> 0.95 <C> 0.96 <C> 0.97 <C> 0.96 <C> 0.96 <C> 0.96 <C> 0.96 <R> <C> Class <C> Amortized <C> 0.99 <C> 0.99 <C> 0.99 <C> 0.96 <C> 0.96 <C> 0.96 <C> 0.92 <C> 0.94 <C> 0.92 <C> 0.89 <C> 0.90 <C> 0.90 <C> 0.92 <C> 0.92 <C> 0.93 <R> <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> Coverage one-shot <C> 82.2 % <C> 82.2 % <C> 82.2 % <R> <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> Coverage amortized <C> 94.3 % <C> 94.3 % <C> 94.3 % <CAP> Table III: Accuracy (A), Precision(P) and Recall(R) for shape, color and class annotations of object hypotheses with and without the amortization effects.
<R> <C> Parameterization <C> Surface <C> BFF  <C> PGCP <C> PGCP with an additional Möbius transformation <R> <C> Free-boundary <C> Sophie <C> 0.18 <C> 0.21 <C> 0.18 <R> <C> Free-boundary <C> Niccolò da Uzzano <C> 0.60 <C> 0.84 <C> 0.57 <R> <C> Free-boundary <C> Mask <C> 0.24 <C> 0.58 <C> 0.32 <R> <C> Free-boundary <C> Max Planck <C> 2.49 <C> 2.62 <C> 2.50 <R> <C> Free-boundary <C> Bunny <C> 2.68 <C> 3.32 <C> 2.95 <R> <C> Free-boundary <C> Julius <C> 0.28 <C> 1.04 <C> 0.52 <R> <C> Free-boundary <C> Buddha <C> 0.78 <C> 1.20 <C> 1.16 <R> <C> Disk-boundary <C> Ogre <C> 1.21 <C> 1.21 <C> 1.21 <R> <C> Disk-boundary <C> Niccolò da Uzzano <C> 0.76 <C> 0.86 <C> 0.57 <R> <C> Disk-boundary <C> Brain <C> 2.17 <C> 2.13 <C> 2.13 <R> <C> Disk-boundary <C> Gargoyle <C> 3.90 <C> 3.90 <C> 3.87 <R> <C> Disk-boundary <C> Hand <C> 5.29 <C> 5.25 <C> 5.25 <R> <C> Disk-boundary <C> Octopus <C> 6.79 <C> 8.13 <C> 8.13 <R> <C> Disk-boundary <C> Buddha <C> 0.78 <C> 0.79 <C> 0.77 <R> <C> Spherical <C> Horse <C> 27.03 <C> 8.90 <C> 6.54 <R> <C> Spherical <C> Bulldog <C> 6.74 <C> 1.09 <C> 1.08 <R> <C> Spherical <C> Chinese Lion <C> 4.46 <C> 1.93 <C> 1.74 <R> <C> Spherical <C> Duck <C> 7.92 <C> 1.00 <C> 0.84 <R> <C> Spherical <C> David <C> 0.85 <C> 0.85 <C> 0.36 <R> <C> Spherical <C> Octopus <C> 26.95 <C> 26.44 <C> 26.19 <R> <C> Spherical <C> Lion Vase <C> 7.13 <C> 0.92 <C> 0.84 <CAP> Table 7: The area distortion mean(|darea|) of the global conformal parameterizations produced by the boundary first flattening (BFF) method [56], the proposed PGCP method, and the proposed PGCP method with an additional step of composing with a Möbius transformation ((41) for free-boundary conformal parameterization, (42) for disk-boundary conformal parameterization, and (41) together with the stereographic projection for spherical conformal parameterization).
<R> <C> Surface <C> # vertices <C> CEM  Time (s) <C> CEM  mean(| [ITALIC] d|) <C> CEM  with CMG Time (s) <C> CEM  with CMG mean(| [ITALIC] d|) <C> PGCP Time (s) <C> PGCP mean(| [ITALIC] d|) <R> <C> Ogre <C> 20K <C> 0.3 <C> 2.6 <C> 0.3 <C> 2.6 <C> 0.5 <C> 1.5 <R> <C> Niccolò da Uzzano <C> 25K <C> 1.4 <C> 1.3 <C> 1.5 <C> 1.4 <C> 0.8 <C> 0.8 <R> <C> Brain <C> 48K <C> 2.9 <C> 1.5 <C> 2.8 <C> 1.5 <C> 1.3 <C> 1.5 <R> <C> Gargoyle <C> 50K <C> 2.8 <C> 2.1 <C> 3.2 <C> 2.1 <C> 1.4 <C> 1.9 <R> <C> Hand <C> 53K <C> 3.4 <C> 1.2 <C> 3.2 <C> 1.4 <C> 1.4 <C> 1.2 <R> <C> Octopus <C> 150K <C> 10.4 <C> 24.0 <C> 9.3 <C> 26.6 <C> 8.9 <C> 5.6 <R> <C> Buddha <C> 240K <C> 25.1 <C> 0.7 <C> 18.5 <C> 0.9 <C> 11.4 <C> 0.7 <R> <C> Nefertiti <C> 1M <C> 83.2 <C> 4.2 <C> 74.4 <C> 4.2 <C> 52.7 <C> 2.9 <CAP> Table 8: The performance of the conformal energy minimization (CEM) [26] method, CEM combined with the Combinatorial Multigrid (CMG) [58], and our proposed PGCP method for disk conformal parameterization of simply-connected open surfaces.
<R> <C> Bin <C> Data size <C> % of Jobs FB <C> % of Jobs CMU <C> % of Resources FB <C> % of Resources CMU <C> % of I/O FB <C> % of I/O CMU <C> Task Time (mins) FB <C> Task Time (mins) CMU <R> <C> A <C> 0-128MB <C> 74.4% <C> 63.4% <C> 25.0% <C> 32.3% <C> 3.2% <C> 10.9% <C> 76.7 <C> 119.5 <R> <C> B <C> 128-512MB <C> 16.2% <C> 29.1% <C> 12.2% <C> 27.9% <C> 16.1% <C> 30.5% <C> 37.6 <C> 103.2 <R> <C> C <C> 0.5-1GB <C> 4.0% <C> 0.9% <C> 7.3% <C> 1.3% <C> 12.0% <C> 2.4% <C> 22.3 <C> 5.0 <R> <C> D <C> 1-2GB <C> 3.0% <C> 4.9% <C> 13.4% <C> 21.0% <C> 19.3% <C> 23.3% <C> 41.0 <C> 77.6 <R> <C> E <C> 2-5GB <C> 1.6% <C> 1.5% <C> 20.8% <C> 15.1% <C> 21.9% <C> 27.8% <C> 63.9 <C> 55.7 <R> <C> F <C> 5-10GB <C> 0.8% <C> 0.3% <C> 21.4% <C> 2.5% <C> 27.5% <C> 5.2% <C> 65.6 <C> 9.2 <CAP> Table 3: Job size distributions. The jobs are binned by their data sizes in our FB and CMU workloads
<R> <C> Code version <C> Time (total) [s] <C> Speedup (total) <C> Time (fraction of total) (subfind_density) [s] <C> Speedup (subfind_density) <R> <C> [ITALIC] original <C> 167.4 <C> [EMPTY] <C> 22.6 (13.5%) <C> [EMPTY] <R> <C> [ITALIC] tuned <C> 142.1 <C> 1.2× <C> 17.1 (12.1%) <C> 1.3× <R> <C> [ITALIC] optimized <C> 137.1 <C> 1.2× <C> 12.7 (9.3%) <C> 1.8× <CAP> TABLE III: Performance results of the P-Gadget3 tests in three different code versions, indicated in the first column. The table reports the time to solution and speedup with respect to the original version for the whole application (second and third column, respectively) and for the subfind_density function (fourth and fifth column.
<R> <C> Label <C> Location <C> vCPU cores <C> GHz <C> RAM <C> Provider <R> <C> okeanos <C> Greece <C> 4 <C> 2.1 <C> 4 GB <C> Okeanos Global <R> <C> linode-SG <C> Singapore <C> 1 <C> 2.8 <C> 2 GB <C> Linode, LLC <R> <C> linode-US <C> California (US) <C> 1 <C> 2.0 <C> 1 GB <C> Linode, LLC <CAP> TABLE I: Execution testbed. All nodes equipped with Ubuntu Linux 18.04.2 LTS.
<R> <C> Group <C> Test User <C> Zurich Hauptbahnhof <C> ETH Zurich Hauptgebaüde <R> <C> 1 <C> 1 <C> 5. Walking <C> 3. Tram <R> <C> 1 <C> 2 <C> 3. Tram <C> 5. Walking <R> <C> 1 <C> 3 <C> 5. Walking <C> 5. Walking <R> <C> 2 <C> 1 <C> 3. Tram <C> 4. Bike <R> <C> 2 <C> 2 <C> 3. Tram <C> 5. Walking <R> <C> 2 <C> 3 <C> 4. Bike <C> 3. Tram <R> <C> [EMPTY] <C> Mean: <C> 3.8 <C> 4.17 <CAP> Table 2: Transport sustainability responses for the two points of interest.
<R> <C> Locations <C> Test users: <C> 1 <C> 2 <C> 3 <C> 4 <C> 5 <C> 6 <C> 7 <C> 8 <C> 9 <C> 10 <C> 11 <C> Mean <C> Median <C> Actual cycling risk  <R> <C> Spot A <C> [EMPTY] <C> 2 <C> 2 <C> 2 <C> 1 <C> 1 <C> 1 <C> 1 <C> 2 <C> 2 <C> 1 <C> 2 <C> 1.55 <C> 2 <C> 1.36 <R> <C> Spot B <C> [EMPTY] <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 2 <C> 1 <C> 1 <C> 1 <C> 1.09 <C> 1 <C> 0.42 <R> <C> Spot C <C> [EMPTY] <C> 2 <C> 1 <C> 1 <C> 1 <C> 2 <C> 3 <C> 1 <C> 3 <C> 4 <C> 2 <C> 2 <C> 2.0 <C> 2 <C> 6.21 <R> <C> Spot D <C> [EMPTY] <C> 3 <C> 3 <C> 3 <C> 2 <C> 4 <C> 4 <C> 2 <C> 2 <C> 3 <C> 4 <C> 4 <C> 3.09 <C> 3 <C> 8.31 <R> <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> Pearson correlation: <C> 0.94 <C> 0.85 <C> [EMPTY] <R> <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <C> Spearman correlation: <C> 1.0 <C> 1.0 <C> [EMPTY] <CAP> Table 3: Perceived cycling risk acquired via the Smart Agora app vs. the actual cycling risk calculated via an empirical model of real-world data [48] in the four urban spots of Figure 9. Users’ responses are in the range [1,5] with 1 for very safe and 5 for very dangerous.
<R> <C> [EMPTY] <C> [EMPTY] <C> [BOLD] cLTL+  [BOLD] (regular) <C> [BOLD] cLTL+  [BOLD] (grid) <C> [BOLD] cLTL+  [BOLD] (continuous) <R> <C> [BOLD] N <C> 4 <C> 10.54 <C> 9.74 <C> 72.04 <R> <C> [BOLD] N <C> 6 <C> 33.86 <C> 17.87 <C> 86.47 <R> <C> [BOLD] N <C> 8 <C> 1974.7 <C> 155.36 <C> 2286 <R> <C> [BOLD] N <C> 10 <C> 992.02 <C> 265.38 <C> 132.18 <R> <C> [BOLD] h <C> 30 <C> 389.97 <C> 853.75 <C> 108.87 <R> <C> [BOLD] h <C> 35 <C> 992.02 <C> 265.38 <C> 132.18 <R> <C> [BOLD] h <C> 40 <C> 2788.1 <C> 556.51 <C> 181.94 <R> <C> [BOLD] h <C> 45 <C> 1842.2 <C> 201.45 <C> 274.3 <R> <C> [BOLD] h <C> 50 <C> 2505 <C> 238.86 <C> 257.77 <R> <C> [BOLD] h <C> 55 <C> 2436.3 <C> 334.97 <C> 364.48 <R> <C> [BOLD] h <C> 60 <C> 3828.1 <C> 266.19 <C> 440.68 <R> <C> [ITALIC] τ <C> 0 <C> 992.02 <C> 265.38 <C> 132.18 <R> <C> [ITALIC] τ <C> 1 <C> 9367.1 <C> 507.96 <C> 829.41 <R> <C> [ITALIC] τ <C> 2 <C> 34222.1 <C> 323.74 <C> 18234 <CAP> TABLE I: Numerical results
<R> <C> [BOLD] N <C> 10 <C> [BOLD] cLTL 10.86 <C> [BOLD] cLTL+ 2.64 <R> <C> [BOLD] N <C> 20 <C> 10.12 <C> 5.87 <R> <C> [BOLD] N <C> 50 <C> 8.99 <C> 56.13 <R> <C> [BOLD] N <C> 500 <C> 12.72 <C> [ITALIC] TO <R> <C> [BOLD] h <C> 20 <C> 10.86 <C> 2.64 <R> <C> [BOLD] h <C> 40 <C> 26.84 <C> 5.32 <R> <C> [BOLD] h <C> 60 <C> 60.93 <C> 7.87 <CAP> TABLE II: Numerical results
<R> <C> [EMPTY] <C> Robust CBF <C> Non-Robust CBF <R> <C> Avg. WCT (ms) <C> 4.473 <C> 4.048 <R> <C> Var. of WCTs (ms2) <C> 5.793 <C> 3.435 <R> <C> Avg. Freq. (Hz) <C> 222 <C> 247 <R> <C> Time Violated (s) <C> 0 <C> 138 <CAP> Table II: Comparison of the Wall-Clock Times (WCTs) for solving the Quadratic Programs with and without the robust CBF formulation. The last entry is the duration during which the constraint was violated for each experiment.
<R> <C> Finch <C> Island A <C> Island B <C> Island C <C> Island D <C> Island E <C> Island F <C> Island G <C> Island H <C> Island I <C> Island J <C> Island K <C> Island L <C> Island M <C> Island N <C> Island O <C> Island P <C> Island Q <R> <C> 1 <C> 0 <C> 0 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <R> <C> 2 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 0 <R> <C> 3 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 0 <R> <C> 4 <C> 0 <C> 0 <C> 1 <C> 1 <C> 1 <C> 0 <C> 0 <C> 1 <C> 0 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 1 <C> 1 <C> 1 <R> <C> 5 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 0 <R> <C> 6 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 1 <C> 0 <C> 1 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> 7 <C> 0 <C> 0 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 0 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 0 <R> <C> 8 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 1 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> 9 <C> 0 <C> 0 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 0 <C> 0 <C> 1 <C> 0 <C> 0 <R> <C> 10 <C> 0 <C> 0 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 0 <R> <C> 11 <C> 0 <C> 0 <C> 1 <C> 1 <C> 1 <C> 0 <C> 1 <C> 1 <C> 0 <C> 1 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> 12 <C> 0 <C> 0 <C> 1 <C> 1 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> 13 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <CAP> Table 1: Occurrence Matrix occurrence matrix of the finches on the Galapagos islands.
<R> <C> Method <C> Filled portion <C> Number of swaps <C> Time per swap (/s) <R> <C> Rectangle Loop <C> 1% <C> 586 <C> 1.18×10−5 <R> <C> Swap <C> 1% <C> 8 <C> 3.67×10−4 <R> <C> Rectangle Loop <C> 5% <C> 977 <C> 5.30×10−6 <R> <C> Swap <C> 5% <C> 42 <C> 3.52×10−5 <R> <C> Rectangle Loop <C> 10% <C> 1838 <C> 3.23×10−6 <R> <C> Swap <C> 10% <C> 156 <C> 1.25×10−5 <R> <C> Rectangle Loop <C> 20% <C> 3271 <C> 2.64×10−6 <R> <C> Swap <C> 20% <C> 509 <C> 5.68×10−6 <R> <C> Rectangle Loop <C> 30% <C> 4222 <C> 2.10×10−6 <R> <C> Swap <C> 30% <C> 803 <C> 5.06×10−6 <R> <C> Rectangle Loop <C> 40% <C> 4794 <C> 1.27×10−6 <R> <C> Swap <C> 40% <C> 1160 <C> 4.98×10−6 <R> <C> Rectangle Loop <C> 50% <C> 5080 <C> 1.37×10−6 <R> <C> Swap <C> 50% <C> 1271 <C> 5.36×10−6 <CAP> Table 4: The comparison between swap algorithm and Rectangle Loop algorithm. Each algorithm is implemented 10000 iterations on 100×100 matrices with different filled portions. The third column records the number of successful swaps among the 10000 iterations, the last column records the average time per swap, respectively.
<R> <C> [ITALIC] δ <C> Hamming bound length of vector ( [ITALIC] m/log [ITALIC] n) <C> Hamming bound exponent ( [ITALIC] γ′) <C> GV bound length of vector ( [ITALIC] m/log [ITALIC] n) <C> GV bound exponent ( [ITALIC] γ′) <R> <C> 0.01 <C> 1.0476 <C> 1.0742 <C> 1.0879 <C> 1.0770 <R> <C> 0.025 <C> 1.1074 <C> 1.1591 <C> 1.2029 <C> 1.1728 <R> <C> 0.05 <C> 1.2029 <C> 1.2844 <C> 1.4013 <C> 1.3313 <R> <C> 0.075 <C> 1.2999 <C> 1.4021 <C> 1.6242 <C> 1.5024 <R> <C> 0.1 <C> 1.4013 <C> 1.5171 <C> 1.8832 <C> 1.6949 <R> <C> 0.125 <C> 1.5090 <C> 1.6316 <C> 2.1909 <C> 1.9170 <R> <C> 0.133 <C> 1.5449 <C> 1.6684 <C> 2.3064 <C> 1.9989 <CAP> Table 1: Running time of our algorithm when vector length m and relative distance δ meets the Hamming bound and GV bound
<R> <C> Data Source <C> Frequency <C> Percent <R> <C> WOS (matched Unpaywall Only articles & reviews) <C> 11,661,206 <C> 57.5% <R> <C> WOS (Only articles & reviews 2000-2017) <C> 20,280,606 <C> - <R> <C> Scopus (matched Unpaywall Only articles & reviews) <C> 14,188,983 <C> 53.48% <R> <C> Scopus (Only articles & reviews 2000-2017) <C> 26,532,295 <C> - <CAP> Table 1: All publications from WOS (2000-2017) and Scopus (2000-2017) that have an equivalent record in Unpaywall database (joined by DOIs)
<R> <C> Number of licences per DOI <C> Frequency of DOIs <C> Percent <R> <C> 0 <C> 9,892,208 <C> 51.41 <R> <C> 1 <C> 8,520,158 <C> 44.28 <R> <C> 2 <C> 824,975 <C> 4.29 <R> <C> 3 <C> 5,770 <C> 0.03 <R> <C> 5 <C> 25 <C> 0.00 <R> <C> 6 <C> 7 <C> 0.00 <CAP> Table 2: Number of licences per DOI found in Crossref
<R> <C> Crossref OA Status <C> Unpaywall OA Status <C> Frequency <C> Percent <R> <C> Closed Access <C> Closed Access <C> 4,452,185 <C> 38.18 <R> <C> [EMPTY] <C> Closed Access <C> 3,512,794 <C> 30.12 <R> <C> [EMPTY] <C> Open Access <C> 1,770,612 <C> 15.18 <R> <C> Closed Access <C> Open Access <C> 1,363,525 <C> 11.69 <R> <C> Open Access <C> Open Access <C> 435,516 <C> 3.73 <R> <C> Open Access <C> Closed Access <C> 126,354 <C> 1.08 <R> <C> Closed Access <C> [EMPTY] <C> 26 <C> 0.00 <R> <C> [EMPTY] <C> [EMPTY] <C> 19 <C> 0.00 <CAP> Table 3: OA status comparison between Unpaywall and Crossref in WOS publications
<R> <C> PDF Manually accessible? <C> Licence status <C> Pub OA? <C> Frequency <C> Percent <R> <C> PDF Accessible <C> Open Access <C> Unpaywall OA <C> 104 <C> 46.85 <R> <C> No Access to PDF <C> Closed Access <C> Unpaywall non-OA <C> 44 <C> 19.82 <R> <C> No Access to PDF <C> Open Access <C> Unpaywall non-OA <C> 18 <C> 8.11 <R> <C> No Access to PDF <C> Closed Access <C> Unpaywall OA <C> 16 <C> 7.21 <R> <C> PDF Accessible <C> Closed Access <C> Unpaywall OA <C> 16 <C> 7.21 <R> <C> PDF Accessible <C> Closed Access <C> Unpaywall non-OA <C> 14 <C> 6.31 <R> <C> No Access to PDF <C> Open Access <C> Unpaywall OA <C> 5 <C> 2.25 <R> <C> [EMPTY] <C> Closed Access <C> Unpaywall non-OA <C> 1 <C> 0.45 <R> <C> No Access to PDF <C> Closed Access <C> Missing on Unpaywall <C> 1 <C> 0.45 <R> <C> PDF Accessible <C> [EMPTY] <C> Unpaywall non-OA <C> 1 <C> 0.45 <R> <C> PDF Accessible <C> Open Access <C> Unpaywall non-OA <C> 1 <C> 0.45 <R> <C> PDF Accessible <C> [EMPTY] <C> Unpaywall OA <C> 1 <C> 0.45 <CAP> Table 5: Random sample OA status check on publications from WOS
<R> <C> Number of cells per node <C> 4096 <R> <C> Number of particles per cell <C> 2048 <R> <C> Compilation flags <C> -openmp, -mavx (Cluster), <R> <C> [EMPTY] <C> -xMIC-AVX512 (Booster) <CAP> TABLE II: xPic experiment setup in the Cluster-Booster architecture evaluation measurements.
<R> <C> #  [BOLD] buses <C> [BOLD] Heuristic <C> [BOLD] Avg Latency <C> [BOLD] Conf. Int. (95%) <C> [BOLD] Errors <R> <C> 60 <C> Fixed Random <C> 72.68 sec <C> [70.43, 74.94] sec <C> 15.37% <R> <C> 60 <C> Dynamic Random <C> 56.0 sec <C> [54.51, 57.5] sec <C> 18.26% <R> <C> 60 <C> Adaptive RTT <C> 22.99 sec <C> [22.69, 23.29] sec <C> 0.81% <R> <C> 120 <C> Fixed Random <C> 87.75 sec <C> [85.38, 90.12] sec <C> 29.49% <R> <C> 120 <C> Dynamic Random <C> 67.6 sec <C> [66.29, 68.9] sec <C> 18.99% <R> <C> 120 <C> Adaptive RTT <C> 27.35 sec <C> [27.11, 27.58] sec <C> 1.1% <R> <C> 240 <C> Fixed Random <C> 177.62 sec <C> [174.25, 181.0] sec <C> 42.81% <R> <C> 240 <C> Dynamic Random <C> 128.2 sec <C> [126.28, 130.12] sec <C> 44.85% <R> <C> 240 <C> Adaptive RTT <C> 73.26 sec <C> [72.68, 73.85] sec <C> 7.55% <CAP> Table I: Results on IOTA, with 60, 120, 240 buses.
<R> <C> #  [BOLD] buses <C> [BOLD] Avg Latency <C> [BOLD] Conf. Int. (95%) <C> [BOLD] Errors <R> <C> 120 <C> 777.17 msec <C> [774.68, 779.65] msec <C> 2.73% <CAP> Table II: Preliminary results on Radix.
<R> <C> [EMPTY] <C> Virginia (US) <C> Japan <C> India <C> Australia <R> <C> Virginia (US) <C> [BOLD] 198 <C> 238 <C> 306 <C> 303 <R> <C> Japan <C> 236 <C> [BOLD] 167 <C> 239 <C> 246 <R> <C> India <C> 304 <C> 242 <C> [BOLD] 229 <C> 305 <R> <C> Australia <C> 303 <C> 232 <C> 304 <C> [BOLD] 229 <CAP> TABLE I: Zyzzyva’s [14] latencies (in ms) in a geo-scale deployment with primary at different locations. Columns indicate the primary’s location. Rows indicate average client-side latency for commands issued from that region. For example, the entry at the 4th row and the 3rd column shows the client-side latency for commands issued from India to the primary in Japan. Lowest latency per primary location is highlighted.
<R> <C> [BOLD] Protocol <C> [BOLD] PBFT <C> [BOLD] Zyzzyva <C> [BOLD] Aliph <C> [BOLD] ezBFT <R> <C> Resilience <C> [ITALIC] f< [ITALIC] n/3 <C> [ITALIC] f< [ITALIC] n/3 <C> [ITALIC] f< [ITALIC] n/3 <C> [ITALIC] f< [ITALIC] n/3 <R> <C> Best-case comm. steps <C> 5 <C> 3 <C> 2 <C> 3 <R> <C> Best-case comm. steps in absence of … <C> Byz. Slow links <C> Byz. Slow links Contention <C> Byz. Slow links Contention <C> Byz. Slow links Contention <R> <C> Slow-path steps <C> - <C> 2 <C> n + 3 <C> 2 <R> <C> Leader <C> Single <C> Single <C> Single <C> Leaderless <CAP> TABLE II: Comparison of existing BFT protocols and ezBFT.
<R> <C> Addr. <C> Exec. (s) <C> Runt. (s) <C> Transm. (s) <C> Total (s) <R> <C> Client <C> 8.10 (0.21) <C> 3.55 (0.11) <C> 0.87 (-) <C> 12.52 (0.32) <R> <C> AoT <C> 9.94 (0.26) <C> 3.77 (0.08) <C> 20.44 (0.13) <C> 34.15 (0.47) <CAP> TABLE I: Average runtimes of workflow parts in the ring scenario in client-only tests and using AoT addressing.
<R> <C> Assign. <C> Exec. (s) <C> Runt. (s) <C> Transm. (s) <C> Total (s) <R> <C> Recent <C> 9.65 (0.26) <C> 3.89 (0.09) <C> 50.94 (10.20) <C> 64.48 (10.50) <R> <C> Random <C> 9.82 (0.16) <C> 3.93 (0.09) <C> 32.60 (4.27) <C> 46.35 (4.25) <R> <C> Best <C> 10.02 (0.28) <C> 3.94 (0.08) <C> 23.54 (9.63) <C> 37.49 (9.99) <R> <C> Spread <C> 9.95 (0.20) <C> 3.95 (0.09) <C> 24.05 (6.82) <C> 37.94 (7.11) <CAP> TABLE II: Average runtimes of workflow parts in the ring scenario using JiT addressing and all four assignments.
<R> <C> Assign. <C> Exec. (s) <C> Runt. (s) <C> Transm. (s) <C> Total (s) <R> <C> Recent <C> 8.7 (0.64) <C> 5.0 (1.89) <C> 269.0 (336.37) <C> 282.8 (338.91) <R> <C> Random <C> 8.9 (1.02) <C> 5.0 (1.84) <C> 254.9 (300.75) <C> 268.8 (303.61) <R> <C> Best <C> 8.9 (0.62) <C> 5.2 (1.80) <C> 135.5 (191.26) <C> 149.6 (193.68) <R> <C> Spread <C> 8.9 (0.68) <C> 5.1 (1.95) <C> 234.2 (300.75) <C> 248.1 (303.61) <CAP> TABLE III: Average runtimes of tasks in mobile JiT scenarios in seconds.
<R> <C> [BOLD] Nodes <C> [BOLD] Avg. latency of sending message <C> [BOLD] Avg. latency of getting message <R> <C> [BOLD] chief <C> 0.149 ( [ITALIC] σ = 0.031) <C> 0.043 ( [ITALIC] σ = 0.039) <R> <C> [BOLD] worker 1 <C> 0.036 ( [ITALIC] σ = 0.020) <C> 0.041 ( [ITALIC] σ = 0.028) <R> <C> [BOLD] worker 2 <C> 0.037 ( [ITALIC] σ = 0.029) <C> 0.042 ( [ITALIC] σ = 0.025) <R> <C> [BOLD] worker 3 <C> 0.036 ( [ITALIC] σ = 0.033) <C> 0.043 ( [ITALIC] σ = 0.021) <R> <C> [BOLD] worker 4 <C> 0.037 ( [ITALIC] σ = 0.026) <C> 0.041 ( [ITALIC] σ = 0.022) <CAP> Table 2: Average latency of sending and getting a message from the BSMD
<R> <C> [BOLD] Model <C> [BOLD] FNR <C> [BOLD] Precision <C> [BOLD] f1-score <C> [BOLD] Accuracy <C> [BOLD] FPR <R> <C> SVM <C> 04.81% <C> 96.62% <C> 95.90% <C> 95.93% <C> 3.33% <R> <C> [EMPTY] <C> (±1.15%) <C> (±0.40%) <C> (±0.80%) <C> (±0.77%) <C> [EMPTY] <R> <C> XGBoost <C> 02.97% <C> 93.59% <C> 95.28% <C> 95.19% <C> 6.64% <R> <C> [EMPTY] <C> (±0.20%) <C> (±0.31%) <C> (±0.23%) <C> (±0.25%) <C> [EMPTY] <R> <C> DNN <C> 13.50% <C> [BOLD] 98.77% <C> 92.22% <C> 92.70% <C> [BOLD] 1.00% <R> <C> [EMPTY] <C> (±0.64%) <C> (±0.62%) <C> (±0.46%) <C> (±0.42%) <C> [EMPTY] <R> <C> RF <C> 04.18% <C> 92.52% <C> 94.14% <C> 94.03% <C> 7.76% <R> <C> [EMPTY] <C> (±0.55%) <C> (±0.98%) <C> (±0.34%) <C> (±0.38%) <C> [EMPTY] <R> <C> K-NN <C> 02.80% <C> 93.36% <C> 95.25% <C> 95.15% <C> 6.91% <R> <C> [EMPTY] <C> (±0.48%) <C> (±0.70%) <C> (±0.55%) <C> (±0.57%) <C> [EMPTY] <R> <C> ELM <C> 03.00% <C> 94.51% <C> 95.76% <C> 95.70% <C> 5.60% <R> <C> [EMPTY] <C> (±0.30%) <C> (±0.47%) <C> (±0.31%) <C> (±0.30%) <C> [EMPTY] <R> <C> Malytics <C> [BOLD] 01.44% <C> 96.45% <C> [BOLD] 97.36% <C> [BOLD] 97.33% <C> 3.90% <R> <C> [EMPTY] <C> (±0.33%) <C> (±0.45%) <C> (±0.29%) <C> (±0.30%) <C> [EMPTY] <R> <C>  <C> 06.37% <C> − <C> − <C> 95.93% <C> 3.96% <R> <C>  <C> 3.00% <C> 95.00% <C> 96.00% <C> − <C> − <CAP> TABLE II: The Mean and Std of Malytics and the baselines for Drebin Dataset.
<R> <C> [BOLD] Model <C> [BOLD] FNR <C> [BOLD] Precision <C> [BOLD] f1-score <C> [BOLD] Accuracy <C> [BOLD] FPR <R> <C> SVM <C> 08.00% <C> 94.77% <C> 93.34% <C> 93.44% <C> 05.07% <R> <C> [EMPTY] <C> (±0.48%) <C> (±0.25%) <C> (±0.18%) <C> (±0.16%) <C> [EMPTY] <R> <C> XGBoost <C> 10.12% <C> 90.74% <C> 90.30% <C> 90.35% <C> 09.17% <R> <C> [EMPTY] <C> (±0.55%) <C> (±0.39%) <C> (±0.36%) <C> (±0.35%) <C> [EMPTY] <R> <C> DNN <C> 24.40% <C> 90.40% <C> 82.23% <C> 83.72% <C> 08.13% <R> <C> [EMPTY] <C> (±3.53%) <C> (±1.73%) <C> (±1.45%) <C> (±0.89%) <C> [EMPTY] <R> <C> RF <C> 13.07% <C> 92.73% <C> 89.73% <C> 90.05% <C> 06.82% <R> <C> [EMPTY] <C> (±0.35%) <C> (±0.32%) <C> (±0.22%) <C> (±0.21%) <C> [EMPTY] <R> <C> K-NN <C> 7.45% <C> 93.36% <C> 91.38% <C> 91.28% <C> 10.00% <R> <C> [EMPTY] <C> (±0.48%) <C> (±0.70%) <C> (±0.55%) <C> (±0.57%) <C> [EMPTY] <R> <C> ELM <C> 16.50% <C> 92.25% <C> 87.66% <C> 88.24% <C> 07.00% <R> <C> [EMPTY] <C> (±0.29%) <C> (±0.67%) <C> (±0.30%) <C> (±0.36%) <C> [EMPTY] <R> <C> Malytics <C> [BOLD] 05.53% <C> [BOLD] 95.88% <C> [BOLD] 95.17% <C> [BOLD] 95.20% <C> [BOLD] 04.06% <R> <C> [EMPTY] <C> (±0.46%) <C> (±0.40%) <C> (±0.20%) <C> (±0.20%) <C> [EMPTY] <R> <C>  <C> 11.60% <C> 88.16% <C> − <C> 88.26% <C> − <R> <C> [EMPTY] <C> (±2.76%) <C> (±1.8%) <C> − <C> (±1.73%) <C> [EMPTY] <CAP> TABLE III: The Mean and Std of Malytics and the baselines for DexShare Dataset.
<R> <C> [BOLD] Model <C> [BOLD] FNR <C> [BOLD] Precision <C> [BOLD] f1-score <C> [BOLD] Accuracy <C> [BOLD] FPR <R> <C> Malytics (APK) <C> 09.43% <C> 91.76% <C> 91.16% <C> 91.22% <C> 8.1% <R> <C> [EMPTY] <C> (±0.61%) <C> (±0.73%) <C> (±0.54%) <C> (±0.48%) <C> [EMPTY] <R> <C> Malytics (Dex, MBR=0.5) <C> 05.33% <C> 95.88% <C> 95.17% <C> 95.20% <C> 4.1% <R> <C> [EMPTY] <C> (±0.46%) <C> (±0.40%) <C> (±0.20%) <C> (±0.20%) <C> [EMPTY] <R> <C> Malytics (Dex, MBR=0.2) <C> [BOLD] 05.27% <C> [BOLD] 98.45% <C> 96.55% <C> 98.65% <C> 3.7% <R> <C> [EMPTY] <C> (±0.63%) <C> (±0.69%) <C> (±0.55%) <C> (±0.21%) <C> [EMPTY] <R> <C> Malytics (Zero-day) <C> [BOLD] 10.59% <C> [BOLD] 96.31% <C> [BOLD] 92.68% <C> 92.99% <C> 3.4% <R> <C>  <C> 12.00% <C> 86.00% <C> 87.00% <C> − <C> − <CAP> TABLE IV: The Mean and Std of Malytics for DexShare dataset on the APK, Dex. Also, the results when the dataset is imbalanced and for zero-day (novel families) detection.
<R> <C> [BOLD] Dataset <C> [BOLD] FNR <C> [BOLD] Precision <C> [BOLD] f1-score <C> [BOLD] Accuracy <C> [BOLD] FPR <R> <C> Drebin <C> 01.53% <C> 96.68% <C> 97.56% <C> 97.54% <C> 3.38% <R> <C> [EMPTY] <C> (±0.50%) <C> (±0.45%) <C> (±0.40%) <C> (±0.30%) <C> [EMPTY] <R> <C> DexShare <C> 04.72% <C> 96.69% <C> 95.96% <C> 96.00% <C> 3.30% <R> <C> [EMPTY] <C> (±0.50%) <C> (±0.35%) <C> (±0.38%) <C> (±0.35%) <C> [EMPTY] <R> <C> DexShare (MBR=0.2) <C> [BOLD] 04.42% <C> 98.91% <C> 97.21% <C> 98.90% <C> [BOLD] 2.60% <R> <C> [EMPTY] <C> (±0.27%) <C> (±0.82%) <C> (±0.53%) <C> (±0.18%) <C> [EMPTY] <CAP> TABLE V: The Mean and Std of Malytics with sparse tf-simashing for both Drebin and DexShare Datasets.
<R> <C> [BOLD] Model <C> [BOLD] FNR <C> [BOLD] Precision <C> [BOLD] f1-score <C> [BOLD] Accuracy <C> [BOLD] AUC <C> [BOLD] FPR <R> <C> SVM <C> 1.30% <C> 99.13% <C> 98.91% <C> 98.92% <C> 98.92% <C> 0.86% <R> <C> [EMPTY] <C> (±0.30%) <C> (±0.25%) <C> (±0.26%) <C> (±0.26%) <C> (±0.25%) <C> [EMPTY] <R> <C> XGBoost <C> 1.30% <C> 98.43% <C> 98.56% <C> 98.56% <C> 98.57% <C> 1.57% <R> <C> [EMPTY] <C> (±0.27%) <C> (±0.26%) <C> (±0.19%) <C> (±0.19%) <C> (±0.19%) <C> [EMPTY] <R> <C> DNN <C> 2.51% <C> 96.77% <C> 97.11% <C> 97.09% <C> 97.09% <C> 3.31% <R> <C> [EMPTY] <C> (±0.59%) <C> (±2.04%) <C> (±0.78%) <C> (±0.83%) <C> (±0.83%) <C> [EMPTY] <R> <C> RF <C> 2.18% <C> 98.44% <C> 98.13% <C> 98.14% <C> 98.14% <C> 1.55% <R> <C> [EMPTY] <C> (±0.35%) <C> (±0.32%) <C> (±0.22%) <C> (±0.21%) <C> (±0.25%) <C> [EMPTY] <R> <C> K-NN <C> 1.56% <C> 98.50% <C> 98.47% <C> 98.47% <C> 98.47% <C> 1.50% <R> <C> [EMPTY] <C> (±0.38%) <C> (±0.04%) <C> (±0.20%) <C> (±0.20%) <C> (±0.20%) <C> [EMPTY] <R> <C> ELM <C> 1.00% <C> 95.82% <C> 97.38% <C> 97.34% <C> 97.79% <C> 4.30% <R> <C> [EMPTY] <C> (±0.17%) <C> (±0.35%) <C> (±0.18%) <C> (±0.19%) <C> (±0.18%) <C> [EMPTY] <R> <C> Malytics <C> [BOLD] 0.55% <C> [BOLD] 99.20% <C> 99.32% <C> [BOLD] 99.32% <C> [BOLD] 99.96% <C> [BOLD] 0.80% <R> <C> [EMPTY] <C> (±0.23%) <C> (±0.27%) <C> (±0.12%) <C> (±0.11%) <C> (±0.19%) <C> [EMPTY] <R> <C>  <C> 1.00% <C> [BOLD] 99.20% <C> [BOLD] 99.70% <C> − <C> 99.30% <C> − <R> <C> [EMPTY] <C> (±0.00%) <C> (±0.00%) <C> (±0.5%) <C> − <C> (±0.1%) <C> [EMPTY] <R> <C>  <C> 0.80% <C> − <C> 99.10% <C> 99.05% <C> [EMPTY] <C> 1.10% <CAP> TABLE VI: The Mean and Std of Malytics and the baselines for WinPE and Mal2016 of the PEShare Dataset.
<R> <C> [EMPTY] <C> [BOLD] s01 <C> [BOLD] s02 <C> [BOLD] s03 <C> [BOLD] s04 <C> [BOLD] s05 <C> [BOLD] s06 <C> [BOLD] s07 <C> [BOLD] s08 <C> [BOLD] s09 <C> [BOLD] s10 <C> [BOLD] Avg <R> <C> [EMPTY] <C> [ITALIC] ’FPc’ <C> [ITALIC] ’FPc’ <C> [ITALIC] ’FPc’ <C> [ITALIC] ’Mc’ <C> [ITALIC] ’Mc’ <C> [ITALIC] ’Mc’ <C> [ITALIC] ’Mc’ <C> [ITALIC] ’FPc’ <C> [ITALIC] ’FPc’ <C> [ITALIC] ’Mc’ <C> [EMPTY] <R> <C> [BOLD] Entropy <C> [BOLD] 0.83 <C> 0.74 <C> [BOLD] 0.83 <C> 0.83 <C> [BOLD] 0.73 <C> [BOLD] 0.76 <C> 0.75 <C> [BOLD] 0.85 <C> [BOLD] 0.85 <C> [BOLD] 0.82 <C> [BOLD] 0.80 ± 0.05 <R> <C> [BOLD] PSD <C> 0.74 <C> [BOLD] 0.78 <C> 0.80 <C> [BOLD] 0.85 <C> 0.60 <C> 0.69 <C> [BOLD] 0.78 <C> 0.84 <C> 0.82 <C> 0.76 <C> 0.76 ± 0.07 <CAP> Table I: Single sample classification accuracy for each subject in classifying between IC and INC states. Comparison between the proposed entropy-based method and the PSD-based method taken from [17].
<R> <C> [EMPTY] <C> [BOLD] config <C> [BOLD] Single Sample Accuracy [%] <C> [BOLD] Single Trial Accuracy [%] <C> [BOLD] Single Trial Missed [%] <C> [BOLD] Delay [sec] <R> <C> s01 <C> [ITALIC] ’FPc’ <C> 0.78 <C> 0.90 <C> 0.10 <C> 1.5 ± 0.7 <R> <C> s02 <C> [ITALIC] ’FPc’ <C> 0.66 <C> 0.75 <C> 0.20 <C> 1.6 ± 0.8 <R> <C> s03 <C> [ITALIC] ’FPc’ <C> 0.70 <C> 0.75 <C> 0.10 <C> 1.5 ± 1.2 <R> <C> s04 <C> [ITALIC] ’Mc’ <C> 0.82 <C> 0.95 <C> 0.05 <C> 1.5 ± 0.9 <R> <C> s05 <C> [ITALIC] ’Mc’ <C> 0.75 <C> 0.70 <C> 0.25 <C> 1.9 ± 0.4 <R> <C> s06 <C> [ITALIC] ’Mc’ <C> 0.73 <C> 0.80 <C> 0.20 <C> 1.2 ± 1.0 <R> <C> s07 <C> [ITALIC] ’Mc’ <C> 0.78 <C> 0.85 <C> 0.10 <C> 1.5 ± 0.5 <R> <C> s08 <C> [ITALIC] ’FPc’ <C> 0.77 <C> 0.65 <C> 0.20 <C> 2.6 ± 0.6 <R> <C> s09 <C> [ITALIC] ’FPc’ <C> 0.71 <C> 0.65 <C> 0.15 <C> 1.8 ± 0.3 <R> <C> s10 <C> [ITALIC] ’Mc’ <C> 0.69 <C> 0.60 <C> 0.20 <C> 1.7 ± 0.7 <R> <C> Avg <C> [EMPTY] <C> 0.74 ± 0.05 <C> 0.76 ± 0.11 <C> 0.15 ± 0.06 <C> 1.7 ± 0.7 <CAP> Table II: Classification performance for each subject in classifying between INC and IC-cue states.
<R> <C> [BOLD] Env.# <C> [BOLD] Navigation  [BOLD] distance (m) <C> [BOLD] Navigation  [BOLD] time (s) <C> [BOLD] Crash <C> [BOLD] Total  [BOLD] reward <R> <C> [BOLD] Env.1 <C> 60.00 <C> 57 <C> N <C> 12.15 <R> <C> [BOLD] Env.1 <C> 60.00 <C> 57 <C> N <C> 11.89 <R> <C> [BOLD] Env.1 <C> 60.00 <C> 57 <C> N <C> 10.94 <R> <C> [BOLD] Env.1 <C> 60.00 <C> 58 <C> N <C> 12.66 <R> <C> [BOLD] Env.1 <C> 60.00 <C> 57 <C> N <C> 11.51 <R> <C> [BOLD] Env.2 <C> 60.00 <C> 58 <C> N <C> 11.93 <R> <C> [BOLD] Env.2 <C> 60.00 <C> 57 <C> N <C> 12.49 <R> <C> [BOLD] Env.2 <C> 60.00 <C> 58 <C> N <C> 12.43 <R> <C> [BOLD] Env.2 <C> 60.00 <C> 57 <C> N <C> 12.28 <R> <C> [BOLD] Env.2 <C> 60.00 <C> 58 <C> N <C> 11.83 <R> <C> [BOLD] Env.3 <C> 60.00 <C> 58 <C> N <C> 10.35 <R> <C> [BOLD] Env.3 <C> 60.00 <C> 58 <C> N <C> 11.93 <R> <C> [BOLD] Env.3 <C> 60.00 <C> 57 <C> N <C> 12.16 <R> <C> [BOLD] Env.3 <C> 60.00 <C> 58 <C> N <C> 11.96 <R> <C> [BOLD] Env.3 <C> 60.00 <C> 58 <C> N <C> 12.14 <R> <C> [BOLD] Env.4 <C> 60.00 <C> 79 <C> N <C> 3.82 <R> <C> [BOLD] Env.4 <C> 60.00 <C> 71 <C> N <C> 4.44 <R> <C> [BOLD] Env.4 <C> 48.85 <C> 120 <C> N <C> 3.61 <R> <C> [BOLD] Env.4 <C> 29.96 <C> 42 <C> Y <C> 1.32 <R> <C> [BOLD] Env.4 <C> 28.15 <C> 33 <C> Y <C> 1.25 <R> <C> [BOLD] Env.5 <C> 60.00 <C> 78 <C> N <C> 3.41 <R> <C> [BOLD] Env.5 <C> 60.00 <C> 75 <C> N <C> 3.58 <R> <C> [BOLD] Env.5 <C> 60.00 <C> 71 <C> N <C> 3.53 <R> <C> [BOLD] Env.5 <C> 21.35 <C> 28 <C> Y <C> 0.51 <R> <C> [BOLD] Env.5 <C> 48.57 <C> 120 <C> N <C> 3.39 <R> <C> [BOLD] Env.6 <C> 60.00 <C> 61 <C> N <C> 4.85 <R> <C> [BOLD] Env.6 <C> 44.44 <C> 120 <C> N <C> 4.35 <R> <C> [BOLD] Env.6 <C> 60.00 <C> 70 <C> N <C> 4.46 <R> <C> [BOLD] Env.6 <C> 60.00 <C> 61 <C> N <C> 4.74 <R> <C> [BOLD] Env.6 <C> 60.00 <C> 61 <C> N <C> 4.81 <R> <C> [BOLD] Env.7 <C> 50.42 <C> 120 <C> N <C> 3.26 <R> <C> [BOLD] Env.7 <C> 41.51 <C> 58 <C> Y <C> 0.53 <R> <C> [BOLD] Env.7 <C> 15.90 <C> 77 <C> Y <C> 0.14 <R> <C> [BOLD] Env.7 <C> 60.00 <C> 95 <C> N <C> 3.27 <R> <C> [BOLD] Env.7 <C> 47.33 <C> 120 <C> N <C> 3.04 <R> <C> [BOLD] Env.8 <C> 60.00 <C> 59 <C> N <C> 7.69 <R> <C> [BOLD] Env.8 <C> 60.00 <C> 59 <C> N <C> 7.61 <R> <C> [BOLD] Env.8 <C> 45.47 <C> 44 <C> Y <C> 5.82 <R> <C> [BOLD] Env.8 <C> 45.39 <C> 45 <C> Y <C> 4.52 <R> <C> [BOLD] Env.8 <C> 60.00 <C> 58 <C> N <C> 9.01 <R> <C> [BOLD] Env.9 <C> 60.00 <C> 57 <C> N <C> 9.24 <R> <C> [BOLD] Env.9 <C> 60.00 <C> 58 <C> N <C> 9.31 <R> <C> [BOLD] Env.9 <C> 60.00 <C> 57 <C> N <C> 8.78 <R> <C> [BOLD] Env.9 <C> 60.00 <C> 57 <C> N <C> 8.24 <R> <C> [BOLD] Env.9 <C> 60.00 <C> 58 <C> N <C> 8.60 <R> <C> [BOLD] Env.10 <C> 60.00 <C> 61 <C> N <C> 5.35 <R> <C> [BOLD] Env.10 <C> 60.00 <C> 58 <C> N <C> 5.29 <R> <C> [BOLD] Env.10 <C> 60.00 <C> 61 <C> N <C> 4.95 <R> <C> [BOLD] Env.10 <C> 60.00 <C> 60 <C> N <C> 5.35 <R> <C> [BOLD] Env.10 <C> 60.00 <C> 60 <C> N <C> 5.88 <CAP> TABLE I: Evaluative test results in AirSim.
<R> <C> [BOLD] Env.# <C> [BOLD] Navigation  [BOLD] distance (m) <C> [BOLD] Navigation  [BOLD] time (s) <C> [BOLD] Crash <C> [BOLD] Total  [BOLD] reward <R> <C> [BOLD] Env.1 <C> 3.50 <C> 21 <C> N <C> 0.44 <R> <C> [BOLD] Env.1 <C> 3.50 <C> 18 <C> N <C> 0.46 <R> <C> [BOLD] Env.1 <C> 3.50 <C> 21 <C> N <C> 0.44 <R> <C> [BOLD] Env.1 <C> 3.50 <C> 19 <C> N <C> 0.43 <R> <C> [BOLD] Env.1 <C> 3.50 <C> 22 <C> N <C> 0.43 <R> <C> [BOLD] Env.2 <C> 0.65 <C> 30 <C> N <C> 0.34 <R> <C> [BOLD] Env.2 <C> 1.03 <C> 15 <C> Y <C> -0.70 <R> <C> [BOLD] Env.2 <C> 1.55 <C> 30 <C> N <C> 0.32 <R> <C> [BOLD] Env.2 <C> 1.38 <C> 30 <C> N <C> 0.34 <R> <C> [BOLD] Env.2 <C> 0.80 <C> 30 <C> N <C> 0.37 <CAP> TABLE II: Evaluative test results in real flights.
<R> <C> [BOLD] GNG Parameters <C> [BOLD] Device Mode <C> [BOLD] Domain State <R> <C> Max No. of Nodes <C> 10000 <C> 20000 <R> <C> Max. Edge Age <C> 100 <C> 50 <R> <C> Decay Rate: After Split <C> 0.5 <C> 0.3 <R> <C> Decay Rate: Error <C> 0.995 <C> 0.9 <CAP> TABLE I: Hyper-parameters for Growing Neural Gas Clustering.
<R> <C> [BOLD] Method <C> [BOLD] Energy Saved (%) <C> [BOLD] Considers User Behaviour <R> <C> Autonomous Appliance Scheduling for Household Energy Management [12] <C> 10.92 <C> No <R> <C> Intelligent Household LED Lighting System Considering Energy Efficiency and User Satisfaction [13] <C> 21.9 <C> Yes <R> <C> Making Smart Home Smarter: Optimizing Energy Consumption with Human in the Loop <C> 30 <C> Yes <CAP> TABLE II: Comparison between different methods.
<R> <C> Rendering <C> Hospital (Generator) <C> Hospital Game <R> <C> SetPass Calls <C> 106 <C> 136 <R> <C> Draw Calls <C> 252 <C> 298 <R> <C> Total Batches <C> 217 <C> 243 <R> <C> Triangles <C> 463.9K <C> 504.9K <R> <C> Vertices <C> 319.5K <C> 361.1K <CAP> TABLE V: Rendering Results of the Hospital Game Generated by the Scenario-Based Video Game Generator vs. Hospital Game
<R> <C> [EMPTY] <C> Energy 1 basic <C> Energy 1 daily IMD <C> Delay <C> Prog-Mem footprint <R> <C> [EMPTY] <C> session ( [ITALIC] μJ) <C> cycle∗ (J) <C> (ms) <C> (kB) <R> <C> Without security <C> 16.61 <C> 16.60 <C> 2.17 <C> ∼1.00 <R> <C> IMDfence (H/W) <C> 108.31 <C> 17.69 <C> 15.73 <C> 6.86 <R> <C> IMDfence (S/W) <C> 213.50 <C> 19.89 <C> 57.22 <C> 7.86 <R> <C> ∗ Which includes a daily two-minute comm. session (see Section  V-B ) <C> ∗ Which includes a daily two-minute comm. session (see Section  V-B ) <C> ∗ Which includes a daily two-minute comm. session (see Section  V-B ) <C> ∗ Which includes a daily two-minute comm. session (see Section  V-B ) <C> ∗ Which includes a daily two-minute comm. session (see Section  V-B ) <CAP> TABLE IV: Summary of costs for running the IMDfence protocol on an IMD
<R> <C> [BOLD] Section <C> [EMPTY] <C> [BOLD] Description (NewsGuard points) <C> [BOLD] Coloring <R> <C> NewsGuard <C> 1. <C> Does not repeatedly publish false content (22.0) <C> [EMPTY] <R> <C> [EMPTY] <C> 2. <C> Gathers and presents information responsibly (18.0) <C> [EMPTY] <R> <C> [EMPTY] <C> 3. <C> Regularly corrects or clarifies errors (12.5) <C> [EMPTY] <R> <C> [EMPTY] <C> 4. <C> Handles the difference between news and opinion responsibly (12.5) <C> [EMPTY] <R> <C> [EMPTY] <C> 5. <C> Avoids deceptive headlines (10.0) <C> [EMPTY] <R> <C> [EMPTY] <C> 6. <C> Website discloses ownership and financing (7.5) <C> [EMPTY] <R> <C> [EMPTY] <C> 7. <C> Clearly labels advertising (7.5) <C> [EMPTY] <R> <C> [EMPTY] <C> 8. <C> Reveals who’s in charge, including any possible conflicts of interest (5.0) <C> [EMPTY] <R> <C> [EMPTY] <C> 9. <C> Provides information about content creators (5.0) <C> [EMPTY] <R> <C> [EMPTY] <C> 10. <C> Aggregated score computed from 1-9 <C> - <R> <C> [EMPTY] <C> 11. <C> Column 10 thresholded at 60 points <C> [EMPTY] <R> <C> Pew Research Center <C> 12. <C> Trust from consistently-liberals <C> [EMPTY] <R> <C> [EMPTY] <C> 13. <C> Trust from mostly-liberals <C> [EMPTY] <R> <C> [EMPTY] <C> 14. <C> Trust from mixed groups <C> [EMPTY] <R> <C> [EMPTY] <C> 15. <C> Trust from mostly-conservatives <C> [EMPTY] <R> <C> [EMPTY] <C> 16. <C> Trust from consistently-conservatives <C> [EMPTY] <R> <C> [EMPTY] <C> 17. <C> Aggregated trust from 12-16 <C> [EMPTY] <R> <C> Wikipedia <C> 18. <C> Existence of source on Wikipedia’s list of fake news sources <C> [EMPTY] <R> <C> Open Sources <C> 19. <C> Marked reliable <C> [EMPTY] <R> <C> [EMPTY] <C> 20. <C> Marked blog <C> [EMPTY] <R> <C> [EMPTY] <C> 21. <C> Marked clickbait <C> [EMPTY] <R> <C> [EMPTY] <C> 22. <C> Marked rumor <C> [EMPTY] <R> <C> [EMPTY] <C> 23. <C> Marked fake <C> [EMPTY] <R> <C> [EMPTY] <C> 24. <C> Marked unreliable <C> [EMPTY] <R> <C> [EMPTY] <C> 25. <C> Marked biased <C> [EMPTY] <R> <C> [EMPTY] <C> 26. <C> Marked conspiracy <C> [EMPTY] <R> <C> [EMPTY] <C> 27. <C> Marked hate speech <C> [EMPTY] <R> <C> [EMPTY] <C> 28. <C> Marked junk science <C> [EMPTY] <R> <C> [EMPTY] <C> 29. <C> Marked political <C> [EMPTY] <R> <C> [EMPTY] <C> 30. <C> Marked satire <C> [EMPTY] <R> <C> [EMPTY] <C> 31. <C> Marked state news <C> [EMPTY] <R> <C> Media Bias / Fact Check <C> 32. <C> Factual reporting from 5 (good) down to 1 (bad) <C> [EMPTY] <R> <C> [EMPTY] <C> 33. <C> Special label; conspiracy, pseudoscience or questionable source (purple), and satire (orange) <C> [EMPTY] <R> <C> [EMPTY] <C> 34. <C> Political leaning / bias from left to right. <C> [EMPTY] <R> <C> Allsides <C> 35. <C> Political leaning / bias <C> [EMPTY] <R> <C> BuzzFeed <C> 36. <C> Political leaning / bias, but only left and right <C> [EMPTY] <R> <C> PolitiFact <C> 37. <C> Has brought story labelled as ”pants on Fire!” <C> [EMPTY] <R> <C> [EMPTY] <C> 38. <C> Has brought story labelled as false <C> [EMPTY] <R> <C> [EMPTY] <C> 39. <C> Has brought story labelled as mostly false <C> [EMPTY] <R> <C> [EMPTY] <C> 40. <C> Has brought story labelled as half-true <C> [EMPTY] <R> <C> [EMPTY] <C> 41. <C> Has brought story labelled as mostly true <C> [EMPTY] <R> <C> [EMPTY] <C> 42. <C> Has brought story labelled as true <C> [EMPTY] <R> <C> Alexa Ranking <C> [EMPTY] <C> The Alexa ranking of the source. <C> Numerical <R> <C> # Articles <C> [EMPTY] <C> The number of articles collected from the source. <C> Numerical <R> <C> First Observed <C> [EMPTY] <C> The date of first articles collected from the source. <C> dd-mm-yyyy <CAP> Table 1: Details of the information for sources found in tables 2, 3 and 4. We generally use green-to-purple for good-to-poor reliability/credibility, with grey as inconclusive. For bias we use blue-to-red for left-to-right bias, with grey as unbiased. Orange is used for special cases. In NewsGuard data it represents missing information, in Open Sources it marks auxiliary labels and for Media Bias / Fact Check it marks satire.
<R> <C> [EMPTY] <C> Go <C> Stop <R> <C> Yield <C> 18,10 <C> 15,4 <R> <C> Walk <C> -500,-400 <C> 0,5 <R> <C> Cycle <C> -600,-200 <C> 5,5 <CAP> Table I: Normal form of the game in Section III with modified payoffs.
<R> <C> [EMPTY] <C> Canvas <C> Canvas Font <C> WebRTC <C> Audio <R> <C> (a) <C> 8,503 <C> 1,387 <C> 1,313 <C> 534 <R> <C> (b) <C> 8,519 <C> 1,387 <C> 1,313 <C> 170 <R> <C> Similarity <C> 87.00% <C> 100% <C> 100% <C> 31.34% <CAP> Table 3: Number of scripts found using heuristics from (a) Englehardt & Narayanan [12] and (b) Das et al. [30]
<R> <C> [EMPTY] <C> Score <C> 6,000 <C> 10,000 <C> 12,000 <C> 14,000 <R> <C> [EMPTY] <C> n scripts over score <C> 28,978 <C> 18,961 <C> 7,915 <C> 3,434 <R> <C> [EMPTY] <C> % of dataset <C> 7.1% <C> 4.6% <C> 1.9% <C> 0.8% <R> <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [EMPTY] <R> <C> [EMPTY] <C> n in heuristic list <C> 5,962 <C> 5,875 <C> 5,722 <C> 1,476 <R> <C> [EMPTY] <C> % of heuristic list <C> 98.9% <C> 97.5% <C> 94.9% <C> 24.5% <R> <C> fingerprinting <C> fingerprinting <C> fingerprinting <C> fingerprinting <C> fingerprinting <C> [EMPTY] <R> <C> [EMPTY] <C> akam <C> 108 <C> 108 <C> 108 <C> 0 <R> <C> [EMPTY] <C> hs <C> 1,857 <C> 1,857 <C> 0 <C> 0 <R> <C> benign use of canvas <C> benign use of canvas <C> benign use of canvas <C> benign use of canvas <C> benign use of canvas <C> [EMPTY] <R> <C> [EMPTY] <C> charting <C> 151 <C> 104 <C> 87 <C> 87 <R> <C> [EMPTY] <C> modernizr <C> 2,588 <C> 453 <C> 453 <C> 453 <R> <C> [EMPTY] <C> sadbundle <C> 335 <C> 281 <C> 258 <C> 258 <R> <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [EMPTY] <R> <C> [EMPTY] <C> [EMPTY] <C> 17,977 <C> 10,283 <C> [BOLD] 1,287 <C> 1,160 <CAP> Table 4: Validation summary of scripts grouped at selected score thresholds. Uncharacterized scripts from the 12,000 score group were manually reviewed.
<R> <C> [EMPTY] <C> Score <C> 250 <C> 350 <C> 450 <R> <C> [EMPTY] <C> n scripts over score <C> 28,927 <C> 7,305 <C> 4,491 <R> <C> [EMPTY] <C> % of dataset <C> 7.1% <C> 1.8% <C> 1.1% <R> <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <C> [BOLD] Pre-characterize <R> <C> [EMPTY] <C> n in heuristic list <C> 5,929 <C> 5,723 <C> 4,255 <R> <C> [EMPTY] <C> % of heuristic list <C> 98.4% <C> 94.9% <C> 70.6% <R> <C> fingerprinting <C> fingerprinting <C> fingerprinting <C> fingerprinting <C> fingerprinting <R> <C> [EMPTY] <C> akam <C> 108 <C> 108 <C> 108 <R> <C> [EMPTY] <C> hs <C> 1,857 <C> 0 <C> 0 <R> <C> benign use of canvas <C> benign use of canvas <C> benign use of canvas <C> benign use of canvas <C> benign use of canvas <R> <C> [EMPTY] <C> charting <C> 151 <C> 89 <C> 0 <R> <C> [EMPTY] <C> modernizr <C> 2,588 <C> 0 <C> 0 <R> <C> [EMPTY] <C> sadbundle <C> 335 <C> 270 <C> 0 <R> <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <C> [BOLD] Remaining uncharacterized <R> <C> [EMPTY] <C> [EMPTY] <C> 17,959 <C> 1,115 <C> 128 <CAP> Table 5: Validation Table - Summary of scripts flagged by keyword “fingerprint” grouped at selected score thresholds.
<R> <C> Experiment <C> Precision <C> Recall <C> Accuracy <C> F-Score <R> <C> StreamSpot (baseline) <C> 0.74 <C> [EMPTY] <C> 0.66 <C> [EMPTY] <R> <C> [ITALIC] R=1 <C> 0.51 <C> 1.0 <C> 0.60 <C> 0.68 <R> <C> [ITALIC] R=3 <C> 0.98 <C> 0.93 <C> 0.96 <C> 0.94 <CAP> TABLE II: Comparison to StreamSpot on the StreamSpot dataset. We estimate StreamSpot’s average accuracy and precision from the figure included in the paper [manzoor2016fast], which does not report exact values. They did not report recall or F-score.
<R> <C> Experiment <C> # of Test Graphs <C> # of FPs ( [ITALIC] R = 1) <C> # of FPs ( [ITALIC] R = 3) <R> <C> YouTube <C> 25 <C> 14 <C> 0 <R> <C> Gmail <C> 25 <C> 19 <C> 0 <R> <C> Download <C> 25 <C> 25 <C> 2 <R> <C> VGame <C> 25 <C> 20 <C> 0 <R> <C> CNN <C> 25 <C> 18 <C> 0 <CAP> TABLE III: Decomposition of Unicorn’s false positive results of the StreamSpot dataset.
<R> <C> Experiment <C> Precision <C> Recall <C> Accuracy <C> F-Score <R> <C> SC-1 <C> 0.85 <C> 0.96 <C> 0.90 <C> 0.90 <R> <C> SC-2 <C> 0.75 <C> 0.80 <C> 0.77 <C> 0.78 <CAP> TABLE VIII: Experimental results of the supply-chain APT attack scenarios.
<R> <C> Two story building with nonlinear links Partitioned Domain Span: [0.10,1.0 [ITALIC] e04]-[1.0,5.0 [ITALIC] e04] <C> Two story building with nonlinear links Partitioned Domain Span: [0.10,1.0 [ITALIC] e04]-[1.0,5.0 [ITALIC] e04] <C> Two story building with nonlinear links Partitioned Domain Span: [0.10,1.0 [ITALIC] e04]-[1.0,5.0 [ITALIC] e04] <C> Two story building with nonlinear links Partitioned Domain Span: [0.10,1.0 [ITALIC] e04]-[1.0,5.0 [ITALIC] e04] <C> Two story building with nonlinear links Partitioned Domain Span: [0.10,1.0 [ITALIC] e04]-[1.0,5.0 [ITALIC] e04] <R> <C> [EMPTY] <C> Mean RE [BOLD] u <C> Max RE [BOLD] u <C> Mean RE [BOLD] rf <C> Max RE [BOLD] rf <R> <C> Partition A - Speed-up factor: 1.28 <C> Partition A - Speed-up factor: 1.28 <C> Partition A - Speed-up factor: 1.28 <C> Partition A - Speed-up factor: 1.28 <C> Partition A - Speed-up factor: 1.28 <R> <C> Global Basis <C> 3.18% <C> 5.22% <C> 4.84% <C> 7.51% <R> <C> Local Basis <C> 0.43% <C> 0.68% <C> 3.06% <C> 3.90% <R> <C> Entries Interp. <C> 0.40% <C> 0.67% <C> 3.25% <C> 3.73% <R> <C> Coefficients Interp. <C> 0.39% <C> 0.67% <C> 3.28% <C> 3.69% <R> <C> Partition B - Speed-up factor: 1.31 <C> Partition B - Speed-up factor: 1.31 <C> Partition B - Speed-up factor: 1.31 <C> Partition B - Speed-up factor: 1.31 <C> Partition B - Speed-up factor: 1.31 <R> <C> Global Basis <C> 1.96% <C> 5.91% <C> 3.94% <C> 8.28% <R> <C> Local Basis <C> 0.15% <C> 0.33% <C> 1.83% <C> 2.86% <R> <C> Entries Interp. <C> 0.12% <C> 0.30% <C> 1.29% <C> 2.86% <R> <C> Coefficients Interp. <C> 0.12% <C> 0.30% <C> 1.30% <C> 3.06% <CAP> Table 3: The performance of the pROM for the domain partition techniques presented in Figure 1(b). The RErf error of Equation (4.1) with respect to the restoring forces rf is evaluated. The average and max error across the domain is presented along with the speed up factor. The pROM variants compared are described in Table 2.
<R> <C> [BOLD] Test-name <C> [BOLD] P-value <C> [BOLD] Result <R> <C> Block Frequency (m = 100) <C> 0.046169 <C> Succeed <R> <C> Frequency <C> 0.681211 <C> Succeed <R> <C> Cusum (Forward) <C> 0.878529 <C> Succeed <R> <C> Cusum (Reverse) <C> 0.674391 <C> Succeed <R> <C> Long Runs of Ones <C> 0.128851 <C> Succeed <R> <C> Spectral DFT <C> 0.149590 <C> Succeed <R> <C> Rank <C> 0.638151 <C> Succeed <R> <C> Lempel Ziv Complexity <C> 1.000000 <C> Succeed <R> <C> Overlapping Templates (m = 9) <C> 0.120402 <C> Succeed <R> <C> NonOverlapping Templates (m = 9) <C> 0.197506 <C> Succeed <R> <C> Approximate Entropy (m = 10) <C> 0.681211 <C> Succeed <R> <C> Universal (L = 7, Q = 1280) <C> 0.051599 <C> Succeed <R> <C> Random Excursions (x = +1) <C> 0.297235 <C> Succeed <R> <C> Serial (m = 16) <C> 0.343750 <C> Succeed <R> <C> Random Excursions Variant (x = +1) <C> 0.050388 <C> Succeed <R> <C> Runs <C> 0.499889 <C> Succeed <R> <C> Linear Complexity (M = 500) <C> 0.703017 <C> Succeed <CAP> TABLE II: Test results for 1048576 bit strings
<R> <C> [EMPTY] <C> Perceived Fairness Model 1 <C> Perceived Fairness Model 2 <C> Perceived Fairness Model 3 <R> <C> [EMPTY] <C> Coef.(S.E.) <C> Coef.(S.E.) <C> Coef.(S.E.) <R> <C> Unfavorable Outcome <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> vs. Favorable Outcome <C> −1.040∗∗∗ (0.112) <C> [EMPTY] <C> −1.034∗∗∗ (0.111) <R> <C> Biased Treatment <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> vs. Unbiased Treatment <C> [EMPTY] <C> −0.410∗∗∗ (0.119) <C> −0.396∗∗∗ (0.111) <R> <C> Self-expected Pass <C> [EMPTY] <C> [EMPTY] <C> [EMPTY] <R> <C> vs. Self-expected Fail <C> 0.682∗∗∗ (0.127) <C> 0.637∗∗∗ (0.135) <C> 0.655∗∗∗ (0.126) <R> <C> Constant <C> 4.063∗∗∗ (0.122) <C> 3.785∗∗∗ (0.133) <C> 4.278∗∗∗ (0.135) <R> <C> R2 <C> 0.164 <C> 0.059 <C> 0.182 <R> <C> Adjusted R2 <C> 0.161 <C> 0.055 <C> 0.177 <R> <C> [ITALIC] Note: <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <CAP> Table 3: Regression models predicting perceived fairness from (un)favorable outcome to an individual (Model 1), (un)biased treatment across groups (Model 2), and both factors together (Model 3).
<R> <C> [EMPTY] <C> Perceived Fairness Model 1 <C> Perceived Fairness Model 2 <R> <C> [EMPTY] <C> Coef. (S.E.) <C> Coef. (S.E.) <R> <C> Unfavorable Outcome vs. Favorable Outcome <C> −1.041∗∗∗ (0.113) <C> −0.887∗∗∗ (0.258) <R> <C> Biased Treatment vs. Unbiased Treatment <C> −0.395∗∗∗ (0.113) <C> −1.068∗∗∗ (0.257) <R> <C> CS Team vs. Outsourced <C> 0.131 (0.138) <C> −0.614∗ (0.240) <R> <C> CS and HR vs. Outsourced <C> 0.201 (0.137) <C> −0.352 (0.224) <R> <C> Machine Learning vs. Rules <C> 0.138 (0.112) <C> 0.086 (0.189) <R> <C> High Transparency vs. Low Transparency <C> −0.154 (0.114) <C> 0.056 (0.191) <R> <C> Mixed Decision vs. Algorithm-only <C> 0.090 (0.113) <C> 0.220 (0.189) <R> <C> Unfavorable Outcome × CS team <C> [EMPTY] <C> 0.426 (0.272) <R> <C> Unfavorable Outcome × CS and HR <C> [EMPTY] <C> 0.015 (0.273) <R> <C> Unfavorable Outcome × Machine Learning <C> [EMPTY] <C> −0.238 (0.220) <R> <C> Unfavorable Outcome × High Transparency <C> [EMPTY] <C> 0.106 (0.224) <R> <C> Unfavorable Outcome × Mixed Decision <C> [EMPTY] <C> −0.420 (0.221) <R> <C> Biased Treatment × CS team <C> [EMPTY] <C> 0.971∗∗∗ (0.272) <R> <C> Biased Treatment × CS and HR <C> [EMPTY] <C> 1.070∗∗∗ (0.271) <R> <C> Biased Treatment × Machine Learning <C> [EMPTY] <C> 0.343 (0.220) <R> <C> Biased Treatment × High Transparency <C> [EMPTY] <C> −0.486∗ (0.224) <R> <C> Biased Treatment × Mixed Decision <C> [EMPTY] <C> 0.174 (0.221) <R> <C> Self-expected Pass vs. Self-expected Fail <C> 0.659∗∗∗ (0.127) <C> 0.616∗∗∗ (0.125) <R> <C> Constant <C> 4.131∗∗∗ (0.178) <C> 4.438∗∗∗ (0.235) <R> <C> R2 <C> 0.190 <C> 0.235 <R> <C> Adjusted R2 <C> 0.178 <C> 0.210 <R> <C> [ITALIC] Note: <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <CAP> Table 4: Regression models predicting perceived fairness from algorithm outcomes and development procedures. Model 1 shows the main effects, and Model 2 includes interaction terms.
<R> <C> [EMPTY] <C> Perceived Fairness Model 1 <C> Perceived Fairness Model 2 <R> <C> [EMPTY] <C> Coef. (S.E.) <C> Coef. (S.E.) <R> <C> Unfavorable Outcome vs. Favorable Outcome <C> −1.057∗∗∗ (0.115) <C> −1.237 (0.651) <R> <C> Biased Treatment vs. Unbiased Treatment <C> −0.426∗∗∗ (0.114) <C> −1.070 (0.671) <R> <C> Low Literacy vs. High Literacy <C> −0.285∗ (0.117) <C> −0.384 (0.204) <R> <C> Above 45 vs. Between 25-45 <C> −0.142 (0.150) <C> 0.060 (0.271) <R> <C> Below 25 vs. Between 25-45 <C> 0.237 (0.208) <C> 0.069 (0.347) <R> <C> Male vs. Female <C> 0.209 (0.122) <C> −0.019 (0.203) <R> <C> Bachelor’s Degree vs. Above Bachelor’s Degree <C> −0.198 (0.188) <C> 0.070 (0.376) <R> <C> Below Bachelor’s Degree vs. Above Bachelor’s Degree <C> −0.272 (0.189) <C> 0.276 (0.371) <R> <C> Asian vs. Non-asian <C> 0.106 (0.282) <C> 0.031 (0.562) <R> <C> White vs. Non-white <C> −0.119 (0.220) <C> −0.534 (0.501) <R> <C> Black vs. Non-black <C> 0.340 (0.244) <C> −0.103 (0.544) <R> <C> Native American vs. Non-native American <C> 0.218 (0.390) <C> 0.690 (0.926) <R> <C> Hispanic vs. Non-hispanic <C> −0.136 (0.240) <C> −0.770 (0.524) <R> <C> Unfavorable Outcome × Low Literacy <C> [EMPTY] <C> 0.268 (0.240) <R> <C> Unfavorable Outcome × Above 45 <C> [EMPTY] <C> −0.334 (0.307) <R> <C> Unfavorable Outcome × Below 25 <C> [EMPTY] <C> 0.215 (0.423) <R> <C> Unfavorable Outcome × Male <C> [EMPTY] <C> 0.558∗ (0.242) <R> <C> Unfavorable Outcome × Bachelor’s Degree <C> [EMPTY] <C> −0.723 (0.389) <R> <C> Unfavorable Outcome × Below Bachelor’s Degree <C> [EMPTY] <C> −1.144∗∗ (0.393) <R> <C> Unfavorable Outcome × Asian <C> [EMPTY] <C> 0.329 (0.624) <R> <C> Unfavorable Outcome × White <C> [EMPTY] <C> 0.601 (0.533) <R> <C> Unfavorable Outcome × Black <C> [EMPTY] <C> 0.918 (0.584) <R> <C> Unfavorable Outcome × Native American <C> [EMPTY] <C> −0.600 (1.029) <R> <C> Unfavorable Outcome × Hispanic <C> [EMPTY] <C> 0.117 (0.568) <R> <C> Biased Treatment × Low Literacy <C> [EMPTY] <C> −0.034 (0.239) <R> <C> Biased Treatment × Above 45 <C> [EMPTY] <C> −0.097 (0.306) <R> <C> Biased Treatment × Below 25 <C> [EMPTY] <C> 0.135 (0.425) <R> <C> Biased Treatment × Male <C> [EMPTY] <C> −0.097 (0.245) <R> <C> Biased Treatment × Bachelor’s Degree <C> [EMPTY] <C> 0.394 (0.387) <R> <C> Biased Treatment × Below Bachelor’s Degree <C> [EMPTY] <C> 0.181 (0.385) <R> <C> Biased Treatment × Asian <C> [EMPTY] <C> 0.011 (0.631) <R> <C> Biased Treatment × White <C> [EMPTY] <C> 0.452 (0.549) <R> <C> Biased Treatment × Black <C> [EMPTY] <C> 0.063 (0.583) <R> <C> Biased Treatment × Native American <C> [EMPTY] <C> −0.241 (1.030) <R> <C> Biased Treatment × Hispanic <C> [EMPTY] <C> 1.234∗ (0.581) <R> <C> Self-expected Pass vs. Self-expected Fail <C> 0.598∗∗∗ (0.133) <C> 0.562∗∗∗ (0.137) <R> <C> Constant <C> 4.649∗∗∗ (0.319) <C> 4.877∗∗∗ (0.622) <R> <C> R2 <C> 0.220 <C> 0.262 <R> <C> Adjusted R2 <C> 0.200 <C> 0.209 <R> <C> [ITALIC] Note: <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <C> ∗p<0.05; ∗∗p<0.01; ∗∗∗p<0.001 <CAP> Table 5: Regression models predicting perceived fairness from algorithm outcomes and individual differences. Model 1 shows the main effects, and Model 2 includes interaction terms.
<R> <C> Traj. type <C> dCor <C> RV <C> GMCC <R> <C> line 0.01 <C> 0.0006 <C> 0.0 <C> 0.001 <R> <C> line 0.02 <C> 0.02 <C> 0.0 <C> 0.005 <R> <C> line 0.04 <C> 0.01 <C> 0.0 <C> 0.02 <R> <C> circle 0.01 <C> 0.0 <C> 0.0 <C> 0.001 <R> <C> circle 0.02 <C> 0.0 <C> 0.0 <C> 0.002 <R> <C> circle 0.04 <C> 0.0035 <C> 0.0 <C> 0.0039 <CAP> TABLE I: Similarity distance measurements for line and circular trajectories with different noises for distance correlation(dCor), RV coefficient and GMCC
<R> <C> Transf. type <C> dCor <C> RV <C> GMCC <R> <C> rotation <C> 0.0 <C> 0.01 <C> 0.0 <R> <C> scale <C> 0.0 <C> 0.0 <C> 0.0 <R> <C> reflection <C> 0.0 <C> 0.009 <C> 0.0 <R> <C> shear <C> 0.12 <C> 0.18 <C> 0.0 <R> <C> squeeze <C> 0.11 <C> 0.14 <C> 0.0 <CAP> TABLE II: Similarity distance measurements for circular trajectories with different transformations for distance correlation(dCor), RV coefficient and GMCC
<R> <C> Transf. type <C> dCor <C> RV <C> GMCC <R> <C> rotation <C> 0.0 <C> 0.82 <C> 0.0 <R> <C> scale <C> 0.0 <C> 0.0 <C> 0.0 <R> <C> reflection <C> 0.0 <C> 0.819 <C> 0.0 <R> <C> shear <C> 0.007 <C> 0.88 <C> 0.0 <R> <C> squeeze <C> 0.0029 <C> 0.16 <C> 0.0 <CAP> TABLE III: Similarity distance measurements for linear trajectories with different transformations for dCor, RV and GMCC
<R> <C> Transf. type <C> dCor <C> RV <C> GMCC <R> <C> line Vs circle <C> 0.5258 <C> 0.27378 <C> 0.871 <CAP> TABLE IV: Similarity distance measurements for line Vs circle
<R> <C> [ITALIC]  [BOLD] Action <C> [ITALIC]  [BOLD] Usefulness  [BOLD] Me <C> [ITALIC]  [BOLD] Usefulness  [BOLD] Other <C> [ITALIC]  [BOLD] Task Progression <C> [ITALIC]  [BOLD] Mutual Help  [BOLD] Me <C> [ITALIC]  [BOLD] Mutual Help  [BOLD] Other <C> [ITALIC]  [BOLD] Competition  [BOLD] Me <C> [ITALIC]  [BOLD] Competition  [BOLD] Other <R> <C> [ITALIC] GIVE <C> [ITALIC] YES <C> [ITALIC] YES <C> [ITALIC] I am ahead <C> 10 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] YES <C> [ITALIC] YES <C> [ITALIC] We are equal <C> 10 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] YES <C> [ITALIC] YES <C> [ITALIC] I am behind <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] NO <C> [ITALIC] YES <C> [ITALIC] I am ahead <C> 10 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] NO <C> [ITALIC] YES <C> [ITALIC] We are equal <C> 10 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] NO <C> [ITALIC] YES <C> [ITALIC] I am behind <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] YES <C> [ITALIC] NO <C> [ITALIC] I am ahead <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] YES <C> [ITALIC] NO <C> [ITALIC] We are equal <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] YES <C> [ITALIC] NO <C> [ITALIC] I am behind <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] NO <C> [ITALIC] NO <C> [ITALIC] I am ahead <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] NO <C> [ITALIC] NO <C> [ITALIC] We are equal <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] GIVE <C> [ITALIC] NO <C> [ITALIC] NO <C> [ITALIC] I am behind <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] TAKE <C> [ITALIC] YES <C> [ITALIC] YES <C> [ITALIC] I am ahead <C> 0 <C> 0 <C> 5 <C> -5 <R> <C> [ITALIC] TAKE <C> [ITALIC] YES <C> [ITALIC] YES <C> [ITALIC] We are equal <C> 10 <C> 0 <C> 5 <C> -5 <R> <C> [ITALIC] TAKE <C> [ITALIC] YES <C> [ITALIC] YES <C> [ITALIC] I am behind <C> 10 <C> 0 <C> 5 <C> -5 <R> <C> [ITALIC] TAKE <C> [ITALIC] NO <C> [ITALIC] YES <C> [ITALIC] I am ahead <C> 0 <C> 0 <C> 0 <C> -5 <R> <C> [ITALIC] TAKE <C> [ITALIC] NO <C> [ITALIC] YES <C> [ITALIC] We are equal <C> 0 <C> 0 <C> 0 <C> -5 <R> <C> [ITALIC] TAKE <C> [ITALIC] NO <C> [ITALIC] YES <C> [ITALIC] I am behind <C> 0 <C> 0 <C> 0 <C> -5 <R> <C> [ITALIC] TAKE <C> [ITALIC] YES <C> [ITALIC] NO <C> [ITALIC] I am ahead <C> 10 <C> 0 <C> 5 <C> 0 <R> <C> [ITALIC] TAKE <C> [ITALIC] YES <C> [ITALIC] NO <C> [ITALIC] We are equal <C> 10 <C> 0 <C> 5 <C> 0 <R> <C> [ITALIC] TAKE <C> [ITALIC] YES <C> [ITALIC] NO <C> [ITALIC] I am behind <C> 10 <C> 0 <C> 5 <C> 0 <R> <C> [ITALIC] TAKE <C> [ITALIC] NO <C> [ITALIC] NO <C> [ITALIC] I am ahead <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] TAKE <C> [ITALIC] NO <C> [ITALIC] NO <C> [ITALIC] We are equal <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> [ITALIC] TAKE <C> [ITALIC] NO <C> [ITALIC] NO <C> [ITALIC] I am behind <C> 0 <C> 0 <C> 0 <C> 0 <CAP> TABLE I: Rewards attributed to each player based on the action a player performs, whether the letter is useful for them, how is their task progression compared to the other player, and the scoring system.
<R> <C> [BOLD] Plagiarized Code <C> [BOLD] P1’s Similarity Degree <C> [BOLD] P2’s Similarity Degree <R> <C> A <C> 70% <C> 50% <R> <C> B <C> 50% <C> 40% <R> <C> C <C> 60% <C> 95% <CAP> TABLE I: Similarity degrees for illustrating how contradicting plagiarism pairs are selected
<R> <C> [BOLD]  Aspect <C> [BOLD] Occurrences <C> [BOLD] Relationship to Evaluated Approaches <R> <C> Statement order <C> 11 <C> Related to SBA since order is a part of source code structure. <R> <C> Semantic <C> 5 <C> Related to SBA since semantic is preserved based on source code structure. <R> <C> Identifier name <C> 3 <C> Related to ABA since identifier name is a source code characteristic. <R> <C> Structure <C> 2 <C> Obviously related to SBA. <R> <C> Output <C> 1 <C> Related to SBA since output is defined based on source code structure. <R> <C> Line of code <C> 1 <C> Related to ABA since line of code is a source code characteristic. <CAP> TABLE II: Considered aspects while suspecting plagiarism cases
<R> <C> [BOLD] Dataset <C> [BOLD] Dimen- <C> [BOLD] Hilbert <C> [BOLD] Dimensions <C> [BOLD] Reference <C> [BOLD] RDB-tree <R> <C> [BOLD] Dataset <C> [BOLD] sions,  [ITALIC] ν <C> [BOLD] order,  [ITALIC] ω <C> [BOLD] per curve,  [ITALIC] η <C> [BOLD] objects,  [ITALIC] m <C> [BOLD] leaf order, Ω <R> <C> SIFTn <C> 128 <C> 8 <C> 16 <C> 10 <C> 63 <R> <C> Yorck <C> 128 <C> 32 <C> 16 <C> 10 <C> 36 <R> <C> SUN <C> 512 <C> 32 <C> 64 <C> 10 <C> 13 <R> <C> Audio <C> 192 <C> 32 <C> 24 <C> 10 <C> 28 <R> <C> Enron <C> 1369 <C> 16 <C> 37 <C> 10 <C> 18 <R> <C> Glove <C> 100 <C> 32 <C> 10 <C> 10 <C> 40 <CAP> Table 3: RDB-tree leaf order (page size = 4 KB).
<R> <C> [BOLD] Dataset <C> [BOLD] Query  [BOLD] Time (ms) <C> [BOLD] Gain of HD-Index in Query Time over  [BOLD] C2LSH <C> [BOLD] Gain of HD-Index in Query Time over  [BOLD] SRS <C> [BOLD] Gain of HD-Index in Query Time over  [BOLD] Multicurves <C> [BOLD] Gain of HD-Index in Query Time over  [BOLD] QALSH <C> [BOLD] Gain of HD-Index in Query Time over  [BOLD] OPQ <C> [BOLD] Gain of HD-Index in Query Time over  [BOLD] HNSW <C> [BOLD] MAP  [BOLD] @100 <C> [BOLD] Gain of HD-Index in MAP@100 over  [BOLD] C2LSH <C> [BOLD] Gain of HD-Index in MAP@100 over  [BOLD] SRS <C> [BOLD] Gain of HD-Index in MAP@100 over  [BOLD] Multicurves <C> [BOLD] Gain of HD-Index in MAP@100 over  [BOLD] QALSH <C> [BOLD] Gain of HD-Index in MAP@100 over  [BOLD] OPQ <C> [BOLD] Gain of HD-Index in MAP@100 over  [BOLD] HNSW <R> <C> [BOLD] SIFT10K <C> 19.46 <C> 0.06x <C> 0.17x <C> [BOLD] 2.88x <C> 0.20x <C> 0.10x <C> 0.004x <C> 0.98 <C> [BOLD] 2.44x <C> [BOLD] 4.45x <C> 0.98x <C> [BOLD] 1.81x <C> 0.99x <C> 0.98x <R> <C> [BOLD] Audio <C> 44.18 <C> 0.02x <C> 0.88x <C> [BOLD] 2.44x <C> 0.21x <C> 0.02x <C> 0.0007x <C> 0.86 <C> [BOLD] 14.33x <C> [BOLD] 6.61x <C> [BOLD] 3.05x <C> [BOLD] 1.28x <C> 0.98x <C> 0.99x <R> <C> [BOLD] SUN <C> 105.78 <C> 0.12x <C> 0.22x <C> [BOLD] NP <C> 0.15x <C> 0.02x <C> 0.007x <C> 0.69 <C> [BOLD] 3.83x <C> [BOLD] 23.00x <C> [BOLD] NP <C> [BOLD] 1.72x <C> 1.00x <C> 0.88x <R> <C> [BOLD] SIFT1M <C> 25.10 <C> [BOLD] 5.30x <C> [BOLD] 1.56x <C> [BOLD] 22.98x <C> [BOLD] 11.27x <C> 0.05x <C> 0.002x <C> 0.56 <C> [BOLD] 2.80x <C> [BOLD] 28.00x <C> 0.97x <C> [BOLD] 1.19x <C> 1.00x <C> 0.92x <R> <C> [BOLD] Yorck <C> 262.29 <C> 0.27x <C> [BOLD] 27.56x <C> [BOLD] 2.21x <C> [BOLD] 33.54x <C> 0.01x <C> 0.002x <C> 0.39 <C> [BOLD] 1542.51x <C> [BOLD] 39.18x <C> [BOLD] 1.24x <C> [BOLD] 1.01x <C> 1.00x <C> [BOLD] 1.02x <R> <C> [BOLD] SIFT100M <C> 732.04 <C> [BOLD] CR <C> [BOLD] 2.17x <C> [BOLD] 1.73x <C> [BOLD] CR <C> [BOLD] CR <C> [BOLD] CR <C> 0.40 <C> [BOLD] CR <C> [BOLD] 75.72x <C> [BOLD] 1.13x <C> [BOLD] CR <C> [BOLD] CR <C> [BOLD] CR <R> <C> [BOLD] SIFT1B <C> 4855.20 <C> [BOLD] CR <C> [BOLD] DNF <C> [BOLD] CR <C> [BOLD] CR <C> [BOLD] CR <C> [BOLD] CR <C> 0.25 <C> [BOLD] CR <C> [BOLD] DNF <C> [BOLD] CR <C> [BOLD] CR <C> [BOLD] CR <C> [BOLD] CR <R> <C> [BOLD] Enron <C> 242.69 <C> 0.02x <C> 0.06x <C> [BOLD] NP <C> [BOLD] NP <C> 0.06x <C> 0.002x <C> 0.92 <C> [BOLD] 5.12x <C> [BOLD] 12.07x <C> [BOLD] NP <C> [BOLD] NP <C> 0.99x <C> 0.99x <R> <C> [BOLD] Glove <C> 85.20 <C> 0.75x <C> 0.06x <C> [BOLD] 2.6x <C> [BOLD] 2.28x <C> 0.05x <C> 0.0003x <C> 0.24 <C> [BOLD] 8.87x <C> [BOLD] 80.00x <C> [BOLD] 1.26x <C> [BOLD] 1.43x <C> 0.99x <C> 0.31x <CAP> Table 5: Comparison of HD-Index with other techniques. DNF indicates that index construction did not terminate even after running for 20 times the duration of the slowest among the other techniques. CR indicates that index construction crashed due to running out of resources. NP indicates that index construction is not at all possible due to an inherent limitation of the technique.
<R> <C> [BOLD] Data/Compression <C> ZFP <C> ISABELA <C> SZ <C> IDEALEM <R> <C> A6BUS1C1MAG <C> 9.99 <C> 5.57 <C> 16.36 <C> 242.3 <R> <C> A6BUS1L1MAG <C> 6.40 <C> 5.57 <C> 58.15 <C> 120.0 <R> <C> BANK514C1MAG <C> 7.50 <C> 5.56 <C> 14.38 <C> 248.4 <R> <C> BANK514L1MAG <C> 8.00 <C> 5.57 <C> 41.71 <C> 156.5 <R> <C> A6BUS1C1ANG <C> 8.76 <C> 5.36 <C> 67.25 <C> 86.89 <R> <C> A6BUS1L1ANG <C> 8.78 <C> 5.38 <C> 177.4 <C> 84.32 <R> <C> BANK514C1ANG <C> 8.76 <C> 5.36 <C> 59.13 <C> 96.39 <R> <C> BANK514L1ANG <C> 8.78 <C> 5.38 <C> 210.8 <C> 85.05 <CAP> TABLE I: Compression Ratios
<R> <C> [BOLD] Data/Compression A6BUS1C1MAG <C> #1 20618980 <C> ZFP 1493207 <C> ISABELA 20678257 <C> SZ 18423314 <C> IDEALEM 41187683 <C> #2 6.04 <C> ZFP 83.34 <C> ISABELA 6.02 <C> SZ 6.75 <C> IDEALEM 3.02 <R> <C> A6BUS1L1MAG <C> 20325437 <C> 1834458 <C> 20393068 <C> 7768430 <C> 41059933 <C> 6.12 <C> 67.84 <C> 6.10 <C> 16.02 <C> 3.03 <R> <C> BANK514C1MAG <C> 16198077 <C> 10951716 <C> 16829379 <C> 13386853 <C> 41154067 <C> 7.68 <C> 11.36 <C> 7.39 <C> 9.30 <C> 3.02 <R> <C> BANK514L1MAG <C> 17308827 <C> 251624 <C> 17410171 <C> 9991781 <C> 41108185 <C> 7.19 <C> 488.7 <C> 7.15 <C> 12.45 <C> 3.03 <R> <C> A6BUS1C1ANG <C> 21591680 <C> 857406 <C> 22104731 <C> 7493261 <C> 22281503 <C> 5.76 <C> 145.1 <C> 5.63 <C> 16.61 <C> 5.59 <R> <C> A6BUS1L1ANG <C> 622017 <C> 41255 <C> 1509371 <C> 34495 <C> 1112170 <C> 200.1 <C> 3016.3 <C> 82.44 <C> 3607.5 <C> 111.9 <R> <C> BANK514C1ANG <C> 16148705 <C> 1934105 <C> 16811692 <C> 7620889 <C> 17017975 <C> 7.71 <C> 64.33 <C> 7.40 <C> 16.33 <C> 7.31 <R> <C> BANK514L1ANG <C> 1561848 <C> 48359 <C> 2430822 <C> 89356 <C> 1456997 <C> 79.66 <C> 2572.9 <C> 51.19 <C> 1392.4 <C> 85.40 <R> <C> [BOLD] Data/Compression <C> #3 <C> ZFP <C> ISABELA <C> SZ <C> IDEALEM <C> #4 <C> ZFP <C> ISABELA <C> SZ <C> IDEALEM <R> <C> A6BUS1C1MAG <C> 0.27 <C> 0.23 <C> 0.27 <C> 0.28 <C> 0.23 <C> 0.35 <C> 2.14 <C> 0.36 <C> 0.40 <C> 0.48 <R> <C> A6BUS1L1MAG <C> 0.46 <C> 0.71 <C> 0.45 <C> 0.61 <C> 0.45 <C> 0.44 <C> 2.88 <C> 0.46 <C> 1.15 <C> 0.96 <R> <C> BANK514C1MAG <C> 5.64 <C> 7.79 <C> 5.54 <C> 6.26 <C> 5.85 <C> 9.86 <C> 14.98 <C> 9.66 <C> 11.93 <C> 11.54 <R> <C> BANK514L1MAG <C> 0.03 <C> 0.00 <C> 0.03 <C> 0.03 <C> 0.03 <C> 0.04 <C> 2.00 <C> 0.04 <C> 0.07 <C> 0.06 <R> <C> A6BUS1C1ANG <C> 0.91 <C> 19.41 <C> 1.02 <C> 1.80 <C> 0.91 <C> 1.25 <C> 26.55 <C> 1.51 <C> 3.60 <C> 0.87 <R> <C> A6BUS1L1ANG <C> 3.80 <C> 123.3 <C> 7.67 <C> 47.82 <C> 7.63 <C> 9.58 <C> 145.2 <C> 5.75 <C> 172.7 <C> 6.46 <R> <C> BANK514C1ANG <C> 1.53 <C> 10.81 <C> 1.65 <C> 2.17 <C> 1.23 <C> 1.68 <C> 12.31 <C> 1.99 <C> 3.55 <C> 0.97 <R> <C> BANK514L1ANG <C> 2.13 <C> 106.5 <C> 4.84 <C> 23.95 <C> 5.72 <C> 3.85 <C> 124.6 <C> 3.62 <C> 67.31 <C> 4.37 <R> <C> [BOLD] Data/Compression <C> #5 <C> ZFP <C> ISABELA <C> SZ <C> IDEALEM <C> #6 <C> ZFP <C> ISABELA <C> SZ <C> IDEALEM <R> <C> A6BUS1C1MAG <C> 67644 <C> 95868 <C> 60379 <C> 66764 <C> 833079 <C> 0.00 <C> 0.09 <C> 0.00 <C> 0.00 <C> 0.01 <R> <C> A6BUS1L1MAG <C> 32 <C> 37 <C> 28 <C> 33 <C> 686 <C> 0.32 <C> 0.21 <C> 0.32 <C> 0.33 <C> 0.32 <R> <C> BANK514C1MAG <C> 1062126 <C> 1070228 <C> 1079142 <C> 1058476 <C> 2415159 <C> 3.16 <C> 3.16 <C> 3.16 <C> 3.16 <C> 2.80 <R> <C> BANK514L1MAG <C> 39 <C> 251621 <C> 37 <C> 42 <C> 9824 <C> 0.11 <C> 0.00 <C> 0.11 <C> 0.12 <C> 0.12 <R> <C> A6BUS1C1ANG <C> 50755 <C> 67443 <C> 50755 <C> 50834 <C> 27152 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> A6BUS1L1ANG <C> 19880 <C> 19271 <C> 20618 <C> 19447 <C> 25015 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> BANK514C1ANG <C> 45882 <C> 57293 <C> 45882 <C> 45980 <C> 23277 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <R> <C> BANK514L1ANG <C> 19904 <C> 19561 <C> 20569 <C> 19752 <C> 22959 <C> 0 <C> 0 <C> 0 <C> 0 <C> 0 <CAP> TABLE II: Reconstruction Qualities with Six Measures
<R> <C> [ITALIC] t <C> join <C> index/filtering filtering <C> index/filtering serialization <C> verification <C> || [ITALIC] C|| <R> <C> 0.95 <C> 233 <C> 134 <C> 96 <C> 92 <C> 72.7GB <R> <C> 0.9 <C> 2815 <C> 1892 <C> 921 <C> 698 <C> 0.56TB <R> <C> 0.85 <C> 11367 <C> 8935 <C> 2430 <C> 2311 <C> 1.8TB <CAP> TABLE IV: GPU join time decomposition for processing the complete DBLP dataset (in secs)
<R> <C> [EMPTY] <C> 0.95 <C> 0.90 <C> 0.85 <C> 0.80 <C> 0.75 <C> 0.7 <C> 0.65 <C> 0.6 <C> 0.55 <C> 0.5 <R> <C> ALL <C> 1 <C> 1 <C> 0 <C> 1 <C> 2 <C> 3 <C> 4 <C> 4 <C> 5 <C> 3 <R> <C> PPJ <C> 2 <C> 2 <C> 2 <C> 4 <C> 4 <C> 3 <C> 2 <C> 2 <C> 1 <C> 3 <R> <C> GRP <C> 4 <C> 4 <C> 5 <C> 2 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <C> 1 <CAP> TABLE V: Number of datasets in which each algorithm is the best per threshold
<R> <C> [BOLD] Systems <C> [BOLD] Precision@K  [BOLD] (Start) <C> [BOLD] Precision@K  [BOLD] (End) <C> [BOLD] Training time <R> <C> Lightor <C> 0.906 <C> 0.719 <C> 1.06 sec <R> <C> Joint-LSTM <C> 0.629 <C> 0.600 <C> >3 days <CAP> TABLE I: An end-to-end comparison between Lightor and Joint-LSTM.
<R> <C> [EMPTY] <C> [BOLD] N <C> [BOLD] % <R> <C> Nationality <C> [EMPTY] <C> [EMPTY] <R> <C> 1 Portuguese <C> 261 <C> 96.3 <R> <C> Other <C> 10 <C> 3.7 <R> <C> Age <C> [EMPTY] <C> [EMPTY] <R> <C> M (DP) <C> 26.60 (8.628) <C> 26.60 (8.628) <R> <C> Min-Max <C> 18 – 58 <C> 18 – 58 <R> <C> Gender <C> [EMPTY] <C> [EMPTY] <R> <C> Female <C> 149 <C> 55.0 <R> <C> Male <C> 122 <C> 45.0 <R> <C> School level <C> [EMPTY] <C> [EMPTY] <R> <C> High school <C> 77 <C> 28.4 <R> <C> College degree <C> 109 <C> 40.2 <R> <C> Master’s degree <C> 79 <C> 29.2 <R> <C> Ph.D. <C> 6 <C> 2.2 <R> <C> Occupation <C> [EMPTY] <C> [EMPTY] <R> <C> Student <C> 178 <C> 65.7 <R> <C> Student worker <C> 50 <C> 18.5 <R> <C> Worker <C> 37 <C> 13.7 <R> <C> Unemployed <C> 6 <C> 2.2 <CAP> Table 1: Respondents characterization
<R> <C> [EMPTY] <C> [BOLD] N <C> [BOLD] % <R> <C> Workers’ occupation <C> [EMPTY] <C> [EMPTY] <R> <C> Technician <C> 26 <C> 70.3 <R> <C> Management <C> 8 <C> 21.6 <R> <C> Commercial <C> 3 <C> 8.1 <R> <C> Workers’ department* <C> [EMPTY] <C> [EMPTY] <R> <C> Research <C> 9 <C> 25.0 <R> <C> Tourism <C> 9 <C> 25.0 <R> <C> Technician <C> 8 <C> 22.2 <R> <C> Health <C> 5 <C> 13.9 <R> <C> Financial management <C> 3 <C> 8.3 <R> <C> Commercial <C> 2 <C> 5.6 <CAP> Table 2: Workers’ situation
<R> <C> [EMPTY] <C> [BOLD] N <C> [BOLD] % <R> <C> Students’ living area <C> [EMPTY] <C> [EMPTY] <R> <C> Urban <C> 178 <C> 78.1 <R> <C> Rural <C> 50 <C> 21.9 <R> <C> Students’ level objective <C> [EMPTY] <C> [EMPTY] <R> <C> College degree <C> 14 <C> 6.1 <R> <C> Master’s degree <C> 169 <C> 74.1 <R> <C> Ph.D. <C> 45 <C> 19.7 <R> <C> Students’ study area* <C> [EMPTY] <C> [EMPTY] <R> <C> Engineering <C> 110 <C> 48.5 <R> <C> Health <C> 53 <C> 23.3 <R> <C> Sciences <C> 33 <C> 14.5 <R> <C> Economy and management <C> 24 <C> 10.6 <R> <C> Arts and architecture <C> 7 <C> 3.1 <CAP> Table 3: Students’ situation
<R> <C> [EMPTY] <C> [BOLD] N <C> [BOLD] % <R> <C> Difficulty to find a pharmacy <C> [EMPTY] <C> [EMPTY] <R> <C> No <C> 171 <C> 63.1 <R> <C> Yes <C> 100 <C> 36.9 <R> <C> Frequency of searching a pharmacy <C> [EMPTY] <C> [EMPTY] <R> <C> Less than 5 times per month <C> 95 <C> 95.0 <R> <C> Between 5 and 10 times per month <C> 1 <C> 1.0 <R> <C> More than 10 times per month <C> 4 <C> 4.0 <R> <C> Necessity for more information about in-service pharmacies or available drugs <C> [EMPTY] <C> [EMPTY] <R> <C> Never <C> 11 <C> 11.0 <R> <C> Rarely <C> 40 <C> 40.0 <R> <C> Sometimes <C> 38 <C> 38.0 <R> <C> Frequently <C> 10 <C> 10.0 <R> <C> Always <C> 1 <C> 1.0 <R> <C> Use of software to locate pharmacies <C> [EMPTY] <C> [EMPTY] <R> <C> No <C> 46 <C> 46.0 <R> <C> Yes <C> 54 <C> 54.0 <R> <C> Which? <C> [EMPTY] <C> [EMPTY] <R> <C> “Farmácias de serviço” <C> 42 <C> 77.8 <R> <C> “Farmácias portuguesas” <C> 34 <C> 63.0 <R> <C> Other <C> 3 <C> 5.6 <CAP> Table 4: Searching for pharmacies
<R> <C> [EMPTY] <C> [BOLD] N <C> [BOLD] % <R> <C> Difficulty to find drugs in a single pharmacy? <C> [EMPTY] <C> [EMPTY] <R> <C> No <C> 49 <C> 49.0 <R> <C> Yes <C> 51 <C> 51.0 <R> <C> Which? <C> [EMPTY] <C> [EMPTY] <R> <C> sometimes the nearest or open pharmacy does not have all the necessary drugs available <C> 60 <C> 60.0 <R> <C> the need to order unavailable drugs and with it a considerable waiting time <C> 25 <C> 25.0 <R> <C> more difficult to get drugs in a weekend or holiday periods <C> 24 <C> 24.0 <R> <C> it takes a long time to find what the respondents want, and sometimes they have to go to several pharmacies <C> 21 <C> 21.0 <R> <C> software systems are not very explanatory of pharmacy search results or are outdated <C> 15 <C> 15.0 <R> <C> pharmacies unavailability <C> 1 <C> 1.0 <R> <C> Previous contact to a pharmacy? <C> [EMPTY] <C> [EMPTY] <R> <C> No <C> 90 <C> 90.0 <R> <C> Yes <C> 10 <C> 10.0 <CAP> Table 5: Difficulties to find drugs
<R> <C> [EMPTY] <C> [BOLD] N <C> [BOLD] % <R> <C> How to search in applications for a pharmacy?* <C> [EMPTY] <C> [EMPTY] <R> <C> Less or equal to 5km search <C> 27 <C> 27.3 <R> <C> More than 5km search <C> 8 <C> 8.1 <R> <C> Search for all near me <C> 31 <C> 31.3 <R> <C> Less or equal to 3 near me <C> 27 <C> 27.3 <R> <C> More than 3 near me <C> 6 <C> 6.1 <R> <C> Imagine you go to a local pharmacy and, after arriving there, you verify that the same does not have all of their drugs available. What do you do? <C> [EMPTY] <C> [EMPTY] <R> <C> search or inquire about nearby pharmacies to complete the prescription <C> 59 <C> 59.0 <R> <C> give up on going to a new pharmacy and order the necessary drugs, getting on waiting list <C> 32 <C> 32.0 <R> <C> call other nearby pharmacies to see if they have the necessary drugs <C> 20 <C> 20.0 <R> <C> try asking someone for advice on the subject or more information <C> 16 <C> 16.0 <R> <C> Interest in a new system <C> [EMPTY] <C> [EMPTY] <R> <C> Without interest <C> 1 <C> 1.0 <R> <C> Low interest <C> 6 <C> 6.0 <R> <C> Some interest <C> 39 <C> 39.0 <R> <C> High interest <C> 54 <C> 54.0 <CAP> Table 6: Behavior of respondents to find drugs
<R> <C> [EMPTY] <C> [EMPTY] <C> Age Less or equal to 23 <C> Age More than 23 <C> X2 <C> p <R> <C> Difficulty in obtaining drugs <C> Yes <C> 19 <C> 32 <C> 6.763 <C> [BOLD] 0.009 <R> <C> [EMPTY] <C> No <C> 31 <C> 18 <C> [EMPTY] <C> [EMPTY] <R> <C> Interest in a new system <C> Some interest <C> 27 <C> 19 <C> 2.576 <C> 0.108 <R> <C> [EMPTY] <C> High interest <C> 23 <C> 31 <C> [EMPTY] <C> [EMPTY] <R> <C> Necessity of more information <C> Rarely <C> 30 <C> 21 <C> 3.241 <C> 0.072 <R> <C> [EMPTY] <C> Frequently <C> 20 <C> 29 <C> [EMPTY] <C> [EMPTY] <R> <C> Use of location software <C> Yes <C> 24 <C> 30 <C> 1.449 <C> 0.229 <R> <C> [EMPTY] <C> No <C> 26 <C> 20 <C> [EMPTY] <C> [EMPTY] <CAP> Table 7: Influence of age in the respondent opinion
<R> <C> [EMPTY] <C> [EMPTY] <C> Necessity of more information Rarely <C> Necessity of more information Frequently <C> X2 <C> p <R> <C> Difficulty in obtaining drugs <C> Yes <C> 21 <C> 30 <C> 4.019 <C> [BOLD] 0.045 <R> <C> [EMPTY] <C> No <C> 30 <C> 19 <C> [EMPTY] <C> [EMPTY] <CAP> Table 8: Relation between necessity of more information and difficulty to obtain drugs
<R> <C> [EMPTY] <C> [EMPTY] <C> Interest in a new system Some interest <C> Interest in a new system High interest <C> X2 <C> p <R> <C> Difficulty to obtain drugs <C> Yes <C> 15 <C> 36 <C> 11.530 <C> [BOLD] 0.001 <R> <C> [EMPTY] <C> No <C> 31 <C> 18 <C> [EMPTY] <C> [EMPTY] <R> <C> Waste of time to find the necessary drugs <C> Yes <C> 5 <C> 16 <C> 5.270 <C> [BOLD] 0.022 <R> <C> [EMPTY] <C> No <C> 41 <C> 38 <C> [EMPTY] <C> [EMPTY] <R> <C> Sometimes the open pharmacy does not have the needed drugs <C> Yes <C> 21 <C> 39 <C> 7.307 <C> [BOLD] 0.007 <R> <C> [EMPTY] <C> No <C> 25 <C> 15 <C> [EMPTY] <C> [EMPTY] <R> <C> I search or inform myself of nearby pharmacies <C> Yes <C> 20 <C> 39 <C> 8.484 <C> [BOLD] 0.004 <R> <C> [EMPTY] <C> No <C> 26 <C> 15 <C> [EMPTY] <C> [EMPTY] <CAP> Table 9: Factors that influence the interest in a new system
<R> <C> [BOLD] Agent <C> [BOLD] KB Size <C> [BOLD] F1 Score (std.) <R> <C> [ITALIC] Dual Track Manager <C> [EMPTY] <C> 0.79 (0.020) <R> <C> [ITALIC] Baseline I <C> 17 <C> 0.59 (0.030) <R> <C> [ITALIC] Baseline II <C> 17 <C> 0.61 (0.017) <R> <C> [ITALIC] Dual Track Manager <C> [EMPTY] <C> 0.77 (0.025) <R> <C> [ITALIC] Baseline I <C> 26 <C> 0.52 (0.016) <R> <C> [ITALIC] Baseline II <C> 26 <C> 0.66 (0.007) <R> <C> [ITALIC] Dual Track Manager <C> [EMPTY] <C> 0.62 (0.011) <R> <C> [ITALIC] Baseline I <C> 37 <C> 0.47 (0.019) <R> <C> [ITALIC] Baseline II <C> 37 <C> 0.46 (0.022) <CAP> TABLE I: F1 Score of KB Update Given Different KB Sizes
<R> <C> [EMPTY] <C> Q1 <C> Q2 <C> Q3 <C> Q4 <R> <C> Our dialog agent <C> 3.42 <C> 2.50 <C> [BOLD] 1.50 <C> [BOLD] 2.50 <R> <C> A baseline agent with static KB <C> 3.33 <C> 1.83 <C> 2.17 <C> 1.75 <CAP> TABLE II: Results of the human participant experiment.
<R> <C> Hyperparameters <C> Classification <C> Regression <R> <C> number of trees <C> 1000 <C> 1000 <R> <C> maximum depth of the trees <C> 2 <C> 2 <R> <C> best split max features <C> √number of features <C> 13(number of features) <CAP> TABLE III: Hyperparameters of the Random Forest models
<R> <C> [BOLD] Model <C> [BOLD] Group 1  [BOLD] Male <C> [BOLD] Group 1  [BOLD] Female <C> [BOLD] Group 2  [BOLD] Male <C> [BOLD] Group 2  [BOLD] Female <C>  [BOLD] Group 3   [BOLD] Male <C>  [BOLD] Group 3   [BOLD] Female <R> <C> VGG-Face <C> 7.99 <C> 9.38 (↑17%) <C> 12.03 (↑50%) <C> 13.95 (↑76%) <C> 18.43 (↑131%) <C> 23.66 (↑196%) <R> <C> ResNet-50 <C> 1.60 <C> 1.96 (↑22%) <C> 2.15 (↑34%) <C> 3.61 (↑126%) <C> 3.25 (↑103%) <C> 5.07 (↑217%) <CAP> Table 1: Performance (False Match Rate in % @ False Non-Match Rate = 0.1%) of Face Recognition Models on the DiveFace dataset. We show in brackets the relative error growth rates with respect to the best class (Group 1 Male).
<R> <C> DoH Server <C> Location <C> Ping (ms) <C> Resolution (ms) <R> <C> cloudflare-dns.com <C> anycast <C> 3.14 <C> 300 <R> <C> commons.host <C> anycast <C> 3.99 <C> 310 <R> <C> dns.google <C> anycast <C> 2.93 <C> 312 <R> <C> mozilla.cloudflare-dns.com <C> anycast <C> 3.19 <C> 314 <R> <C> doh.dnswarden.com <C> DE <C> 87.50 <C> 327 <R> <C> doh.powerdns.org <C> NL <C> 77.90 <C> 331 <R> <C> doh.securedns.eu <C> NL <C> 85.30 <C> 335 <R> <C> doh.li <C> UK <C> 74.90 <C> 335 <R> <C> doh.appliedprivacy.net <C> AT <C> 96.60 <C> 342 <R> <C> doh.42l.fr <C> FR <C> 76.20 <C> 343 <R> <C> dns.dnsoverhttps.net <C> US <C> 73.00 <C> 343 <R> <C> dns.aa.net.uk <C> UK <C> 71.40 <C> 344 <R> <C> doh.xfinity.com <C> US <C> 23.53 <C> 347 <R> <C> dns.containerpi.com <C> JP <C> 162.10 <C> 347 <R> <C> doh.opendns.com <C> anycast <C> 3.90 <C> 355 <R> <C> jcdns.fun <C> NL <C> 85.23 <C> 358 <R> <C> rdns.faelix.net <C> anycast <C> 82.70 <C> 358 <R> <C> dns.hostux.net <C> LU <C> 81.60 <C> 364 <R> <C> dohdot.coxlab.net <C> US <C> [EMPTY] <C> 376 <R> <C> doh-2.seby.io <C> AU <C> [EMPTY] <C> 377 <R> <C> dns.twnic.tw <C> TW <C> 230.00 <C> 380 <R> <C> doh.dns.sb <C> anycast <C> 3.20 <C> 388 <R> <C> ibksturm.synology.me <C> CH <C> 105.80 <C> 416 <R> <C> jp.tiarap.org <C> anycast <C> 3.28 <C> 421 <R> <C> ibuki.cgnat.net <C> BR <C> 137.10 <C> 426 <R> <C> dns.dns-over-https.com <C> JP <C> [EMPTY] <C> 452 <CAP> TABLE I: Geographical location information of the 26 DoH recursors and the median of their resolution time.
<R> <C> system parameters <C> system parameters <C> system parameters <C> algorithm parameters <C> algorithm parameters <R> <C> maximum <C> minimum <C> churn <C> [ITALIC] join_ [ITALIC] bound <C> [ITALIC] rw_ [ITALIC] bound <R> <C> failures <C> system <C> rate <C> fraction <C> fraction <R> <C> ( [ITALIC] f) <C> size ( [ITALIC] NSmin) <C> ( [ITALIC] α) <C> ( [ITALIC] γ) <C> ( [ITALIC] β) <R> <C> 1 <C> 8 <C> 0 <C> [EMPTY] <C> 0.86 <R> <C> 1 <C> 10 <C> 0.01 <C> 0.82 <C> 0.84 <R> <C> 1 <C> 13 <C> 0.02 <C> 0.79 <C> 0.80 <R> <C> 1 <C> 190 <C> 0.05 <C> 0.79 <C> 0.80 <R> <C> 2 <C> 19 <C> 0.01 <C> 0.80 <C> 0.83 <R> <C> 2 <C> 24 <C> 0.02 <C> 0.81 <C> 0.82 <R> <C> 2 <C> 347 <C> 0.05 <C> 0.70 <C> 0.77 <R> <C> 5 <C> 44 <C> 0.01 <C> 0.80 <C> 0.83 <R> <C> 5 <C> 57 <C> 0.02 <C> 0.79 <C> 0.82 <R> <C> 5 <C> 826 <C> 0.05 <C> 0.79 <C> 0.82 <R> <C> 10 <C> 85 <C> 0.01 <C> 0.80 <C> 0.83 <R> <C> 10 <C> 113 <C> 0.02 <C> 0.79 <C> 0.82 <R> <C> 10 <C> 1630 <C> 0.05 <C> 0.79 <C> 0.82 <R> <C> 100 <C> 838 <C> 0.01 <C> 0.79 <C> 0.82 <R> <C> 100 <C> 1107 <C> 0.02 <C> 0.79 <C> 0.82 <R> <C> 100 <C> 16015 <C> 0.05 <C> 0.79 <C> 0.82 <R> <C> 1000 <C> 8360 <C> 0.01 <C> 0.79 <C> 0.82 <R> <C> 1000 <C> 11042 <C> 0.02 <C> 0.79 <C> 0.82 <R> <C> 1000 <C> 159935 <C> 0.05 <C> 0.79 <C> 0.82 <CAP> TABLE I: Values for the parameters that satisfy constraints (1)–(7).
<R> <C> Surface <C> # vertices <C> SCP  Time (s) <C> SCP  mean(| [ITALIC] d|) <C> CETM  Time (s) <C> CETM  mean(| [ITALIC] d|) <C> PGCP Time (s) <C> PGCP mean(| [ITALIC] d|) <R> <C> Sophie <C> 21K <C> 1.1 <C> 0.2 <C> 1.2 <C> 0.2 <C> 0.6 <C> 0.2 <R> <C> Niccolò da Uzzano <C> 25K <C> 1.3 <C> 0.6 <C> Failed <C> Failed <C> 0.7 <C> 0.6 <R> <C> Mask <C> 32K <C> 1.6 <C> 0.2 <C> 7.3 <C> 0.2 <C> 0.9 <C> 0.2 <R> <C> Max Planck <C> 50K <C> 2.6 <C> 0.5 <C> 5.5 <C> 0.5 <C> 1.5 <C> 0.5 <R> <C> Bunny <C> 85K <C> 4.4 <C> 0.5 <C> 18.8 <C> 0.5 <C> 2.0 <C> 0.5 <R> <C> Julius <C> 220K <C> 14.2 <C> 0.1 <C> 19.5 <C> 0.1 <C> 6.6 <C> 0.1 <R> <C> Buddha <C> 240K <C> 13.7 <C> 0.6 <C> 49.0 <C> 0.6 <C> 9.2 <C> 0.6 <R> <C> Face <C> 1M <C> 85.2 <C> <0.1 <C> 98.1 <C> <0.1 <C> 47.6 <C> <0.1 <CAP> Table 1: The performance of spectral conformal parameterization (SCP) [17], conformal equivalence of triangle meshes (CETM) [18] and PGCP for free-boundary conformal parameterization of simply-connected open surfaces.
<R> <C> Surface <C> # vertices <C> LDM  Time (s) <C> LDM  mean(| [ITALIC] d|) <C> CEM  Time (s) <C> CEM  mean(| [ITALIC] d|) <C> PGCP Time (s) <C> PGCP mean(| [ITALIC] d|) <R> <C> Ogre <C> 20K <C> 1.1 <C> 1.5 <C> 0.3 <C> 2.6 <C> 0.5 <C> 1.5 <R> <C> Niccolò da Uzzano <C> 25K <C> 1.6 <C> 0.8 <C> 1.4 <C> 1.3 <C> 0.8 <C> 0.8 <R> <C> Brain <C> 48K <C> 2.9 <C> 1.6 <C> 2.9 <C> 1.5 <C> 1.3 <C> 1.5 <R> <C> Gargoyle <C> 50K <C> 3.1 <C> 1.9 <C> 2.8 <C> 2.1 <C> 1.4 <C> 1.9 <R> <C> Hand <C> 53K <C> 3.4 <C> 1.2 <C> 3.4 <C> 1.2 <C> 1.4 <C> 1.2 <R> <C> Octopus <C> 150K <C> 15.4 <C> 7.2 <C> 10.4 <C> 24.0 <C> 8.9 <C> 5.6 <R> <C> Buddha <C> 240K <C> 22.4 <C> 0.7 <C> 25.1 <C> 0.7 <C> 11.4 <C> 0.7 <R> <C> Nefertiti <C> 1M <C> 87.9 <C> 2.9 <C> 83.2 <C> 4.2 <C> 52.7 <C> 2.9 <CAP> Table 2: The performance of linear disk conformal map (LDM) [25], conformal energy minimization (CEM) [26] and PGCP for disk conformal parameterization of simply-connected open surfaces.
<R> <C> Surface <C> # vertices <C> FFGCM  Time (s) <C> FFGCM  mean( [ITALIC] d) <C> FLASH  Time (s) <C> FLASH  mean( [ITALIC] d) <C> PGCP Time (s) <C> PGCP mean( [ITALIC] d) <R> <C> Horse <C> 20K <C> 12.1 <C> 11.0 <C> 0.4 <C> 3.0 <C> 0.4 <C> 2.7 <R> <C> Bulldog <C> 50K <C> 22.0 <C> 1.0 <C> 0.9 <C> 1.1 <C> 1.0 <C> 1.0 <R> <C> Chinese Lion <C> 50K <C> 29.3 <C> 1.3 <C> 1.1 <C> 1.3 <C> 1.1 <C> 1.3 <R> <C> Duck <C> 100K <C> 100.4 <C> 1.1 <C> 2.2 <C> 0.4 <C> 2.4 <C> 0.3 <R> <C> David <C> 130K <C> 46.6 <C> 0.2 <C> 3.5 <C> 0.2 <C> 3.4 <C> 0.2 <R> <C> Octopus <C> 150K <C> 112.3 <C> 37.2 <C> 10.1 <C> 6.9 <C> 7.1 <C> 2.6 <R> <C> Lion Vase <C> 210K <C> 222.7 <C> 14.4 <C> 4.5 <C> 0.8 <C> 4.7 <C> 0.7 <R> <C> Asian Dragon <C> 1M <C> Failed <C> Failed <C> 64.4 <C> 1.3 <C> 48.5 <C> 0.9 <CAP> Table 3: The performance of folding-free global conformal mapping (FFGCM) [30], FLASH [31] and PGCP for spherical conformal parameterization of genus-0 closed surfaces.
<R> <C> Parameterization <C> Surface <C> # vertices <C> BFF  Time (s) <C> BFF  mean(| [ITALIC] d|) <C> PGCP Time (s) <C> PGCP mean(| [ITALIC] d|) <R> <C> Free-boundary <C> Sophie <C> 21K <C> 0.9 <C> 0.2 <C> 0.6 <C> 0.2 <R> <C> Free-boundary <C> Niccolò da Uzzano <C> 25K <C> 1.0 <C> 0.5 <C> 0.7 <C> 0.6 <R> <C> Free-boundary <C> Mask <C> 32K <C> 1.3 <C> 0.2 <C> 0.9 <C> 0.2 <R> <C> Free-boundary <C> Max Planck <C> 50K <C> 3.0 <C> 0.5 <C> 1.5 <C> 0.5 <R> <C> Free-boundary <C> Bunny <C> 85K <C> 4.7 <C> 1.2 <C> 2.0 <C> 0.5 <R> <C> Free-boundary <C> Julius <C> 220K <C> 16.8 <C> 0.1 <C> 6.6 <C> 0.1 <R> <C> Free-boundary <C> Buddha <C> 240K <C> 14.4 <C> 0.6 <C> 9.2 <C> 0.6 <R> <C> Free-boundary <C> Face <C> 1M <C> Failed <C> Failed <C> 47.6 <C> <0.1 <R> <C> Disk-boundary <C> Ogre <C> 20K <C> 0.7 <C> 1.5 <C> 0.5 <C> 1.5 <R> <C> Disk-boundary <C> Niccolò da Uzzano <C> 25K <C> 1.0 <C> 1.1 <C> 0.8 <C> 0.8 <R> <C> Disk-boundary <C> Brain <C> 48K <C> 2.4 <C> 1.6 <C> 1.3 <C> 1.5 <R> <C> Disk-boundary <C> Gargoyle <C> 50K <C> 2.1 <C> 1.9 <C> 1.4 <C> 1.9 <R> <C> Disk-boundary <C> Hand <C> 53K <C> 2.6 <C> 1.6 <C> 1.4 <C> 1.2 <R> <C> Disk-boundary <C> Octopus <C> 150K <C> 5.5 <C> 24.7 <C> 8.9 <C> 5.6 <R> <C> Disk-boundary <C> Buddha <C> 240K <C> 14.5 <C> 0.9 <C> 11.4 <C> 0.7 <R> <C> Disk-boundary <C> Nefertiti <C> 1M <C> Failed <C> Failed <C> 52.7 <C> 2.9 <R> <C> Spherical <C> Horse <C> 20K <C> 1.0 <C> 74.52 <C> 0.4 <C> 2.7 <R> <C> Spherical <C> Bulldog <C> 50K <C> 3.1 <C> 11.5 <C> 1.0 <C> 1.0 <R> <C> Spherical <C> Chinese Lion <C> 50K <C> 3.0 <C> 4.4 <C> 1.1 <C> 1.3 <R> <C> Spherical <C> Duck <C> 100K <C> 7.6 <C> 5.7 <C> 2.4 <C> 0.3 <R> <C> Spherical <C> David <C> 130K <C> 15.9 <C> 2.6 <C> 3.4 <C> 0.2 <R> <C> Spherical <C> Octopus <C> 150K <C> 10.2 <C> 74.3 <C> 7.1 <C> 2.6 <R> <C> Spherical <C> Lion Vase <C> 210K <C> 14.2 <C> 4.9 <C> 4.7 <C> 0.7 <R> <C> Spherical <C> Asian Dragon <C> 1M <C> Failed <C> Failed <C> 48.5 <C> 0.9 <CAP> Table 4: Comparison between BFF [56] and PGCP for free-boundary conformal parameterization for simply-connected open surfaces, disk conformal parameterization for simply-connected open surfaces, and spherical conformal parameterization for genus-0 closed surfaces.
<R> <C> Surface <C> Cut paths <C> mean(| [ITALIC] d|) <C> sd(| [ITALIC] d|) <C> median(| [ITALIC] d|) <C> iqr(| [ITALIC] d|) <R> <C> Face <C> Figure  12  (top, leftmost) <C> 0.25 <C> 0.44 <C> 0.13 <C> 0.23 <R> <C> Face <C> Figure  12  (top, second left) <C> 0.26 <C> 0.44 <C> 0.16 <C> 0.24 <R> <C> Face <C> Figure  12  (top, second right) <C> 0.24 <C> 0.44 <C> 0.12 <C> 0.24 <R> <C> Face <C> Figure  12  (top, rightmost) <C> 0.26 <C> 0.44 <C> 0.15 <C> 0.25 <R> <C> Bunny <C> Figure  12  (middle, leftmost) <C> 0.49 <C> 0.70 <C> 0.33 <C> 0.48 <R> <C> Bunny <C> Figure  12  (middle, second left) <C> 0.49 <C> 0.70 <C> 0.33 <C> 0.48 <R> <C> Bunny <C> Figure  12  (middle, second right) <C> 0.49 <C> 0.70 <C> 0.33 <C> 0.48 <R> <C> Bunny <C> Figure  12  (middle, rightmost) <C> 0.49 <C> 0.70 <C> 0.33 <C> 0.49 <R> <C> Duck <C> Figure  12  (bottom, leftmost) <C> 0.27 <C> 0.46 <C> 0.16 <C> 0.27 <R> <C> Duck <C> Figure  12  (bottom, second left) <C> 0.27 <C> 0.46 <C> 0.16 <C> 0.27 <R> <C> Duck <C> Figure  12  (bottom, second right) <C> 0.28 <C> 0.48 <C> 0.17 <C> 0.30 <R> <C> Duck <C> Figure  12  (bottom, rightmost) <C> 0.27 <C> 0.47 <C> 0.16 <C> 0.27 <CAP> Table 5: The performance of our proposed PGCP method with different choices of cut paths. The mean, standard deviation, median, and interquartile range of the absolute angular distortion |d| are evaluated.
<R> <C> # of subdomains  [ITALIC] n <C> 2 <C> 3 <C> 4 <C> 5 <C> 6 <R> <C> Average mesh size |V|/ [ITALIC] n <C> 42K <C> 28K <C> 21K <C> 17K <C> 14K <R> <C> Parallel speedup  [ITALIC] Sn <C> 1 <C> 1.31 <C> 1.66 <C> 1.91 <C> 2.05 <R> <C> [ITALIC] n/2 <C> 1 <C> 1.5 <C> 2 <C> 2.5 <C> 3 <R> <C> Parallel efficiency  [ITALIC] En <C> 1 <C> 0.87 <C> 0.83 <C> 0.76 <C> 0.68 <CAP> Table 6: The performance of our proposed PGCP method for parameterizing the bunny model, with different number of subdomains used. Note that the welding algorithm requires at least two subdomains and hence we use n=2 as the baseline. For this reason, we define the parallel speedup to be Sn=T2Tn where Ti is the time taken with i subdomains used, and the parallel efficiency to be En=Snn/2.